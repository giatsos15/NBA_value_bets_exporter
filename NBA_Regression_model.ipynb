{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f2a745b",
      "metadata": {},
      "source": [
        "## NBA Analytics and Betting Value Analysis Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "07decdf1",
      "metadata": {
        "id": "07decdf1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For data analysis\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "01631fd1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching NBA betting data and lineups...\n",
            "Successfully fetched RAW odds rows: 1695 | columns: 263\n",
            "Successfully fetched lineups for 0 games\n",
            "Data successfully saved to nba_betting_data_20251102_204000.xlsx\n",
            "\n",
            "==================================================\n",
            "NBA BETTING DATA SUMMARY\n",
            "==================================================\n",
            "\n",
            "Betting Lines: 0 player-stat combinations\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "class NBAOddsAndLineupsScraper:\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.setup_headers()\n",
        "    \n",
        "    def setup_headers(self):\n",
        "        \"\"\"Setup common headers for requests\"\"\"\n",
        "        self.headers = {\n",
        "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "            'accept-language': 'en-US,en;q=0.9',\n",
        "            'cache-control': 'max-age=0',\n",
        "            'priority': 'u=0, i',\n",
        "            'referer': 'https://www.rotowire.com/',\n",
        "            'sec-ch-ua': '\"Chromium\";v=\"130\", \"Google Chrome\";v=\"130\", \"Not?A_Brand\";v=\"99\"',\n",
        "            'sec-ch-ua-mobile': '?0',\n",
        "            'sec-ch-ua-platform': '\"Windows\"',\n",
        "            'sec-fetch-dest': 'document',\n",
        "            'sec-fetch-mode': 'navigate',\n",
        "            'sec-fetch-site': 'same-origin',\n",
        "            'sec-fetch-user': '?1',\n",
        "            'upgrade-insecure-requests': '1',\n",
        "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36'\n",
        "        }\n",
        "\n",
        "    # --------- RAW WIDE ODDS (no aggregation) ---------------------------------\n",
        "    def get_player_props_odds_wide_raw(self, book='mgm'):\n",
        "        \"\"\"\n",
        "        Return the raw 'wide' odds table by scraping Rotowire's player-props page.\n",
        "        This preserves columns like:\n",
        "          name, team, opp, <book>_pts, <book>_ptsUnder, <book>_ptsOver, ...\n",
        "        Works across many books present in the page JSON blocks.\n",
        "        \"\"\"\n",
        "        url = f\"https://www.rotowire.com/betting/nba/player-props.php?book={book}\"\n",
        "        try:\n",
        "            r = self.session.get(url, headers=self.headers)\n",
        "            r.raise_for_status()\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to GET odds page: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Extract ALL JSON lists assigned to \"data:\" in the page\n",
        "        matches = re.findall(r\"data:\\s*(\\[\\{.*?\\}\\])\", r.text, flags=re.DOTALL)\n",
        "        frames = []\n",
        "        for m in matches:\n",
        "            try:\n",
        "                rows = json.loads(m)\n",
        "                if isinstance(rows, list) and rows:\n",
        "                    frames.append(pd.DataFrame(rows))\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        if not frames:\n",
        "            print(\"No odds JSON blocks found.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.concat(frames, ignore_index=True)\n",
        "        # keep the most useful id/basic columns if present\n",
        "        base_cols = [c for c in [\"name\",\"gameID\",\"playerID\",\"firstName\",\"lastName\",\"team\",\"opp\",\"logo\",\"playerLink\"] if c in df.columns]\n",
        "        other_cols = [c for c in df.columns if c not in base_cols]\n",
        "        df = df[base_cols + other_cols]\n",
        "        # normalize team/opponent field names\n",
        "        if \"opp\" in df.columns and \"opponent\" not in df.columns:\n",
        "            df = df.rename(columns={\"opp\": \"opponent\"})\n",
        "        # add as-of date and (best-guess) game_date if not present\n",
        "        df[\"asof_date\"] = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "        if \"game_date\" not in df.columns:\n",
        "            df[\"game_date\"] = df[\"asof_date\"]\n",
        "        print(f\"Successfully fetched RAW odds rows: {len(df)} | columns: {len(df.columns)}\")\n",
        "        return df\n",
        "\n",
        "    # --------- Legacy aggregated method (kept in case you still call it) ------\n",
        "    def get_player_props_odds(self, book='mgm'):\n",
        "        \"\"\"\n",
        "        Old helper that aggregated rows by 'name'.\n",
        "        Prefer get_player_props_odds_wide_raw() for modeling/joins.\n",
        "        \"\"\"\n",
        "        wide = self.get_player_props_odds_wide_raw(book=book)\n",
        "        if wide.empty:\n",
        "            return None\n",
        "        aggregated_df = wide.groupby('name', as_index=False, sort=False).agg(\n",
        "            lambda x: ', '.join(pd.Series(x).dropna().astype(str).unique())\n",
        "        )\n",
        "        aggregated_df = aggregated_df.dropna(axis=1, how='all')\n",
        "        print(f\"Successfully aggregated odds for {len(aggregated_df)} players\")\n",
        "        return aggregated_df\n",
        "\n",
        "    # --------- Lineups scraping (unchanged logic, made a bit sturdier) --------\n",
        "    def get_expected_lineups(self):\n",
        "        \"\"\"Get expected lineups from Rotowire\"\"\"\n",
        "        url = \"https://www.rotowire.com/basketball/nba-lineups.php\"\n",
        "        try:\n",
        "            r = self.session.get(url, headers=self.headers)\n",
        "            r.raise_for_status()\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to retrieve lineup page: {e}\")\n",
        "            return None\n",
        "\n",
        "        soup = BeautifulSoup(r.content, 'html.parser')\n",
        "        game_containers = soup.find_all('div', class_='lineup__main')\n",
        "        if not game_containers:\n",
        "            print(\"No lineup data found\")\n",
        "            return None\n",
        "\n",
        "        lineups_data = []\n",
        "        for game in game_containers:\n",
        "            game_info = self._parse_game_info(game)\n",
        "            if game_info:\n",
        "                lineups_data.append(game_info)\n",
        "\n",
        "        print(f\"Successfully fetched lineups for {len(lineups_data)} games\")\n",
        "        return lineups_data\n",
        "\n",
        "    def _parse_game_info(self, game_container):\n",
        "        \"\"\"Parse individual game information and lineups\"\"\"\n",
        "        try:\n",
        "            game_data = {}\n",
        "            header = game_container.find('div', class_='lineup__hdr')\n",
        "            if header:\n",
        "                teams = header.find_all('div', class_='lineup__team')\n",
        "                if len(teams) >= 2:\n",
        "                    game_data['away_team'] = teams[0].get_text(strip=True)\n",
        "                    game_data['home_team'] = teams[1].get_text(strip=True)\n",
        "            time_info = header.find('div', class_='lineup__time') if header else None\n",
        "            if time_info:\n",
        "                game_data['game_time'] = time_info.get_text(strip=True)\n",
        "            lineup_containers = game_container.find_all('div', class_='lineup__box')\n",
        "            if len(lineup_containers) >= 2:\n",
        "                game_data['away_starters'] = self._parse_team_lineup(lineup_containers[0])\n",
        "                game_data['home_starters'] = self._parse_team_lineup(lineup_containers[1])\n",
        "            return game_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing game info: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _parse_team_lineup(self, team_container):\n",
        "        \"\"\"Parse individual team lineup\"\"\"\n",
        "        starters = []\n",
        "        try:\n",
        "            starters_section = team_container.find('div', class_='lineup__list')\n",
        "            if starters_section:\n",
        "                player_elements = starters_section.find_all('div', class_='lineup__player')\n",
        "                for player_elem in player_elements:\n",
        "                    player_info = self._parse_player_info(player_elem)\n",
        "                    if player_info:\n",
        "                        starters.append(player_info)\n",
        "            return starters\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing team lineup: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _parse_player_info(self, player_elem):\n",
        "        \"\"\"Parse individual player information\"\"\"\n",
        "        try:\n",
        "            player_data = {}\n",
        "            name_elem = player_elem.find('a', class_='lineup__player-link')\n",
        "            if name_elem:\n",
        "                player_data['name'] = name_elem.get_text(strip=True)\n",
        "                player_data['player_link'] = name_elem.get('href', '')\n",
        "            pos_elem = player_elem.find('span', class_='lineup__pos')\n",
        "            if pos_elem:\n",
        "                player_data['position'] = pos_elem.get_text(strip=True)\n",
        "            injury_elem = player_elem.find('span', class_='lineup__inj')\n",
        "            player_data['injury_status'] = injury_elem.get_text(strip=True) if injury_elem else 'Active'\n",
        "            confirmed_elem = player_elem.find('span', class_='lineup__confirm')\n",
        "            player_data['confirmed_starter'] = confirmed_elem is not None\n",
        "            return player_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing player info: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_comprehensive_data(self):\n",
        "        \"\"\"Get both odds and lineups data\"\"\"\n",
        "        print(\"Fetching NBA betting data and lineups...\")\n",
        "        odds_data = self.get_player_props_odds_wide_raw()  # <-- use RAW wide\n",
        "        lineups_data = self.get_expected_lineups()\n",
        "        combined_data = {\n",
        "            'odds': odds_data,\n",
        "            'lineups': lineups_data,\n",
        "            'last_updated': datetime.now().isoformat()\n",
        "        }\n",
        "        return combined_data\n",
        "    \n",
        "    def save_to_excel(self, data, filename=None):\n",
        "        \"\"\"Save the scraped data to Excel files\"\"\"\n",
        "        if filename is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f'nba_betting_data_{timestamp}.xlsx'\n",
        "        try:\n",
        "            with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "                if isinstance(data.get('odds'), pd.DataFrame) and not data['odds'].empty:\n",
        "                    data['odds'].to_excel(writer, sheet_name='Player_Odds', index=False)\n",
        "                if data.get('lineups') is not None:\n",
        "                    lineups_list = []\n",
        "                    for game in data['lineups']:\n",
        "                        for starter_type in ['away_starters', 'home_starters']:\n",
        "                            team = game.get('away_team' if starter_type == 'away_starters' else 'home_team', 'Unknown')\n",
        "                            starters = game.get(starter_type, [])\n",
        "                            for starter in starters:\n",
        "                                lineups_list.append({\n",
        "                                    'game_time': game.get('game_time', ''),\n",
        "                                    'team': team,\n",
        "                                    'player_name': starter.get('name', ''),\n",
        "                                    'position': starter.get('position', ''),\n",
        "                                    'injury_status': starter.get('injury_status', ''),\n",
        "                                    'confirmed_starter': starter.get('confirmed_starter', False),\n",
        "                                    'player_link': starter.get('player_link', '')\n",
        "                                })\n",
        "                    if lineups_list:\n",
        "                        lineups_df = pd.DataFrame(lineups_list)\n",
        "                        lineups_df.to_excel(writer, sheet_name='Expected_Lineups', index=False)\n",
        "                metadata = pd.DataFrame([{\n",
        "                    'last_updated': data.get('last_updated', ''),\n",
        "                    'total_games': len(data.get('lineups', [])) if isinstance(data.get('lineups'), list) else 0,\n",
        "                    'total_players_odds': len(data.get('odds', [])) if isinstance(data.get('odds'), pd.DataFrame) else 0\n",
        "                }])\n",
        "                metadata.to_excel(writer, sheet_name='Metadata', index=False)\n",
        "            print(f\"Data successfully saved to {filename}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving to Excel: {e}\")\n",
        "            return False\n",
        "\n",
        "# Usage example and integration with your existing analytics\n",
        "def integrate_with_analytics():\n",
        "    \"\"\"Integrate the scraper with your existing analytics\"\"\"\n",
        "    scraper = NBAOddsAndLineupsScraper()\n",
        "    nba_data = scraper.get_comprehensive_data()\n",
        "    scraper.save_to_excel(nba_data)\n",
        "    processed_data = process_for_analytics(nba_data)\n",
        "    return processed_data\n",
        "\n",
        "def process_for_analytics(nba_data):\n",
        "    \"\"\"Process the scraped data for use in analytics\"\"\"\n",
        "    processed = {}\n",
        "    # Odds data â†’ extract basic lines for PTS/REB/AST if present\n",
        "    if isinstance(nba_data.get('odds'), pd.DataFrame) and not nba_data['odds'].empty:\n",
        "        odds_df = nba_data['odds']\n",
        "        def pick_line(row, market):\n",
        "            # Look for any <book>_<marketLower> columns (line, Under, Over)\n",
        "            m = market.lower()\n",
        "            line = None\n",
        "            over = None\n",
        "            under = None\n",
        "            for col in row.index:\n",
        "                c = col.lower()\n",
        "                if c.endswith(f\"_{m}\"):\n",
        "                    line = row[col]\n",
        "                elif c.endswith(f\"_{m}over\"):\n",
        "                    over = row[col]\n",
        "                elif c.endswith(f\"_{m}under\"):\n",
        "                    under = row[col]\n",
        "            try:\n",
        "                line = float(line) if line is not None and str(line).strip() not in (\"\", \"None\", \"nan\") else None\n",
        "            except Exception:\n",
        "                line = None\n",
        "            return line, over, under\n",
        "\n",
        "        betting_lines = []\n",
        "        for _, r in odds_df.iterrows():\n",
        "            player_name = r.get('name', '')\n",
        "            for mk in [\"pts\", \"reb\", \"ast\"]:\n",
        "                line, over, under = pick_line(r, mk)\n",
        "                if line is not None:\n",
        "                    betting_lines.append({\n",
        "                        \"player\": player_name,\n",
        "                        \"stat\": {\"pts\":\"points\",\"reb\":\"rebounds\",\"ast\":\"assists\"}[mk],\n",
        "                        \"line\": line,\n",
        "                        \"over_odds\": over,\n",
        "                        \"under_odds\": under\n",
        "                    })\n",
        "        processed['betting_lines'] = pd.DataFrame(betting_lines)\n",
        "\n",
        "    # Lineups\n",
        "    if nba_data.get('lineups') is not None:\n",
        "        lineups = nba_data['lineups']\n",
        "        team_players = {}\n",
        "        for game in lineups:\n",
        "            away_team = game.get('away_team')\n",
        "            if away_team and away_team not in team_players:\n",
        "                team_players[away_team] = []\n",
        "            for starter in game.get('away_starters', []):\n",
        "                if away_team and starter.get('name'):\n",
        "                    team_players[away_team].append({\n",
        "                        'name': starter['name'],\n",
        "                        'position': starter.get('position', ''),\n",
        "                        'status': starter.get('injury_status', 'Active'),\n",
        "                        'confirmed': starter.get('confirmed_starter', False)\n",
        "                    })\n",
        "            home_team = game.get('home_team')\n",
        "            if home_team and home_team not in team_players:\n",
        "                team_players[home_team] = []\n",
        "            for starter in game.get('home_starters', []):\n",
        "                if home_team and starter.get('name'):\n",
        "                    team_players[home_team].append({\n",
        "                        'name': starter['name'],\n",
        "                        'position': starter.get('position', ''),\n",
        "                        'status': starter.get('injury_status', 'Active'),\n",
        "                        'confirmed': starter.get('confirmed_starter', False)\n",
        "                    })\n",
        "        processed['team_lineups'] = team_players\n",
        "        processed['games_today'] = lineups\n",
        "    return processed\n",
        "\n",
        "def extract_betting_line(player_row, stat_type):\n",
        "    \"\"\"Extract betting line for specific stat type (legacy helper)\"\"\"\n",
        "    line_col = over_odds_col = under_odds_col = None\n",
        "    for col in player_row.index:\n",
        "        col_lower = col.lower()\n",
        "        if stat_type in col_lower and 'line' in col_lower:\n",
        "            line_col = col\n",
        "        elif stat_type in col_lower and 'over' in col_lower and 'odds' in col_lower:\n",
        "            over_odds_col = col\n",
        "        elif stat_type in col_lower and 'under' in col_lower and 'odds' in col_lower:\n",
        "            under_odds_col = col\n",
        "    line_value = player_row.get(line_col) if line_col else None\n",
        "    if line_value and str(line_value).replace('.', '').isdigit():\n",
        "        return {\n",
        "            'line': float(line_value),\n",
        "            'over_odds': player_row.get(over_odds_col) if over_odds_col else None,\n",
        "            'under_odds': player_row.get(under_odds_col) if under_odds_col else None\n",
        "        }\n",
        "    return None\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    data = integrate_with_analytics()\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"NBA BETTING DATA SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    if data.get('betting_lines') is not None:\n",
        "        print(f\"\\nBetting Lines: {len(data['betting_lines'])} player-stat combinations\")\n",
        "        print(data['betting_lines'].head(10))\n",
        "    if data.get('team_lineups'):\n",
        "        print(f\"\\nTeams with Lineups: {len(data['team_lineups'])}\")\n",
        "        for team, players in list(data['team_lineups'].items())[:3]:\n",
        "            print(f\"{team}: {len(players)} players\")\n",
        "            for player in players[:3]:\n",
        "                print(f\"  - {player['name']} ({player['position']}) - {player['status']}\")\n",
        "    if data.get('games_today'):\n",
        "        print(f\"\\nGames Today: {len(data['games_today'])}\")\n",
        "        for game in data['games_today'][:3]:\n",
        "            print(f\"{game.get('away_team', 'TBD')} @ {game.get('home_team', 'TBD')} - {game.get('game_time', 'Time TBD')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "25a19799",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_daily_matchups(date=None):\n",
        "    \"\"\"Get NBA games for a specific date\"\"\"\n",
        "    if date is None:\n",
        "        date = datetime.now().strftime('%Y-%m-%d')\n",
        "    # Placeholder demo; replace with a real schedule API if desired\n",
        "    sample_matchups = [\n",
        "        {'home_team': 'GSW', 'away_team': 'LAL', 'time': '7:30 PM ET'},\n",
        "        {'home_team': 'BOS', 'away_team': 'MIA', 'time': '8:00 PM ET'},\n",
        "        {'home_team': 'DEN', 'away_team': 'DAL', 'time': '9:00 PM ET'},\n",
        "    ]\n",
        "    return sample_matchups\n",
        "\n",
        "def calculate_player_correlations(player_a_logs, player_b_logs):\n",
        "    \"\"\"Calculate correlation between two players' performances\"\"\"\n",
        "    merged = pd.merge(player_a_logs, player_b_logs, on='GAME_DATE', suffixes=('_a', '_b'))\n",
        "    correlations = {}\n",
        "    for stat in ['PTS', 'REB', 'AST']:\n",
        "        if f'{stat}_a' in merged.columns and f'{stat}_b' in merged.columns:\n",
        "            corr = merged[f'{stat}_a'].corr(merged[f'{stat}_b'])\n",
        "            correlations[stat] = corr\n",
        "    return correlations\n",
        "\n",
        "# Export results to Excel\n",
        "def export_analysis(results, filename='nba_betting_analysis.xlsx'):\n",
        "    \"\"\"Export analysis results to Excel\"\"\"\n",
        "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "        if 'value_bets' in results:\n",
        "            pd.DataFrame(results['value_bets']).to_excel(writer, sheet_name='Value_Bets', index=False)\n",
        "        if 'predictions' in results:\n",
        "            predictions_df = pd.DataFrame.from_dict(results['predictions'], orient='index')\n",
        "            predictions_df.to_excel(writer, sheet_name='Player_Predictions')\n",
        "    print(f\"Analysis exported to {filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c0368a",
      "metadata": {},
      "source": [
        "## NBA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "f4896f17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ€ Fetching NBA stats for 2023-24...\n",
            "â†’ Attempt 1 fetching 2023-24 data...\n",
            "âœ… 2023-24: saved 572 player records to 'nba_player_stats_2023_24.csv'\n",
            "\n",
            "ðŸ€ Fetching NBA stats for 2024-25...\n",
            "â†’ Attempt 1 fetching 2024-25 data...\n",
            "âœ… 2024-25: saved 569 player records to 'nba_player_stats_2024_25.csv'\n",
            "\n",
            "ðŸŽ‰ Done! Both 2023-24 and 2024-25 seasons downloaded.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "url = \"https://stats.nba.com/stats/leaguedashplayerstats\"\n",
        "\n",
        "base_params = {\n",
        "    \"College\": \"\",\n",
        "    \"Conference\": \"\",\n",
        "    \"Country\": \"\",\n",
        "    \"DateFrom\": \"\",\n",
        "    \"DateTo\": \"\",\n",
        "    \"Division\": \"\",\n",
        "    \"DraftPick\": \"\",\n",
        "    \"DraftYear\": \"\",\n",
        "    \"GameScope\": \"\",\n",
        "    \"GameSegment\": \"\",\n",
        "    \"Height\": \"\",\n",
        "    \"ISTRound\": \"\",\n",
        "    \"LastNGames\": \"0\",\n",
        "    \"LeagueID\": \"00\",\n",
        "    \"Location\": \"\",\n",
        "    \"MeasureType\": \"Base\",\n",
        "    \"Month\": \"0\",\n",
        "    \"OpponentTeamID\": \"0\",\n",
        "    \"Outcome\": \"\",\n",
        "    \"PORound\": \"0\",\n",
        "    \"PaceAdjust\": \"N\",\n",
        "    \"PerMode\": \"PerGame\",\n",
        "    \"Period\": \"0\",\n",
        "    \"PlayerExperience\": \"\",\n",
        "    \"PlayerPosition\": \"\",\n",
        "    \"PlusMinus\": \"N\",\n",
        "    \"Rank\": \"N\",\n",
        "    \"SeasonSegment\": \"\",\n",
        "    \"SeasonType\": \"Regular Season\",\n",
        "    \"ShotClockRange\": \"\",\n",
        "    \"StarterBench\": \"\",\n",
        "    \"TeamID\": \"0\",\n",
        "    \"VsConference\": \"\",\n",
        "    \"VsDivision\": \"\",\n",
        "    \"Weight\": \"\"\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"Accept\": \"application/json, text/plain, */*\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Origin\": \"https://www.nba.com\",\n",
        "    \"Referer\": \"https://www.nba.com/\",\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                  \"Chrome/141.0.0.0 Safari/537.36\",\n",
        "    \"x-nba-stats-origin\": \"stats\",\n",
        "    \"x-nba-stats-token\": \"true\"\n",
        "}\n",
        "\n",
        "seasons = [\"2023-24\", \"2024-25\"]\n",
        "\n",
        "def fetch_season_data(season, retries=3):\n",
        "    \"\"\"Fetch one seasonâ€™s player stats, retrying if timeout or network error.\"\"\"\n",
        "    params = base_params.copy()\n",
        "    params[\"Season\"] = season\n",
        "\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            print(f\"â†’ Attempt {attempt} fetching {season} data...\")\n",
        "            response = requests.get(url, headers=headers, params=params, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(f\"âš ï¸ Timeout on attempt {attempt}/{retries} for {season}. Retrying...\")\n",
        "            time.sleep(3 * attempt)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"âŒ Error on attempt {attempt}/{retries}: {e}\")\n",
        "            time.sleep(3 * attempt)\n",
        "    raise RuntimeError(f\"Failed to fetch {season} data after {retries} attempts.\")\n",
        "\n",
        "# Main loop\n",
        "for season in seasons:\n",
        "    print(f\"\\nðŸ€ Fetching NBA stats for {season}...\")\n",
        "    data = fetch_season_data(season)\n",
        "\n",
        "    headers_list = data[\"resultSets\"][0][\"headers\"]\n",
        "    rows = data[\"resultSets\"][0][\"rowSet\"]\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=headers_list)\n",
        "    filename = f\"nba_player_stats_{season.replace('-', '_')}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"âœ… {season}: saved {len(df)} player records to '{filename}'\")\n",
        "\n",
        "    # Wait 3â€“6 seconds before next season to avoid throttling\n",
        "    time.sleep(random.uniform(3, 6))\n",
        "\n",
        "print(\"\\nðŸŽ‰ Done! Both 2023-24 and 2024-25 seasons downloaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f33a76b7",
      "metadata": {},
      "source": [
        "## GAME LOGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "7e080d50",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching 2023-24...\n",
            "âœ… Saved 26401 records for 2023-24\n",
            "Fetching 2024-25...\n",
            "âœ… Saved 26306 records for 2024-25\n",
            "Fetching 2025-26...\n",
            "âœ… Saved 1933 records for 2025-26\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def get_box_scores(season, season_type=\"Regular Season\"):\n",
        "    url = \"https://stats.nba.com/stats/leaguegamelog\"\n",
        "    params = {\n",
        "        \"Counter\": 1000,\n",
        "        \"DateFrom\": \"\",\n",
        "        \"DateTo\": \"\",\n",
        "        \"Direction\": \"DESC\",\n",
        "        \"ISTRound\": \"\",\n",
        "        \"LeagueID\": \"00\",\n",
        "        \"PlayerOrTeam\": \"P\",\n",
        "        \"Season\": season,\n",
        "        \"SeasonType\": season_type,\n",
        "        \"Sorter\": \"DATE\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
        "        \"Referer\": \"https://www.nba.com/\",\n",
        "        \"Origin\": \"https://www.nba.com\",\n",
        "        \"Accept\": \"application/json, text/plain, */*\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params, headers=headers, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    data = response.json()[\"resultSets\"][0]\n",
        "    df = pd.DataFrame(data[\"rowSet\"], columns=data[\"headers\"])\n",
        "    return df\n",
        "\n",
        "# Get all three seasons\n",
        "seasons = [\"2023-24\", \"2024-25\", \"2025-26\"]\n",
        "for season in seasons:\n",
        "    print(f\"Fetching {season}...\")\n",
        "    df = get_box_scores(season)\n",
        "    df.to_csv(f\"nba_boxscores_{season}.csv\", index=False)\n",
        "    print(f\"âœ… Saved {len(df)} records for {season}\")\n",
        "    time.sleep(2)  # polite delay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "a49f8cf8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: nba_player_stats_2023_24_enriched.csv\n",
            "âœ… Saved: nba_player_stats_2024_25_enriched.csv\n",
            "ðŸ€ Combined: nba_player_stats_2023_25_combined.csv\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "import unicodedata\n",
        "\n",
        "# ---- Keep/Map settings -------------------------------------------------------\n",
        "\n",
        "ADV_COLS_KEEP = [\n",
        "    \"Player\", \"Pos\", \"Age\", \"Tm\", \"G\", \"MP\",\n",
        "    \"PER\", \"TS%\", \"3PAr\", \"FTr\",\n",
        "    \"ORB%\", \"DRB%\", \"TRB%\",\n",
        "    \"AST%\", \"STL%\", \"BLK%\",\n",
        "    \"TOV%\", \"USG%\",\n",
        "    \"ORtg\", \"DRtg\",\n",
        "    \"OWS\", \"DWS\", \"WS\", \"WS/48\",\n",
        "    \"OBPM\", \"DBPM\", \"BPM\", \"VORP\"\n",
        "]\n",
        "\n",
        "# Basketball-Reference -> NBA/your dataset codes\n",
        "TEAM_ABBR_MAP = {\n",
        "    \"BRK\": \"BKN\",\n",
        "    \"PHO\": \"PHX\",\n",
        "    \"CHO\": \"CHA\",\n",
        "    \"UTH\": \"UTA\",   # rare alias safety\n",
        "    \"NJN\": \"BKN\",   # historical\n",
        "    \"SEA\": \"OKC\",   # historical\n",
        "    \"VAN\": \"MEM\",   # historical\n",
        "}\n",
        "\n",
        "# ---- Helpers -----------------------------------------------------------------\n",
        "\n",
        "def normalize_name(s):\n",
        "    \"\"\"Normalize player names for consistent joining (lowercase, no accents/punct).\"\"\"\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    s = s.strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    for ch in [\".\", \"'\", \"`\", \"â€™\", \"â€œ\", \"â€\", \",\"]:\n",
        "        s = s.replace(ch, \"\")\n",
        "    s = \" \".join(s.split())\n",
        "    return s\n",
        "\n",
        "# ---- Fetch advanced table from Basketball-Reference --------------------------\n",
        "\n",
        "def fetch_advanced_table(season=2026):\n",
        "    \"\"\"\n",
        "    Fetch and clean Basketball-Reference advanced stats table for a given season.\n",
        "    Example: season=2025 -> https://www.basketball-reference.com/leagues/NBA_2025_advanced.html\n",
        "    \"\"\"\n",
        "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_advanced.html\"\n",
        "    headers = {\n",
        "        \"User-Agent\": (\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "            \"Chrome/120.0.0.0 Safari/537.36\"\n",
        "        ),\n",
        "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
        "    }\n",
        "    resp = requests.get(url, headers=headers, timeout=30)\n",
        "    resp.raise_for_status()\n",
        "\n",
        "    tables = pd.read_html(io.StringIO(resp.text), header=0)\n",
        "    if not tables:\n",
        "        raise RuntimeError(\"No tables found on Basketball-Reference page.\")\n",
        "\n",
        "    df = tables[0].copy()\n",
        "\n",
        "    # Remove duplicate header rows\n",
        "    if \"Rk\" in df.columns:\n",
        "        df = df[df[\"Rk\"] != \"Rk\"].copy()\n",
        "        df.drop(columns=[\"Rk\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "    # Normalize column names (strip and upper-case for easy access)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    # Basketball Reference sometimes labels the team column differently â€” make sure it exists\n",
        "    team_col = None\n",
        "    for c in df.columns:\n",
        "        if c.lower() in [\"tm\", \"team\", \"team_name\"]:\n",
        "            team_col = c\n",
        "            break\n",
        "    if not team_col:\n",
        "        raise KeyError(f\"Could not find a team column in advanced table. Found: {df.columns.tolist()}\")\n",
        "    df.rename(columns={team_col: \"Tm\"}, inplace=True)\n",
        "\n",
        "    # Keep relevant columns if present\n",
        "    keep = [c for c in ADV_COLS_KEEP if c in df.columns]\n",
        "    df = df[keep].copy()\n",
        "\n",
        "    # Convert numeric columns\n",
        "    non_numeric = {\"Player\", \"Pos\", \"Tm\"}\n",
        "    for c in [c for c in df.columns if c not in non_numeric]:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    # Map team abbreviations to match your dataset\n",
        "    df[\"Tm\"] = df[\"Tm\"].replace(TEAM_ABBR_MAP)\n",
        "\n",
        "    # Add join keys\n",
        "    df[\"player_key\"] = df[\"Player\"].map(normalize_name)\n",
        "    df[\"team_key\"] = df[\"Tm\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ---- Load your averages CSV and align columns --------------------------------\n",
        "\n",
        "def load_averages_csv(path):\n",
        "    \"\"\"\n",
        "    Load your NBA averages CSV (with headers like PLAYER_NAME, TEAM_ABBREVIATION).\n",
        "    Renames to canonical 'Player' and 'Team' and adds join keys.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Auto-map your headers to canonical names\n",
        "    col_map = {}\n",
        "    for c in df.columns:\n",
        "        cl = c.strip().lower()\n",
        "        if cl == \"player_name\":\n",
        "            col_map[c] = \"Player\"\n",
        "        elif cl in (\"team_abbreviation\", \"tm\", \"team\"):\n",
        "            col_map[c] = \"Team\"\n",
        "        # keep other columns as-is\n",
        "\n",
        "    df = df.rename(columns=col_map)\n",
        "\n",
        "    if \"Player\" not in df.columns or \"Team\" not in df.columns:\n",
        "        raise ValueError(\n",
        "            \"Couldn't find columns for 'Player' and 'Team'. \"\n",
        "            f\"Available columns: {list(df.columns)}\"\n",
        "        )\n",
        "\n",
        "    # Join keys\n",
        "    df[\"player_key\"] = df[\"Player\"].map(normalize_name)\n",
        "    df[\"team_key\"] = df[\"Team\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ---- Merge logic (with TOT fallback for traded players) ----------------------\n",
        "\n",
        "def merge_advanced_into_averages(df_avg, df_adv):\n",
        "    \"\"\"\n",
        "    Merge advanced metrics into averages.\n",
        "    1) Exact Player+Team match (ignore TOT).\n",
        "    2) For remaining NaNs, fill from TOT row by Player.\n",
        "    \"\"\"\n",
        "    adv_team = df_adv[df_adv[\"Tm\"] != \"TOT\"].copy()\n",
        "    adv_tot  = df_adv[df_adv[\"Tm\"] == \"TOT\"].copy()\n",
        "\n",
        "    adv_cols_to_add = [c for c in df_adv.columns if c not in {\"Player\", \"Pos\", \"Age\", \"Tm\", \"player_key\", \"team_key\"}]\n",
        "    meta_cols = [c for c in [\"Pos\", \"Age\"] if c in df_adv.columns]\n",
        "    join_cols_full = meta_cols + adv_cols_to_add\n",
        "\n",
        "    merged = df_avg.merge(\n",
        "        adv_team[[\"player_key\", \"team_key\"] + join_cols_full],\n",
        "        on=[\"player_key\", \"team_key\"],\n",
        "        how=\"left\",\n",
        "        suffixes=(\"\", \"_adv\"),\n",
        "    )\n",
        "\n",
        "    # Determine \"missing\" based on a representative advanced column\n",
        "    probe_col = \"PER\" if \"PER\" in merged.columns else (\"WS/48\" if \"WS/48\" in merged.columns else None)\n",
        "    missing_mask = merged[probe_col].isna() if probe_col else merged.isna().any(axis=1)\n",
        "\n",
        "    if missing_mask.any() and not adv_tot.empty:\n",
        "        fallback = merged[missing_mask].merge(\n",
        "            adv_tot[[\"player_key\"] + join_cols_full],\n",
        "            on=\"player_key\",\n",
        "            how=\"left\",\n",
        "            suffixes=(\"\", \"_tot\"),\n",
        "        )\n",
        "        for col in join_cols_full:\n",
        "            if col in merged.columns and col in fallback.columns:\n",
        "                merged.loc[missing_mask, col] = merged.loc[missing_mask, col].fillna(fallback[col])\n",
        "\n",
        "    return merged\n",
        "\n",
        "# ==============================================================================\n",
        "# Example usage for your two files\n",
        "# ==============================================================================\n",
        "\n",
        "# ---- 2023â€“24 (Basketball-Reference season code = 2024) -----------------------\n",
        "df_avg_2024 = load_averages_csv(\"nba_player_stats_2023_24.csv\")\n",
        "df_adv_2024 = fetch_advanced_table(season=2024)\n",
        "df_enriched_2024 = merge_advanced_into_averages(df_avg_2024, df_adv_2024)\n",
        "df_enriched_2024.to_csv(\"nba_player_stats_2023_24_enriched.csv\", index=False)\n",
        "print(\"âœ… Saved: nba_player_stats_2023_24_enriched.csv\")\n",
        "\n",
        "# ---- 2024â€“25 (Basketball-Reference season code = 2025) -----------------------\n",
        "df_avg_2025 = load_averages_csv(\"nba_player_stats_2024_25.csv\")\n",
        "df_adv_2025 = fetch_advanced_table(season=2025)\n",
        "df_enriched_2025 = merge_advanced_into_averages(df_avg_2025, df_adv_2025)\n",
        "df_enriched_2025.to_csv(\"nba_player_stats_2024_25_enriched.csv\", index=False)\n",
        "print(\"âœ… Saved: nba_player_stats_2024_25_enriched.csv\")\n",
        "\n",
        "# ---- (Optional) Combine both seasons into one file ---------------------------\n",
        "df_combined = pd.concat([df_enriched_2024, df_enriched_2025], ignore_index=True)\n",
        "df_combined.to_csv(\"nba_player_stats_2023_25_combined.csv\", index=False)\n",
        "print(\"ðŸ€ Combined: nba_player_stats_2023_25_combined.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9c7c7d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "87786090",
      "metadata": {},
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "05885691",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Input file assumptions:\n",
        "# - You have player game logs with at least:\n",
        "#   ['GAME_DATE', 'PLAYER_NAME', 'TEAM_ABBREVIATION', 'OPPONENT_ABBREVIATION',\n",
        "#    'MIN', 'PTS', 'REB', 'AST', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'TOV', 'BLK', 'STL', 'PLUS_MINUS', 'START_POSITION']\n",
        "#   Column names can be auto-mapped below if they differ slightly (e.g., 'TEAM_ID' not needed).\n",
        "# -----------------------------\n",
        "\n",
        "def standardize_logs_cols(df_logs: pd.DataFrame) -> pd.DataFrame:\n",
        "    colmap = {}\n",
        "    for c in df_logs.columns:\n",
        "        cl = c.strip().lower()\n",
        "        if cl in [\"game_date\", \"game_date_est\", \"date\"]:\n",
        "            colmap[c] = \"GAME_DATE\"\n",
        "        elif cl in [\"player\", \"player_name\"]:\n",
        "            colmap[c] = \"PLAYER_NAME\"\n",
        "        elif cl in [\"team\", \"team_abbreviation\", \"tm\"]:\n",
        "            colmap[c] = \"TEAM_ABBREVIATION\"\n",
        "        elif cl in [\"opp\", \"opponent\", \"opponent_abbreviation\"]:\n",
        "            colmap[c] = \"OPPONENT_ABBREVIATION\"\n",
        "        elif cl in [\"min\", \"minutes\"]:\n",
        "            colmap[c] = \"MIN\"\n",
        "    df = df_logs.rename(columns=colmap).copy()\n",
        "    # types\n",
        "    df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
        "    df = df.sort_values([\"PLAYER_NAME\", \"GAME_DATE\"])\n",
        "    return df\n",
        "\n",
        "def add_shooting_efficiency(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Compute TS% from game logs (per game)\n",
        "    # TS% = PTS / (2*(FGA + 0.44*FTA))\n",
        "    for col in [\"FGA\", \"FTA\", \"PTS\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = 0.0\n",
        "    denom = 2 * (df[\"FGA\"].astype(float) + 0.44 * df[\"FTA\"].astype(float))\n",
        "    df[\"TS_game\"] = np.where(denom > 0, df[\"PTS\"].astype(float) / denom, np.nan)\n",
        "    return df\n",
        "\n",
        "def rolling_player_form(df: pd.DataFrame, windows=(3,5,10,20)) -> pd.DataFrame:\n",
        "    # Rolling stats per player before each game\n",
        "    df = df.sort_values([\"PLAYER_NAME\", \"GAME_DATE\"]).copy()\n",
        "    group = df.groupby(\"PLAYER_NAME\", group_keys=False)\n",
        "    for w in windows:\n",
        "        for stat in [\"PTS\", \"REB\", \"AST\", \"MIN\", \"TS_game\"]:\n",
        "            if stat not in df.columns:\n",
        "                df[stat] = np.nan\n",
        "            col = f\"{stat}_roll{w}\"\n",
        "            df[col] = group[stat].shift(1).rolling(w, min_periods=1).mean()\n",
        "    # recent usage proxy: last-5 share of team FGA\n",
        "    if {\"FGA\",\"TEAM_ABBREVIATION\"}.issubset(df.columns):\n",
        "        df[\"teamFGA_game\"] = df.groupby([\"TEAM_ABBREVIATION\",\"GAME_DATE\"])[\"FGA\"].transform(\"sum\")\n",
        "        df[\"usage_share\"] = np.where(df[\"teamFGA_game\"]>0, df[\"FGA\"]/df[\"teamFGA_game\"], np.nan)\n",
        "        df[\"usage_share_roll5\"] = group[\"usage_share\"].shift(1).rolling(5, min_periods=1).mean()\n",
        "    return df\n",
        "\n",
        "def team_daily_ratings(df: pd.DataFrame, windows=(5,10)):\n",
        "    # Build team-level ORtg/DRtg/Pace rolling using box score approximations\n",
        "    # Possessions â‰ˆ FGA + 0.44*FTA - OREB + TOV (OREB optional if present)\n",
        "    need_cols = [\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\"GAME_DATE\",\"PTS\",\"FGA\",\"FTA\",\"TOV\",\"OREB\"]\n",
        "    for c in need_cols:\n",
        "        if c not in df.columns:\n",
        "            df[c] = 0.0\n",
        "    # aggregate team totals per game\n",
        "    g = df.groupby([\"GAME_DATE\",\"TEAM_ABBREVIATION\"], as_index=False).agg(\n",
        "        PTS_team=(\"PTS\",\"sum\"), FGA=(\"FGA\",\"sum\"), FTA=(\"FTA\",\"sum\"),\n",
        "        TOV=(\"TOV\",\"sum\"), OREB=(\"OREB\",\"sum\")\n",
        "    )\n",
        "    g[\"poss\"] = g[\"FGA\"] + 0.44*g[\"FTA\"] - g[\"OREB\"] + g[\"TOV\"]\n",
        "    # opponent join to get DRtg inputs\n",
        "    opp = g.rename(columns={\n",
        "        \"TEAM_ABBREVIATION\":\"OPPONENT_ABBREVIATION\",\n",
        "        \"PTS_team\":\"PTS_opp\",\n",
        "        \"poss\":\"poss_opp\"\n",
        "    })[[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\",\"PTS_opp\",\"poss_opp\"]]\n",
        "    g2 = g.merge(opp, on=[\"GAME_DATE\"], how=\"left\")\n",
        "    # approximate per-team DRtg from opponent scoring\n",
        "    g2[\"ORtg_g\"] = np.where(g2[\"poss\"]>0, 100*g2[\"PTS_team\"]/g2[\"poss\"], np.nan)\n",
        "    g2[\"DRtg_g\"] = np.where(g2[\"poss_opp\"]>0, 100*g2[\"PTS_opp\"]/g2[\"poss_opp\"], np.nan)\n",
        "    g2[\"Pace_g\"] = (g2[\"poss\"] + g2[\"poss_opp\"]) / 2.0\n",
        "    g2 = g2.sort_values([\"TEAM_ABBREVIATION\",\"GAME_DATE\"])\n",
        "    # rolling\n",
        "    out = g2.copy()\n",
        "    for w in windows:\n",
        "        for stat in [\"ORtg_g\",\"DRtg_g\",\"Pace_g\"]:\n",
        "            out[f\"{stat}_roll{w}\"] = out.groupby(\"TEAM_ABBREVIATION\")[stat].shift(1).rolling(w, min_periods=1).mean()\n",
        "    return out[[\"GAME_DATE\",\"TEAM_ABBREVIATION\",\"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
        "                \"ORtg_g_roll10\",\"DRtg_g_roll10\",\"Pace_g_roll10\"]]\n",
        "\n",
        "def opponent_position_allowances(df: pd.DataFrame, window=10):\n",
        "    # How many points/assists/rebounds a team allows per opponent position (rolling)\n",
        "    if \"START_POSITION\" not in df.columns:\n",
        "        df[\"START_POSITION\"] = np.nan  # if not available, this will be sparse\n",
        "    base = df.groupby([\"GAME_DATE\",\"OPPONENT_ABBREVIATION\",\"START_POSITION\"], as_index=False)\\\n",
        "             .agg(PTS_allowed=(\"PTS\",\"sum\"), AST_allowed=(\"AST\",\"sum\"), REB_allowed=(\"REB\",\"sum\"))\n",
        "    base = base.sort_values([\"OPPONENT_ABBREVIATION\",\"START_POSITION\",\"GAME_DATE\"])\n",
        "    for w in [window]:\n",
        "        for stat in [\"PTS_allowed\",\"AST_allowed\",\"REB_allowed\"]:\n",
        "            base[f\"{stat}_roll{w}\"] = base.groupby([\"OPPONENT_ABBREVIATION\",\"START_POSITION\"])[stat]\\\n",
        "                                            .shift(1).rolling(w, min_periods=3).mean()\n",
        "    # pivot to wide per opponent (columns per position)\n",
        "    wide = base.pivot_table(index=[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\"],\n",
        "                            columns=\"START_POSITION\",\n",
        "                            values=[f\"PTS_allowed_roll{window}\",f\"AST_allowed_roll{window}\",f\"REB_allowed_roll{window}\"])\n",
        "    wide.columns = [f\"{a}_{b}\" for a,b in wide.columns.to_flat_index()]\n",
        "    wide = wide.reset_index()\n",
        "    return wide\n",
        "\n",
        "def assemble_player_game_features(df_logs: pd.DataFrame, df_enriched_season: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = standardize_logs_cols(df_logs)\n",
        "    df = add_shooting_efficiency(df)\n",
        "    df = rolling_player_form(df)\n",
        "\n",
        "    # Team rolling ratings\n",
        "    tr = team_daily_ratings(df)\n",
        "    df = df.merge(tr, on=[\"GAME_DATE\",\"TEAM_ABBREVIATION\"], how=\"left\")\n",
        "\n",
        "    # Opponent allowances by position\n",
        "    oppw = opponent_position_allowances(df)\n",
        "    df = df.merge(oppw, left_on=[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\"], right_on=[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\"], how=\"left\")\n",
        "\n",
        "    # Merge season-enriched averages (PER/TS%/USG%/ORtg/DRtg etc.)\n",
        "    tmp = df_enriched_season.copy()\n",
        "    # normalize keys like before\n",
        "    def _norm(s):\n",
        "        import unicodedata\n",
        "        s = str(s).strip().lower()\n",
        "        s = unicodedata.normalize(\"NFKD\", s)\n",
        "        s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "        for ch in [\".\",\"'\",\"`\",\"â€™\",\"â€œ\",\"â€\",\",\"]:\n",
        "            s = s.replace(ch,\"\")\n",
        "        return \" \".join(s.split())\n",
        "    df[\"player_key\"] = df[\"PLAYER_NAME\"].map(_norm)\n",
        "    df[\"team_key\"] = df[\"TEAM_ABBREVIATION\"].str.upper()\n",
        "\n",
        "    tmp[\"player_key\"] = tmp[\"Player\"].map(_norm)\n",
        "    tmp[\"team_key\"] = tmp[\"Team\"].astype(str).str.upper()\n",
        "\n",
        "    keep_adv = [c for c in [\"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\"Pos\",\"Age\"] if c in tmp.columns]\n",
        "    df = df.merge(tmp[[\"player_key\",\"team_key\"] + keep_adv], on=[\"player_key\",\"team_key\"], how=\"left\")\n",
        "\n",
        "    # simple situational flags\n",
        "    if \"MATCHUP\" in df.columns:\n",
        "        df[\"HOME\"] = df[\"MATCHUP\"].str.contains(\" vs. \", regex=False).astype(int)\n",
        "    else:\n",
        "        df[\"HOME\"] = np.nan  # placeholder\n",
        "\n",
        "    # Days rest\n",
        "    df[\"prev_date\"] = df.groupby(\"PLAYER_NAME\")[\"GAME_DATE\"].shift(1)\n",
        "    df[\"days_rest\"] = (df[\"GAME_DATE\"] - df[\"prev_date\"]).dt.days\n",
        "\n",
        "    # Targets: next-game points, rebounds, assists\n",
        "    df = df.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "    for target, src in [(\"PTS_next\",\"PTS\"), (\"REB_next\",\"REB\"), (\"AST_next\",\"AST\")]:\n",
        "        if src not in df.columns:\n",
        "            df[src] = np.nan\n",
        "        df[target] = df.groupby(\"PLAYER_NAME\")[src].shift(-1)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "c6fc8992",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Player PTS MAE (TimeSeries CV): 4.86 Â± 0.06\n",
            "Baseline Player REB MAE (TimeSeries CV): 2.10 Â± 0.03\n",
            "Baseline Player AST MAE (TimeSeries CV): 1.47 Â± 0.03\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Load your logs and enriched season files (paths must match Cell 4 / 5 outputs) ---\n",
        "logs_2324 = pd.read_csv(\"nba_boxscores_2023-24.csv\")        # adjust if your path differs\n",
        "logs_2425 = pd.read_csv(\"nba_boxscores_2024-25.csv\")\n",
        "enriched_2324 = pd.read_csv(\"nba_player_stats_2023_24_enriched.csv\")\n",
        "enriched_2425 = pd.read_csv(\"nba_player_stats_2024_25_enriched.csv\")\n",
        "\n",
        "# --- Build feature tables per season and concatenate ---\n",
        "feat_2324 = assemble_player_game_features(logs_2324, enriched_2324)\n",
        "feat_2425 = assemble_player_game_features(logs_2425, enriched_2425)\n",
        "features_all = pd.concat([feat_2324, feat_2425], ignore_index=True)\n",
        "\n",
        "# --- Base feature pool (we'll filter by existence) ---\n",
        "BASE_FEATURES = [\n",
        "    # rolling form (generic)\n",
        "    \"MIN_roll5\",\"MIN_roll10\",\"TS_game_roll5\",\"TS_game_roll10\",\"usage_share_roll5\",\n",
        "    # team context\n",
        "    \"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
        "    # advanced season context\n",
        "    \"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\n",
        "    # rest / home\n",
        "    \"days_rest\",\"HOME\"\n",
        "]\n",
        "\n",
        "# Stat-specific rolling features to add per target\n",
        "STAT_ROLLING = {\n",
        "    \"PTS\": [\"PTS_roll5\",\"PTS_roll10\"],\n",
        "    \"REB\": [\"REB_roll5\",\"REB_roll10\"],\n",
        "    \"AST\": [\"AST_roll5\",\"AST_roll10\"],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "TARGETS = {\n",
        "    \"PTS\": \"PTS_next\",\n",
        "    \"REB\": \"REB_next\",\n",
        "    \"AST\": \"AST_next\",\n",
        "}\n",
        "\n",
        "# Containers for later cells\n",
        "models = {}                 # e.g., models[\"PTS\"] = fitted RF\n",
        "feature_cols_by_stat = {}   # e.g., feature_cols_by_stat[\"PTS\"] = [...]\n",
        "cv_scores = {}              # MAE per stat\n",
        "\n",
        "# Time series CV\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Train one model per stat\n",
        "for stat, target_col in TARGETS.items():\n",
        "    # Build the candidate features for this stat\n",
        "    cand_feats = BASE_FEATURES + STAT_ROLLING[stat]\n",
        "    # Keep only columns that exist\n",
        "    feat_cols = [c for c in cand_feats if c in features_all.columns]\n",
        "    feature_cols_by_stat[stat] = feat_cols\n",
        "\n",
        "    # Drop rows with missing features/target\n",
        "    data = features_all.dropna(subset=feat_cols + [target_col]).copy()\n",
        "    if data.empty:\n",
        "        print(f\"âš ï¸ No training rows available for {stat} (missing features/target). Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Sort by time to avoid leakage\n",
        "    data_sorted = data.sort_values(\"GAME_DATE\")\n",
        "    X = data_sorted[feat_cols]\n",
        "    y = data_sorted[target_col]\n",
        "\n",
        "    # CV loop\n",
        "    maes = []\n",
        "    for train_idx, test_idx in tscv.split(X):\n",
        "        Xtr, Xte = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        ytr, yte = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=400,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        model.fit(Xtr, ytr)\n",
        "        pred = model.predict(Xte)\n",
        "        maes.append(mean_absolute_error(yte, pred))\n",
        "\n",
        "    cv_scores[stat] = (float(np.mean(maes)), float(np.std(maes)))\n",
        "    print(f\"Baseline Player {stat} MAE (TimeSeries CV): {np.mean(maes):.2f} Â± {np.std(maes):.2f}\")\n",
        "\n",
        "    # Fit final model on all data for this stat\n",
        "    final_model = RandomForestRegressor(\n",
        "        n_estimators=400,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    final_model.fit(X, y)\n",
        "    models[stat] = final_model\n",
        "\n",
        "# For convenience (optional): keep last-trained model/feature_cols for Cell 8 fallback\n",
        "# (Cell 8 below will use the per-stat dict to show importances for each target.)\n",
        "if \"PTS\" in models:\n",
        "    model = models[\"PTS\"]\n",
        "    feature_cols = feature_cols_by_stat[\"PTS\".]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "3de4ad9e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 15 importances â€” PTS:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "usage_share_roll5    0.482456\n",
              "USG%                 0.090536\n",
              "TS_game_roll10       0.045736\n",
              "MIN_roll5            0.043958\n",
              "TS_game_roll5        0.043564\n",
              "MIN_roll10           0.041790\n",
              "PTS_roll10           0.040254\n",
              "PTS_roll5            0.033015\n",
              "ORtg_g_roll5         0.031883\n",
              "TS%                  0.025988\n",
              "PER                  0.023671\n",
              "Pace_g_roll5         0.021363\n",
              "VORP                 0.021111\n",
              "BPM                  0.020008\n",
              "WS/48                0.015846\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 15 importances â€” REB:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "REB_roll5            0.407061\n",
              "REB_roll10           0.067645\n",
              "TS_game_roll5        0.060479\n",
              "TS_game_roll10       0.060150\n",
              "usage_share_roll5    0.057093\n",
              "MIN_roll10           0.052025\n",
              "MIN_roll5            0.051689\n",
              "PER                  0.044327\n",
              "WS/48                0.033217\n",
              "TS%                  0.029726\n",
              "USG%                 0.025026\n",
              "ORtg_g_roll5         0.024518\n",
              "VORP                 0.022242\n",
              "Pace_g_roll5         0.022217\n",
              "BPM                  0.021760\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 15 importances â€” AST:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AST_roll5            0.452974\n",
              "AST_roll10           0.070789\n",
              "TS_game_roll10       0.054000\n",
              "TS_game_roll5        0.052377\n",
              "usage_share_roll5    0.052266\n",
              "MIN_roll10           0.045795\n",
              "MIN_roll5            0.044593\n",
              "USG%                 0.034208\n",
              "VORP                 0.031465\n",
              "ORtg_g_roll5         0.031287\n",
              "TS%                  0.026002\n",
              "PER                  0.021997\n",
              "Pace_g_roll5         0.021815\n",
              "WS/48                0.021601\n",
              "BPM                  0.018444\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "if not models:\n",
        "    raise RuntimeError(\"No models trained in Cell 7. Ensure features/targets exist and rerun Cell 7.\")\n",
        "\n",
        "all_imps = {}\n",
        "for stat, mdl in models.items():\n",
        "    feat_cols = feature_cols_by_stat.get(stat, [])\n",
        "    if hasattr(mdl, \"feature_importances_\"):\n",
        "        imp_series = pd.Series(mdl.feature_importances_, index=feat_cols).sort_values(ascending=False)\n",
        "        all_imps[stat] = imp_series\n",
        "        print(f\"\\nTop 15 importances â€” {stat}:\")\n",
        "        display(imp_series.head(15))\n",
        "    else:\n",
        "        print(f\"\\nModel for {stat} has no feature_importances_ attribute.\")\n",
        "\n",
        "# Keep the most recently shown importances in 'imp' for backward compatibility\n",
        "if \"PTS\" in all_imps:\n",
        "    imp = all_imps[\"PTS\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a40247d",
      "metadata": {},
      "source": [
        "## team-level predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "73bf580f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Team PTS baseline R^2: 0.15181475578664994\n"
          ]
        }
      ],
      "source": [
        "# Team game table\n",
        "team_games = features_all.groupby([\"GAME_DATE\",\"TEAM_ABBREVIATION\"], as_index=False)\\\n",
        "    .agg(\n",
        "        team_pts=(\"PTS\",\"sum\"),\n",
        "        team_pts_next=(\"PTS_next\",\"sum\"),\n",
        "        or5=(\"ORtg_g_roll5\",\"mean\"),\n",
        "        dr5=(\"DRtg_g_roll5\",\"mean\"),\n",
        "        pace5=(\"Pace_g_roll5\",\"mean\"),\n",
        "    )\n",
        "\n",
        "# Join opponent features (same date)\n",
        "opp = team_games.rename(columns={\n",
        "    \"TEAM_ABBREVIATION\":\"OPPONENT_ABBREVIATION\",\n",
        "    \"team_pts\":\"opp_pts\",\n",
        "    \"team_pts_next\":\"opp_pts_next\",\n",
        "    \"or5\":\"opp_or5\",\"dr5\":\"opp_dr5\",\"pace5\":\"opp_pace5\"\n",
        "})\n",
        "team_matchups = team_games.merge(opp, on=[\"GAME_DATE\"], how=\"inner\")\n",
        "\n",
        "# Simple features for team total prediction\n",
        "team_feature_cols = [\"or5\",\"dr5\",\"pace5\",\"opp_or5\",\"opp_dr5\",\"opp_pace5\"]\n",
        "tm = team_matchups.dropna(subset=team_feature_cols + [\"team_pts_next\"]).copy()\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "X_tm = tm[team_feature_cols]\n",
        "y_tm = tm[\"team_pts_next\"]\n",
        "ridge = Ridge(alpha=5.0).fit(X_tm, y_tm)\n",
        "print(\"Team PTS baseline R^2:\", ridge.score(X_tm, y_tm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d849f19",
      "metadata": {},
      "source": [
        "## Lineups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "a505d3a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install selenium webdriver-manager bs4 pandas lxml\n",
        "\n",
        "import os, re, time, pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# ---------------- helpers ----------------\n",
        "\n",
        "def _clean_list(xs):\n",
        "    return [re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", x) for x in xs]\n",
        "\n",
        "def _try_click_consent(driver, timeout=6):\n",
        "    XPATHS = [\n",
        "        \"//button[contains(.,'Accept')]\",\n",
        "        \"//button[contains(.,'I Agree')]\",\n",
        "        \"//button[contains(.,'Agree')]\",\n",
        "        \"//button[contains(.,'Î‘Ï€Î¿Î´Î¿Ï‡Î®')]\",\n",
        "        \"//button[contains(.,'Î£Ï…Î¼Ï†Ï‰Î½ÏŽ')]\",\n",
        "    ]\n",
        "    end = time.time() + timeout\n",
        "    for xp in XPATHS:\n",
        "        try:\n",
        "            btn = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, xp)))\n",
        "            btn.click()\n",
        "            return True\n",
        "        except Exception:\n",
        "            if time.time() > end: break\n",
        "    return False\n",
        "\n",
        "def _progress_scroll(driver, steps=10, pause=0.8):\n",
        "    h = driver.execute_script(\"return document.body.scrollHeight || document.documentElement.scrollHeight;\")\n",
        "    for i in range(1, steps + 1):\n",
        "        y = int(h * i / steps)\n",
        "        driver.execute_script(f\"window.scrollTo(0, {y});\")\n",
        "        time.sleep(pause)\n",
        "\n",
        "def _extract_team(side):\n",
        "    team_el = side.select_one(\".lineup__abbr, .lineup__team-name, .lineup__name\")\n",
        "    if team_el:\n",
        "        return team_el.get_text(strip=True)\n",
        "    logo = side.select_one(\"img[alt]\")\n",
        "    return (logo.get(\"alt\") or \"\").strip() if logo else \"\"\n",
        "\n",
        "def _extract_status(side):\n",
        "    status_el = side.select_one(\".lineup__status\")\n",
        "    txt = (status_el.get_text(\" \", strip=True) if status_el else \"\").upper()\n",
        "    if \"CONFIRM\" in txt:  return \"CONFIRMED\"\n",
        "    if \"EXPECT\" in txt or \"PROBABLE\" in txt: return \"EXPECTED\"\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "def _extract_starters(side):\n",
        "    # Try several variants for starters content\n",
        "    containers = side.select(\".lineup__list--starters, .lineup__list, .lineup__players\")\n",
        "    if not containers:\n",
        "        containers = [side]\n",
        "\n",
        "    names = []\n",
        "    for blk in containers:\n",
        "        for a in blk.select(\"a.lineup__player-link, .lineup__player a\"):\n",
        "            t = a.get_text(\" \", strip=True)\n",
        "            if t: names.append(t)\n",
        "        if not names:\n",
        "            for row in blk.select(\".lineup__player\"):\n",
        "                t = row.get_text(\" \", strip=True)\n",
        "                if re.match(r\"^(PG|SG|SF|PF|C)\\b\", t): names.append(t)\n",
        "        if not names:\n",
        "            for li in blk.select(\"li\"):\n",
        "                t = li.get_text(\" \", strip=True)\n",
        "                if re.match(r\"^(PG|SG|SF|PF|C)\\b\", t): names.append(t)\n",
        "\n",
        "    if not names:\n",
        "        txt = side.get_text(\"\\n\", strip=True)\n",
        "        names = re.findall(r\"(?:^|\\n)(?:PG|SG|SF|PF|C)\\s+[^\\n]+\", txt)\n",
        "\n",
        "    return _clean_list(names)[:5]\n",
        "\n",
        "# ---------------- main ----------------\n",
        "\n",
        "def fetch_rotowire_lineups_selenium(date: str | None = None,\n",
        "                                    wait_sec: float = 14.0,\n",
        "                                    headless: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Render Rotowire lineups & parse BOTH sides per game (global side selectors).\n",
        "    Returns:\n",
        "      game_time, team, side (AWAY/HOME), lineup_status, starters,\n",
        "      starter_1..starter_5, lineup_confirmed (0/1)\n",
        "    \"\"\"\n",
        "    base = \"https://www.rotowire.com/basketball/nba-lineups.php\"\n",
        "    url = base if not date else f\"{base}?date={date}\"\n",
        "\n",
        "    opts = Options()\n",
        "    if headless: opts.add_argument(\"--headless=new\")\n",
        "    opts.add_argument(\"--disable-gpu\")\n",
        "    opts.add_argument(\"--no-sandbox\")\n",
        "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
        "    opts.add_argument(\"--window-size=1400,1000\")\n",
        "    opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "    opts.add_experimental_option(\"useAutomationExtension\", False)\n",
        "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "    opts.add_argument(\"--lang=en-US,en;q=0.9\")\n",
        "    opts.add_argument(\n",
        "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "    )\n",
        "\n",
        "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
        "    driver.get(url)\n",
        "\n",
        "    _try_click_consent(driver, timeout=6)\n",
        "    time.sleep(1.2)\n",
        "    try:\n",
        "        WebDriverWait(driver, int(wait_sec)).until(\n",
        "            EC.presence_of_element_located((By.CSS_SELECTOR, \".lineup, .lineup.is-nba\"))\n",
        "        )\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    _progress_scroll(driver, steps=10, pause=0.8)\n",
        "    time.sleep(1.0)\n",
        "\n",
        "    # quick diagnostics\n",
        "    blocks = driver.find_elements(By.CSS_SELECTOR, \".lineup.is-nba, .lineup\")\n",
        "    players = driver.find_elements(By.CSS_SELECTOR, \".lineup__player, a.lineup__player-link\")\n",
        "    print(f\"diagnostics: lineup blocks={len(blocks)}, player nodes={len(players)}\")\n",
        "\n",
        "    html = driver.page_source\n",
        "    os.makedirs(\"_rotowire_debug\", exist_ok=True)\n",
        "    with open(\"_rotowire_debug/last_lineups.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html)\n",
        "    try:\n",
        "        driver.save_screenshot(\"_rotowire_debug/last_lineups.png\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    driver.quit()\n",
        "\n",
        "    # -------- parse globally by side classes ----------\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    # game time map: find each game container time\n",
        "    game_time_map = {}\n",
        "    for gi, g in enumerate(soup.select(\".lineup__main, .lineup.is-nba, .lineup\")):\n",
        "        t = g.select_one(\".lineup__time, .game-time\")\n",
        "        game_time_map[id(g)] = t.get_text(strip=True) if t else \"\"\n",
        "\n",
        "    # Select **visit/away** & **home** side boxes explicitly\n",
        "    visit_sel = (\n",
        "        '[class*=\"lineup__box\"][class*=\"is-visit\"], '\n",
        "        '[class*=\"lineup__team\"][class*=\"is-visit\"], '\n",
        "        '[class*=\"lineup__side\"][class*=\"is-visit\"], '\n",
        "        '[class*=\"visit\"]'\n",
        "    )\n",
        "    home_sel = (\n",
        "        '[class*=\"lineup__box\"][class*=\"is-home\"], '\n",
        "        '[class*=\"lineup__team\"][class*=\"is-home\"], '\n",
        "        '[class*=\"lineup__side\"][class*=\"is-home\"], '\n",
        "        '[class*=\"home\"]'\n",
        "    )\n",
        "\n",
        "    visit_boxes = soup.select(visit_sel)\n",
        "    home_boxes  = soup.select(home_sel)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    def add_rows(boxes, side_label):\n",
        "        for box in boxes:\n",
        "            # nearest parent game container for time\n",
        "            parent = box.find_parent(lambda tag: tag.has_attr(\"class\") and any(\n",
        "                c in {\"lineup__main\",\"lineup\",\"lineup is-nba\"} for c in tag.get(\"class\", [])\n",
        "            ))\n",
        "            game_time = game_time_map.get(id(parent), \"\") if parent else \"\"\n",
        "            team = _extract_team(box)\n",
        "            starters = _extract_starters(box)\n",
        "            status = _extract_status(box)\n",
        "            if starters or team:\n",
        "                rows.append({\n",
        "                    \"game_time\": game_time,\n",
        "                    \"team\": team,\n",
        "                    \"side\": side_label,\n",
        "                    \"lineup_status\": status,\n",
        "                    \"starters\": starters,\n",
        "                    \"starter_1\": starters[0] if len(starters)>0 else None,\n",
        "                    \"starter_2\": starters[1] if len(starters)>1 else None,\n",
        "                    \"starter_3\": starters[2] if len(starters)>2 else None,\n",
        "                    \"starter_4\": starters[3] if len(starters)>3 else None,\n",
        "                    \"starter_5\": starters[4] if len(starters)>4 else None,\n",
        "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
        "                })\n",
        "\n",
        "    add_rows(visit_boxes, \"AWAY\")\n",
        "    add_rows(home_boxes,  \"HOME\")\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    if not df.empty:\n",
        "        df = df.drop_duplicates(\n",
        "            subset=[\"game_time\",\"team\",\"side\",\"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]\n",
        "        )\n",
        "        all_na = df[[\"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]].isna().all(axis=1)\n",
        "        df = df[~all_na].reset_index(drop=True)\n",
        "    else:\n",
        "        print(\"âš ï¸ Parsed zero rows. Check _rotowire_debug/last_lineups.html & .png\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "cc3237d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diagnostics: lineup blocks=11, player nodes=136\n",
            "âœ… Shape: (16, 11)\n",
            "game_time team side lineup_status                                                                           starters             starter_1        starter_2     starter_3     starter_4        starter_5  lineup_confirmed\n",
            "               AWAY     CONFIRMED                  [J. Fears, Trey Murphy, Herbert Jones, Z. Williamson, Yves Missi]              J. Fears      Trey Murphy Herbert Jones Z. Williamson       Yves Missi                 1\n",
            "               AWAY      EXPECTED     [N. Alexander-Walker, Dyson Daniels, Z. Risacher, Jalen Johnson, K. Porzingis]   N. Alexander-Walker    Dyson Daniels   Z. Risacher Jalen Johnson     K. Porzingis                 0\n",
            "               AWAY      EXPECTED                [Tyrese Maxey, VJ Edgecombe, Kelly Oubre, Jabari Walker, Adem Bona]          Tyrese Maxey     VJ Edgecombe   Kelly Oubre Jabari Walker        Adem Bona                 0\n",
            "               AWAY      EXPECTED         [Cam Spencer, K. Caldwell-Pope, Jaylen Wells, Jaren Jackson, Jock Landale]           Cam Spencer K. Caldwell-Pope  Jaylen Wells Jaren Jackson     Jock Landale                 0\n",
            "               AWAY      EXPECTED              [K. George, S. Mykhailiuk, L. Markkanen, K. Filipowski, Jusuf Nurkic]             K. George    S. Mykhailiuk  L. Markkanen K. Filipowski     Jusuf Nurkic                 0\n",
            "               AWAY      EXPECTED                   [Tre Jones, Josh Giddey, Isaac Okoro, Matas Buzelis, N. Vucevic]             Tre Jones      Josh Giddey   Isaac Okoro Matas Buzelis       N. Vucevic                 0\n",
            "               AWAY      EXPECTED                [S. Castle, Devin Vassell, J. Champagnie, H. Barnes, V. Wembanyama]             S. Castle    Devin Vassell J. Champagnie     H. Barnes    V. Wembanyama                 0\n",
            "               AWAY      EXPECTED                     [D. Mitchell, N. Powell, A. Wiggins, Bam Adebayo, Kel'el Ware]           D. Mitchell        N. Powell    A. Wiggins   Bam Adebayo      Kel'el Ware                 0\n",
            "               HOME     CONFIRMED [S. Gilgeous-Alexander, Cason Wallace, Aaron Wiggins, J. Williams, I. Hartenstein] S. Gilgeous-Alexander    Cason Wallace Aaron Wiggins   J. Williams   I. Hartenstein                 1\n",
            "               HOME      EXPECTED                     [D. Mitchell, Jaylon Tyson, D. Hunter, Dean Wade, Evan Mobley]           D. Mitchell     Jaylon Tyson     D. Hunter     Dean Wade      Evan Mobley                 0\n",
            "               HOME      EXPECTED                      [Ben Saraf, Cam Thomas, Terance Mann, M. Porter, Nic Claxton]             Ben Saraf       Cam Thomas  Terance Mann     M. Porter      Nic Claxton                 0\n",
            "               HOME      EXPECTED                  [I. Quickley, RJ Barrett, B. Ingram, S. Barnes, C. Murray-Boyles]           I. Quickley       RJ Barrett     B. Ingram     S. Barnes C. Murray-Boyles                 0\n"
          ]
        }
      ],
      "source": [
        "# ---------- run it ----------\n",
        "df_lineups = fetch_rotowire_lineups_selenium(wait_sec=14.0, headless=False)\n",
        "print(\"âœ… Shape:\", df_lineups.shape)\n",
        "print(df_lineups.sort_values([\"game_time\",\"side\"]).head(12).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "202f0cd8",
      "metadata": {},
      "source": [
        "## Selenium rotowire search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "b0a3dc4a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DOM diagnostics: {'lineup__teams': 8, 'ul.lineup__list': 16, 'ul.is-visit': 8, 'ul.is-home': 8, 'see-proj-minutes buttons': 16, 'header abbr': 0, 'header team': 0, 'player anchors': 136, 'MNP titles': 16}\n",
            "Fallback B: scanning all ul.lineup__list globally...\n",
            "â†’ Parsed rows: 16\n",
            "\n",
            "âœ… Preview:\n",
            "game_time team side lineup_status  may_not_play_count             starter_1        starter_2     starter_3     starter_4        starter_5\n",
            "           ATL AWAY      EXPECTED                   7   N. Alexander-Walker    Dyson Daniels   Z. Risacher Jalen Johnson     K. Porzingis\n",
            "           CHI AWAY      EXPECTED                   9             Tre Jones      Josh Giddey   Isaac Okoro Matas Buzelis       N. Vucevic\n",
            "           MEM AWAY      EXPECTED                  10           Cam Spencer K. Caldwell-Pope  Jaylen Wells Jaren Jackson     Jock Landale\n",
            "           MIA AWAY      EXPECTED                   9           D. Mitchell       A. Wiggins   Bam Adebayo   Kel'el Ware      D. Mitchell\n",
            "           NOP AWAY     CONFIRMED                   6              J. Fears      Trey Murphy Herbert Jones Z. Williamson       Yves Missi\n",
            "           PHI AWAY      EXPECTED                   9          Tyrese Maxey     VJ Edgecombe   Kelly Oubre Jabari Walker        Adem Bona\n",
            "           SAS AWAY      EXPECTED                  10             S. Castle    Devin Vassell J. Champagnie     H. Barnes    V. Wembanyama\n",
            "           UTA AWAY      EXPECTED                   8             K. George    S. Mykhailiuk  L. Markkanen K. Filipowski     Jusuf Nurkic\n",
            "           BKN HOME      EXPECTED                   7             Ben Saraf       Cam Thomas  Terance Mann     M. Porter      Nic Claxton\n",
            "           CHA HOME      EXPECTED                   9         Collin Sexton       Sion James  Kon Knueppel Miles Bridges   R. Kalkbrenner\n",
            "           CLE HOME      EXPECTED                   9           D. Mitchell     Jaylon Tyson     D. Hunter     Dean Wade      Evan Mobley\n",
            "           LAL HOME      EXPECTED                   5           Luka Doncic    Austin Reaves  Marcus Smart Rui Hachimura      Luka Doncic\n",
            "           NYK HOME      EXPECTED                   6         Jalen Brunson    Mikal Bridges    OG Anunoby      K. Towns    Jalen Brunson\n",
            "           OKC HOME     CONFIRMED                  12 S. Gilgeous-Alexander    Cason Wallace Aaron Wiggins   J. Williams   I. Hartenstein\n",
            "           PHX HOME      EXPECTED                   8          Devin Booker    Grayson Allen Royce O'Neale     Ryan Dunn    Mark Williams\n",
            "           TOR HOME      EXPECTED                   7           I. Quickley       RJ Barrett     B. Ingram     S. Barnes C. Murray-Boyles\n"
          ]
        }
      ],
      "source": [
        "# pip install bs4 lxml pandas\n",
        "import re, os, pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def _txt(x):\n",
        "    return re.sub(r\"\\s+\", \" \", x.get_text(\" \", strip=True)) if x else \"\"\n",
        "\n",
        "def _clean_player(n):\n",
        "    if not n: return n\n",
        "    n = re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", n).strip()\n",
        "    n = re.sub(r\"^(PG|SG|SF|PF|C)\\s+\", \"\", n, flags=re.I)\n",
        "    return n\n",
        "\n",
        "def _get_mnp_from_ul(ul):\n",
        "    \"\"\"Extract 'May Not Play' entries from a team UL.\"\"\"\n",
        "    mnp = []\n",
        "    # Strategy 1: find the title li inside this UL, then collect following player lis until next title\n",
        "    title = ul.find(\"li\", class_=lambda c: c and \"lineup__title\" in c and re.search(r\"may\\s+not\\s+play\", _txt(ul.find(\"li\", class_=c)) if ul.find(\"li\", class_=c) else \"\", re.I))\n",
        "    if title:\n",
        "        for li in title.find_all_next(\"li\"):\n",
        "            # stop if next section title\n",
        "            if \"lineup__title\" in (li.get(\"class\") or []):\n",
        "                break\n",
        "            if \"lineup__player\" in (li.get(\"class\") or []):\n",
        "                a = li.select_one(\"a\")\n",
        "                tag = li.select_one(\".lineup__inj\")\n",
        "                nm = _txt(a) if a else \"\"\n",
        "                if nm:\n",
        "                    mnp.append(f\"{nm} ({_txt(tag)})\" if tag else nm)\n",
        "        # normalize\n",
        "        return [_clean_player(x) for x in mnp if x and x.lower() != \"none\"]\n",
        "\n",
        "    # Strategy 2: common MNP containers inside UL\n",
        "    for li in ul.select(\".lineup__notplay li, .lineup__status--out, .lineup__inj-list li\"):\n",
        "        nm = _txt(li)\n",
        "        if nm: mnp.append(_clean_player(nm))\n",
        "    return [x for x in mnp if x and x.lower() != \"none\"]\n",
        "\n",
        "def _extract_starters_from_ul(ul):\n",
        "    \"\"\"Try multiple ways to get five starters out of a team UL.\"\"\"\n",
        "    names = []\n",
        "    # Most reliable: 100% rows\n",
        "    for li in ul.select(\"li.lineup__player.is-pct-play-100 a\"):\n",
        "        nm = _txt(li)\n",
        "        if nm: names.append(nm)\n",
        "    # Fallback: any lineup__player anchors in first list group\n",
        "    if len(names) < 5:\n",
        "        for li in ul.select(\"li.lineup__player a\"):\n",
        "            nm = _txt(li)\n",
        "            if nm: names.append(nm)\n",
        "            if len(names) >= 5: break\n",
        "    # Final cleanup + trim\n",
        "    names = [_clean_player(n) for n in names]\n",
        "    return names[:5]\n",
        "\n",
        "def _lineup_status(ul):\n",
        "    st = _txt(ul.select_one(\".lineup__status\"))\n",
        "    stU = st.upper()\n",
        "    if \"CONFIRM\" in stU: return \"CONFIRMED\"\n",
        "    if \"EXPECT\" in stU or \"PROBABLE\" in stU: return \"EXPECTED\"\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "def parse_rotowire_lineups_flexible(html_path: str) -> pd.DataFrame:\n",
        "    with open(html_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        html = f.read()\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    # --- Diagnostics to understand the DOM you have ---\n",
        "    diag = {\n",
        "        \"lineup__teams\": len(soup.select(\"div.lineup__teams\")),\n",
        "        \"ul.lineup__list\": len(soup.select(\"ul.lineup__list\")),\n",
        "        \"ul.is-visit\": len(soup.select(\"ul.lineup__list.is-visit\")),\n",
        "        \"ul.is-home\": len(soup.select(\"ul.lineup__list.is-home\")),\n",
        "        \"see-proj-minutes buttons\": len(soup.select(\"button.see-proj-minutes\")),\n",
        "        \"header abbr\": len(soup.select(\".lineup__hdr .lineup__abbr\")),\n",
        "        \"header team\": len(soup.select(\".lineup__hdr .lineup__team\")),\n",
        "        \"player anchors\": len(soup.select(\"a.lineup__player-link, .lineup__player a\")),\n",
        "        \"MNP titles\": len(soup.find_all(string=re.compile(r\"^\\s*may\\s+not\\s+play\\s*$\", re.I))),\n",
        "    }\n",
        "    print(\"DOM diagnostics:\", diag)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    # ========== STRATEGY A: by matchup blocks ==========\n",
        "    for teams_div in soup.select(\"div.lineup__teams\"):\n",
        "        # game time near this block (looks upward for a sibling header)\n",
        "        time_el = teams_div.find_previous(\"div\", class_=\"lineup__time\")\n",
        "        game_time = _txt(time_el)\n",
        "\n",
        "        # find both team ULs inside this matchup\n",
        "        uls = teams_div.select(\"ul.lineup__list\")\n",
        "        if len(uls) < 1:\n",
        "            continue\n",
        "\n",
        "        # Try to pair AWAY then HOME by class flags; else preserve order\n",
        "        away_ul = None\n",
        "        home_ul = None\n",
        "        for ul in uls:\n",
        "            classes = \" \".join(ul.get(\"class\", [])).lower()\n",
        "            if \"is-visit\" in classes or \"visit\" in classes or \"away\" in classes:\n",
        "                away_ul = ul\n",
        "            if \"is-home\" in classes or \"home\" in classes:\n",
        "                home_ul = home_ul or ul  # keep the first\n",
        "\n",
        "        if away_ul is None and home_ul is None and len(uls) >= 2:\n",
        "            away_ul, home_ul = uls[0], uls[1]\n",
        "        elif away_ul is None and len(uls) >= 1:\n",
        "            away_ul = uls[0]\n",
        "        elif home_ul is None and len(uls) >= 2:\n",
        "            # pick the other UL as home\n",
        "            home_ul = next((u for u in uls if u is not away_ul), None)\n",
        "\n",
        "        pairs = [(\"AWAY\", away_ul), (\"HOME\", home_ul)]\n",
        "        # Extract team code (prefer button data-team; else header abbrs in the same matchup)\n",
        "        header_abbrs = [ _txt(el) for el in teams_div.select(\".lineup__abbr\") if _txt(el) ]\n",
        "        # If header not inside teams_div, try its parent block\n",
        "        if not header_abbrs:\n",
        "            parent_main = teams_div.find_parent([\"div\",\"section\"])\n",
        "            if parent_main:\n",
        "                header_abbrs = [ _txt(el) for el in parent_main.select(\".lineup__abbr\") if _txt(el) ]\n",
        "\n",
        "        for idx, (side, ul) in enumerate(pairs):\n",
        "            if not ul: continue\n",
        "            btn = ul.select_one(\"button.see-proj-minutes\")\n",
        "            team = btn[\"data-team\"].strip().upper() if btn and btn.has_attr(\"data-team\") else None\n",
        "            if not team and header_abbrs and idx < len(header_abbrs):\n",
        "                team = header_abbrs[idx].upper()\n",
        "\n",
        "            starters = _extract_starters_from_ul(ul)\n",
        "            mnp = _get_mnp_from_ul(ul)\n",
        "            status = _lineup_status(ul)\n",
        "\n",
        "            # Only add if we have at least a team or any player info\n",
        "            if team or starters or mnp:\n",
        "                rows.append({\n",
        "                    \"game_time\": game_time,\n",
        "                    \"team\": team,\n",
        "                    \"side\": side,\n",
        "                    \"lineup_status\": status,\n",
        "                    \"starters\": starters,\n",
        "                    \"may_not_play\": mnp,\n",
        "                    \"may_not_play_count\": len(mnp),\n",
        "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
        "                })\n",
        "\n",
        "    # ========== STRATEGY B: fall back to any lineup ULs globally ==========\n",
        "    if not rows:\n",
        "        print(\"Fallback B: scanning all ul.lineup__list globally...\")\n",
        "        for ul in soup.select(\"ul.lineup__list\"):\n",
        "            # Guess side by class or position among siblings\n",
        "            side = \"AWAY\" if \"is-visit\" in (ul.get(\"class\") or []) else (\"HOME\" if \"is-home\" in (ul.get(\"class\") or []) else None)\n",
        "            # Team from button\n",
        "            btn = ul.select_one(\"button.see-proj-minutes\")\n",
        "            team = btn[\"data-team\"].strip().upper() if btn and btn.has_attr(\"data-team\") else None\n",
        "            starters = _extract_starters_from_ul(ul)\n",
        "            mnp = _get_mnp_from_ul(ul)\n",
        "            status = _lineup_status(ul)\n",
        "\n",
        "            if side and (team or starters or mnp):\n",
        "                rows.append({\n",
        "                    \"game_time\": \"\",  # unknown at this scope\n",
        "                    \"team\": team,\n",
        "                    \"side\": side,\n",
        "                    \"lineup_status\": status,\n",
        "                    \"starters\": starters,\n",
        "                    \"may_not_play\": mnp,\n",
        "                    \"may_not_play_count\": len(mnp),\n",
        "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
        "                })\n",
        "\n",
        "    # ========== STRATEGY C: header-driven pairing (very defensive) ==========\n",
        "    if not rows:\n",
        "        print(\"Fallback C: pairing by header labels and nearest lists...\")\n",
        "        for block in soup.select(\".lineup, .lineup__main\"):\n",
        "            hdr = block.select(\".lineup__hdr .lineup__abbr, .lineup__hdr .lineup__team\")\n",
        "            labels = [ _txt(x) for x in hdr if _txt(x) ]\n",
        "            if len(labels) < 2:\n",
        "                continue\n",
        "            away_label, home_label = labels[:2]\n",
        "            lists = block.select(\"ul.lineup__list\")\n",
        "            if len(lists) < 2:\n",
        "                continue\n",
        "            for side, lab, ul in [(\"AWAY\", away_label, lists[0]), (\"HOME\", home_label, lists[1])]:\n",
        "                starters = _extract_starters_from_ul(ul)\n",
        "                mnp = _get_mnp_from_ul(ul)\n",
        "                status = _lineup_status(ul)\n",
        "                rows.append({\n",
        "                    \"game_time\": _txt(block.select_one(\".lineup__time, .game-time\")),\n",
        "                    \"team\": lab.upper(),\n",
        "                    \"side\": side,\n",
        "                    \"lineup_status\": status,\n",
        "                    \"starters\": starters,\n",
        "                    \"may_not_play\": mnp,\n",
        "                    \"may_not_play_count\": len(mnp),\n",
        "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    # Expand starters to columns for easier merging\n",
        "    for i in range(5):\n",
        "        col = f\"starter_{i+1}\"\n",
        "        df[col] = df[\"starters\"].apply(lambda xs: xs[i] if isinstance(xs, list) and len(xs) > i else None)\n",
        "\n",
        "    print(f\"â†’ Parsed rows: {len(df)}\")\n",
        "    return df\n",
        "\n",
        "# ---- RUN IT (point to your saved file) ----\n",
        "HTML_PATH = \"_rotowire_debug/last_lineups.html\"  # change if needed\n",
        "if not os.path.exists(HTML_PATH):\n",
        "    # if you uploaded as 'last_lineups.html' in current directory\n",
        "    if os.path.exists(\"last_lineups.html\"):\n",
        "        HTML_PATH = \"last_lineups.html\"\n",
        "\n",
        "df_lineups = parse_rotowire_lineups_flexible(HTML_PATH)\n",
        "\n",
        "# Safe display\n",
        "if df_lineups.empty:\n",
        "    print(\"\\nâš ï¸ Still empty. Please share the values printed in 'DOM diagnostics' (above).\")\n",
        "else:\n",
        "    cols = [\"game_time\",\"team\",\"side\",\"lineup_status\",\"may_not_play_count\",\n",
        "            \"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]\n",
        "    print(\"\\nâœ… Preview:\")\n",
        "    print(df_lineups[cols].sort_values([\"game_time\",\"side\",\"team\"], na_position=\"last\").to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "4e2b9e20",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8 games in HTML.\n",
            "âœ… Parsed 56 'May Not Play' players across 16 teams.\n",
            " game_time team side position       player status            title_text  likelihood_pct\n",
            "3:30 PM ET  NOP AWAY        G    D. Murray    Out Very Unlikely To Play               0\n",
            "3:30 PM ET  OKC HOME        C  C. Holmgren    Out Very Unlikely To Play               0\n",
            "3:30 PM ET  OKC HOME        F  J. Williams    Out Very Unlikely To Play               0\n",
            "3:30 PM ET  OKC HOME        F  K. Williams    Out Very Unlikely To Play               0\n",
            "3:30 PM ET  OKC HOME        F      L. Dort    Out Very Unlikely To Play               0\n",
            "3:30 PM ET  OKC HOME        G     N. Topic    Out Very Unlikely To Play               0\n",
            "3:30 PM ET  OKC HOME        F     O. Dieng   Ques   Very Likely To Play             100\n",
            "3:30 PM ET  OKC HOME        C    T. Sorber    OFS   Very Likely To Play               0\n",
            "6:00 PM ET  ATL AWAY        G   K. Wallace    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  ATL AWAY        G   Trae Young    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  MEM AWAY        C    B. Clarke    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  MEM AWAY        G    Ja Morant    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  MEM AWAY        G    S. Pippen    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  MEM AWAY        G    Ty Jerome    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  MEM AWAY        C    Zach Edey    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  PHI AWAY        C    D. Barlow    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  PHI AWAY        C    J. Embiid    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  PHI AWAY        G    J. McCain    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  PHI AWAY        F    P. George    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  UTA AWAY        F     G. Niang    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  UTA AWAY        G   I. Collier    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  UTA AWAY        C   W. Kessler    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  BKN HOME        F   Danny Wolf    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  BKN HOME        F H. Highsmith    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  CHA HOME        F    B. Miller    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  CHA HOME        F  G. Williams    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  CHA HOME        F   Josh Green    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  CHA HOME        G      L. Ball    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  CLE HOME        G   D. Garland    Out Very Unlikely To Play               0\n",
            "6:00 PM ET  CLE HOME        C     J. Allen    Out Very Unlikely To Play               0\n",
            "\n",
            "Saved: may_not_play_players.csv\n"
          ]
        }
      ],
      "source": [
        "# pip install bs4 lxml pandas\n",
        "import os, re, pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "HTML_PATH = \"_rotowire_debug/last_lineups.html\" if os.path.exists(\"_rotowire_debug/last_lineups.html\") else \"last_lineups.html\"\n",
        "\n",
        "LIKELIHOOD_MAP = {\n",
        "    \"is-pct-play-100\": 100, \"is-pct-play-90\": 90, \"is-pct-play-75\": 75,\n",
        "    \"is-pct-play-60\": 60, \"is-pct-play-50\": 50, \"is-pct-play-40\": 40,\n",
        "    \"is-pct-play-25\": 25, \"is-pct-play-10\": 10, \"is-pct-play-0\": 0\n",
        "}\n",
        "\n",
        "def _txt(node): return re.sub(r\"\\s+\", \" \", node.get_text(\" \", strip=True)) if node else \"\"\n",
        "def _likelihood(classes): \n",
        "    for c in classes: \n",
        "        if c in LIKELIHOOD_MAP: \n",
        "            return LIKELIHOOD_MAP[c]\n",
        "    return None\n",
        "\n",
        "def parse_rotowire_mnp_final(html_path: str) -> pd.DataFrame:\n",
        "    with open(html_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        soup = BeautifulSoup(f.read(), \"lxml\")\n",
        "\n",
        "    rows = []\n",
        "    games = soup.select(\"div.lineup.is-nba[data-lnum]\")\n",
        "    print(f\"Found {len(games)} games in HTML.\")\n",
        "\n",
        "    for game in games:\n",
        "        game_time = _txt(game.select_one(\".lineup__time\"))\n",
        "        team_blocks = game.select(\".lineup__team\")\n",
        "        teams = []\n",
        "        for tb in team_blocks:\n",
        "            abbr = _txt(tb.select_one(\".lineup__abbr\"))\n",
        "            side = \"AWAY\" if \"is-visit\" in tb.get(\"class\", []) else \"HOME\" if \"is-home\" in tb.get(\"class\", []) else None\n",
        "            teams.append((abbr, side))\n",
        "\n",
        "        ul_lists = game.select(\"ul.lineup__list\")\n",
        "        for idx, ul in enumerate(ul_lists):\n",
        "            if idx >= len(teams):  # mismatch safety\n",
        "                continue\n",
        "            team, side = teams[idx]\n",
        "            mnp_title = ul.find(\"li\", class_=\"lineup__title\", string=lambda s: s and \"MAY NOT PLAY\" in s.upper())\n",
        "            if not mnp_title:\n",
        "                continue\n",
        "\n",
        "            for li in mnp_title.find_next_siblings(\"li\"):\n",
        "                classes = li.get(\"class\") or []\n",
        "                if \"lineup__title\" in classes:\n",
        "                    break\n",
        "                if \"lineup__player\" not in classes:\n",
        "                    continue\n",
        "\n",
        "                pos = _txt(li.select_one(\".lineup__pos\"))\n",
        "                a = li.select_one(\"a\")\n",
        "                player = _txt(a)\n",
        "                if not player:\n",
        "                    continue\n",
        "\n",
        "                status = _txt(li.select_one(\".lineup__inj\"))\n",
        "                title_text = (li.get(\"title\") or \"\").strip()\n",
        "                likelihood_pct = _likelihood(classes)\n",
        "\n",
        "                rows.append({\n",
        "                    \"game_time\": game_time,\n",
        "                    \"team\": team,\n",
        "                    \"side\": side,\n",
        "                    \"position\": pos,\n",
        "                    \"player\": player,\n",
        "                    \"status\": status,\n",
        "                    \"title_text\": title_text,\n",
        "                    \"likelihood_pct\": likelihood_pct\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    if df.empty:\n",
        "        print(\"âš ï¸ No 'May Not Play' players found. Check if Rotowire changed markup.\")\n",
        "    else:\n",
        "        df = df.sort_values([\"game_time\",\"side\",\"team\",\"player\"]).reset_index(drop=True)\n",
        "        print(f\"âœ… Parsed {len(df)} 'May Not Play' players across {df['team'].nunique()} teams.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# ---- RUN ----\n",
        "mnp_df = parse_rotowire_mnp_final(HTML_PATH)\n",
        "if not mnp_df.empty:\n",
        "    print(mnp_df.head(30).to_string(index=False))\n",
        "    mnp_df.to_csv(\"may_not_play_players.csv\", index=False)\n",
        "    print(\"\\nSaved: may_not_play_players.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecea42b8",
      "metadata": {},
      "source": [
        "## Cell 15: odds math + Excel export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "f6c2e17e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "def american_to_prob(odds):\n",
        "    if pd.isna(odds): return np.nan\n",
        "    o = float(odds)\n",
        "    return 100.0/(o+100.0) if o>0 else (-o)/(-o+100.0)\n",
        "\n",
        "def devig_pair(p_over, p_under):\n",
        "    if pd.isna(p_over) or pd.isna(p_under): return (np.nan, np.nan)\n",
        "    s = p_over + p_under\n",
        "    if s <= 0: return (np.nan, np.nan)\n",
        "    return (p_over/s, p_under/s)\n",
        "\n",
        "def kelly_fraction(p, american_odds, cap=0.25):\n",
        "    if pd.isna(p) or pd.isna(american_odds): return 0.0\n",
        "    o = float(american_odds)\n",
        "    b = o/100.0 if o>0 else 100.0/(-o)\n",
        "    f = (p*(b+1)-1)/b\n",
        "    return float(max(0.0, min(f, cap)))\n",
        "\n",
        "def ev_flat_over(p, american_odds):\n",
        "    if pd.isna(p) or pd.isna(american_odds): return np.nan\n",
        "    o = float(american_odds)\n",
        "    win = o/100.0 if o>0 else 100.0/(-o)\n",
        "    lose = 1.0\n",
        "    return p*win - (1-p)*lose\n",
        "\n",
        "# Normal CDF helper (if SciPy available) to turn mean/sd into p_over\n",
        "try:\n",
        "    from scipy.stats import norm\n",
        "    def p_over_from_normal(mu, sd, line):\n",
        "        if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: return np.nan\n",
        "        return 1.0 - norm.cdf((line - mu)/sd)\n",
        "except Exception:\n",
        "    def p_over_from_normal(mu, sd, line): return np.nan\n",
        "\n",
        "def build_value_bets_excel(\n",
        "    df_projections, df_odds, outfile_path=None,\n",
        "    join_keys=(\"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\"game_date\"),\n",
        "    cap_kelly=0.25\n",
        "):\n",
        "    def _norm(x): return None if pd.isna(x) else str(x).strip()\n",
        "    proj, odds = df_projections.copy(), df_odds.copy()\n",
        "    for k in join_keys:\n",
        "        if k in proj: proj[k] = proj[k].map(_norm)\n",
        "        if k in odds: odds[k] = odds[k].map(_norm)\n",
        "\n",
        "    merged = proj.merge(odds, on=list(join_keys), how=\"inner\", suffixes=(\"\", \"_odds\"))\n",
        "\n",
        "    if \"p_over_model\" not in merged.columns or merged[\"p_over_model\"].isna().all():\n",
        "        merged[\"p_over_model\"] = merged.apply(\n",
        "            lambda r: p_over_from_normal(r.get(\"projection_mean\"), r.get(\"projection_sd\"), r.get(\"line\")), axis=1\n",
        "        )\n",
        "\n",
        "    merged[\"p_over_imp\"]  = merged[\"over_odds\"].map(american_to_prob)\n",
        "    merged[\"p_under_imp\"] = merged[\"under_odds\"].map(american_to_prob)\n",
        "    merged[[\"p_over_fair\",\"p_under_fair\"]] = merged.apply(\n",
        "        lambda r: pd.Series(devig_pair(r[\"p_over_imp\"], r[\"p_under_imp\"])), axis=1\n",
        "    )\n",
        "\n",
        "    merged[\"edge_over\"]       = merged[\"p_over_model\"] - merged[\"p_over_fair\"]\n",
        "    merged[\"kelly_frac_over\"] = merged.apply(lambda r: kelly_fraction(r[\"p_over_model\"], r[\"over_odds\"], cap=cap_kelly), axis=1)\n",
        "    merged[\"EV_over_1u\"]      = merged.apply(lambda r: ev_flat_over(r[\"p_over_model\"], r[\"over_odds\"]), axis=1)\n",
        "    merged[\"asof_date\"]       = merged.get(\"asof_date\") if \"asof_date\" in merged else datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    preferred = [\n",
        "        \"asof_date\",\"game_date\",\"book\",\"player\",\"team\",\"opponent\",\"market\",\"line\",\"lineup_status\",\n",
        "        \"over_odds\",\"under_odds\",\"p_over_imp\",\"p_under_imp\",\"p_over_fair\",\"p_under_fair\",\"p_over_model\",\n",
        "        \"edge_over\",\"kelly_frac_over\",\"EV_over_1u\",\n",
        "        \"projected_minutes\",\"projection_mean\",\"projection_sd\",\"start_prob\",\n",
        "        \"opponent_allowance_idx\",\"team_orating\",\"opp_drating\",\n",
        "    ]\n",
        "    cols = [c for c in preferred if c in merged.columns] + [c for c in merged.columns if c not in preferred]\n",
        "    bets = merged[cols].sort_values([\"edge_over\",\"EV_over_1u\"], ascending=False).reset_index(drop=True)\n",
        "\n",
        "    summary = pd.DataFrame({\n",
        "        \"n_bets\":[len(bets)],\n",
        "        \"avg_edge_pp\":[bets[\"edge_over\"].mean()*100.0 if len(bets) else np.nan],\n",
        "        \"avg_kelly_pct\":[bets[\"kelly_frac_over\"].mean()*100.0 if len(bets) else np.nan],\n",
        "        \"avg_ev_1u\":[bets[\"EV_over_1u\"].mean() if len(bets) else np.nan],\n",
        "    })\n",
        "    by_market = bets.groupby(\"market\", dropna=False).agg(\n",
        "        n=(\"player\",\"count\"),\n",
        "        avg_edge_pp=(\"edge_over\", lambda x: 100.0*x.mean()),\n",
        "        avg_kelly_pct=(\"kelly_frac_over\", lambda x: 100.0*x.mean()),\n",
        "        avg_ev_1u=(\"EV_over_1u\",\"mean\")\n",
        "    ).reset_index()\n",
        "    by_book = bets.groupby(\"book\", dropna=False).agg(\n",
        "        n=(\"player\",\"count\"),\n",
        "        avg_edge_pp=(\"edge_over\", lambda x: 100.0*x.mean()),\n",
        "        avg_ev_1u=(\"EV_over_1u\",\"mean\")\n",
        "    ).reset_index()\n",
        "\n",
        "    if outfile_path is None:\n",
        "        outfile_path = f\"nba_value_bets_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "    with pd.ExcelWriter(outfile_path, engine=\"openpyxl\") as w:\n",
        "        bets.to_excel(w, sheet_name=\"Bets\", index=False)\n",
        "        summary.to_excel(w, sheet_name=\"Summary\", index=False, startrow=0)\n",
        "        by_market.to_excel(w, sheet_name=\"Summary\", index=False, startrow=5)\n",
        "        by_book.to_excel(w, sheet_name=\"Summary\", index=False, startrow=5+len(by_market)+3)\n",
        "\n",
        "        dd = pd.DataFrame([\n",
        "            (\"asof_date\",\"UTC run date\"), (\"game_date\",\"Game date\"),\n",
        "            (\"player\",\"Player\"), (\"team\",\"Team abbr\"), (\"opponent\",\"Opponent abbr\"),\n",
        "            (\"market\",\"PTS/REB/AST/3PM/PRA etc.\"), (\"line\",\"Book line\"), (\"book\",\"Sportsbook id\"),\n",
        "            (\"lineup_status\",\"EXPECTED/CONFIRMED/UNKNOWN\"),\n",
        "            (\"over_odds\",\"American odds Over\"), (\"under_odds\",\"American odds Under\"),\n",
        "            (\"p_over_imp\",\"Implied prob Over (pre-vig)\"), (\"p_under_imp\",\"Implied prob Under (pre-vig)\"),\n",
        "            (\"p_over_fair\",\"De-vigged prob Over\"), (\"p_under_fair\",\"De-vigged prob Under\"),\n",
        "            (\"p_over_model\",\"Model prob Over\"), (\"edge_over\",\"p_model âˆ’ p_fair\"),\n",
        "            (\"kelly_frac_over\",\"Kelly fraction (cap)\"), (\"EV_over_1u\",\"EV if staking 1u\"),\n",
        "            (\"projected_minutes\",\"Projected minutes\"), (\"projection_mean\",\"Projected mean\"),\n",
        "            (\"projection_sd\",\"Projected stdev\"), (\"start_prob\",\"Start probability\"),\n",
        "            (\"opponent_allowance_idx\",\"Opponent allowance index\"),\n",
        "            (\"team_orating\",\"Team ORtg\"), (\"opp_drating\",\"Opponent DRtg\"),\n",
        "        ], columns=[\"column\",\"description\"])\n",
        "        dd.to_excel(w, sheet_name=\"Data_Dictionary\", index=False)\n",
        "\n",
        "    return bets, outfile_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "4afd97de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 16: raw wide odds + resilient numeric parsing ===\n",
        "import re, json, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def _first_numeric_float(x):\n",
        "    \"\"\"Return the first decimal number in x (e.g., '23.5, 24.5' -> 23.5).\"\"\"\n",
        "    if x is None: return None\n",
        "    s = str(x)\n",
        "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", s)\n",
        "    return float(m.group()) if m else None\n",
        "\n",
        "def _first_numeric_int(x):\n",
        "    \"\"\"Return the first integer in x (e.g., '+110, +105' -> 110).\"\"\"\n",
        "    if x is None: return None\n",
        "    s = str(x)\n",
        "    m = re.search(r\"[-+]?\\d+\", s)\n",
        "    return int(m.group()) if m else None\n",
        "\n",
        "# override the helpers used by 16d converter (if defined)\n",
        "def _to_float_or_none(x):  # noqa: F811\n",
        "    return _first_numeric_float(x)\n",
        "\n",
        "def _to_int_or_none(x):    # noqa: F811\n",
        "    return _first_numeric_int(x)\n",
        "\n",
        "def get_player_props_odds_wide_raw(self, book=\"mgm\"):\n",
        "    \"\"\"\n",
        "    Returns the raw 'wide' odds table from Rotowire (no grouping, no aggregation).\n",
        "    Contains columns like mgm_pts, mgm_ptsOver, mgm_ptsUnder, etc.\n",
        "    \"\"\"\n",
        "    url = f\"https://www.rotowire.com/betting/nba/player-props.php?book={book}\"\n",
        "    r = self.session.get(url, headers=self.headers, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    matches = re.findall(r'data:\\s*(\\[\\{.*?\\}\\])', r.text, flags=re.DOTALL)\n",
        "    frames = []\n",
        "    for blob in matches:\n",
        "        try:\n",
        "            frames.append(pd.DataFrame(json.loads(blob)))\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not frames:\n",
        "        return pd.DataFrame()\n",
        "    # concat all blocks without grouping to preserve raw book columns\n",
        "    wide_raw = pd.concat(frames, ignore_index=True)\n",
        "    return wide_raw\n",
        "\n",
        "# attach to your scraper class\n",
        "NBAOddsAndLineupsScraper.get_player_props_odds_wide_raw = get_player_props_odds_wide_raw\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "fe88486d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Projection rows by market: {'PTS': 694, 'REB': 694, 'AST': 694}\n"
          ]
        }
      ],
      "source": [
        "# === Cell 16: projections for PTS/REB/AST using your trained RF models ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Safety checks\n",
        "if \"models\" not in globals() or not models:\n",
        "    raise RuntimeError(\"No trained models found. Run Cell 7 first to populate `models` and `feature_cols_by_stat`.\")\n",
        "\n",
        "# We'll project for these markets\n",
        "MARKETS = [\"PTS\", \"REB\", \"AST\"]\n",
        "\n",
        "# Latest row per player as basis for \"next game\"\n",
        "latest = features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).groupby(\"PLAYER_NAME\").tail(1).copy()\n",
        "\n",
        "# Helper: per-stat stdev from last N actual games\n",
        "def _player_sd_map(stat: str, n=10):\n",
        "    def _sd(g):\n",
        "        s = g[stat].tail(n)\n",
        "        if s.notna().sum() >= 4:\n",
        "            return float(s.std(ddof=1))\n",
        "        return float(features_all[stat].std(ddof=1))\n",
        "    return features_all.groupby(\"PLAYER_NAME\").apply(_sd)\n",
        "\n",
        "# Normalize export keys common to all markets\n",
        "base_cols = {\n",
        "    \"PLAYER_NAME\": \"player\",\n",
        "    \"TEAM_ABBREVIATION\": \"team\",\n",
        "    \"OPPONENT_ABBREVIATION\": \"opponent\",\n",
        "}\n",
        "base_out = latest.rename(columns=base_cols)[[\"player\",\"team\",\"opponent\"]].copy()\n",
        "base_out[\"game_date\"] = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "base_out[\"projected_minutes\"] = latest.get(\"MIN_roll5\", pd.Series(index=latest.index)).fillna(30).clip(lower=10, upper=40).values\n",
        "base_out[\"start_prob\"] = 0.90\n",
        "base_out[\"lineup_status\"] = \"EXPECTED\"\n",
        "\n",
        "# Build one projection frame per market\n",
        "proj_frames = {}\n",
        "for stat in MARKETS:\n",
        "    if stat not in models:\n",
        "        print(f\"âš ï¸ Skipping {stat}: model not found in `models`.\")\n",
        "        continue\n",
        "    feat_cols = feature_cols_by_stat.get(stat, [])\n",
        "    if not feat_cols:\n",
        "        print(f\"âš ï¸ Skipping {stat}: no feature columns recorded in `feature_cols_by_stat`.\")\n",
        "        continue\n",
        "\n",
        "    X_pred = latest[feat_cols].fillna(method=\"ffill\").fillna(0)\n",
        "    pred_mean = models[stat].predict(X_pred)\n",
        "\n",
        "    # per-player SD\n",
        "    sd_map = _player_sd_map(stat)\n",
        "    pred_sd = latest[\"PLAYER_NAME\"].map(sd_map)\n",
        "    # conservative fallback SD = 15% of mean (min 1.0)\n",
        "    sd_fallback = np.maximum(np.abs(pred_mean) * 0.15, 1.0)\n",
        "    pred_sd = np.where(np.isnan(pred_sd), sd_fallback, pred_sd)\n",
        "\n",
        "    dfp = base_out.copy()\n",
        "    dfp[\"projection_mean\"] = pred_mean\n",
        "    dfp[\"projection_sd\"] = pred_sd\n",
        "    dfp[\"market\"] = stat\n",
        "\n",
        "    # Expose per-market frames\n",
        "    proj_frames[stat] = dfp[[\"player\",\"team\",\"opponent\",\"game_date\",\"market\",\n",
        "                             \"projection_mean\",\"projection_sd\",\"projected_minutes\",\"start_prob\",\"lineup_status\"]].copy()\n",
        "\n",
        "# Individual frames (kept for backward compatibility)\n",
        "df_projections_pts = proj_frames.get(\"PTS\", pd.DataFrame())\n",
        "df_projections_reb = proj_frames.get(\"REB\", pd.DataFrame())\n",
        "df_projections_ast = proj_frames.get(\"AST\", pd.DataFrame())\n",
        "\n",
        "# Combined projections across markets\n",
        "df_projections_all = pd.concat(list(proj_frames.values()), ignore_index=True) if proj_frames else pd.DataFrame()\n",
        "\n",
        "print(\"Projection rows by market:\",\n",
        "      {k: len(v) for k, v in proj_frames.items()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows in raw wide: 1661\n",
            "Books present in columns: ['betrivers', 'caesars', 'draftkings', 'espnbet', 'fanduel', 'hardrock', 'mgm']\n",
            "Books with lines: {'PTS': ['betrivers', 'caesars', 'draftkings', 'fanduel', 'hardrock', 'mgm'], 'REB': ['betrivers', 'caesars', 'draftkings', 'fanduel', 'hardrock', 'mgm'], 'AST': ['betrivers', 'caesars', 'draftkings', 'fanduel', 'hardrock', 'mgm']}\n",
            "odds_long rows: 1723\n",
            "odds_long columns: ['asof_date', 'book', 'player', 'team', 'opponent', 'market', 'line', 'over_odds', 'under_odds', 'game_date']\n",
            "    asof_date        book       player team opponent market  line  over_odds  \\\n",
            "0  2025-11-02   BETRIVERS  Luka Doncic  LAL      MIA    PTS  33.5       -106   \n",
            "1  2025-11-02     CAESARS  Luka Doncic  LAL      MIA    PTS  33.5       -114   \n",
            "2  2025-11-02  DRAFTKINGS  Luka Doncic  LAL      MIA    PTS  33.5       -109   \n",
            "3  2025-11-02     FANDUEL  Luka Doncic  LAL      MIA    PTS  32.5       -122   \n",
            "4  2025-11-02    HARDROCK  Luka Doncic  LAL      MIA    PTS  34.5       -105   \n",
            "\n",
            "   under_odds   game_date  \n",
            "0        -106  2025-11-02  \n",
            "1        -118  2025-11-02  \n",
            "2        -117  2025-11-02  \n",
            "3        -110  2025-11-02  \n",
            "4        -125  2025-11-02  \n",
            "\n",
            "Saved value bets to: nba_value_bets_20251102.xlsx\n",
            "300 value bets found across 3 markets.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asof_date</th>\n",
              "      <th>game_date</th>\n",
              "      <th>book</th>\n",
              "      <th>player</th>\n",
              "      <th>team</th>\n",
              "      <th>opponent</th>\n",
              "      <th>market</th>\n",
              "      <th>line</th>\n",
              "      <th>lineup_status</th>\n",
              "      <th>over_odds</th>\n",
              "      <th>...</th>\n",
              "      <th>projection_mean</th>\n",
              "      <th>projection_sd</th>\n",
              "      <th>start_prob</th>\n",
              "      <th>team_odds</th>\n",
              "      <th>opponent_odds</th>\n",
              "      <th>line_odds</th>\n",
              "      <th>book_odds</th>\n",
              "      <th>game_date_odds</th>\n",
              "      <th>over_odds_odds</th>\n",
              "      <th>under_odds_odds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>Aaron Wiggins</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>AST</td>\n",
              "      <td>2.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>140</td>\n",
              "      <td>...</td>\n",
              "      <td>6.986667</td>\n",
              "      <td>1.048000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>2.5</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>140</td>\n",
              "      <td>-183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>Jamal Shead</td>\n",
              "      <td>TOR</td>\n",
              "      <td>MEM</td>\n",
              "      <td>AST</td>\n",
              "      <td>4.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>134</td>\n",
              "      <td>...</td>\n",
              "      <td>8.957333</td>\n",
              "      <td>1.343600</td>\n",
              "      <td>0.9</td>\n",
              "      <td>TOR</td>\n",
              "      <td>MEM</td>\n",
              "      <td>4.5</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>134</td>\n",
              "      <td>-172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>MGM</td>\n",
              "      <td>Miles McBride</td>\n",
              "      <td>NYK</td>\n",
              "      <td>CHI</td>\n",
              "      <td>AST</td>\n",
              "      <td>2.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>130</td>\n",
              "      <td>...</td>\n",
              "      <td>7.988333</td>\n",
              "      <td>1.198250</td>\n",
              "      <td>0.9</td>\n",
              "      <td>NYK</td>\n",
              "      <td>CHI</td>\n",
              "      <td>2.5</td>\n",
              "      <td>MGM</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>130</td>\n",
              "      <td>-175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>Cam Thomas</td>\n",
              "      <td>BKN</td>\n",
              "      <td>PHI</td>\n",
              "      <td>AST</td>\n",
              "      <td>4.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>132</td>\n",
              "      <td>...</td>\n",
              "      <td>9.638750</td>\n",
              "      <td>1.445812</td>\n",
              "      <td>0.9</td>\n",
              "      <td>BKN</td>\n",
              "      <td>PHI</td>\n",
              "      <td>4.5</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>132</td>\n",
              "      <td>-170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>Patrick Williams</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>REB</td>\n",
              "      <td>3.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>132</td>\n",
              "      <td>...</td>\n",
              "      <td>5.968042</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>3.5</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>132</td>\n",
              "      <td>-172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>CAESARS</td>\n",
              "      <td>Isaiah Joe</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>REB</td>\n",
              "      <td>3.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>125</td>\n",
              "      <td>...</td>\n",
              "      <td>5.964167</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>3.5</td>\n",
              "      <td>CAESARS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>125</td>\n",
              "      <td>-185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>Josh Giddey</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>REB</td>\n",
              "      <td>8.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>15.633720</td>\n",
              "      <td>2.345058</td>\n",
              "      <td>0.9</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>8.5</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>116</td>\n",
              "      <td>-148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>CAESARS</td>\n",
              "      <td>Dyson Daniels</td>\n",
              "      <td>ATL</td>\n",
              "      <td>@CLE</td>\n",
              "      <td>REB</td>\n",
              "      <td>6.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>115</td>\n",
              "      <td>...</td>\n",
              "      <td>9.875780</td>\n",
              "      <td>1.481367</td>\n",
              "      <td>0.9</td>\n",
              "      <td>ATL</td>\n",
              "      <td>@CLE</td>\n",
              "      <td>6.5</td>\n",
              "      <td>CAESARS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>115</td>\n",
              "      <td>-157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>HARDROCK</td>\n",
              "      <td>Ayo Dosunmu</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>REB</td>\n",
              "      <td>2.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>110</td>\n",
              "      <td>...</td>\n",
              "      <td>5.002708</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>2.5</td>\n",
              "      <td>HARDROCK</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>110</td>\n",
              "      <td>-155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>Jaxson Hayes</td>\n",
              "      <td>LAL</td>\n",
              "      <td>MIA</td>\n",
              "      <td>PTS</td>\n",
              "      <td>4.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>6.943810</td>\n",
              "      <td>1.041571</td>\n",
              "      <td>0.9</td>\n",
              "      <td>LAL</td>\n",
              "      <td>MIA</td>\n",
              "      <td>4.5</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>116</td>\n",
              "      <td>-148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>MGM</td>\n",
              "      <td>Alex Caruso</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>PTS</td>\n",
              "      <td>8.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>105</td>\n",
              "      <td>...</td>\n",
              "      <td>18.924583</td>\n",
              "      <td>2.838688</td>\n",
              "      <td>0.9</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>8.5</td>\n",
              "      <td>MGM</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>105</td>\n",
              "      <td>-145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>MGM</td>\n",
              "      <td>Day'Ron Sharpe</td>\n",
              "      <td>BKN</td>\n",
              "      <td>PHI</td>\n",
              "      <td>AST</td>\n",
              "      <td>2.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>140</td>\n",
              "      <td>...</td>\n",
              "      <td>4.011875</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>BKN</td>\n",
              "      <td>PHI</td>\n",
              "      <td>2.5</td>\n",
              "      <td>MGM</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>140</td>\n",
              "      <td>-185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>MGM</td>\n",
              "      <td>Sandro Mamukelashvili</td>\n",
              "      <td>TOR</td>\n",
              "      <td>MEM</td>\n",
              "      <td>AST</td>\n",
              "      <td>2.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>140</td>\n",
              "      <td>...</td>\n",
              "      <td>3.990542</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>TOR</td>\n",
              "      <td>MEM</td>\n",
              "      <td>2.5</td>\n",
              "      <td>MGM</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>140</td>\n",
              "      <td>-190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>BETRIVERS</td>\n",
              "      <td>Keldon Johnson</td>\n",
              "      <td>SAS</td>\n",
              "      <td>@PHX</td>\n",
              "      <td>REB</td>\n",
              "      <td>5.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>106</td>\n",
              "      <td>...</td>\n",
              "      <td>8.972333</td>\n",
              "      <td>1.345850</td>\n",
              "      <td>0.9</td>\n",
              "      <td>SAS</td>\n",
              "      <td>@PHX</td>\n",
              "      <td>5.5</td>\n",
              "      <td>BETRIVERS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>106</td>\n",
              "      <td>-141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>Dyson Daniels</td>\n",
              "      <td>ATL</td>\n",
              "      <td>@CLE</td>\n",
              "      <td>AST</td>\n",
              "      <td>5.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>7.820958</td>\n",
              "      <td>1.173144</td>\n",
              "      <td>0.9</td>\n",
              "      <td>ATL</td>\n",
              "      <td>@CLE</td>\n",
              "      <td>5.5</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>116</td>\n",
              "      <td>-151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>Scottie Barnes</td>\n",
              "      <td>TOR</td>\n",
              "      <td>MEM</td>\n",
              "      <td>REB</td>\n",
              "      <td>7.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>114</td>\n",
              "      <td>...</td>\n",
              "      <td>10.880833</td>\n",
              "      <td>1.632125</td>\n",
              "      <td>0.9</td>\n",
              "      <td>TOR</td>\n",
              "      <td>MEM</td>\n",
              "      <td>7.5</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>114</td>\n",
              "      <td>-146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>Isaac Okoro</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>PTS</td>\n",
              "      <td>6.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>105</td>\n",
              "      <td>...</td>\n",
              "      <td>14.357792</td>\n",
              "      <td>2.153669</td>\n",
              "      <td>0.9</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>6.5</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>105</td>\n",
              "      <td>-134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>Zion Williamson</td>\n",
              "      <td>NOP</td>\n",
              "      <td>@OKC</td>\n",
              "      <td>AST</td>\n",
              "      <td>4.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>104</td>\n",
              "      <td>...</td>\n",
              "      <td>7.974750</td>\n",
              "      <td>1.196212</td>\n",
              "      <td>0.9</td>\n",
              "      <td>NOP</td>\n",
              "      <td>@OKC</td>\n",
              "      <td>4.5</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>104</td>\n",
              "      <td>-135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>MGM</td>\n",
              "      <td>Dalton Knecht</td>\n",
              "      <td>LAL</td>\n",
              "      <td>MIA</td>\n",
              "      <td>PTS</td>\n",
              "      <td>6.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>4.050000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>LAL</td>\n",
              "      <td>MIA</td>\n",
              "      <td>6.5</td>\n",
              "      <td>MGM</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>100</td>\n",
              "      <td>-135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>Patrick Williams</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>PTS</td>\n",
              "      <td>8.5</td>\n",
              "      <td>EXPECTED</td>\n",
              "      <td>103</td>\n",
              "      <td>...</td>\n",
              "      <td>15.069125</td>\n",
              "      <td>2.260369</td>\n",
              "      <td>0.9</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>8.5</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>103</td>\n",
              "      <td>-131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     asof_date   game_date        book                 player team opponent  \\\n",
              "0   2025-11-02  2025-11-02  DRAFTKINGS          Aaron Wiggins  OKC      NOP   \n",
              "1   2025-11-02  2025-11-02     FANDUEL            Jamal Shead  TOR      MEM   \n",
              "2   2025-11-02  2025-11-02         MGM          Miles McBride  NYK      CHI   \n",
              "3   2025-11-02  2025-11-02     FANDUEL             Cam Thomas  BKN      PHI   \n",
              "4   2025-11-02  2025-11-02  DRAFTKINGS       Patrick Williams  CHI     @NYK   \n",
              "5   2025-11-02  2025-11-02     CAESARS             Isaiah Joe  OKC      NOP   \n",
              "6   2025-11-02  2025-11-02     FANDUEL            Josh Giddey  CHI     @NYK   \n",
              "7   2025-11-02  2025-11-02     CAESARS          Dyson Daniels  ATL     @CLE   \n",
              "8   2025-11-02  2025-11-02    HARDROCK            Ayo Dosunmu  CHI     @NYK   \n",
              "9   2025-11-02  2025-11-02  DRAFTKINGS           Jaxson Hayes  LAL      MIA   \n",
              "10  2025-11-02  2025-11-02         MGM            Alex Caruso  OKC      NOP   \n",
              "11  2025-11-02  2025-11-02         MGM         Day'Ron Sharpe  BKN      PHI   \n",
              "12  2025-11-02  2025-11-02         MGM  Sandro Mamukelashvili  TOR      MEM   \n",
              "13  2025-11-02  2025-11-02   BETRIVERS         Keldon Johnson  SAS     @PHX   \n",
              "14  2025-11-02  2025-11-02  DRAFTKINGS          Dyson Daniels  ATL     @CLE   \n",
              "15  2025-11-02  2025-11-02     FANDUEL         Scottie Barnes  TOR      MEM   \n",
              "16  2025-11-02  2025-11-02  DRAFTKINGS            Isaac Okoro  CHI     @NYK   \n",
              "17  2025-11-02  2025-11-02  DRAFTKINGS        Zion Williamson  NOP     @OKC   \n",
              "18  2025-11-02  2025-11-02         MGM          Dalton Knecht  LAL      MIA   \n",
              "19  2025-11-02  2025-11-02  DRAFTKINGS       Patrick Williams  CHI     @NYK   \n",
              "\n",
              "   market  line lineup_status  over_odds  ...  projection_mean  projection_sd  \\\n",
              "0     AST   2.5      EXPECTED        140  ...         6.986667       1.048000   \n",
              "1     AST   4.5      EXPECTED        134  ...         8.957333       1.343600   \n",
              "2     AST   2.5      EXPECTED        130  ...         7.988333       1.198250   \n",
              "3     AST   4.5      EXPECTED        132  ...         9.638750       1.445812   \n",
              "4     REB   3.5      EXPECTED        132  ...         5.968042       1.000000   \n",
              "5     REB   3.5      EXPECTED        125  ...         5.964167       1.000000   \n",
              "6     REB   8.5      EXPECTED        116  ...        15.633720       2.345058   \n",
              "7     REB   6.5      EXPECTED        115  ...         9.875780       1.481367   \n",
              "8     REB   2.5      EXPECTED        110  ...         5.002708       1.000000   \n",
              "9     PTS   4.5      EXPECTED        116  ...         6.943810       1.041571   \n",
              "10    PTS   8.5      EXPECTED        105  ...        18.924583       2.838688   \n",
              "11    AST   2.5      EXPECTED        140  ...         4.011875       1.000000   \n",
              "12    AST   2.5      EXPECTED        140  ...         3.990542       1.000000   \n",
              "13    REB   5.5      EXPECTED        106  ...         8.972333       1.345850   \n",
              "14    AST   5.5      EXPECTED        116  ...         7.820958       1.173144   \n",
              "15    REB   7.5      EXPECTED        114  ...        10.880833       1.632125   \n",
              "16    PTS   6.5      EXPECTED        105  ...        14.357792       2.153669   \n",
              "17    AST   4.5      EXPECTED        104  ...         7.974750       1.196212   \n",
              "18    PTS   6.5      EXPECTED        100  ...        27.000000       4.050000   \n",
              "19    PTS   8.5      EXPECTED        103  ...        15.069125       2.260369   \n",
              "\n",
              "    start_prob  team_odds  opponent_odds  line_odds   book_odds  \\\n",
              "0          0.9        OKC            NOP        2.5  DRAFTKINGS   \n",
              "1          0.9        TOR            MEM        4.5     FANDUEL   \n",
              "2          0.9        NYK            CHI        2.5         MGM   \n",
              "3          0.9        BKN            PHI        4.5     FANDUEL   \n",
              "4          0.9        CHI           @NYK        3.5  DRAFTKINGS   \n",
              "5          0.9        OKC            NOP        3.5     CAESARS   \n",
              "6          0.9        CHI           @NYK        8.5     FANDUEL   \n",
              "7          0.9        ATL           @CLE        6.5     CAESARS   \n",
              "8          0.9        CHI           @NYK        2.5    HARDROCK   \n",
              "9          0.9        LAL            MIA        4.5  DRAFTKINGS   \n",
              "10         0.9        OKC            NOP        8.5         MGM   \n",
              "11         0.9        BKN            PHI        2.5         MGM   \n",
              "12         0.9        TOR            MEM        2.5         MGM   \n",
              "13         0.9        SAS           @PHX        5.5   BETRIVERS   \n",
              "14         0.9        ATL           @CLE        5.5  DRAFTKINGS   \n",
              "15         0.9        TOR            MEM        7.5     FANDUEL   \n",
              "16         0.9        CHI           @NYK        6.5  DRAFTKINGS   \n",
              "17         0.9        NOP           @OKC        4.5  DRAFTKINGS   \n",
              "18         0.9        LAL            MIA        6.5         MGM   \n",
              "19         0.9        CHI           @NYK        8.5  DRAFTKINGS   \n",
              "\n",
              "    game_date_odds  over_odds_odds  under_odds_odds  \n",
              "0       2025-11-02             140             -183  \n",
              "1       2025-11-02             134             -172  \n",
              "2       2025-11-02             130             -175  \n",
              "3       2025-11-02             132             -170  \n",
              "4       2025-11-02             132             -172  \n",
              "5       2025-11-02             125             -185  \n",
              "6       2025-11-02             116             -148  \n",
              "7       2025-11-02             115             -157  \n",
              "8       2025-11-02             110             -155  \n",
              "9       2025-11-02             116             -148  \n",
              "10      2025-11-02             105             -145  \n",
              "11      2025-11-02             140             -185  \n",
              "12      2025-11-02             140             -190  \n",
              "13      2025-11-02             106             -141  \n",
              "14      2025-11-02             116             -151  \n",
              "15      2025-11-02             114             -146  \n",
              "16      2025-11-02             105             -134  \n",
              "17      2025-11-02             104             -135  \n",
              "18      2025-11-02             100             -135  \n",
              "19      2025-11-02             103             -131  \n",
              "\n",
              "[20 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# === Cell 17: wide_raw â†’ long (PTS/REB/AST) â†’ join â†’ export ===\n",
        "from datetime import datetime\n",
        "import re, unicodedata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "scraper = NBAOddsAndLineupsScraper()\n",
        "\n",
        "# 1) Raw wide odds (no grouping)\n",
        "wide_raw = scraper.get_player_props_odds_wide_raw(book=\"mgm\")\n",
        "if wide_raw.empty:\n",
        "    raise RuntimeError(\"Raw wide odds are empty. The page structure may have changed or was blocked.\")\n",
        "\n",
        "print(\"Total rows in raw wide:\", len(wide_raw))\n",
        "\n",
        "# 2) Detect books present\n",
        "books_seen = sorted({\n",
        "    m.group(1) for c in wide_raw.columns\n",
        "    if (m := re.match(r\"^(draftkings|fanduel|caesars|betrivers|espnbet|hardrock|mgm)_(.+)$\", c))\n",
        "})\n",
        "print(\"Books present in columns:\", books_seen)\n",
        "\n",
        "def _col_exists_nonnull(df, col):\n",
        "    return (col in df.columns) and df[col].notna().any()\n",
        "\n",
        "# Which books have each market today?\n",
        "market_suffix = {\"PTS\":\"pts\",\"REB\":\"reb\",\"AST\":\"ast\"}\n",
        "books_by_market = {\n",
        "    m: [b for b in books_seen if _col_exists_nonnull(wide_raw, f\"{b}_{market_suffix[m]}\")]\n",
        "    for m in [\"PTS\",\"REB\",\"AST\"]\n",
        "}\n",
        "print(\"Books with lines:\", {m: v for m, v in books_by_market.items() if v})\n",
        "\n",
        "# 3) Convert wide â†’ long for markets that actually have any lines\n",
        "target_markets = tuple([m for m, bs in books_by_market.items() if bs])\n",
        "if not target_markets:\n",
        "    raise RuntimeError(\"No books have non-null PTS/REB/AST lines today.\")\n",
        "\n",
        "odds_long = odds_wide_to_long_from_columns(\n",
        "    wide_raw,\n",
        "    books=tuple(sorted({b for bs in books_by_market.values() for b in bs})),\n",
        "    markets=target_markets\n",
        ")\n",
        "if odds_long.empty:\n",
        "    raise RuntimeError(\"odds_long is empty after conversion. Verify your `odds_wide_to_long_from_columns` mapping.\")\n",
        "\n",
        "# Normalize obvious numerics\n",
        "def _num_float(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
        "    return float(m.group()) if m else np.nan\n",
        "\n",
        "def _num_int(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    m = re.search(r\"[-+]?\\d+\", str(x))\n",
        "    return int(m.group()) if m else np.nan\n",
        "\n",
        "odds_long[\"line\"] = odds_long[\"line\"].apply(_num_float)\n",
        "odds_long[\"over_odds\"] = odds_long[\"over_odds\"].apply(_num_int)\n",
        "odds_long[\"under_odds\"] = odds_long[\"under_odds\"].apply(_num_int)\n",
        "\n",
        "print(\"odds_long rows:\", len(odds_long))\n",
        "print(\"odds_long columns:\", odds_long.columns.tolist())\n",
        "print(odds_long.head(5))\n",
        "\n",
        "# 4) Prepare projections union (must be created earlier, e.g., Cell 16e)\n",
        "if \"df_projections_all\" not in globals() or df_projections_all.empty:\n",
        "    raise RuntimeError(\"df_projections_all not found or empty (run Cell 16 that builds PTS/REB/AST projections).\")\n",
        "\n",
        "# Light name normalizer\n",
        "def _norm_player(name: str) -> str:\n",
        "    if not isinstance(name, str): return \"\"\n",
        "    s = unicodedata.normalize(\"NFKD\", name)\n",
        "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    s = re.sub(r\"[.\\-`'â€™]\", \"\", s).strip().lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "odds_long = odds_long.copy()\n",
        "df_projections_all = df_projections_all.copy()\n",
        "\n",
        "odds_long[\"player_key\"] = odds_long[\"player\"].map(_norm_player)\n",
        "df_projections_all[\"player_key\"] = df_projections_all[\"player\"].map(_norm_player)\n",
        "\n",
        "# Ensure projection SD exists per market (fallback to 15% of mean, min 1.0)\n",
        "for m in [\"PTS\",\"REB\",\"AST\"]:\n",
        "    mask = df_projections_all[\"market\"].eq(m)\n",
        "    if \"projection_sd\" not in df_projections_all.columns:\n",
        "        df_projections_all[\"projection_sd\"] = np.nan\n",
        "    missing_sd = df_projections_all.loc[mask, \"projection_sd\"].isna() | (df_projections_all.loc[mask, \"projection_sd\"] <= 0)\n",
        "    if missing_sd.any():\n",
        "        df_projections_all.loc[mask, \"projection_sd\"] = (\n",
        "            df_projections_all.loc[mask, \"projection_mean\"].abs() * 0.15\n",
        "        ).clip(lower=1.0)\n",
        "\n",
        "# 5) Split and join per market, then combine\n",
        "joined_frames = []\n",
        "for mkt in target_markets:\n",
        "    odds_m = odds_long.loc[odds_long[\"market\"].eq(mkt)].copy()\n",
        "    proj_m = df_projections_all.loc[df_projections_all[\"market\"].eq(mkt)].copy()\n",
        "    if odds_m.empty or proj_m.empty:\n",
        "        print(f\"âš ï¸ Skipping {mkt}: odds or projections empty.\")\n",
        "        continue\n",
        "\n",
        "    join_keys = [\"player_key\",\"market\"]\n",
        "    view_cols_odds = join_keys + [\"player\",\"team\",\"opponent\",\"line\",\"book\",\"game_date\",\"over_odds\",\"under_odds\"]\n",
        "    view_cols_odds = [c for c in view_cols_odds if c in odds_m.columns]\n",
        "\n",
        "    view_cols_proj = join_keys + [\n",
        "        \"player\",\"team\",\"opponent\",\"game_date\",\"projection_mean\",\"projection_sd\",\n",
        "        \"projected_minutes\",\"start_prob\",\"lineup_status\"\n",
        "    ]\n",
        "    view_cols_proj = [c for c in view_cols_proj if c in proj_m.columns]\n",
        "\n",
        "    dfj = proj_m[view_cols_proj].merge(\n",
        "        odds_m[view_cols_odds].rename(columns={\"player\":\"player_odds\",\"team\":\"team_odds\",\"opponent\":\"opponent_odds\",\"game_date\":\"game_date_odds\"}),\n",
        "        on=join_keys, how=\"inner\", suffixes=(\"_proj\",\"_odds\")\n",
        "    )\n",
        "\n",
        "    if dfj.empty:\n",
        "        print(f\"âš ï¸ Join produced 0 rows for {mkt}. Check name variants.\")\n",
        "        continue\n",
        "\n",
        "    # Resolve canonical columns\n",
        "    def _pick_first(df_, names, default=np.nan):\n",
        "        for n in names:\n",
        "            if n in df_.columns:\n",
        "                return df_[n]\n",
        "        return default\n",
        "\n",
        "    dfj = dfj.loc[:, ~dfj.columns.duplicated()].copy()\n",
        "    dfj[\"player\"]    = _pick_first(dfj, [\"player_odds\",\"player_proj\",\"player\"])\n",
        "    dfj[\"team\"]      = _pick_first(dfj, [\"team_odds\",\"team_proj\",\"team\"])\n",
        "    dfj[\"opponent\"]  = _pick_first(dfj, [\"opponent_odds\",\"opponent_proj\",\"opponent\"])\n",
        "    dfj[\"game_date\"] = _pick_first(dfj, [\"game_date_odds\",\"game_date_proj\",\"game_date\"])\n",
        "    # line already numeric above, but if any slipped through:\n",
        "    dfj[\"line\"] = dfj[\"line\"].apply(_num_float)\n",
        "\n",
        "    # Compute model probability P(Over)\n",
        "    if \"p_over_from_normal\" not in globals():\n",
        "        from statistics import NormalDist\n",
        "        def p_over_from_normal(mu, sd, line):\n",
        "            if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or float(sd) <= 0: return np.nan\n",
        "            z = (float(line) - float(mu)) / float(sd)\n",
        "            return 1.0 - NormalDist().cdf(z)\n",
        "\n",
        "    dfj[\"p_over_model\"] = dfj.apply(\n",
        "        lambda r: p_over_from_normal(r.get(\"projection_mean\"), r.get(\"projection_sd\"), r.get(\"line\")), axis=1\n",
        "    )\n",
        "\n",
        "    # Implied/fair probabilities + edge (so we can pick best book later)\n",
        "    def implied_prob(american):\n",
        "        o = _num_int(american)\n",
        "        if pd.isna(o): return np.nan\n",
        "        return (-o)/(-o+100.0) if o < 0 else 100.0/(o+100.0)\n",
        "\n",
        "    dfj[\"p_over_imp\"]  = dfj[\"over_odds\"].apply(implied_prob)\n",
        "    dfj[\"p_under_imp\"] = dfj[\"under_odds\"].apply(implied_prob)\n",
        "\n",
        "    def devig_pair(p_over_imp, p_under_imp):\n",
        "        if pd.isna(p_over_imp) or pd.isna(p_under_imp):\n",
        "            return (np.nan, np.nan)\n",
        "        s = p_over_imp + p_under_imp\n",
        "        if s <= 0:\n",
        "            return (np.nan, np.nan)\n",
        "        return (p_over_imp/s, p_under_imp/s)\n",
        "\n",
        "    fair = dfj.apply(\n",
        "        lambda r: pd.Series(devig_pair(r[\"p_over_imp\"], r[\"p_under_imp\"]), index=[\"p_over_fair\",\"p_under_fair\"]),\n",
        "        axis=1\n",
        "    )\n",
        "    dfj = pd.concat([dfj, fair], axis=1)\n",
        "\n",
        "    dfj[\"edge_over\"] = np.where(\n",
        "        dfj[\"p_over_fair\"].notna(),\n",
        "        dfj[\"p_over_model\"] - dfj[\"p_over_fair\"],\n",
        "        dfj[\"p_over_model\"] - dfj[\"p_over_imp\"]\n",
        "    )\n",
        "\n",
        "    # Keep the best book per player/market (highest edge)\n",
        "    dfj = dfj.sort_values([\"player\",\"market\",\"edge_over\"], ascending=[True, True, False])\n",
        "    dfj = dfj.drop_duplicates(subset=[\"player\",\"market\"], keep=\"first\")\n",
        "\n",
        "    joined_frames.append(\n",
        "        dfj[[\n",
        "            \"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\"game_date\",\n",
        "            \"over_odds\",\"under_odds\",\"projection_mean\",\"projection_sd\",\n",
        "            \"projected_minutes\",\"start_prob\",\"lineup_status\",\"p_over_model\",\"edge_over\"\n",
        "        ]]\n",
        "    )\n",
        "\n",
        "# Combined joined frame for all markets\n",
        "if not joined_frames:\n",
        "    raise RuntimeError(\"No joined rows produced for any market.\")\n",
        "df_proj_join_all = pd.concat(joined_frames, ignore_index=True)\n",
        "\n",
        "# 6) Prepare odds slice for Excel builder\n",
        "df_odds_for_excel = df_proj_join_all[[\n",
        "    \"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\"game_date\",\"over_odds\",\"under_odds\"\n",
        "]].copy()\n",
        "\n",
        "# 7) Export full bets workbook\n",
        "bets, excel_path = build_value_bets_excel(\n",
        "    df_projections=df_proj_join_all,\n",
        "    df_odds=df_odds_for_excel,\n",
        "    outfile_path=f\"nba_value_bets_{datetime.utcnow().strftime('%Y%m%d')}.xlsx\",\n",
        "    join_keys=(\"player\",\"market\")  # permissive merge\n",
        ")\n",
        "\n",
        "print(f\"\\nSaved value bets to: {excel_path}\")\n",
        "print(len(bets), \"value bets found across\", df_proj_join_all['market'].nunique(), \"markets.\")\n",
        "display(bets.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved Top-100 value bets (PTS/REB/AST) to: value_bets_top100_20251102.xlsx\n",
            "Positive-edge available: 155; Exported: 300\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>player</th>\n",
              "      <th>team</th>\n",
              "      <th>opponent</th>\n",
              "      <th>market</th>\n",
              "      <th>posted_line</th>\n",
              "      <th>expected_line</th>\n",
              "      <th>book</th>\n",
              "      <th>over_odds</th>\n",
              "      <th>under_odds</th>\n",
              "      <th>edge_rank</th>\n",
              "      <th>p_over_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>Aaron Wiggins</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>AST</td>\n",
              "      <td>2.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>140</td>\n",
              "      <td>-183</td>\n",
              "      <td>0.608132</td>\n",
              "      <td>0.999991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aaron Wiggins</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>PTS</td>\n",
              "      <td>15.5</td>\n",
              "      <td>27.9</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>-109</td>\n",
              "      <td>-117</td>\n",
              "      <td>0.506768</td>\n",
              "      <td>0.998453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>Aaron Wiggins</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>REB</td>\n",
              "      <td>4.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>HARDROCK</td>\n",
              "      <td>-130</td>\n",
              "      <td>-105</td>\n",
              "      <td>0.466619</td>\n",
              "      <td>0.991226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adem Bona</td>\n",
              "      <td>PHI</td>\n",
              "      <td>@BKN</td>\n",
              "      <td>PTS</td>\n",
              "      <td>8.5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>BETRIVERS</td>\n",
              "      <td>112</td>\n",
              "      <td>-106</td>\n",
              "      <td>0.520814</td>\n",
              "      <td>0.999082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>Adem Bona</td>\n",
              "      <td>PHI</td>\n",
              "      <td>@BKN</td>\n",
              "      <td>REB</td>\n",
              "      <td>6.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>108</td>\n",
              "      <td>-138</td>\n",
              "      <td>0.512892</td>\n",
              "      <td>0.966191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>Alex Caruso</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>AST</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>HARDROCK</td>\n",
              "      <td>115</td>\n",
              "      <td>-165</td>\n",
              "      <td>0.272906</td>\n",
              "      <td>0.700498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alex Caruso</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>PTS</td>\n",
              "      <td>8.5</td>\n",
              "      <td>18.9</td>\n",
              "      <td>MGM</td>\n",
              "      <td>105</td>\n",
              "      <td>-145</td>\n",
              "      <td>0.548059</td>\n",
              "      <td>0.999880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>Alex Caruso</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>REB</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>118</td>\n",
              "      <td>-150</td>\n",
              "      <td>0.499377</td>\n",
              "      <td>0.932653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>Andrew Wiggins</td>\n",
              "      <td>MIA</td>\n",
              "      <td>@LAL</td>\n",
              "      <td>AST</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>MGM</td>\n",
              "      <td>110</td>\n",
              "      <td>-145</td>\n",
              "      <td>0.255007</td>\n",
              "      <td>0.700867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Andrew Wiggins</td>\n",
              "      <td>MIA</td>\n",
              "      <td>@LAL</td>\n",
              "      <td>REB</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.9</td>\n",
              "      <td>HARDROCK</td>\n",
              "      <td>-110</td>\n",
              "      <td>-130</td>\n",
              "      <td>0.192306</td>\n",
              "      <td>0.673295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Austin Reaves</td>\n",
              "      <td>LAL</td>\n",
              "      <td>MIA</td>\n",
              "      <td>REB</td>\n",
              "      <td>4.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>BETRIVERS</td>\n",
              "      <td>100</td>\n",
              "      <td>-132</td>\n",
              "      <td>0.523125</td>\n",
              "      <td>0.990867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Ayo Dosunmu</td>\n",
              "      <td>CHI</td>\n",
              "      <td>@NYK</td>\n",
              "      <td>REB</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>HARDROCK</td>\n",
              "      <td>110</td>\n",
              "      <td>-155</td>\n",
              "      <td>0.554561</td>\n",
              "      <td>0.993838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>Bam Adebayo</td>\n",
              "      <td>MIA</td>\n",
              "      <td>@LAL</td>\n",
              "      <td>AST</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.1</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>100</td>\n",
              "      <td>-130</td>\n",
              "      <td>0.240324</td>\n",
              "      <td>0.709711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bam Adebayo</td>\n",
              "      <td>MIA</td>\n",
              "      <td>@LAL</td>\n",
              "      <td>PTS</td>\n",
              "      <td>20.5</td>\n",
              "      <td>22.9</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>-114</td>\n",
              "      <td>-114</td>\n",
              "      <td>0.253685</td>\n",
              "      <td>0.753685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Bam Adebayo</td>\n",
              "      <td>MIA</td>\n",
              "      <td>@LAL</td>\n",
              "      <td>REB</td>\n",
              "      <td>9.5</td>\n",
              "      <td>11.9</td>\n",
              "      <td>MGM</td>\n",
              "      <td>110</td>\n",
              "      <td>-150</td>\n",
              "      <td>0.465203</td>\n",
              "      <td>0.907681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>Brandon Ingram</td>\n",
              "      <td>TOR</td>\n",
              "      <td>MEM</td>\n",
              "      <td>AST</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.8</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>-153</td>\n",
              "      <td>118</td>\n",
              "      <td>0.066087</td>\n",
              "      <td>0.634744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>Cam Thomas</td>\n",
              "      <td>BKN</td>\n",
              "      <td>PHI</td>\n",
              "      <td>AST</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.6</td>\n",
              "      <td>FANDUEL</td>\n",
              "      <td>132</td>\n",
              "      <td>-170</td>\n",
              "      <td>0.593429</td>\n",
              "      <td>0.999810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>Cam Thomas</td>\n",
              "      <td>BKN</td>\n",
              "      <td>PHI</td>\n",
              "      <td>REB</td>\n",
              "      <td>2.5</td>\n",
              "      <td>6.1</td>\n",
              "      <td>MGM</td>\n",
              "      <td>-105</td>\n",
              "      <td>-125</td>\n",
              "      <td>0.520136</td>\n",
              "      <td>0.999832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Cason Wallace</td>\n",
              "      <td>OKC</td>\n",
              "      <td>NOP</td>\n",
              "      <td>PTS</td>\n",
              "      <td>9.5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>DRAFTKINGS</td>\n",
              "      <td>-113</td>\n",
              "      <td>-113</td>\n",
              "      <td>0.319038</td>\n",
              "      <td>0.819038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Collin Gillespie</td>\n",
              "      <td>PHX</td>\n",
              "      <td>SAS</td>\n",
              "      <td>PTS</td>\n",
              "      <td>11.5</td>\n",
              "      <td>12.0</td>\n",
              "      <td>HARDROCK</td>\n",
              "      <td>-120</td>\n",
              "      <td>-110</td>\n",
              "      <td>0.097650</td>\n",
              "      <td>0.607772</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               player team opponent market  posted_line  expected_line  \\\n",
              "211     Aaron Wiggins  OKC      NOP    AST          2.5            7.0   \n",
              "0       Aaron Wiggins  OKC      NOP    PTS         15.5           27.9   \n",
              "108     Aaron Wiggins  OKC      NOP    REB          4.5            7.0   \n",
              "1           Adem Bona  PHI     @BKN    PTS          8.5           16.0   \n",
              "109         Adem Bona  PHI     @BKN    REB          6.5            9.0   \n",
              "213       Alex Caruso  OKC      NOP    AST          2.5            3.0   \n",
              "3         Alex Caruso  OKC      NOP    PTS          8.5           18.9   \n",
              "111       Alex Caruso  OKC      NOP    REB          3.5            5.0   \n",
              "214    Andrew Wiggins  MIA     @LAL    AST          2.5            3.0   \n",
              "113    Andrew Wiggins  MIA     @LAL    REB          4.5            4.9   \n",
              "114     Austin Reaves  LAL      MIA    REB          4.5            7.0   \n",
              "115       Ayo Dosunmu  CHI     @NYK    REB          2.5            5.0   \n",
              "217       Bam Adebayo  MIA     @LAL    AST          3.5            4.1   \n",
              "8         Bam Adebayo  MIA     @LAL    PTS         20.5           22.9   \n",
              "116       Bam Adebayo  MIA     @LAL    REB          9.5           11.9   \n",
              "218    Brandon Ingram  TOR      MEM    AST          3.5            3.8   \n",
              "219        Cam Thomas  BKN      PHI    AST          4.5            9.6   \n",
              "118        Cam Thomas  BKN      PHI    REB          2.5            6.1   \n",
              "11      Cason Wallace  OKC      NOP    PTS          9.5           11.0   \n",
              "12   Collin Gillespie  PHX      SAS    PTS         11.5           12.0   \n",
              "\n",
              "           book  over_odds  under_odds  edge_rank  p_over_model  \n",
              "211  DRAFTKINGS        140        -183   0.608132      0.999991  \n",
              "0    DRAFTKINGS       -109        -117   0.506768      0.998453  \n",
              "108    HARDROCK       -130        -105   0.466619      0.991226  \n",
              "1     BETRIVERS        112        -106   0.520814      0.999082  \n",
              "109     FANDUEL        108        -138   0.512892      0.966191  \n",
              "213    HARDROCK        115        -165   0.272906      0.700498  \n",
              "3           MGM        105        -145   0.548059      0.999880  \n",
              "111     FANDUEL        118        -150   0.499377      0.932653  \n",
              "214         MGM        110        -145   0.255007      0.700867  \n",
              "113    HARDROCK       -110        -130   0.192306      0.673295  \n",
              "114   BETRIVERS        100        -132   0.523125      0.990867  \n",
              "115    HARDROCK        110        -155   0.554561      0.993838  \n",
              "217  DRAFTKINGS        100        -130   0.240324      0.709711  \n",
              "8       FANDUEL       -114        -114   0.253685      0.753685  \n",
              "116         MGM        110        -150   0.465203      0.907681  \n",
              "218  DRAFTKINGS       -153         118   0.066087      0.634744  \n",
              "219     FANDUEL        132        -170   0.593429      0.999810  \n",
              "118         MGM       -105        -125   0.520136      0.999832  \n",
              "11   DRAFTKINGS       -113        -113   0.319038      0.819038  \n",
              "12     HARDROCK       -120        -110   0.097650      0.607772  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# === Cell: Build & export Top-100 Value Bets (PTS/REB/AST) â€” robust & lean ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# ---- 0) Source table ---------------------------------------------------------\n",
        "if \"df_proj_join_all\" in globals() and isinstance(df_proj_join_all, pd.DataFrame) and not df_proj_join_all.empty:\n",
        "    df = df_proj_join_all.copy()\n",
        "elif \"bets\" in globals() and isinstance(bets, pd.DataFrame) and not bets.empty:\n",
        "    df = bets.copy()\n",
        "elif \"df_proj_join\" in globals() and isinstance(df_proj_join, pd.DataFrame) and not df_proj_join.empty:\n",
        "    df = df_proj_join.copy()\n",
        "else:\n",
        "    raise RuntimeError(\"No joined dataset found (df_proj_join_all/bets/df_proj_join). Run the join cell first.\")\n",
        "\n",
        "# ---- 1) Canonicalize minimal fields -----------------------------------------\n",
        "def _pick(df_, names):\n",
        "    for n in names:\n",
        "        if n in df_.columns:\n",
        "            return df_[n]\n",
        "    return pd.Series([np.nan]*len(df_))\n",
        "\n",
        "df = df.copy()\n",
        "df[\"player\"]          = _pick(df, [\"player\",\"player_proj\",\"player_odds\"])\n",
        "df[\"team\"]            = _pick(df, [\"team\",\"team_proj\",\"team_odds\"])\n",
        "df[\"opponent\"]        = _pick(df, [\"opponent\",\"opponent_proj\",\"opponent_odds\"])\n",
        "df[\"market\"]          = _pick(df, [\"market\"])\n",
        "df[\"line\"]            = _pick(df, [\"line\",\"posted_line\",\"book_line\"])\n",
        "df[\"book\"]            = _pick(df, [\"book\"])\n",
        "df[\"over_odds\"]       = _pick(df, [\"over_odds\"])\n",
        "df[\"under_odds\"]      = _pick(df, [\"under_odds\"])\n",
        "df[\"projection_mean\"] = _pick(df, [\"projection_mean\",\"expected_line\"])\n",
        "df[\"projection_sd\"]   = _pick(df, [\"projection_sd\"])\n",
        "\n",
        "# ---- 2) Coerce numerics ------------------------------------------------------\n",
        "def _first_float(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
        "    return float(m.group()) if m else np.nan\n",
        "\n",
        "def _first_int(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    m = re.search(r\"[-+]?\\d+\", str(x))\n",
        "    return float(m.group()) if m else np.nan\n",
        "\n",
        "for col in [\"line\",\"projection_mean\",\"projection_sd\"]:\n",
        "    df[col] = df[col].apply(_first_float)\n",
        "\n",
        "# ---- 3) Ensure p_over_model (with fallback SD) -------------------------------\n",
        "if \"p_over_model\" not in df.columns or df[\"p_over_model\"].isna().all():\n",
        "    sd_missing = (\"projection_sd\" not in df.columns) or df[\"projection_sd\"].fillna(0).eq(0).all()\n",
        "    if sd_missing:\n",
        "        df[\"projection_sd\"] = (df[\"projection_mean\"].abs() * 0.15).clip(lower=1.0)\n",
        "\n",
        "    from statistics import NormalDist\n",
        "    def p_over_from_normal(mean, sd, line):\n",
        "        if pd.isna(mean) or pd.isna(sd) or pd.isna(line) or float(sd) <= 0:\n",
        "            return np.nan\n",
        "        z = (float(line) - float(mean)) / float(sd)\n",
        "        return 1.0 - NormalDist().cdf(z)\n",
        "\n",
        "    df[\"p_over_model\"] = df.apply(\n",
        "        lambda r: p_over_from_normal(r[\"projection_mean\"], r[\"projection_sd\"], r[\"line\"]),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "# ---- 4) Implied / fair probs + edge (build if missing) -----------------------\n",
        "def implied_prob_from_american(american):\n",
        "    o = _first_int(american)\n",
        "    if pd.isna(o): return np.nan\n",
        "    return (-o)/(-o+100.0) if o < 0 else 100.0/(o+100.0)\n",
        "\n",
        "if \"p_over_imp\" not in df.columns:\n",
        "    df[\"p_over_imp\"] = df[\"over_odds\"].apply(implied_prob_from_american)\n",
        "if \"p_under_imp\" not in df.columns:\n",
        "    df[\"p_under_imp\"] = df[\"under_odds\"].apply(implied_prob_from_american)\n",
        "\n",
        "if \"p_over_fair\" not in df.columns or \"p_under_fair\" not in df.columns:\n",
        "    fair = df.apply(\n",
        "        lambda r: pd.Series(\n",
        "            (np.nan, np.nan) if (pd.isna(r[\"p_over_imp\"]) or pd.isna(r[\"p_under_imp\"])) else\n",
        "            (r[\"p_over_imp\"]/(r[\"p_over_imp\"]+r[\"p_under_imp\"]), r[\"p_under_imp\"]/(r[\"p_over_imp\"]+r[\"p_under_imp\"]))\n",
        "        , index=[\"p_over_fair\",\"p_under_fair\"]), axis=1)\n",
        "    df = pd.concat([df, fair], axis=1)\n",
        "\n",
        "if \"edge_over\" not in df.columns:\n",
        "    df[\"edge_over\"] = np.where(\n",
        "        df[\"p_over_fair\"].notna(),\n",
        "        df[\"p_over_model\"] - df[\"p_over_fair\"],\n",
        "        df[\"p_over_model\"] - df[\"p_over_imp\"]\n",
        "    )\n",
        "\n",
        "# ---- 5) Fallback ranking signal if probs weak: z-score of (expected - line) --\n",
        "df[\"z_score\"] = (df[\"projection_mean\"] - df[\"line\"]) / df[\"projection_sd\"].replace(0, np.nan)\n",
        "# If edge is NaN, use z_score scaled to pseudo-prob edge (~convert z to prob diff)\n",
        "from statistics import NormalDist\n",
        "nd = NormalDist()\n",
        "df[\"edge_fallback\"] = df[\"z_score\"].map(lambda z: (nd.cdf(z) - 0.5)*2 if pd.notna(z) else np.nan)\n",
        "df[\"edge_rank\"] = np.where(df[\"edge_over\"].notna(), df[\"edge_over\"], df[\"edge_fallback\"])\n",
        "\n",
        "# ---- 6) Build lean, keep best book per player/market -------------------------\n",
        "lean = df.loc[:, [\n",
        "    \"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\"over_odds\",\"under_odds\",\n",
        "    \"projection_mean\",\"p_over_model\",\"edge_rank\",\"edge_over\"\n",
        "]].copy()\n",
        "\n",
        "# Drop rows missing essentials\n",
        "lean = lean.dropna(subset=[\"player\",\"market\",\"line\",\"projection_mean\",\"book\",\"over_odds\"], how=\"any\")\n",
        "\n",
        "# Keep the best row per player/market by edge_rank\n",
        "lean = lean.sort_values([\"player\",\"market\",\"edge_rank\"], ascending=[True, True, False])\n",
        "lean = lean.drop_duplicates(subset=[\"player\",\"market\"], keep=\"first\")\n",
        "\n",
        "# ---- 7) Select Top-100: positives first, then fill with the next best --------\n",
        "pos = lean[lean[\"edge_rank\"] > 0].copy()\n",
        "neg = lean[lean[\"edge_rank\"] <= 0].copy().sort_values([\"edge_rank\",\"p_over_model\"], ascending=[False, False])\n",
        "top = pd.concat([pos, neg]).head(300).copy()\n",
        "\n",
        "# ---- 8) Final formatting & export -------------------------------------------\n",
        "top.rename(columns={\"line\":\"posted_line\",\"projection_mean\":\"expected_line\"}, inplace=True)\n",
        "for c in [\"posted_line\",\"expected_line\"]:\n",
        "    top[c] = pd.to_numeric(top[c], errors=\"coerce\").round(1)\n",
        "\n",
        "final_cols = [\"player\",\"team\",\"opponent\",\"market\",\"posted_line\",\"expected_line\",\"book\",\"over_odds\",\"under_odds\",\"edge_rank\",\"p_over_model\"]\n",
        "top_out = top[final_cols].copy()\n",
        "\n",
        "out_path = f\"value_bets_top100_{datetime.utcnow().strftime('%Y%m%d')}.xlsx\"\n",
        "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as w:\n",
        "    top_out.to_excel(w, sheet_name=\"Top100\", index=False)\n",
        "\n",
        "print(f\"âœ… Saved Top-100 value bets (PTS/REB/AST) to: {out_path}\")\n",
        "print(f\"Positive-edge available: {len(pos)}; Exported: {len(top_out)}\")\n",
        "display(top_out.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3662135",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c68841f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
