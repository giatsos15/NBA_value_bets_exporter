{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f2a745b",
      "metadata": {},
      "source": [
        "## NBA Analytics and Betting Value Analysis Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "id": "07decdf1",
      "metadata": {
        "id": "07decdf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Env ready | DATA_DIR: data_raw | DEBUG_DIR: _rotowire_debug | EXPORT_DIR: exports\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 1: imports, config, folders -----------------------------------------\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Display & randomness\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 160)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Folders\n",
        "DATA_DIR = \"data_raw\"\n",
        "DEBUG_DIR = \"_rotowire_debug\"\n",
        "EXPORT_DIR = \"exports\"\n",
        "\n",
        "for d in (DATA_DIR, DEBUG_DIR, EXPORT_DIR):\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Env ready | DATA_DIR:\", DATA_DIR, \"| DEBUG_DIR:\", DEBUG_DIR, \"| EXPORT_DIR:\", EXPORT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "id": "01631fd1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fetched 2230 odds rows | 264 columns | book=mgm\n",
            "\n",
            "üîé Long odds preview:\n",
            "                 player team opponent  game_date market book  line  over_odds  under_odds\n",
            "Shai Gilgeous-Alexander  OKC     @SAC 2025-11-08    PTS  mgm  31.5     -125.0      -105.0\n",
            "           Nikola Jokic  DEN      GSW 2025-11-08    PTS  mgm  26.5     -110.0      -120.0\n",
            "       Jonathan Kuminga  GSW     @DEN 2025-11-08    PTS  mgm  21.5      100.0      -130.0\n",
            "            Zach LaVine  SAC      OKC 2025-11-08    PTS  mgm  22.5     -105.0      -125.0\n",
            "          DeMar DeRozan  SAC      OKC 2025-11-08    PTS  mgm  20.5     -110.0      -118.0\n",
            "           Jamal Murray  DEN      GSW 2025-11-08    PTS  mgm  21.5     -110.0      -118.0\n",
            "           Jimmy Butler  GSW     @DEN 2025-11-08    PTS  mgm  20.5     -105.0      -125.0\n",
            "          Ajay Mitchell  OKC     @SAC 2025-11-08    PTS  mgm  16.5     -120.0      -110.0\n",
            "          Chet Holmgren  OKC     @SAC 2025-11-08    PTS  mgm  17.5     -115.0      -115.0\n",
            "           Aaron Gordon  DEN      GSW 2025-11-08    PTS  mgm  16.5     -118.0      -110.0\n",
            "      Russell Westbrook  SAC      OKC 2025-11-08    PTS  mgm  14.5     -105.0      -125.0\n",
            "     Brandin Podziemski  GSW     @DEN 2025-11-08    PTS  mgm  13.5     -125.0      -105.0\n",
            "\n",
            "üíæ Saved: data_raw/rotowire_odds_wide_mgm_20251108_013805.csv\n",
            "üíæ Saved: data_raw/rotowire_odds_long_mgm_20251108_013805.csv\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 2: odds scraper + wide->long helper ---------------------------------\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "class NBAOddsScraper:\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.setup_headers()\n",
        "\n",
        "    def setup_headers(self):\n",
        "        self.headers = {\n",
        "            \"accept\": \"*/*\",\n",
        "            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/130.0.0.0 Safari/537.36\",\n",
        "            \"referer\": \"https://www.rotowire.com/\",\n",
        "        }\n",
        "\n",
        "    def get_player_props_odds_wide_raw(self, book: str = \"mgm\") -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Pulls the RotoWire player-props page for a single book and extracts all JSON 'data: [...]' blobs.\n",
        "        Returns a single wide DataFrame with the raw columns RotoWire emits.\n",
        "        \"\"\"\n",
        "        url = f\"https://www.rotowire.com/betting/nba/player-props.php?book={book}\"\n",
        "        try:\n",
        "            r = self.session.get(url, headers=self.headers, timeout=20)\n",
        "            r.raise_for_status()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to GET odds page: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        matches = re.findall(r\"data:\\s*(\\[\\{.*?\\}\\])\", r.text, flags=re.DOTALL)\n",
        "        frames = []\n",
        "        for m in matches:\n",
        "            try:\n",
        "                rows = json.loads(m)\n",
        "                if isinstance(rows, list) and rows:\n",
        "                    frames.append(pd.DataFrame(rows))\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        if not frames:\n",
        "            print(\"‚ö†Ô∏è No odds JSON blocks found.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.concat(frames, ignore_index=True)\n",
        "\n",
        "        # Normalize a few columns\n",
        "        base_cols = [c for c in [\"name\",\"gameID\",\"playerID\",\"firstName\",\"lastName\",\"team\",\"opp\",\"logo\",\"playerLink\"] if c in df.columns]\n",
        "        other_cols = [c for c in df.columns if c not in base_cols]\n",
        "        df = df[base_cols + other_cols]\n",
        "\n",
        "        if \"opp\" in df.columns and \"opponent\" not in df.columns:\n",
        "            df = df.rename(columns={\"opp\": \"opponent\"})\n",
        "\n",
        "        df[\"asof_date\"] = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "        if \"game_date\" not in df.columns:\n",
        "            df[\"game_date\"] = df[\"asof_date\"]\n",
        "        df[\"book\"] = book\n",
        "\n",
        "        print(f\"‚úÖ Fetched {len(df)} odds rows | {len(df.columns)} columns | book={book}\")\n",
        "        return df\n",
        "\n",
        "def odds_wide_to_long_from_columns(wide: pd.DataFrame,\n",
        "                                   books=(\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\",\"espnbet\",\"hardrock\"),\n",
        "                                   markets=(\"PTS\",\"REB\",\"AST\")) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert the scraped wide odds table into tidy long format:\n",
        "    columns: player, team, opponent, game_date, market, book, line, over_odds, under_odds\n",
        "    Works by scanning for patterns like '{book}_{suffix}' where suffix in {'pts','reb','ast'}.\n",
        "    \"\"\"\n",
        "    if wide.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # base identity cols best-effort\n",
        "    base_map = {\n",
        "        \"name\": \"player\",\n",
        "        \"team\": \"team\",\n",
        "        \"opponent\": \"opponent\",\n",
        "        \"game_date\": \"game_date\",\n",
        "    }\n",
        "    present_keys = [src for src in base_map if src in wide.columns]\n",
        "    base = wide[present_keys].rename(columns={k: base_map[k] for k in present_keys}).copy()\n",
        "\n",
        "    rows = []\n",
        "    suffix_map = {\"PTS\":\"pts\",\"REB\":\"reb\",\"AST\":\"ast\"}\n",
        "\n",
        "    for m in markets:\n",
        "        suf = suffix_map[m]\n",
        "        for b in books:\n",
        "            line_col  = f\"{b}_{suf}\"\n",
        "            over_col  = f\"{b}_{suf}Over\"\n",
        "            under_col = f\"{b}_{suf}Under\"\n",
        "\n",
        "            if line_col not in wide.columns:\n",
        "                continue  # this book-market not present\n",
        "\n",
        "            # Use get to avoid KeyErrors if over/under missing\n",
        "            sub = pd.DataFrame({\n",
        "                \"player\":   base.get(\"player\", pd.Series([\"\"]*len(wide))),\n",
        "                \"team\":     base.get(\"team\", pd.Series([\"\"]*len(wide))),\n",
        "                \"opponent\": base.get(\"opponent\", pd.Series([\"\"]*len(wide))),\n",
        "                \"game_date\":base.get(\"game_date\", pd.Series([\"\"]*len(wide))),\n",
        "                \"market\":   m,\n",
        "                \"book\":     b,\n",
        "                \"line\":     wide[line_col],\n",
        "                \"over_odds\":wide.get(over_col),\n",
        "                \"under_odds\":wide.get(under_col),\n",
        "            })\n",
        "            rows.append(sub)\n",
        "\n",
        "    out = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
        "    # numeric cleaning\n",
        "    def _num_float(x):\n",
        "        try:\n",
        "            if pd.isna(x): return np.nan\n",
        "            s = str(x).strip()\n",
        "            if s==\"\" or s.lower()==\"none\": return np.nan\n",
        "            return float(re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", s).group())\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "\n",
        "    def _num_int(x):\n",
        "        try:\n",
        "            if pd.isna(x): return np.nan\n",
        "            s = str(x).strip()\n",
        "            if s==\"\" or s.lower()==\"none\": return np.nan\n",
        "            return int(re.search(r\"[-+]?\\d+\", s).group())\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "\n",
        "    if not out.empty:\n",
        "        out[\"line\"] = out[\"line\"].apply(_num_float)\n",
        "        if \"over_odds\" in out.columns:\n",
        "            out[\"over_odds\"] = out[\"over_odds\"].apply(_num_int)\n",
        "        if \"under_odds\" in out.columns:\n",
        "            out[\"under_odds\"] = out[\"under_odds\"].apply(_num_int)\n",
        "        out = out.dropna(subset=[\"line\"]).reset_index(drop=True)\n",
        "\n",
        "    return out\n",
        "\n",
        "# ---- Run scrape + save -------------------------------------------------------\n",
        "scraper = NBAOddsScraper()\n",
        "odds_wide_mgm = scraper.get_player_props_odds_wide_raw(book=\"mgm\")\n",
        "odds_long = odds_wide_to_long_from_columns(odds_wide_mgm)\n",
        "\n",
        "print(\"\\nüîé Long odds preview:\")\n",
        "print(odds_long.head(12).to_string(index=False))\n",
        "\n",
        "# Save both forms\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "wide_path = f\"{DATA_DIR}/rotowire_odds_wide_mgm_{stamp}.csv\"\n",
        "long_path = f\"{DATA_DIR}/rotowire_odds_long_mgm_{stamp}.csv\"\n",
        "odds_wide_mgm.to_csv(wide_path, index=False)\n",
        "odds_long.to_csv(long_path, index=False)\n",
        "print(f\"\\nüíæ Saved: {wide_path}\\nüíæ Saved: {long_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "id": "c5e40802",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diagnostics: lineup blocks=14, player nodes=168\n",
            "‚úÖ Shape: (22, 11)\n",
            "game_time team side lineup_status                                                                             starters             starter_1     starter_2     starter_3     starter_4      starter_5  lineup_confirmed\n",
            "               AWAY     CONFIRMED              [Derrick White, P. Pritchard, Jaylen Brown, Josh Minott, Neemias Queta]         Derrick White  P. Pritchard  Jaylen Brown   Josh Minott  Neemias Queta                 1\n",
            "               AWAY     CONFIRMED                     [D. Garland, D. Mitchell, D. Hunter, Evan Mobley, Jarrett Allen]            D. Garland   D. Mitchell     D. Hunter   Evan Mobley  Jarrett Allen                 1\n",
            "               AWAY     CONFIRMED                        [I. Quickley, RJ Barrett, B. Ingram, S. Barnes, Jakob Poeltl]           I. Quickley    RJ Barrett     B. Ingram     S. Barnes   Jakob Poeltl                 1\n",
            "               AWAY     CONFIRMED                   [C. Cunningham, D. Robinson, A. Thompson, I. Stewart, Jalen Duren]         C. Cunningham   D. Robinson   A. Thompson    I. Stewart    Jalen Duren                 1\n",
            "               AWAY     CONFIRMED                  [Amen Thompson, Josh Okogie, Kevin Durant, Jabari Smith, A. Sengun]         Amen Thompson   Josh Okogie  Kevin Durant  Jabari Smith      A. Sengun                 1\n",
            "               AWAY     CONFIRMED                  [Tre Mann, Sion James, Kon Knueppel, Miles Bridges, R. Kalkbrenner]              Tre Mann    Sion James  Kon Knueppel Miles Bridges R. Kalkbrenner                 1\n",
            "               AWAY     CONFIRMED                     [Tre Jones, Josh Giddey, Isaac Okoro, Matas Buzelis, N. Vucevic]             Tre Jones   Josh Giddey   Isaac Okoro Matas Buzelis     N. Vucevic                 1\n",
            "               AWAY     CONFIRMED                   [K. George, S. Mykhailiuk, I. Collier, L. Markkanen, Jusuf Nurkic]             K. George S. Mykhailiuk    I. Collier  L. Markkanen   Jusuf Nurkic                 1\n",
            "               AWAY     CONFIRMED                  [D. Russell, Cooper Flagg, Max Christie, P. Washington, D. Gafford]            D. Russell  Cooper Flagg  Max Christie P. Washington     D. Gafford                 1\n",
            "               AWAY      EXPECTED                       [B. Podziemski, J. Butler, J. Kuminga, D. Green, Quinten Post]         B. Podziemski     J. Butler    J. Kuminga      D. Green   Quinten Post                 0\n",
            "               AWAY      EXPECTED [S. Gilgeous-Alexander, Cason Wallace, Ajay Mitchell, Chet Holmgren, I. Hartenstein] S. Gilgeous-Alexander Cason Wallace Ajay Mitchell Chet Holmgren I. Hartenstein                 0\n",
            "               HOME     CONFIRMED                    [Jalen Suggs, Desmond Bane, Franz Wagner, P. Banchero, W. Carter]           Jalen Suggs  Desmond Bane  Franz Wagner   P. Banchero      W. Carter                 1\n"
          ]
        }
      ],
      "source": [
        "# pip install selenium webdriver-manager bs4 pandas lxml\n",
        "\n",
        "import os, re, time, pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# ---------------- helpers ----------------\n",
        "\n",
        "def _clean_list(xs):\n",
        "    return [re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", x) for x in xs]\n",
        "\n",
        "def _try_click_consent(driver, timeout=6):\n",
        "    XPATHS = [\n",
        "        \"//button[contains(.,'Accept')]\",\n",
        "        \"//button[contains(.,'I Agree')]\",\n",
        "        \"//button[contains(.,'Agree')]\",\n",
        "        \"//button[contains(.,'ŒëœÄŒøŒ¥ŒøœáŒÆ')]\",\n",
        "        \"//button[contains(.,'Œ£œÖŒºœÜœâŒΩœé')]\",\n",
        "    ]\n",
        "    end = time.time() + timeout\n",
        "    for xp in XPATHS:\n",
        "        try:\n",
        "            btn = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, xp)))\n",
        "            btn.click()\n",
        "            return True\n",
        "        except Exception:\n",
        "            if time.time() > end: break\n",
        "    return False\n",
        "\n",
        "def _progress_scroll(driver, steps=10, pause=0.8):\n",
        "    h = driver.execute_script(\"return document.body.scrollHeight || document.documentElement.scrollHeight;\")\n",
        "    for i in range(1, steps + 1):\n",
        "        y = int(h * i / steps)\n",
        "        driver.execute_script(f\"window.scrollTo(0, {y});\")\n",
        "        time.sleep(pause)\n",
        "\n",
        "def _extract_team(side):\n",
        "    team_el = side.select_one(\".lineup__abbr, .lineup__team-name, .lineup__name\")\n",
        "    if team_el:\n",
        "        return team_el.get_text(strip=True)\n",
        "    logo = side.select_one(\"img[alt]\")\n",
        "    return (logo.get(\"alt\") or \"\").strip() if logo else \"\"\n",
        "\n",
        "def _extract_status(side):\n",
        "    status_el = side.select_one(\".lineup__status\")\n",
        "    txt = (status_el.get_text(\" \", strip=True) if status_el else \"\").upper()\n",
        "    if \"CONFIRM\" in txt:  return \"CONFIRMED\"\n",
        "    if \"EXPECT\" in txt or \"PROBABLE\" in txt: return \"EXPECTED\"\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "def _extract_starters(side):\n",
        "    # Try several variants for starters content\n",
        "    containers = side.select(\".lineup__list--starters, .lineup__list, .lineup__players\")\n",
        "    if not containers:\n",
        "        containers = [side]\n",
        "\n",
        "    names = []\n",
        "    for blk in containers:\n",
        "        for a in blk.select(\"a.lineup__player-link, .lineup__player a\"):\n",
        "            t = a.get_text(\" \", strip=True)\n",
        "            if t: names.append(t)\n",
        "        if not names:\n",
        "            for row in blk.select(\".lineup__player\"):\n",
        "                t = row.get_text(\" \", strip=True)\n",
        "                if re.match(r\"^(PG|SG|SF|PF|C)\\b\", t): names.append(t)\n",
        "        if not names:\n",
        "            for li in blk.select(\"li\"):\n",
        "                t = li.get_text(\" \", strip=True)\n",
        "                if re.match(r\"^(PG|SG|SF|PF|C)\\b\", t): names.append(t)\n",
        "\n",
        "    if not names:\n",
        "        txt = side.get_text(\"\\n\", strip=True)\n",
        "        names = re.findall(r\"(?:^|\\n)(?:PG|SG|SF|PF|C)\\s+[^\\n]+\", txt)\n",
        "\n",
        "    return _clean_list(names)[:5]\n",
        "\n",
        "# ---------------- main ----------------\n",
        "\n",
        "def fetch_rotowire_lineups_selenium(date: str | None = None,\n",
        "                                    wait_sec: float = 14.0,\n",
        "                                    headless: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Render Rotowire lineups & parse BOTH sides per game (global side selectors).\n",
        "    Returns:\n",
        "      game_time, team, side (AWAY/HOME), lineup_status, starters,\n",
        "      starter_1..starter_5, lineup_confirmed (0/1)\n",
        "    \"\"\"\n",
        "    base = \"https://www.rotowire.com/basketball/nba-lineups.php\"\n",
        "    url = base if not date else f\"{base}?date={date}\"\n",
        "\n",
        "    opts = Options()\n",
        "    if headless: opts.add_argument(\"--headless=new\")\n",
        "    opts.add_argument(\"--disable-gpu\")\n",
        "    opts.add_argument(\"--no-sandbox\")\n",
        "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
        "    opts.add_argument(\"--window-size=1400,1000\")\n",
        "    opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "    opts.add_experimental_option(\"useAutomationExtension\", False)\n",
        "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "    opts.add_argument(\"--lang=en-US,en;q=0.9\")\n",
        "    opts.add_argument(\n",
        "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "    )\n",
        "\n",
        "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
        "    driver.get(url)\n",
        "\n",
        "    _try_click_consent(driver, timeout=6)\n",
        "    time.sleep(1.2)\n",
        "    try:\n",
        "        WebDriverWait(driver, int(wait_sec)).until(\n",
        "            EC.presence_of_element_located((By.CSS_SELECTOR, \".lineup, .lineup.is-nba\"))\n",
        "        )\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    _progress_scroll(driver, steps=10, pause=0.8)\n",
        "    time.sleep(1.0)\n",
        "\n",
        "    # quick diagnostics\n",
        "    blocks = driver.find_elements(By.CSS_SELECTOR, \".lineup.is-nba, .lineup\")\n",
        "    players = driver.find_elements(By.CSS_SELECTOR, \".lineup__player, a.lineup__player-link\")\n",
        "    print(f\"diagnostics: lineup blocks={len(blocks)}, player nodes={len(players)}\")\n",
        "\n",
        "    html = driver.page_source\n",
        "    os.makedirs(\"_rotowire_debug\", exist_ok=True)\n",
        "    with open(\"_rotowire_debug/last_lineups.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html)\n",
        "    try:\n",
        "        driver.save_screenshot(\"_rotowire_debug/last_lineups.png\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    driver.quit()\n",
        "\n",
        "    # -------- parse globally by side classes ----------\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    # game time map: find each game container time\n",
        "    game_time_map = {}\n",
        "    for gi, g in enumerate(soup.select(\".lineup__main, .lineup.is-nba, .lineup\")):\n",
        "        t = g.select_one(\".lineup__time, .game-time\")\n",
        "        game_time_map[id(g)] = t.get_text(strip=True) if t else \"\"\n",
        "\n",
        "    # Select **visit/away** & **home** side boxes explicitly\n",
        "    visit_sel = (\n",
        "        '[class*=\"lineup__box\"][class*=\"is-visit\"], '\n",
        "        '[class*=\"lineup__team\"][class*=\"is-visit\"], '\n",
        "        '[class*=\"lineup__side\"][class*=\"is-visit\"], '\n",
        "        '[class*=\"visit\"]'\n",
        "    )\n",
        "    home_sel = (\n",
        "        '[class*=\"lineup__box\"][class*=\"is-home\"], '\n",
        "        '[class*=\"lineup__team\"][class*=\"is-home\"], '\n",
        "        '[class*=\"lineup__side\"][class*=\"is-home\"], '\n",
        "        '[class*=\"home\"]'\n",
        "    )\n",
        "\n",
        "    visit_boxes = soup.select(visit_sel)\n",
        "    home_boxes  = soup.select(home_sel)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    def add_rows(boxes, side_label):\n",
        "        for box in boxes:\n",
        "            # nearest parent game container for time\n",
        "            parent = box.find_parent(lambda tag: tag.has_attr(\"class\") and any(\n",
        "                c in {\"lineup__main\",\"lineup\",\"lineup is-nba\"} for c in tag.get(\"class\", [])\n",
        "            ))\n",
        "            game_time = game_time_map.get(id(parent), \"\") if parent else \"\"\n",
        "            team = _extract_team(box)\n",
        "            starters = _extract_starters(box)\n",
        "            status = _extract_status(box)\n",
        "            if starters or team:\n",
        "                rows.append({\n",
        "                    \"game_time\": game_time,\n",
        "                    \"team\": team,\n",
        "                    \"side\": side_label,\n",
        "                    \"lineup_status\": status,\n",
        "                    \"starters\": starters,\n",
        "                    \"starter_1\": starters[0] if len(starters)>0 else None,\n",
        "                    \"starter_2\": starters[1] if len(starters)>1 else None,\n",
        "                    \"starter_3\": starters[2] if len(starters)>2 else None,\n",
        "                    \"starter_4\": starters[3] if len(starters)>3 else None,\n",
        "                    \"starter_5\": starters[4] if len(starters)>4 else None,\n",
        "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
        "                })\n",
        "\n",
        "    add_rows(visit_boxes, \"AWAY\")\n",
        "    add_rows(home_boxes,  \"HOME\")\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    if not df.empty:\n",
        "        df = df.drop_duplicates(\n",
        "            subset=[\"game_time\",\"team\",\"side\",\"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]\n",
        "        )\n",
        "        all_na = df[[\"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]].isna().all(axis=1)\n",
        "        df = df[~all_na].reset_index(drop=True)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Parsed zero rows. Check _rotowire_debug/last_lineups.html & .png\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ---------- run it ----------\n",
        "df_lineups = fetch_rotowire_lineups_selenium(wait_sec=14.0, headless=False)\n",
        "print(\"‚úÖ Shape:\", df_lineups.shape)\n",
        "print(df_lineups.sort_values([\"game_time\",\"side\"]).head(12).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "32a4ac06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DOM diagnostics: {'lineup__teams': 11, 'ul.lineup__list': 22, 'ul.is-visit': 11, 'ul.is-home': 11, 'see-proj-minutes buttons': 22, 'header abbr': 0, 'header team': 0, 'player anchors': 168, 'MNP titles': 22}\n",
            "Fallback B: scanning all ul.lineup__list globally...\n",
            "‚Üí Parsed rows: 22\n",
            "üíæ Saved parsed lineups to data_raw/lineups_parsed_20251108_013841.csv\n",
            "\n",
            "‚úÖ Preview:\n",
            "game_time team side lineup_status  may_not_play_count             starter_1        starter_2     starter_3        starter_4      starter_5\n",
            "           BOS AWAY     CONFIRMED                   7         Derrick White     P. Pritchard  Jaylen Brown      Josh Minott  Neemias Queta\n",
            "           CHA AWAY     CONFIRMED                  10              Tre Mann       Sion James  Kon Knueppel    Miles Bridges R. Kalkbrenner\n",
            "           CHI AWAY     CONFIRMED                   7             Tre Jones      Josh Giddey   Isaac Okoro    Matas Buzelis     N. Vucevic\n",
            "           CLE AWAY     CONFIRMED                   8            D. Garland      D. Mitchell     D. Hunter      Evan Mobley  Jarrett Allen\n",
            "           DAL AWAY     CONFIRMED                   9            D. Russell     Cooper Flagg  Max Christie    P. Washington     D. Gafford\n",
            "           DET AWAY     CONFIRMED                   8         C. Cunningham      D. Robinson   A. Thompson       I. Stewart    Jalen Duren\n",
            "           GSW AWAY      EXPECTED                  10         B. Podziemski       J. Kuminga      D. Green     Quinten Post  B. Podziemski\n",
            "           HOU AWAY     CONFIRMED                   7         Amen Thompson      Josh Okogie  Kevin Durant     Jabari Smith      A. Sengun\n",
            "           OKC AWAY      EXPECTED                  11 S. Gilgeous-Alexander    Cason Wallace Ajay Mitchell    Chet Holmgren I. Hartenstein\n",
            "           TOR AWAY     CONFIRMED                   5           I. Quickley       RJ Barrett     B. Ingram        S. Barnes   Jakob Poeltl\n",
            "           UTA AWAY     CONFIRMED                   7             K. George    S. Mykhailiuk    I. Collier     L. Markkanen   Jusuf Nurkic\n",
            "           ATL HOME     CONFIRMED                   8   N. Alexander-Walker    Dyson Daniels   Z. Risacher    Jalen Johnson   K. Porzingis\n",
            "           BKN HOME     CONFIRMED                   7          Terance Mann       Egor Demin     M. Porter     Noah Clowney    Nic Claxton\n",
            "           DEN HOME      EXPECTED                   6          Jamal Murray         C. Braun    C. Johnson     Aaron Gordon   Nikola Jokic\n",
            "           MEM HOME     CONFIRMED                   9             Ja Morant K. Caldwell-Pope  Jaylen Wells    Jaren Jackson   Jock Landale\n",
            "           MIA HOME     CONFIRMED                   8           D. Mitchell    Norman Powell Pelle Larsson       A. Wiggins    Kel'el Ware\n",
            "           MIL HOME     CONFIRMED                   7          Ryan Rollins         AJ Green    Gary Trent G. Antetokounmpo   Myles Turner\n",
            "           MIN HOME     CONFIRMED                   6         D. DiVincenzo       A. Edwards  J. McDaniels    Julius Randle    Rudy Gobert\n",
            "           ORL HOME     CONFIRMED                   6           Jalen Suggs     Desmond Bane  Franz Wagner      P. Banchero      W. Carter\n",
            "           SAC HOME      EXPECTED                   2           D. Schroder     R. Westbrook   Zach LaVine    DeMar DeRozan   Drew Eubanks\n",
            "           SAS HOME     CONFIRMED                   8             S. Castle    Devin Vassell J. Champagnie        H. Barnes  V. Wembanyama\n",
            "           WAS HOME     CONFIRMED                   7         B. Carrington      CJ McCollum   Tre Johnson     K. Middleton      Alex Sarr\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 4: parse saved HTML to starters + MNP count --------------------------\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def _txt(x):\n",
        "    return re.sub(r\"\\s+\", \" \", x.get_text(\" \", strip=True)) if x else \"\"\n",
        "\n",
        "def _clean_player(n):\n",
        "    if not n:\n",
        "        return n\n",
        "    n = re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", n).strip()\n",
        "    n = re.sub(r\"^(PG|SG|SF|PF|C)\\s+\", \"\", n, flags=re.I)\n",
        "    return n\n",
        "\n",
        "def _get_mnp_from_ul(ul):\n",
        "    \"\"\"Extract 'May Not Play' entries from a team UL.\"\"\"\n",
        "    mnp = []\n",
        "    title = ul.find(\"li\", class_=lambda c: c and \"lineup__title\" in c and re.search(\n",
        "        r\"may\\s+not\\s+play\", _txt(ul.find(\"li\", class_=c)) if ul.find(\"li\", class_=c) else \"\", re.I\n",
        "    ))\n",
        "    if title:\n",
        "        for li in title.find_all_next(\"li\"):\n",
        "            if \"lineup__title\" in (li.get(\"class\") or []):\n",
        "                break\n",
        "            if \"lineup__player\" in (li.get(\"class\") or []):\n",
        "                a = li.select_one(\"a\")\n",
        "                tag = li.select_one(\".lineup__inj\")\n",
        "                nm = _txt(a) if a else \"\"\n",
        "                if nm:\n",
        "                    mnp.append(f\"{nm} ({_txt(tag)})\" if tag else nm)\n",
        "        return [_clean_player(x) for x in mnp if x and x.lower() != \"none\"]\n",
        "\n",
        "    for li in ul.select(\".lineup__notplay li, .lineup__status--out, .lineup__inj-list li\"):\n",
        "        nm = _txt(li)\n",
        "        if nm:\n",
        "            mnp.append(_clean_player(nm))\n",
        "    return [x for x in mnp if x and x.lower() != \"none\"]\n",
        "\n",
        "def _extract_starters_from_ul(ul):\n",
        "    names = []\n",
        "    for li in ul.select(\"li.lineup__player.is-pct-play-100 a\"):\n",
        "        nm = _txt(li)\n",
        "        if nm:\n",
        "            names.append(nm)\n",
        "    if len(names) < 5:\n",
        "        for li in ul.select(\"li.lineup__player a\"):\n",
        "            nm = _txt(li)\n",
        "            if nm:\n",
        "                names.append(nm)\n",
        "            if len(names) >= 5:\n",
        "                break\n",
        "    names = [_clean_player(n) for n in names]\n",
        "    return names[:5]\n",
        "\n",
        "def _lineup_status(ul):\n",
        "    st = _txt(ul.select_one(\".lineup__status\"))\n",
        "    stU = st.upper()\n",
        "    if \"CONFIRM\" in stU: return \"CONFIRMED\"\n",
        "    if \"EXPECT\" in stU or \"PROBABLE\" in stU: return \"EXPECTED\"\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "def parse_rotowire_lineups_flexible(html_path: str) -> pd.DataFrame:\n",
        "    with open(html_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        html = f.read()\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    diag = {\n",
        "        \"lineup__teams\": len(soup.select(\"div.lineup__teams\")),\n",
        "        \"ul.lineup__list\": len(soup.select(\"ul.lineup__list\")),\n",
        "        \"ul.is-visit\": len(soup.select(\"ul.lineup__list.is-visit\")),\n",
        "        \"ul.is-home\": len(soup.select(\"ul.lineup__list.is-home\")),\n",
        "        \"see-proj-minutes buttons\": len(soup.select(\"button.see-proj-minutes\")),\n",
        "        \"header abbr\": len(soup.select(\".lineup__hdr .lineup__abbr\")),\n",
        "        \"header team\": len(soup.select(\".lineup__hdr .lineup__team\")),\n",
        "        \"player anchors\": len(soup.select(\"a.lineup__player-link, .lineup__player a\")),\n",
        "        \"MNP titles\": len(soup.find_all(string=re.compile(r\"^\\s*may\\s+not\\s+play\\s*$\", re.I))),\n",
        "    }\n",
        "    print(\"DOM diagnostics:\", diag)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    # Strategy A: by matchup blocks\n",
        "    for teams_div in soup.select(\"div.lineup__teams\"):\n",
        "        time_el = teams_div.find_previous(\"div\", class_=\"lineup__time\")\n",
        "        game_time = _txt(time_el)\n",
        "\n",
        "        uls = teams_div.select(\"ul.lineup__list\")\n",
        "        if len(uls) < 1:\n",
        "            continue\n",
        "\n",
        "        away_ul = None\n",
        "        home_ul = None\n",
        "        for ul in uls:\n",
        "            classes = \" \".join(ul.get(\"class\", [])).lower()\n",
        "            if \"is-visit\" in classes or \"visit\" in classes or \"away\" in classes:\n",
        "                away_ul = ul\n",
        "            if \"is-home\" in classes or \"home\" in classes:\n",
        "                home_ul = home_ul or ul\n",
        "\n",
        "        if away_ul is None and home_ul is None and len(uls) >= 2:\n",
        "            away_ul, home_ul = uls[0], uls[1]\n",
        "        elif away_ul is None and len(uls) >= 1:\n",
        "            away_ul = uls[0]\n",
        "        elif home_ul is None and len(uls) >= 2:\n",
        "            home_ul = next((u for u in uls if u is not away_ul), None)\n",
        "\n",
        "        header_abbrs = [_txt(el) for el in teams_div.select(\".lineup__abbr\") if _txt(el)]\n",
        "        if not header_abbrs:\n",
        "            parent_main = teams_div.find_parent([\"div\",\"section\"])\n",
        "            if parent_main:\n",
        "                header_abbrs = [_txt(el) for el in parent_main.select(\".lineup__abbr\") if _txt(el)]\n",
        "\n",
        "        for idx, (side, ul) in enumerate([(\"AWAY\", away_ul), (\"HOME\", home_ul)]):\n",
        "            if not ul:\n",
        "                continue\n",
        "            btn = ul.select_one(\"button.see-proj-minutes\")\n",
        "            team = btn[\"data-team\"].strip().upper() if btn and btn.has_attr(\"data-team\") else None\n",
        "            if not team and header_abbrs and idx < len(header_abbrs):\n",
        "                team = header_abbrs[idx].upper()\n",
        "\n",
        "            starters = _extract_starters_from_ul(ul)\n",
        "            mnp = _get_mnp_from_ul(ul)\n",
        "            status = _lineup_status(ul)\n",
        "\n",
        "            if team or starters or mnp:\n",
        "                rows.append({\n",
        "                    \"game_time\": game_time,\n",
        "                    \"team\": team,\n",
        "                    \"side\": side,\n",
        "                    \"lineup_status\": status,\n",
        "                    \"starters\": starters,\n",
        "                    \"may_not_play\": mnp,\n",
        "                    \"may_not_play_count\": len(mnp),\n",
        "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
        "                })\n",
        "\n",
        "    # Strategy B: global scan if A found nothing\n",
        "    if not rows:\n",
        "        print(\"Fallback B: scanning all ul.lineup__list globally...\")\n",
        "        for ul in soup.select(\"ul.lineup__list\"):\n",
        "            side = \"AWAY\" if \"is-visit\" in (ul.get(\"class\") or []) else (\"HOME\" if \"is-home\" in (ul.get(\"class\") or []) else None)\n",
        "            btn = ul.select_one(\"button.see-proj-minutes\")\n",
        "            team = btn[\"data-team\"].strip().upper() if btn and btn.has_attr(\"data-team\") else None\n",
        "            starters = _extract_starters_from_ul(ul)\n",
        "            mnp = _get_mnp_from_ul(ul)\n",
        "            status = _lineup_status(ul)\n",
        "\n",
        "            if side and (team or starters or mnp):\n",
        "                rows.append({\n",
        "                    \"game_time\": \"\",\n",
        "                    \"team\": team,\n",
        "                    \"side\": side,\n",
        "                    \"lineup_status\": status,\n",
        "                    \"starters\": starters,\n",
        "                    \"may_not_play\": mnp,\n",
        "                    \"may_not_play_count\": len(mnp),\n",
        "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    for i in range(5):\n",
        "        col = f\"starter_{i+1}\"\n",
        "        if \"starters\" in df.columns:\n",
        "            df[col] = df[\"starters\"].apply(lambda xs: xs[i] if isinstance(xs, list) and len(xs) > i else None)\n",
        "\n",
        "    print(f\"‚Üí Parsed rows: {len(df)}\")\n",
        "\n",
        "    # Save a copy for downstream\n",
        "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_path = f\"{DATA_DIR}/lineups_parsed_{stamp}.csv\"\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"üíæ Saved parsed lineups to {out_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ---- RUN IT (point to the saved HTML) ----\n",
        "HTML_PATH = f\"{DEBUG_DIR}/last_lineups.html\"\n",
        "if not os.path.exists(HTML_PATH) and os.path.exists(\"last_lineups.html\"):\n",
        "    HTML_PATH = \"last_lineups.html\"\n",
        "\n",
        "df_lineups = parse_rotowire_lineups_flexible(HTML_PATH)\n",
        "\n",
        "if df_lineups.empty:\n",
        "    print(\"\\n‚ö†Ô∏è Still empty. Check DOM diagnostics and ensure Cell 3 ran successfully.\")\n",
        "else:\n",
        "    cols = [\"game_time\",\"team\",\"side\",\"lineup_status\",\"may_not_play_count\",\n",
        "            \"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]\n",
        "    print(\"\\n‚úÖ Preview:\")\n",
        "    print(df_lineups[cols].sort_values([\"game_time\",\"side\",\"team\"], na_position=\"last\").to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "id": "8974b977",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 11 games in HTML.\n",
            "‚úÖ Parsed 58 'May Not Play' players across 21 teams.\n",
            "  game_time team side position          player status            title_text  likelihood_pct\n",
            "10:00 PM ET  GSW AWAY        C      A. Horford   Ques       Toss Up To Play              50\n",
            "10:00 PM ET  GSW AWAY        G       D. Melton    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  GSW AWAY        F       J. Butler   Ques       Toss Up To Play              50\n",
            "10:00 PM ET  GSW AWAY        F        M. Moody   Ques       Toss Up To Play              50\n",
            "10:00 PM ET  GSW AWAY        G        S. Curry    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  OKC AWAY        F      A. Wiggins    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  OKC AWAY        F     J. Williams    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  OKC AWAY        F     K. Williams    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  OKC AWAY        F         L. Dort    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  OKC AWAY        G        N. Topic    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  OKC AWAY        C       T. Sorber    OFS   Very Likely To Play               0\n",
            "10:00 PM ET  DEN HOME        C        Z. Nnaji   Prob        Likely To Play              75\n",
            "10:00 PM ET  SAC HOME        C      D. Sabonis    Out Very Unlikely To Play               0\n",
            "10:00 PM ET  SAC HOME        F       K. Murray    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  BOS AWAY        F        J. Tatum    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  BOS AWAY        F      X. Tillman    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  CLE AWAY        F       Dean Wade    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  CLE AWAY        G      Lonzo Ball    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  CLE AWAY        F       Max Strus    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  ORL HOME        C       M. Wagner    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  WAS HOME        F    B. Coulibaly    Out Very Unlikely To Play               0\n",
            " 7:00 PM ET  WAS HOME        F       K. George    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  DET AWAY        G      Jaden Ivey    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  DET AWAY        G       M. Sasser    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  DET AWAY        F       T. Harris    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  HOU AWAY        F D. Finney-Smith    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  HOU AWAY        G     F. VanVleet    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  ATL HOME        G      L. Kennard    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  ATL HOME        F      N. Durisic    Out Very Unlikely To Play               0\n",
            " 7:30 PM ET  ATL HOME        G      Trae Young    Out Very Unlikely To Play               0\n",
            "\n",
            "üíæ Saved: data_raw/may_not_play_players_20251108_013841.csv\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 5: Parse \"May Not Play\" (MNP) from saved HTML -----------------------\n",
        "# pip install bs4 lxml pandas\n",
        "import os, re, pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "\n",
        "# Folders (fallbacks, in case Cell 1 wasn't run)\n",
        "DATA_DIR = \"data_raw\"; DEBUG_DIR = \"_rotowire_debug\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True); os.makedirs(DEBUG_DIR, exist_ok=True)\n",
        "\n",
        "HTML_PATH = f\"{DEBUG_DIR}/last_lineups.html\" if os.path.exists(f\"{DEBUG_DIR}/last_lineups.html\") else \"last_lineups.html\"\n",
        "\n",
        "LIKELIHOOD_MAP = {\n",
        "    \"is-pct-play-100\": 100, \"is-pct-play-90\": 90, \"is-pct-play-75\": 75,\n",
        "    \"is-pct-play-60\": 60, \"is-pct-play-50\": 50, \"is-pct-play-40\": 40,\n",
        "    \"is-pct-play-25\": 25, \"is-pct-play-10\": 10, \"is-pct-play-0\": 0\n",
        "}\n",
        "\n",
        "def _txt(node): \n",
        "    return re.sub(r\"\\s+\", \" \", node.get_text(\" \", strip=True)) if node else \"\"\n",
        "\n",
        "def _likelihood_from_classes(classes):\n",
        "    for c in classes or []:\n",
        "        if c in LIKELIHOOD_MAP:\n",
        "            return LIKELIHOOD_MAP[c]\n",
        "    return None\n",
        "\n",
        "def _clean_player(n):\n",
        "    if not n: return n\n",
        "    n = re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", n).strip()\n",
        "    n = re.sub(r\"^(PG|SG|SF|PF|C)\\s+\", \"\", n, flags=re.I)\n",
        "    return n\n",
        "\n",
        "def parse_rotowire_mnp_final(html_path: str) -> pd.DataFrame:\n",
        "    with open(html_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        soup = BeautifulSoup(f.read(), \"lxml\")\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    # Primary structure\n",
        "    games = soup.select(\"div.lineup.is-nba[data-lnum]\")\n",
        "    print(f\"Found {len(games)} games in HTML.\")\n",
        "\n",
        "    for game in games:\n",
        "        game_time = _txt(game.select_one(\".lineup__time\"))\n",
        "        # Pair teams by .lineup__team, then iterate their ULs\n",
        "        team_blocks = game.select(\".lineup__team\")\n",
        "        teams = []\n",
        "        for tb in team_blocks:\n",
        "            abbr = _txt(tb.select_one(\".lineup__abbr\")) or _txt(tb.select_one(\".lineup__team-name\"))\n",
        "            side = \"AWAY\" if \"is-visit\" in (tb.get(\"class\") or []) else (\"HOME\" if \"is-home\" in (tb.get(\"class\") or []) else None)\n",
        "            teams.append((abbr, side))\n",
        "\n",
        "        ul_lists = game.select(\"ul.lineup__list\")\n",
        "        for idx, ul in enumerate(ul_lists):\n",
        "            team, side = (teams[idx] if idx < len(teams) else (None, None))\n",
        "            # Find the MNP title in this UL\n",
        "            mnp_title = ul.find(\"li\", class_=\"lineup__title\", string=lambda s: s and \"MAY NOT PLAY\" in s.upper())\n",
        "            if not mnp_title:\n",
        "                continue\n",
        "\n",
        "            for li in mnp_title.find_next_siblings(\"li\"):\n",
        "                classes = li.get(\"class\") or []\n",
        "                if \"lineup__title\" in classes:\n",
        "                    break\n",
        "                if \"lineup__player\" not in classes:\n",
        "                    continue\n",
        "\n",
        "                pos = _txt(li.select_one(\".lineup__pos\"))\n",
        "                a = li.select_one(\"a\")\n",
        "                player = _clean_player(_txt(a))\n",
        "                if not player:\n",
        "                    continue\n",
        "\n",
        "                status = _txt(li.select_one(\".lineup__inj\"))\n",
        "                title_text = (li.get(\"title\") or \"\").strip()\n",
        "                likelihood_pct = _likelihood_from_classes(classes)\n",
        "\n",
        "                rows.append({\n",
        "                    \"game_time\": game_time,\n",
        "                    \"team\": team,\n",
        "                    \"side\": side,\n",
        "                    \"position\": pos,\n",
        "                    \"player\": player,\n",
        "                    \"status\": status,\n",
        "                    \"title_text\": title_text,\n",
        "                    \"likelihood_pct\": likelihood_pct\n",
        "                })\n",
        "\n",
        "    # Fallback: global scan (if nothing found in primary structure)\n",
        "    if not rows:\n",
        "        print(\"Fallback: global MNP scan‚Ä¶\")\n",
        "        for ul in soup.select(\"ul.lineup__list\"):\n",
        "            title = ul.find(\"li\", class_=\"lineup__title\", string=lambda s: s and \"MAY NOT PLAY\" in s.upper())\n",
        "            if not title:\n",
        "                continue\n",
        "            for li in title.find_next_siblings(\"li\"):\n",
        "                classes = li.get(\"class\") or []\n",
        "                if \"lineup__title\" in classes:\n",
        "                    break\n",
        "                if \"lineup__player\" not in classes:\n",
        "                    continue\n",
        "                player = _clean_player(_txt(li.select_one(\"a\")))\n",
        "                if not player:\n",
        "                    continue\n",
        "                rows.append({\n",
        "                    \"game_time\": \"\",\n",
        "                    \"team\": None,\n",
        "                    \"side\": None,\n",
        "                    \"position\": _txt(li.select_one(\".lineup__pos\")),\n",
        "                    \"player\": player,\n",
        "                    \"status\": _txt(li.select_one(\".lineup__inj\")),\n",
        "                    \"title_text\": (li.get(\"title\") or \"\").strip(),\n",
        "                    \"likelihood_pct\": _likelihood_from_classes(classes)\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    if df.empty:\n",
        "        print(\"‚ö†Ô∏è No 'May Not Play' players found. Check if Rotowire changed markup or re-run Cell 3.\")\n",
        "        return df\n",
        "\n",
        "    df = df.sort_values([\"game_time\",\"side\",\"team\",\"player\"], na_position=\"last\").reset_index(drop=True)\n",
        "    print(f\"‚úÖ Parsed {len(df)} 'May Not Play' players across {df['team'].nunique(dropna=True)} teams.\")\n",
        "    return df\n",
        "\n",
        "# ---- RUN ----\n",
        "mnp_df = parse_rotowire_mnp_final(HTML_PATH)\n",
        "if not mnp_df.empty:\n",
        "    print(mnp_df.head(30).to_string(index=False))\n",
        "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_csv = f\"{DATA_DIR}/may_not_play_players_{stamp}.csv\"\n",
        "    mnp_df.to_csv(out_csv, index=False)\n",
        "    print(f\"\\nüíæ Saved: {out_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "25a19799",
      "metadata": {},
      "outputs": [],
      "source": [
        "#-- Cell 6: NBA betting analysis functions -------------------------------------\n",
        "def get_daily_matchups(date=None):\n",
        "    \"\"\"Get NBA games for a specific date\"\"\"\n",
        "    if date is None:\n",
        "        date = datetime.now().strftime('%Y-%m-%d')\n",
        "    # Placeholder demo; replace with a real schedule API if desired\n",
        "    sample_matchups = [\n",
        "        {'home_team': 'GSW', 'away_team': 'LAL', 'time': '7:30 PM ET'},\n",
        "        {'home_team': 'BOS', 'away_team': 'MIA', 'time': '8:00 PM ET'},\n",
        "        {'home_team': 'DEN', 'away_team': 'DAL', 'time': '9:00 PM ET'},\n",
        "    ]\n",
        "    return sample_matchups\n",
        "\n",
        "def calculate_player_correlations(player_a_logs, player_b_logs):\n",
        "    \"\"\"Calculate correlation between two players' performances\"\"\"\n",
        "    merged = pd.merge(player_a_logs, player_b_logs, on='GAME_DATE', suffixes=('_a', '_b'))\n",
        "    correlations = {}\n",
        "    for stat in ['PTS', 'REB', 'AST']:\n",
        "        if f'{stat}_a' in merged.columns and f'{stat}_b' in merged.columns:\n",
        "            corr = merged[f'{stat}_a'].corr(merged[f'{stat}_b'])\n",
        "            correlations[stat] = corr\n",
        "    return correlations\n",
        "\n",
        "# Export results to Excel\n",
        "def export_analysis(results, filename='nba_betting_analysis.xlsx'):\n",
        "    \"\"\"Export analysis results to Excel\"\"\"\n",
        "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "        if 'value_bets' in results:\n",
        "            pd.DataFrame(results['value_bets']).to_excel(writer, sheet_name='Value_Bets', index=False)\n",
        "        if 'predictions' in results:\n",
        "            predictions_df = pd.DataFrame.from_dict(results['predictions'], orient='index')\n",
        "            predictions_df.to_excel(writer, sheet_name='Player_Predictions')\n",
        "    print(f\"Analysis exported to {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "id": "782cf0e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created 108 starter probability rows.\n",
            "‚úÖ Starter flags sample:\n",
            "       player team  is_starter  start_prob\n",
            "Derrick White  BOS           1         0.7\n",
            " P. Pritchard  BOS           1         0.7\n",
            " Jaylen Brown  BOS           1         0.7\n",
            "  Josh Minott  BOS           1         0.7\n",
            "Neemias Queta  BOS           1         0.7\n",
            "  Jalen Suggs  ORL           1         0.7\n",
            " Desmond Bane  ORL           1         0.7\n",
            " Franz Wagner  ORL           1         0.7\n",
            "  P. Banchero  ORL           1         0.7\n",
            "    W. Carter  ORL           1         0.7\n",
            "\n",
            "‚úÖ Injury flags sample:\n",
            "     player  may_not_play  injury_prob\n",
            " A. Horford           1.0          0.5\n",
            "  D. Melton           1.0          1.0\n",
            "  J. Butler           1.0          0.5\n",
            "   M. Moody           1.0          0.5\n",
            "   S. Curry           1.0          1.0\n",
            " A. Wiggins           1.0          1.0\n",
            "J. Williams           1.0          1.0\n",
            "K. Williams           1.0          1.0\n",
            "    L. Dort           1.0          1.0\n",
            "   N. Topic           1.0          1.0\n",
            "\n",
            "üíæ Saved starter flags ‚Üí data_raw/starter_flags_20251108_013841.csv\n",
            "üíæ Saved injury flags ‚Üí data_raw/injury_flags_20251108_013841.csv\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 7: starter flags (time-aware) + injury flags ------------------------\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Folders (fallbacks, in case Cell 1 wasn't run)\n",
        "DATA_DIR = \"data_raw\"; os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def compute_time_based_prob(game_time_str: str, lineup_status: str) -> float:\n",
        "    \"\"\"Rough start probability based on status and hours to tip (ET).\"\"\"\n",
        "    try:\n",
        "        if not game_time_str:\n",
        "            return 0.7\n",
        "        game_time_clean = game_time_str.replace(\"ET\", \"\").strip()\n",
        "        base_dt = datetime.strptime(game_time_clean, \"%I:%M %p\")\n",
        "        now_et = datetime.now(pytz.timezone(\"US/Eastern\"))\n",
        "        game_dt = now_et.replace(hour=base_dt.hour, minute=base_dt.minute, second=0, microsecond=0)\n",
        "        hours_to_tip = (game_dt - now_et).total_seconds() / 3600.0\n",
        "        if hours_to_tip < -3:\n",
        "            game_dt += timedelta(days=1)\n",
        "            hours_to_tip = (game_dt - now_et).total_seconds() / 3600.0\n",
        "    except Exception:\n",
        "        hours_to_tip = 6.0\n",
        "\n",
        "    st = (lineup_status or \"\").upper()\n",
        "    if \"CONFIRM\" in st:\n",
        "        return 1.0\n",
        "    if \"EXPECT\" in st or \"PROBABLE\" in st:\n",
        "        if hours_to_tip > 6: return 0.70\n",
        "        if hours_to_tip > 2: return 0.85\n",
        "        return 0.95\n",
        "    # unknown\n",
        "    return 0.60 if hours_to_tip > 4 else 0.80\n",
        "\n",
        "def build_starter_flags_timeaware(df_lineups: pd.DataFrame, mnp_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"From df_lineups (with 'starters' list per row), emit per-player start_prob.\"\"\"\n",
        "    mnp_players = set(mnp_df[\"player\"].str.strip()) if (isinstance(mnp_df, pd.DataFrame) and not mnp_df.empty) else set()\n",
        "    rows = []\n",
        "\n",
        "    if df_lineups is None or df_lineups.empty or \"starters\" not in df_lineups.columns:\n",
        "        return pd.DataFrame(columns=[\"player\",\"team\",\"is_starter\",\"start_prob\"])\n",
        "\n",
        "    for _, row in df_lineups.iterrows():\n",
        "        team = row.get(\"team\", None)\n",
        "        lineup_status = row.get(\"lineup_status\", \"\")\n",
        "        game_time = row.get(\"game_time\", \"\")\n",
        "        starters = row.get(\"starters\", [])\n",
        "        starters = starters if isinstance(starters, list) else []\n",
        "\n",
        "        for p in starters:\n",
        "            p_clean = (p or \"\").strip()\n",
        "            if not p_clean:\n",
        "                continue\n",
        "            prob = compute_time_based_prob(game_time, lineup_status)\n",
        "            if p_clean in mnp_players:\n",
        "                prob *= 0.6  # penalize if on MNP\n",
        "            rows.append({\n",
        "                \"player\": p_clean,\n",
        "                \"team\": team,\n",
        "                \"is_starter\": 1,\n",
        "                \"start_prob\": round(float(np.clip(prob, 0.0, 1.0)), 2),\n",
        "            })\n",
        "\n",
        "    df_out = pd.DataFrame(rows).drop_duplicates(subset=[\"player\"])\n",
        "    print(f\"‚úÖ Created {len(df_out)} starter probability rows.\")\n",
        "    return df_out\n",
        "\n",
        "def build_injury_flags(mnp_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Return DataFrame with may_not_play flag and injury_prob derived from status.\"\"\"\n",
        "    if mnp_df is None or mnp_df.empty:\n",
        "        return pd.DataFrame(columns=[\"player\",\"may_not_play\",\"injury_prob\"])\n",
        "\n",
        "    def map_status_to_prob(status: str):\n",
        "        \"\"\"Map injury status string to (may_not_play, injury_prob).\"\"\"\n",
        "        status = str(status).lower().strip()\n",
        "        if \"out\" in status:\n",
        "            return 1, 1.0\n",
        "        elif \"ques\" in status or \"doubt\" in status:\n",
        "            return 1, 0.5\n",
        "        elif \"prob\" in status:\n",
        "            return 0, 0.25\n",
        "        return 0, 0.0\n",
        "\n",
        "    mapped = mnp_df.dropna(subset=[\"player\"]).copy()\n",
        "    mapped[\"player\"] = mapped[\"player\"].str.strip()\n",
        "\n",
        "    if \"status\" in mapped.columns:\n",
        "        mapped[[\"may_not_play\", \"injury_prob\"]] = mapped[\"status\"].apply(\n",
        "            lambda s: pd.Series(map_status_to_prob(s))\n",
        "        )\n",
        "    else:\n",
        "        mapped[\"injury_prob\"] = mapped[\"likelihood_pct\"].fillna(40) / 100.0\n",
        "        mapped[\"may_not_play\"] = 1\n",
        "\n",
        "    return mapped[[\"player\", \"may_not_play\", \"injury_prob\"]].drop_duplicates(subset=[\"player\"])\n",
        "\n",
        "# ---- RUN (expects df_lineups from Cell 3 and mnp_df from Cell 5) ------------\n",
        "starter_flags_df = build_starter_flags_timeaware(df_lineups, mnp_df)\n",
        "injury_flags_df = build_injury_flags(mnp_df)\n",
        "\n",
        "print(\"‚úÖ Starter flags sample:\")\n",
        "print(starter_flags_df.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\n‚úÖ Injury flags sample:\")\n",
        "print(injury_flags_df.head(10).to_string(index=False))\n",
        "\n",
        "# Save outputs\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "sf_path  = f\"{DATA_DIR}/starter_flags_{stamp}.csv\"\n",
        "inj_path = f\"{DATA_DIR}/injury_flags_{stamp}.csv\"\n",
        "starter_flags_df.to_csv(sf_path, index=False)\n",
        "injury_flags_df.to_csv(inj_path, index=False)\n",
        "print(f\"\\nüíæ Saved starter flags ‚Üí {sf_path}\\nüíæ Saved injury flags ‚Üí {inj_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c0368a",
      "metadata": {},
      "source": [
        "## NBA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "id": "f4896f17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÄ Fetching NBA stats for 2023-24‚Ä¶\n",
            "‚Üí Attempt 1 fetching 2023-24‚Ä¶\n",
            "‚úÖ 2023-24: saved 572 rows ‚Üí data_raw/nba_player_stats_2023_24.csv\n",
            "\n",
            "üèÄ Fetching NBA stats for 2024-25‚Ä¶\n",
            "‚Üí Attempt 1 fetching 2024-25‚Ä¶\n",
            "‚úÖ 2024-25: saved 569 rows ‚Üí data_raw/nba_player_stats_2024_25.csv\n",
            "\n",
            "üèÄ Fetching NBA stats for 2025-26‚Ä¶\n",
            "‚Üí Attempt 1 fetching 2025-26‚Ä¶\n",
            "‚úÖ 2025-26: saved 450 rows ‚Üí data_raw/nba_player_stats_2025_26.csv\n",
            "\n",
            "üéâ Done! Saved: ['data_raw/nba_player_stats_2023_24.csv', 'data_raw/nba_player_stats_2024_25.csv', 'data_raw/nba_player_stats_2025_26.csv']\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 8: Download per-season player stats from NBA Stats API --------------\n",
        "# (Be polite: retries + small random delays)\n",
        "import os, time, random, requests, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Folders (fallbacks)\n",
        "DATA_DIR = \"data_raw\"; os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "URL = \"https://stats.nba.com/stats/leaguedashplayerstats\"\n",
        "\n",
        "BASE_PARAMS = {\n",
        "    \"College\": \"\", \"Conference\": \"\", \"Country\": \"\", \"DateFrom\": \"\", \"DateTo\": \"\",\n",
        "    \"Division\": \"\", \"DraftPick\": \"\", \"DraftYear\": \"\", \"GameScope\": \"\", \"GameSegment\": \"\",\n",
        "    \"Height\": \"\", \"ISTRound\": \"\", \"LastNGames\": \"0\", \"LeagueID\": \"00\", \"Location\": \"\",\n",
        "    \"MeasureType\": \"Base\", \"Month\": \"0\", \"OpponentTeamID\": \"0\", \"Outcome\": \"\",\n",
        "    \"PORound\": \"0\", \"PaceAdjust\": \"N\", \"PerMode\": \"PerGame\", \"Period\": \"0\",\n",
        "    \"PlayerExperience\": \"\", \"PlayerPosition\": \"\", \"PlusMinus\": \"N\", \"Rank\": \"N\",\n",
        "    \"SeasonSegment\": \"\", \"SeasonType\": \"Regular Season\", \"ShotClockRange\": \"\",\n",
        "    \"StarterBench\": \"\", \"TeamID\": \"0\", \"VsConference\": \"\", \"VsDivision\": \"\", \"Weight\": \"\"\n",
        "}\n",
        "\n",
        "HEADERS = {\n",
        "    \"Accept\": \"application/json, text/plain, */*\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Origin\": \"https://www.nba.com\",\n",
        "    \"Referer\": \"https://www.nba.com/\",\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
        "    \"x-nba-stats-origin\": \"stats\",\n",
        "    \"x-nba-stats-token\": \"true\"\n",
        "}\n",
        "\n",
        "SEASONS = [\"2023-24\", \"2024-25\", \"2025-26\"]\n",
        "\n",
        "def fetch_season(season: str, retries: int = 3) -> pd.DataFrame:\n",
        "    params = BASE_PARAMS.copy()\n",
        "    params[\"Season\"] = season\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            print(f\"‚Üí Attempt {attempt} fetching {season}‚Ä¶\")\n",
        "            r = requests.get(URL, headers=HEADERS, params=params, timeout=30)\n",
        "            r.raise_for_status()\n",
        "            js = r.json()\n",
        "            rs = js[\"resultSets\"][0]\n",
        "            df = pd.DataFrame(rs[\"rowSet\"], columns=rs[\"headers\"])\n",
        "            return df\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(f\"‚ö†Ô∏è Timeout {attempt}/{retries}; retrying‚Ä¶\")\n",
        "            time.sleep(2 * attempt)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ùå Error {attempt}/{retries}: {e}\"); time.sleep(2 * attempt)\n",
        "    raise RuntimeError(f\"Failed to fetch {season} after {retries} attempts.\")\n",
        "\n",
        "all_paths = []\n",
        "for season in SEASONS:\n",
        "    print(f\"\\nüèÄ Fetching NBA stats for {season}‚Ä¶\")\n",
        "    df = fetch_season(season)\n",
        "    path = f\"{DATA_DIR}/nba_player_stats_{season.replace('-','_')}.csv\"\n",
        "    df.to_csv(path, index=False)\n",
        "    print(f\"‚úÖ {season}: saved {len(df)} rows ‚Üí {path}\")\n",
        "    all_paths.append(path)\n",
        "    time.sleep(random.uniform(3, 6))  # throttle politely\n",
        "\n",
        "print(\"\\nüéâ Done! Saved:\", all_paths)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f33a76b7",
      "metadata": {},
      "source": [
        "## GAME LOGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "id": "7e080d50",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching 2023-24‚Ä¶\n",
            "‚úÖ Saved 26401 records ‚Üí data_raw/nba_boxscores_2023-24.csv\n",
            "Fetching 2024-25‚Ä¶\n",
            "‚úÖ Saved 26306 records ‚Üí data_raw/nba_boxscores_2024-25.csv\n",
            "Fetching 2025-26‚Ä¶\n",
            "‚úÖ Saved 2891 records ‚Üí data_raw/nba_boxscores_2025-26.csv\n",
            "\n",
            "üéâ Box score downloads complete.\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 9: Download player game logs (box scores) by season ------------------\n",
        "import os, time, requests, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Folders (fallbacks)\n",
        "DATA_DIR = \"data_raw\"; os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def get_box_scores(season: str, season_type: str = \"Regular Season\") -> pd.DataFrame:\n",
        "    url = \"https://stats.nba.com/stats/leaguegamelog\"\n",
        "    params = {\n",
        "        \"Counter\": 1000, \"DateFrom\": \"\", \"DateTo\": \"\", \"Direction\": \"DESC\",\n",
        "        \"ISTRound\": \"\", \"LeagueID\": \"00\", \"PlayerOrTeam\": \"P\",\n",
        "        \"Season\": season, \"SeasonType\": season_type, \"Sorter\": \"DATE\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
        "        \"Referer\": \"https://www.nba.com/\", \"Origin\": \"https://www.nba.com\",\n",
        "        \"Accept\": \"application/json, text/plain, */*\"\n",
        "    }\n",
        "    r = requests.get(url, params=params, headers=headers, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()[\"resultSets\"][0]\n",
        "    df = pd.DataFrame(data[\"rowSet\"], columns=data[\"headers\"])\n",
        "    return df\n",
        "\n",
        "SEASONS = [\"2023-24\",\"2024-25\",\"2025-26\"]\n",
        "# already saved once season: [\"2023-24\", \"2024-25\"]\n",
        "saved = []\n",
        "for season in SEASONS:\n",
        "    print(f\"Fetching {season}‚Ä¶\")\n",
        "    df = get_box_scores(season)\n",
        "    path = f\"{DATA_DIR}/nba_boxscores_{season}.csv\"\n",
        "    df.to_csv(path, index=False)\n",
        "    print(f\"‚úÖ Saved {len(df)} records ‚Üí {path}\")\n",
        "    saved.append(path)\n",
        "    time.sleep(2)  # polite delay\n",
        "\n",
        "print(\"\\nüéâ Box score downloads complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "a49f8cf8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved: data_enriched\\nba_player_stats_2023_24_enriched.csv\n",
            "‚úÖ Saved: data_enriched\\nba_player_stats_2024_25_enriched.csv\n",
            "‚úÖ Saved: data_enriched\\nba_player_stats_2025_26_enriched.csv\n",
            "üèÄ Combined ‚Üí data_enriched\\nba_player_stats_2023_25_combined.csv\n"
          ]
        }
      ],
      "source": [
        "# -- Cell 10: Fetch BBRef Advanced tables, align, and enrich season CSVs -------\n",
        "import os, io, unicodedata, requests, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Folders (work even if Cell 1 didn't run)\n",
        "DATA_DIR   = \"data_raw\"\n",
        "ENRICH_DIR = \"data_enriched\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(ENRICH_DIR, exist_ok=True)\n",
        "\n",
        "ADV_COLS_KEEP = [\n",
        "    \"Player\",\"Pos\",\"Age\",\"Tm\",\"G\",\"MP\",\n",
        "    \"PER\",\"TS%\",\"3PAr\",\"FTr\",\n",
        "    \"ORB%\",\"DRB%\",\"TRB%\",\n",
        "    \"AST%\",\"STL%\",\"BLK%\",\n",
        "    \"TOV%\",\"USG%\",\n",
        "    \"ORtg\",\"DRtg\",\n",
        "    \"OWS\",\"DWS\",\"WS\",\"WS/48\",\n",
        "    \"OBPM\",\"DBPM\",\"BPM\",\"VORP\"\n",
        "]\n",
        "\n",
        "TEAM_ABBR_MAP = {\n",
        "    \"BRK\": \"BKN\",\n",
        "    \"PHO\": \"PHX\",\n",
        "    \"CHO\": \"CHA\",\n",
        "    \"UTH\": \"UTA\",\n",
        "    \"NJN\": \"BKN\",\n",
        "    \"SEA\": \"OKC\",\n",
        "    \"VAN\": \"MEM\",\n",
        "}\n",
        "\n",
        "def normalize_name(s: str):\n",
        "    if pd.isna(s): return s\n",
        "    s = str(s).strip().lower()\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    for ch in [\".\",\"'\",\"`\",\"‚Äô\",\"‚Äú\",\"‚Äù\",\",\"]:\n",
        "        s = s.replace(ch, \"\")\n",
        "    return \" \".join(s.split())\n",
        "\n",
        "def fetch_advanced_table(season_end_year: int, retries: int = 3) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    season_end_year=2025 -> https://www.basketball-reference.com/leagues/NBA_2025_advanced.html\n",
        "    \"\"\"\n",
        "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season_end_year}_advanced.html\"\n",
        "    headers = {\n",
        "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                       \"Chrome/120.0.0.0 Safari/537.36\")\n",
        "    }\n",
        "    last_err = None\n",
        "    for attempt in range(1, retries+1):\n",
        "        try:\n",
        "            r = requests.get(url, headers=headers, timeout=30)\n",
        "            r.raise_for_status()\n",
        "            tables = pd.read_html(io.StringIO(r.text), header=0)\n",
        "            if not tables:\n",
        "                raise RuntimeError(\"No tables parsed from page.\")\n",
        "            df = tables[0].copy()\n",
        "            # Drop duplicate header rows\n",
        "            if \"Rk\" in df.columns:\n",
        "                df = df[df[\"Rk\"] != \"Rk\"].copy()\n",
        "                df.drop(columns=[\"Rk\"], inplace=True, errors=\"ignore\")\n",
        "            df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "            # Ensure team column name\n",
        "            team_col = None\n",
        "            for c in df.columns:\n",
        "                if c.lower() in (\"tm\",\"team\",\"team_name\"):\n",
        "                    team_col = c; break\n",
        "            if not team_col:\n",
        "                raise KeyError(f\"Team column not found. Columns: {df.columns.tolist()}\")\n",
        "            df.rename(columns={team_col: \"Tm\"}, inplace=True)\n",
        "\n",
        "            keep = [c for c in ADV_COLS_KEEP if c in df.columns]\n",
        "            df = df[keep].copy()\n",
        "\n",
        "            for c in df.columns:\n",
        "                if c not in {\"Player\",\"Pos\",\"Tm\"}:\n",
        "                    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "            df[\"Tm\"] = df[\"Tm\"].replace(TEAM_ABBR_MAP)\n",
        "            df[\"player_key\"] = df[\"Player\"].map(normalize_name)\n",
        "            df[\"team_key\"] = df[\"Tm\"].astype(str).str.strip().str.upper()\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    raise last_err\n",
        "\n",
        "def load_averages_csv(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    # map columns to canonical 'Player' and 'Team'\n",
        "    col_map = {}\n",
        "    for c in df.columns:\n",
        "        cl = c.strip().lower()\n",
        "        if cl == \"player_name\": col_map[c] = \"Player\"\n",
        "        elif cl in (\"team_abbreviation\",\"tm\",\"team\"): col_map[c] = \"Team\"\n",
        "    df = df.rename(columns=col_map)\n",
        "    if \"Player\" not in df.columns or \"Team\" not in df.columns:\n",
        "        raise ValueError(f\"'Player' and 'Team' required. Got: {list(df.columns)}\")\n",
        "    df[\"player_key\"] = df[\"Player\"].map(normalize_name)\n",
        "    df[\"team_key\"]   = df[\"Team\"].astype(str).str.strip().str.upper()\n",
        "    return df\n",
        "\n",
        "def merge_advanced_into_averages(df_avg: pd.DataFrame, df_adv: pd.DataFrame) -> pd.DataFrame:\n",
        "    adv_team = df_adv[df_adv[\"Tm\"] != \"TOT\"].copy()\n",
        "    adv_tot  = df_adv[df_adv[\"Tm\"] == \"TOT\"].copy()\n",
        "\n",
        "    adv_cols = [c for c in df_adv.columns if c not in {\"Player\",\"Pos\",\"Age\",\"Tm\",\"player_key\",\"team_key\"}]\n",
        "    meta_cols = [c for c in [\"Pos\",\"Age\"] if c in df_adv.columns]\n",
        "    add_cols = meta_cols + adv_cols\n",
        "\n",
        "    merged = df_avg.merge(\n",
        "        adv_team[[\"player_key\",\"team_key\"] + add_cols],\n",
        "        on=[\"player_key\",\"team_key\"], how=\"left\"\n",
        "    )\n",
        "\n",
        "    # Fill gaps from TOT by player\n",
        "    probe = \"PER\" if \"PER\" in merged.columns else (\"WS/48\" if \"WS/48\" in merged.columns else None)\n",
        "    missing = merged[probe].isna() if probe else merged.isna().any(axis=1)\n",
        "    if missing.any() and not adv_tot.empty:\n",
        "        fb = merged.loc[missing, [\"player_key\"]].merge(\n",
        "            adv_tot[[\"player_key\"] + add_cols], on=\"player_key\", how=\"left\"\n",
        "        )\n",
        "        for col in add_cols:\n",
        "            if col in merged.columns and col in fb.columns:\n",
        "                merged.loc[missing, col] = merged.loc[missing, col].fillna(fb[col])\n",
        "    return merged\n",
        "\n",
        "# --- Build both seasons and save into ENRICH_DIR ------------------------------\n",
        "# Map: \"2023-24\" -> 2024, \"2024-25\" -> 2025\n",
        "pairs = [\n",
        "    (\"2023_24\", 2024),\n",
        "    (\"2024_25\", 2025),\n",
        "    (\"2025_26\", 2026),\n",
        "]\n",
        "out_paths = []\n",
        "for tag, yr in pairs:\n",
        "    avg_path = os.path.join(DATA_DIR, f\"nba_player_stats_{tag}.csv\")\n",
        "    if not os.path.exists(avg_path):\n",
        "        raise FileNotFoundError(f\"Missing averages CSV: {avg_path}. Run Cell 8 first.\")\n",
        "    df_avg = load_averages_csv(avg_path)\n",
        "    df_adv = fetch_advanced_table(yr)\n",
        "    df_enriched = merge_advanced_into_averages(df_avg, df_adv)\n",
        "\n",
        "    outp = os.path.join(ENRICH_DIR, f\"nba_player_stats_{tag}_enriched.csv\")\n",
        "    df_enriched.to_csv(outp, index=False)\n",
        "    print(f\"‚úÖ Saved: {outp}\")\n",
        "    out_paths.append(outp)\n",
        "\n",
        "# Optional combined\n",
        "combined = pd.concat([pd.read_csv(p) for p in out_paths], ignore_index=True)\n",
        "combined.to_csv(os.path.join(ENRICH_DIR, \"nba_player_stats_2023_25_combined.csv\"), index=False)\n",
        "print(\"üèÄ Combined ‚Üí\", os.path.join(ENRICH_DIR, \"nba_player_stats_2023_25_combined.csv\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "id": "86805666",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- Cell 11: Game-log ‚Üí features (rolling, team ratings, opponent allowances) -\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def standardize_logs_cols(df_logs: pd.DataFrame) -> pd.DataFrame:\n",
        "    colmap = {}\n",
        "    for c in df_logs.columns:\n",
        "        cl = c.strip().lower()\n",
        "        if cl in {\"game_date\",\"game_date_est\",\"date\"}: colmap[c] = \"GAME_DATE\"\n",
        "        elif cl in {\"player\",\"player_name\"}: colmap[c] = \"PLAYER_NAME\"\n",
        "        elif cl in {\"team\",\"team_abbreviation\",\"tm\"}: colmap[c] = \"TEAM_ABBREVIATION\"\n",
        "        elif cl in {\"opp\",\"opponent\",\"opponent_abbreviation\"}: colmap[c] = \"OPPONENT_ABBREVIATION\"\n",
        "        elif cl in {\"min\",\"minutes\"}: colmap[c] = \"MIN\"\n",
        "    df = df_logs.rename(columns=colmap).copy()\n",
        "    df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
        "    df = df.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "    return df\n",
        "\n",
        "def add_shooting_efficiency(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    for col in [\"FGA\",\"FTA\",\"PTS\"]:\n",
        "        if col not in df.columns: df[col] = 0.0\n",
        "    denom = 2 * (df[\"FGA\"].astype(float) + 0.44 * df[\"FTA\"].astype(float))\n",
        "    df[\"TS_game\"] = np.where(denom > 0, df[\"PTS\"].astype(float)/denom, np.nan)\n",
        "    return df\n",
        "\n",
        "def rolling_player_form(df: pd.DataFrame, windows=(3,5,10,20)) -> pd.DataFrame:\n",
        "    df = df.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).copy()\n",
        "    g = df.groupby(\"PLAYER_NAME\", group_keys=False)\n",
        "    for w in windows:\n",
        "        for stat in [\"PTS\",\"REB\",\"AST\",\"MIN\",\"TS_game\"]:\n",
        "            if stat not in df.columns: df[stat] = np.nan\n",
        "            df[f\"{stat}_roll{w}\"] = g[stat].shift(1).rolling(w, min_periods=1).mean()\n",
        "    if {\"FGA\",\"TEAM_ABBREVIATION\"}.issubset(df.columns):\n",
        "        df[\"teamFGA_game\"] = df.groupby([\"TEAM_ABBREVIATION\",\"GAME_DATE\"])[\"FGA\"].transform(\"sum\")\n",
        "        df[\"usage_share\"] = np.where(df[\"teamFGA_game\"]>0, df[\"FGA\"]/df[\"teamFGA_game\"], np.nan)\n",
        "        df[\"usage_share_roll5\"] = g[\"usage_share\"].shift(1).rolling(5, min_periods=1).mean()\n",
        "    return df\n",
        "\n",
        "def team_daily_ratings(df: pd.DataFrame, windows=(5,10)) -> pd.DataFrame:\n",
        "    # Poss ‚âà FGA + 0.44*FTA - OREB + TOV  (OREB optional)\n",
        "    for c in [\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\"GAME_DATE\",\"PTS\",\"FGA\",\"FTA\",\"TOV\",\"OREB\"]:\n",
        "        if c not in df.columns: df[c] = 0.0\n",
        "\n",
        "    g = df.groupby([\"GAME_DATE\",\"TEAM_ABBREVIATION\"], as_index=False).agg(\n",
        "        PTS_team=(\"PTS\",\"sum\"), FGA=(\"FGA\",\"sum\"), FTA=(\"FTA\",\"sum\"),\n",
        "        TOV=(\"TOV\",\"sum\"), OREB=(\"OREB\",\"sum\")\n",
        "    )\n",
        "    g[\"poss\"] = g[\"FGA\"] + 0.44*g[\"FTA\"] - g[\"OREB\"] + g[\"TOV\"]\n",
        "\n",
        "    opp = g.rename(columns={\n",
        "        \"TEAM_ABBREVIATION\":\"OPPONENT_ABBREVIATION\",\n",
        "        \"PTS_team\":\"PTS_opp\", \"poss\":\"poss_opp\"\n",
        "    })[[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\",\"PTS_opp\",\"poss_opp\"]]\n",
        "\n",
        "    g2 = g.merge(opp, on=[\"GAME_DATE\"], how=\"left\")\n",
        "    g2[\"ORtg_g\"] = np.where(g2[\"poss\"]>0, 100*g2[\"PTS_team\"]/g2[\"poss\"], np.nan)\n",
        "    g2[\"DRtg_g\"] = np.where(g2[\"poss_opp\"]>0, 100*g2[\"PTS_opp\"]/g2[\"poss_opp\"], np.nan)\n",
        "    g2[\"Pace_g\"] = (g2[\"poss\"] + g2[\"poss_opp\"]) / 2.0\n",
        "\n",
        "    g2 = g2.sort_values([\"TEAM_ABBREVIATION\",\"GAME_DATE\"])\n",
        "    for w in windows:\n",
        "        for stat in [\"ORtg_g\",\"DRtg_g\",\"Pace_g\"]:\n",
        "            g2[f\"{stat}_roll{w}\"] = (\n",
        "                g2.groupby(\"TEAM_ABBREVIATION\")[stat].shift(1).rolling(w, min_periods=1).mean()\n",
        "            )\n",
        "    keep = [\"GAME_DATE\",\"TEAM_ABBREVIATION\",\"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
        "            \"ORtg_g_roll10\",\"DRtg_g_roll10\",\"Pace_g_roll10\"]\n",
        "    return g2[keep].drop_duplicates(subset=[\"GAME_DATE\",\"TEAM_ABBREVIATION\"], keep=\"last\")\n",
        "\n",
        "def opponent_position_allowances(df: pd.DataFrame, window=10) -> pd.DataFrame:\n",
        "    if \"START_POSITION\" not in df.columns:\n",
        "        df[\"START_POSITION\"] = np.nan\n",
        "    base = (df.groupby([\"GAME_DATE\",\"OPPONENT_ABBREVIATION\",\"START_POSITION\"], as_index=False)\n",
        "              .agg(PTS_allowed=(\"PTS\",\"sum\"), AST_allowed=(\"AST\",\"sum\"), REB_allowed=(\"REB\",\"sum\"))\n",
        "              .sort_values([\"OPPONENT_ABBREVIATION\",\"START_POSITION\",\"GAME_DATE\"]))\n",
        "    for stat in [\"PTS_allowed\",\"AST_allowed\",\"REB_allowed\"]:\n",
        "        base[f\"{stat}_roll{window}\"] = (\n",
        "            base.groupby([\"OPPONENT_ABBREVIATION\",\"START_POSITION\"])[stat]\n",
        "                .shift(1).rolling(window, min_periods=3).mean()\n",
        "        )\n",
        "    wide = base.pivot_table(\n",
        "        index=[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\"],\n",
        "        columns=\"START_POSITION\",\n",
        "        values=[f\"PTS_allowed_roll{window}\",f\"AST_allowed_roll{window}\",f\"REB_allowed_roll{window}\"]\n",
        "    )\n",
        "    wide.columns = [f\"{a}_{b}\" for a,b in wide.columns.to_flat_index()]\n",
        "    return wide.reset_index()\n",
        "\n",
        "def assemble_player_game_features(df_logs: pd.DataFrame, df_enriched_season: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = standardize_logs_cols(df_logs)\n",
        "    # Extract OPPONENT_ABBREVIATION from MATCHUP column\n",
        "    df[\"OPPONENT_ABBREVIATION\"] = df[\"MATCHUP\"].str.extract(r\"(?:vs\\.|@)\\s+([A-Z]+)\")\n",
        "    # Normalize opp_key from abbreviation\n",
        "    abbrev_to_key = {\n",
        "        \"ATL\": \"ATLANTAHAWKS\", \"BOS\": \"BOSTONCELTICS\", \"BKN\": \"BROOKLYNNETS\", \"CHA\": \"CHARLOTTEHORNETS\",\n",
        "        \"CHI\": \"CHICAGOBULLS\", \"CLE\": \"CAVALIERS\", \"DAL\": \"DALLASMAVERICKS\", \"DEN\": \"DENVERNUGGETS\",\n",
        "        \"DET\": \"DETPISTONS\", \"GSW\": \"WARRIORS\", \"HOU\": \"ROCKETS\", \"IND\": \"PACERS\",\n",
        "        \"LAC\": \"CLIPPERS\", \"LAL\": \"LAKERS\", \"MEM\": \"GRIZZLIES\", \"MIA\": \"HEAT\",\n",
        "        \"MIL\": \"BUCKS\", \"MIN\": \"TIMBERWOLVES\", \"NOP\": \"PELICANS\", \"NYK\": \"KNICKS\",\n",
        "        \"OKC\": \"THUNDER\", \"ORL\": \"MAGIC\", \"PHI\": \"SIXERS\", \"PHX\": \"SUNS\",\n",
        "        \"POR\": \"BLAZERS\", \"SAC\": \"KINGS\", \"SAS\": \"SPURS\", \"TOR\": \"RAPTORS\",\n",
        "        \"UTA\": \"UTAHJAZZ\", \"WAS\": \"WASHINGTONWIZARDS\"\n",
        "    }\n",
        "\n",
        "    df[\"opp_key\"] = df[\"OPPONENT_ABBREVIATION\"].map(abbrev_to_key)\n",
        "    \n",
        "    df = add_shooting_efficiency(df)\n",
        "    df = rolling_player_form(df)\n",
        "\n",
        "    tr = team_daily_ratings(df)\n",
        "    df = df.merge(tr, on=[\"GAME_DATE\",\"TEAM_ABBREVIATION\"], how=\"left\")\n",
        "\n",
        "    oppw = opponent_position_allowances(df)\n",
        "    df = df.merge(oppw, on=[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\"], how=\"left\")\n",
        "\n",
        "    # Merge season-enriched (PER/TS%/USG%/ORtg/DRtg/etc.)\n",
        "    def _norm(s):\n",
        "        s = str(s).strip().lower()\n",
        "        s = unicodedata.normalize(\"NFKD\", s)\n",
        "        s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "        for ch in [\".\",\"'\",\"`\",\"‚Äô\",\"‚Äú\",\"‚Äù\",\",\"]:\n",
        "            s = s.replace(ch,\"\")\n",
        "        return \" \".join(s.split())\n",
        "\n",
        "    tmp = df_enriched_season.copy()\n",
        "    df[\"player_key\"] = df[\"PLAYER_NAME\"].map(_norm)\n",
        "    df[\"team_key\"]   = df[\"TEAM_ABBREVIATION\"].astype(str).str.upper()\n",
        "    tmp[\"player_key\"] = tmp[\"Player\"].map(_norm)\n",
        "    tmp[\"team_key\"]   = tmp[\"Team\"].astype(str).str.upper()\n",
        "\n",
        "    keep_adv = [c for c in [\"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\"Pos\",\"Age\"] if c in tmp.columns]\n",
        "    df = df.merge(tmp[[\"player_key\",\"team_key\"] + keep_adv], on=[\"player_key\",\"team_key\"], how=\"left\")\n",
        "\n",
        "    # Situational flags\n",
        "    if \"MATCHUP\" in df.columns:\n",
        "        df[\"HOME\"] = df[\"MATCHUP\"].str.contains(\" vs. \", regex=False).astype(int)\n",
        "    else:\n",
        "        df[\"HOME\"] = np.nan\n",
        "\n",
        "    # Rest flags + next-game targets (minutes too)\n",
        "    df = df.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "    df[\"prev_date\"] = df.groupby(\"PLAYER_NAME\")[\"GAME_DATE\"].shift(1)\n",
        "    df[\"days_rest\"] = (df[\"GAME_DATE\"] - df[\"prev_date\"]).dt.days\n",
        "    df[\"is_b2b\"]    = (df[\"days_rest\"] == 0).astype(int)\n",
        "\n",
        "    for target, src in [(\"PTS_next\",\"PTS\"), (\"REB_next\",\"REB\"), (\"AST_next\",\"AST\"), (\"MIN_next\",\"MIN\")]:\n",
        "        if src not in df.columns: df[src] = np.nan\n",
        "        df[target] = df.groupby(\"PLAYER_NAME\")[src].shift(-1)\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "id": "600ad827",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Total records: 810\n",
            "Columns: ['id', 'name', 'l3', 'l5', 'l10', 'all', 'season_id', 'stats_id', 'position_id', 'stat_type', 'position']\n",
            "  id               name     l3     l5    l10    all  season_id  stats_id  position_id stat_type position\n",
            "0  1      Atlanta Hawks  20.50  17.17  17.50  17.50         25         4            1       PTS        G\n",
            "1  2     Boston Celtics  15.00  16.75  19.63  19.63         25         4            1       PTS        G\n",
            "2  3      Brooklyn Nets  21.40  17.67  18.79  18.79         25         4            1       PTS        G\n",
            "3  4  Charlotte Hornets  14.80  14.88  17.38  17.38         25         4            1       PTS        G\n",
            "4  5      Chicago Bulls  21.50  19.18  17.93  17.93         25         4            1       PTS        G\n",
            "\n",
            "üíæ Saved to defense_vs_position_combined.csv\n"
          ]
        }
      ],
      "source": [
        "# -- cell 12a --\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Base URL\n",
        "url = \"https://www.dunkest.com/api/stats/defense-vs-position\"\n",
        "\n",
        "# Define the combinations with corrected mappings\n",
        "stats_ids = [4, 26, 5]  # 4: pts, 26: reb, 5: ast\n",
        "position_ids = [1, 2, 3]  # 1: G, 2: F, 3: C\n",
        "season_ids = [25, 19, 13]  # 25: 2025‚Äì26, 19: 2024‚Äì25, 13: 2023‚Äì24\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0\",\n",
        "    \"Accept\": \"application/json\"\n",
        "}\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for season_id in season_ids:\n",
        "    for stats_id in stats_ids:\n",
        "        for position_id in position_ids:\n",
        "            params = {\n",
        "                \"season_id\": season_id,\n",
        "                \"stats_id\": stats_id,\n",
        "                \"position_id\": position_id\n",
        "            }\n",
        "            \n",
        "            try:\n",
        "                response = requests.get(url, params=params, headers=headers)\n",
        "                data = response.json()\n",
        "                \n",
        "                # Add identifiers to each record\n",
        "                for record in data:\n",
        "                    record['season_id'] = season_id   # ‚úÖ FIXED: correct single season_id\n",
        "                    record['stats_id'] = stats_id\n",
        "                    record['position_id'] = position_id\n",
        "\n",
        "                    # Map IDs to readable names\n",
        "                    stat_names = {4: 'PTS', 26: 'REB', 5: 'AST'}\n",
        "                    position_names = {1: 'G', 2: 'F', 3: 'C'}\n",
        "\n",
        "                    record['stat_type'] = stat_names.get(stats_id, f'unknown_{stats_id}')\n",
        "                    record['position'] = position_names.get(position_id, f'unknown_{position_id}')\n",
        "                \n",
        "                all_data.extend(data)\n",
        "                \n",
        "                time.sleep(0.5)  # be polite to API\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error fetching stats_id={stats_id}, position_id={position_id}, season_id={season_id}: {e}\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_combined = pd.DataFrame(all_data)\n",
        "\n",
        "print(f\"\\n‚úÖ Total records: {len(df_combined)}\")\n",
        "print(f\"Columns: {df_combined.columns.tolist()}\")\n",
        "print(df_combined.head())\n",
        "\n",
        "# Optional: Save to CSV\n",
        "df_combined.to_csv('defense_vs_position_combined.csv', index=False)\n",
        "print(f\"\\nüíæ Saved to defense_vs_position_combined.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "id": "c8906fea",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SEASON_ID</th>\n",
              "      <th>PLAYER_ID</th>\n",
              "      <th>PLAYER_NAME</th>\n",
              "      <th>TEAM_ID</th>\n",
              "      <th>TEAM_ABBREVIATION</th>\n",
              "      <th>TEAM_NAME</th>\n",
              "      <th>GAME_ID</th>\n",
              "      <th>GAME_DATE</th>\n",
              "      <th>MATCHUP</th>\n",
              "      <th>WL</th>\n",
              "      <th>MIN</th>\n",
              "      <th>FGM</th>\n",
              "      <th>FGA</th>\n",
              "      <th>FG_PCT</th>\n",
              "      <th>FG3M</th>\n",
              "      <th>FG3A</th>\n",
              "      <th>FG3_PCT</th>\n",
              "      <th>FTM</th>\n",
              "      <th>FTA</th>\n",
              "      <th>FT_PCT</th>\n",
              "      <th>OREB</th>\n",
              "      <th>DREB</th>\n",
              "      <th>REB</th>\n",
              "      <th>AST</th>\n",
              "      <th>STL</th>\n",
              "      <th>BLK</th>\n",
              "      <th>TOV</th>\n",
              "      <th>PF</th>\n",
              "      <th>PTS</th>\n",
              "      <th>PLUS_MINUS</th>\n",
              "      <th>FANTASY_PTS</th>\n",
              "      <th>VIDEO_AVAILABLE</th>\n",
              "      <th>OPPONENT_ABBREVIATION</th>\n",
              "      <th>opp_key</th>\n",
              "      <th>TS_game</th>\n",
              "      <th>PTS_roll3</th>\n",
              "      <th>REB_roll3</th>\n",
              "      <th>AST_roll3</th>\n",
              "      <th>MIN_roll3</th>\n",
              "      <th>TS_game_roll3</th>\n",
              "      <th>PTS_roll5</th>\n",
              "      <th>REB_roll5</th>\n",
              "      <th>AST_roll5</th>\n",
              "      <th>MIN_roll5</th>\n",
              "      <th>TS_game_roll5</th>\n",
              "      <th>PTS_roll10</th>\n",
              "      <th>REB_roll10</th>\n",
              "      <th>AST_roll10</th>\n",
              "      <th>MIN_roll10</th>\n",
              "      <th>TS_game_roll10</th>\n",
              "      <th>PTS_roll20</th>\n",
              "      <th>REB_roll20</th>\n",
              "      <th>AST_roll20</th>\n",
              "      <th>MIN_roll20</th>\n",
              "      <th>TS_game_roll20</th>\n",
              "      <th>teamFGA_game</th>\n",
              "      <th>usage_share</th>\n",
              "      <th>usage_share_roll5</th>\n",
              "      <th>ORtg_g_roll5</th>\n",
              "      <th>DRtg_g_roll5</th>\n",
              "      <th>Pace_g_roll5</th>\n",
              "      <th>ORtg_g_roll10</th>\n",
              "      <th>DRtg_g_roll10</th>\n",
              "      <th>Pace_g_roll10</th>\n",
              "      <th>START_POSITION</th>\n",
              "      <th>player_key</th>\n",
              "      <th>team_key</th>\n",
              "      <th>PER</th>\n",
              "      <th>TS%</th>\n",
              "      <th>USG%</th>\n",
              "      <th>WS/48</th>\n",
              "      <th>BPM</th>\n",
              "      <th>VORP</th>\n",
              "      <th>Pos</th>\n",
              "      <th>Age</th>\n",
              "      <th>HOME</th>\n",
              "      <th>prev_date</th>\n",
              "      <th>days_rest</th>\n",
              "      <th>is_b2b</th>\n",
              "      <th>PTS_next</th>\n",
              "      <th>REB_next</th>\n",
              "      <th>AST_next</th>\n",
              "      <th>MIN_next</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300277</td>\n",
              "      <td>2023-12-01</td>\n",
              "      <td>DAL vs. MEM</td>\n",
              "      <td>L</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1</td>\n",
              "      <td>MEM</td>\n",
              "      <td>GRIZZLIES</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>92</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94.719871</td>\n",
              "      <td>111.136901</td>\n",
              "      <td>101.024</td>\n",
              "      <td>94.719871</td>\n",
              "      <td>112.807308</td>\n",
              "      <td>99.830</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300287</td>\n",
              "      <td>2023-12-02</td>\n",
              "      <td>DAL vs. OKC</td>\n",
              "      <td>L</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0.400</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.429</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>OKC</td>\n",
              "      <td>THUNDER</td>\n",
              "      <td>0.551471</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>87</td>\n",
              "      <td>0.114943</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>117.187500</td>\n",
              "      <td>109.794310</td>\n",
              "      <td>103.896</td>\n",
              "      <td>117.187500</td>\n",
              "      <td>115.510621</td>\n",
              "      <td>102.764</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-12-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22301213</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>DAL vs. UTA</td>\n",
              "      <td>W</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1</td>\n",
              "      <td>UTA</td>\n",
              "      <td>UTAHJAZZ</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>101</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>0.062906</td>\n",
              "      <td>139.521640</td>\n",
              "      <td>102.837230</td>\n",
              "      <td>104.280</td>\n",
              "      <td>139.521640</td>\n",
              "      <td>105.263825</td>\n",
              "      <td>103.660</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-12-02</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22301226</td>\n",
              "      <td>2023-12-08</td>\n",
              "      <td>DAL @ POR</td>\n",
              "      <td>W</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1</td>\n",
              "      <td>POR</td>\n",
              "      <td>BLAZERS</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>91</td>\n",
              "      <td>0.032967</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>117.172853</td>\n",
              "      <td>110.954684</td>\n",
              "      <td>103.672</td>\n",
              "      <td>117.172853</td>\n",
              "      <td>115.883515</td>\n",
              "      <td>103.930</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300299</td>\n",
              "      <td>2023-12-11</td>\n",
              "      <td>DAL @ MEM</td>\n",
              "      <td>W</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1</td>\n",
              "      <td>MEM</td>\n",
              "      <td>GRIZZLIES</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.628268</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>86</td>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.044645</td>\n",
              "      <td>118.389897</td>\n",
              "      <td>113.679259</td>\n",
              "      <td>102.652</td>\n",
              "      <td>118.389897</td>\n",
              "      <td>119.208900</td>\n",
              "      <td>102.326</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-08</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SEASON_ID  PLAYER_ID  PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION         TEAM_NAME   GAME_ID  GAME_DATE      MATCHUP WL  MIN  FGM  FGA  FG_PCT  FG3M  FG3A  \\\n",
              "0      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300277 2023-12-01  DAL vs. MEM  L    4    0    1   0.000     0     1   \n",
              "1      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300287 2023-12-02  DAL vs. OKC  L   19    4   10   0.400     3     7   \n",
              "2      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301213 2023-12-06  DAL vs. UTA  W    7    2    2   1.000     0     0   \n",
              "3      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301226 2023-12-08    DAL @ POR  W    7    1    3   0.333     0     2   \n",
              "4      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300299 2023-12-11    DAL @ MEM  W   14    2    7   0.286     0     4   \n",
              "\n",
              "   FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  FANTASY_PTS  VIDEO_AVAILABLE OPPONENT_ABBREVIATION    opp_key  \\\n",
              "0    0.000    1    2     0.5     0     1    1    0    0    0    0   0    1           4          2.2                1                   MEM  GRIZZLIES   \n",
              "1    0.429    1    2     0.5     0     0    0    2    0    1    0   1   12           9         18.0                1                   OKC    THUNDER   \n",
              "2      NaN    0    0     NaN     1     0    1    0    0    0    0   0    4           7          5.2                1                   UTA   UTAHJAZZ   \n",
              "3    0.000    0    0     NaN     0     1    1    0    0    0    0   1    2          -4          3.2                1                   POR    BLAZERS   \n",
              "4    0.000    0    0     NaN     1     0    1    1    0    0    1   0    4           1          5.7                1                   MEM  GRIZZLIES   \n",
              "\n",
              "    TS_game  PTS_roll3  REB_roll3  AST_roll3  MIN_roll3  TS_game_roll3  PTS_roll5  REB_roll5  AST_roll5  MIN_roll5  TS_game_roll5  PTS_roll10  REB_roll10  \\\n",
              "0  0.265957        NaN        NaN        NaN        NaN            NaN        NaN        NaN        NaN        NaN            NaN         NaN         NaN   \n",
              "1  0.551471   1.000000   1.000000   0.000000        4.0       0.265957   1.000000   1.000000   0.000000       4.00       0.265957    1.000000    1.000000   \n",
              "2  1.000000   6.500000   0.500000   1.000000       11.5       0.408714   6.500000   0.500000   1.000000      11.50       0.408714    6.500000    0.500000   \n",
              "3  0.333333   5.666667   0.666667   0.666667       10.0       0.605809   5.666667   0.666667   0.666667      10.00       0.605809    5.666667    0.666667   \n",
              "4  0.285714   6.000000   0.666667   0.666667       11.0       0.628268   4.750000   0.750000   0.500000       9.25       0.537690    4.750000    0.750000   \n",
              "\n",
              "   AST_roll10  MIN_roll10  TS_game_roll10  PTS_roll20  REB_roll20  AST_roll20  MIN_roll20  TS_game_roll20  teamFGA_game  usage_share  usage_share_roll5  \\\n",
              "0         NaN         NaN             NaN         NaN         NaN         NaN         NaN             NaN            92     0.010870                NaN   \n",
              "1    0.000000        4.00        0.265957    1.000000    1.000000    0.000000        4.00        0.265957            87     0.114943           0.010870   \n",
              "2    1.000000       11.50        0.408714    6.500000    0.500000    1.000000       11.50        0.408714           101     0.019802           0.062906   \n",
              "3    0.666667       10.00        0.605809    5.666667    0.666667    0.666667       10.00        0.605809            91     0.032967           0.048538   \n",
              "4    0.500000        9.25        0.537690    4.750000    0.750000    0.500000        9.25        0.537690            86     0.081395           0.044645   \n",
              "\n",
              "   ORtg_g_roll5  DRtg_g_roll5  Pace_g_roll5  ORtg_g_roll10  DRtg_g_roll10  Pace_g_roll10  START_POSITION player_key team_key   PER    TS%  USG%  WS/48  BPM  \\\n",
              "0     94.719871    111.136901       101.024      94.719871     112.807308         99.830             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
              "1    117.187500    109.794310       103.896     117.187500     115.510621        102.764             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
              "2    139.521640    102.837230       104.280     139.521640     105.263825        103.660             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
              "3    117.172853    110.954684       103.672     117.172853     115.883515        103.930             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
              "4    118.389897    113.679259       102.652     118.389897     119.208900        102.326             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
              "\n",
              "   VORP Pos   Age  HOME  prev_date  days_rest  is_b2b  PTS_next  REB_next  AST_next  MIN_next  \n",
              "0  -0.2  SG  23.0     1        NaT        NaN       0      12.0       0.0       2.0      19.0  \n",
              "1  -0.2  SG  23.0     1 2023-12-01        1.0       0       4.0       1.0       0.0       7.0  \n",
              "2  -0.2  SG  23.0     1 2023-12-02        4.0       0       2.0       1.0       0.0       7.0  \n",
              "3  -0.2  SG  23.0     0 2023-12-06        2.0       0       4.0       1.0       1.0      14.0  \n",
              "4  -0.2  SG  23.0     0 2023-12-08        3.0       0       0.0       0.0       0.0       0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# -- Cell 12_data: Load logs + build features_all with season weights ------------------------------\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "DATA_DIR   = \"data_raw\"\n",
        "ENRICH_DIR = \"data_enriched\"\n",
        "\n",
        "paths = {\n",
        "    \"logs_2324\": os.path.join(DATA_DIR, \"nba_boxscores_2023-24.csv\"),\n",
        "    \"logs_2425\": os.path.join(DATA_DIR, \"nba_boxscores_2024-25.csv\"),\n",
        "    \"logs_2526\": os.path.join(DATA_DIR, \"nba_boxscores_2025-26.csv\"),\n",
        "    \"enr_2324\":  os.path.join(ENRICH_DIR, \"nba_player_stats_2023_24_enriched.csv\"),\n",
        "    \"enr_2425\":  os.path.join(ENRICH_DIR, \"nba_player_stats_2024_25_enriched.csv\"),\n",
        "    \"enr_2526\":  os.path.join(ENRICH_DIR, \"nba_player_stats_2025_26_enriched.csv\")\n",
        "}\n",
        "\n",
        "# Check all required files exist\n",
        "for k, p in paths.items():\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"Missing required file {p} (from earlier cells).\")\n",
        "\n",
        "# Load boxscores + enriched stats\n",
        "logs_2324     = pd.read_csv(paths[\"logs_2324\"])\n",
        "logs_2425     = pd.read_csv(paths[\"logs_2425\"])\n",
        "logs_2526     = pd.read_csv(paths[\"logs_2526\"])\n",
        "enriched_2324 = pd.read_csv(paths[\"enr_2324\"])\n",
        "enriched_2425 = pd.read_csv(paths[\"enr_2425\"])\n",
        "enriched_2526 = pd.read_csv(paths[\"enr_2526\"])\n",
        "\n",
        "# Apply weights to enriched stats before combining\n",
        "enriched_2324[\"season_weight\"] = 0.1\n",
        "enriched_2425[\"season_weight\"] = 0.3\n",
        "enriched_2526[\"season_weight\"] = 0.6\n",
        "\n",
        "# Optionally mark source season (if needed later)\n",
        "enriched_2324[\"season\"] = \"2023-24\"\n",
        "enriched_2425[\"season\"] = \"2024-25\"\n",
        "enriched_2526[\"season\"] = \"2025-26\"\n",
        "\n",
        "# Feature engineering\n",
        "feat_2324 = assemble_player_game_features(logs_2324, enriched_2324)\n",
        "feat_2425 = assemble_player_game_features(logs_2425, enriched_2425)\n",
        "feat_2526 = assemble_player_game_features(logs_2526, enriched_2526)\n",
        "\n",
        "# Combine all seasons\n",
        "features_all = pd.concat([feat_2324, feat_2425, feat_2526], ignore_index=True)\n",
        "\n",
        "# Parse game dates\n",
        "if \"GAME_DATE\" in features_all.columns:\n",
        "    features_all[\"GAME_DATE\"] = pd.to_datetime(features_all[\"GAME_DATE\"])\n",
        "\n",
        "display(features_all.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8036d12f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>l3</th>\n",
              "      <th>l5</th>\n",
              "      <th>l10</th>\n",
              "      <th>all</th>\n",
              "      <th>season_id</th>\n",
              "      <th>stats_id</th>\n",
              "      <th>position_id</th>\n",
              "      <th>stat_type</th>\n",
              "      <th>position</th>\n",
              "      <th>team_key</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>20.50</td>\n",
              "      <td>17.17</td>\n",
              "      <td>17.50</td>\n",
              "      <td>17.50</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>PTS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ATLANTAHAWKS</td>\n",
              "      <td>2025-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>15.00</td>\n",
              "      <td>16.75</td>\n",
              "      <td>19.63</td>\n",
              "      <td>19.63</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>PTS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BOSTONCELTICS</td>\n",
              "      <td>2025-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Brooklyn Nets</td>\n",
              "      <td>21.40</td>\n",
              "      <td>17.67</td>\n",
              "      <td>18.79</td>\n",
              "      <td>18.79</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>PTS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BROOKLYNNETS</td>\n",
              "      <td>2025-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Charlotte Hornets</td>\n",
              "      <td>14.80</td>\n",
              "      <td>14.88</td>\n",
              "      <td>17.38</td>\n",
              "      <td>17.38</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>PTS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CHARLOTTEHORNETS</td>\n",
              "      <td>2025-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Chicago Bulls</td>\n",
              "      <td>21.50</td>\n",
              "      <td>19.18</td>\n",
              "      <td>17.93</td>\n",
              "      <td>17.93</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>PTS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CHICAGOBULLS</td>\n",
              "      <td>2025-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  id               name     l3     l5    l10    all  season_id  stats_id  position_id stat_type position          team_key   season\n",
              "0  1      Atlanta Hawks  20.50  17.17  17.50  17.50         25         4            1       PTS      NaN      ATLANTAHAWKS  2025-26\n",
              "1  2     Boston Celtics  15.00  16.75  19.63  19.63         25         4            1       PTS      NaN     BOSTONCELTICS  2025-26\n",
              "2  3      Brooklyn Nets  21.40  17.67  18.79  18.79         25         4            1       PTS      NaN      BROOKLYNNETS  2025-26\n",
              "3  4  Charlotte Hornets  14.80  14.88  17.38  17.38         25         4            1       PTS      NaN  CHARLOTTEHORNETS  2025-26\n",
              "4  5      Chicago Bulls  21.50  19.18  17.93  17.93         25         4            1       PTS      NaN      CHICAGOBULLS  2025-26"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SEASON_ID</th>\n",
              "      <th>PLAYER_ID</th>\n",
              "      <th>PLAYER_NAME</th>\n",
              "      <th>TEAM_ID</th>\n",
              "      <th>TEAM_ABBREVIATION</th>\n",
              "      <th>TEAM_NAME</th>\n",
              "      <th>GAME_ID</th>\n",
              "      <th>GAME_DATE</th>\n",
              "      <th>MATCHUP</th>\n",
              "      <th>WL</th>\n",
              "      <th>MIN</th>\n",
              "      <th>FGM</th>\n",
              "      <th>FGA</th>\n",
              "      <th>FG_PCT</th>\n",
              "      <th>FG3M</th>\n",
              "      <th>FG3A</th>\n",
              "      <th>FG3_PCT</th>\n",
              "      <th>FTM</th>\n",
              "      <th>FTA</th>\n",
              "      <th>FT_PCT</th>\n",
              "      <th>OREB</th>\n",
              "      <th>DREB</th>\n",
              "      <th>REB</th>\n",
              "      <th>AST</th>\n",
              "      <th>STL</th>\n",
              "      <th>BLK</th>\n",
              "      <th>TOV</th>\n",
              "      <th>PF</th>\n",
              "      <th>PTS</th>\n",
              "      <th>PLUS_MINUS</th>\n",
              "      <th>FANTASY_PTS</th>\n",
              "      <th>VIDEO_AVAILABLE</th>\n",
              "      <th>OPPONENT_ABBREVIATION</th>\n",
              "      <th>opp_key</th>\n",
              "      <th>TS_game</th>\n",
              "      <th>PTS_roll3</th>\n",
              "      <th>REB_roll3</th>\n",
              "      <th>AST_roll3</th>\n",
              "      <th>MIN_roll3</th>\n",
              "      <th>TS_game_roll3</th>\n",
              "      <th>PTS_roll5</th>\n",
              "      <th>REB_roll5</th>\n",
              "      <th>AST_roll5</th>\n",
              "      <th>MIN_roll5</th>\n",
              "      <th>TS_game_roll5</th>\n",
              "      <th>PTS_roll10</th>\n",
              "      <th>REB_roll10</th>\n",
              "      <th>AST_roll10</th>\n",
              "      <th>MIN_roll10</th>\n",
              "      <th>TS_game_roll10</th>\n",
              "      <th>PTS_roll20</th>\n",
              "      <th>REB_roll20</th>\n",
              "      <th>AST_roll20</th>\n",
              "      <th>MIN_roll20</th>\n",
              "      <th>TS_game_roll20</th>\n",
              "      <th>teamFGA_game</th>\n",
              "      <th>usage_share</th>\n",
              "      <th>usage_share_roll5</th>\n",
              "      <th>ORtg_g_roll5</th>\n",
              "      <th>DRtg_g_roll5</th>\n",
              "      <th>Pace_g_roll5</th>\n",
              "      <th>ORtg_g_roll10</th>\n",
              "      <th>DRtg_g_roll10</th>\n",
              "      <th>Pace_g_roll10</th>\n",
              "      <th>START_POSITION</th>\n",
              "      <th>player_key</th>\n",
              "      <th>team_key</th>\n",
              "      <th>PER</th>\n",
              "      <th>TS%</th>\n",
              "      <th>USG%</th>\n",
              "      <th>WS/48</th>\n",
              "      <th>BPM</th>\n",
              "      <th>VORP</th>\n",
              "      <th>Pos</th>\n",
              "      <th>Age</th>\n",
              "      <th>HOME</th>\n",
              "      <th>prev_date</th>\n",
              "      <th>days_rest</th>\n",
              "      <th>is_b2b</th>\n",
              "      <th>PTS_next</th>\n",
              "      <th>REB_next</th>\n",
              "      <th>AST_next</th>\n",
              "      <th>MIN_next</th>\n",
              "      <th>dvp_position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300277</td>\n",
              "      <td>2023-12-01</td>\n",
              "      <td>DAL vs. MEM</td>\n",
              "      <td>L</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1</td>\n",
              "      <td>MEM</td>\n",
              "      <td>MEM</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>92</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94.719871</td>\n",
              "      <td>111.136901</td>\n",
              "      <td>101.024</td>\n",
              "      <td>94.719871</td>\n",
              "      <td>112.807308</td>\n",
              "      <td>99.830</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>SG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300287</td>\n",
              "      <td>2023-12-02</td>\n",
              "      <td>DAL vs. OKC</td>\n",
              "      <td>L</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0.400</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.429</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>OKC</td>\n",
              "      <td>OKC</td>\n",
              "      <td>0.551471</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>87</td>\n",
              "      <td>0.114943</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>117.187500</td>\n",
              "      <td>109.794310</td>\n",
              "      <td>103.896</td>\n",
              "      <td>117.187500</td>\n",
              "      <td>115.510621</td>\n",
              "      <td>102.764</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-12-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>SG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22301213</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>DAL vs. UTA</td>\n",
              "      <td>W</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1</td>\n",
              "      <td>UTA</td>\n",
              "      <td>UTA</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>101</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>0.062906</td>\n",
              "      <td>139.521640</td>\n",
              "      <td>102.837230</td>\n",
              "      <td>104.280</td>\n",
              "      <td>139.521640</td>\n",
              "      <td>105.263825</td>\n",
              "      <td>103.660</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-12-02</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>SG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22301226</td>\n",
              "      <td>2023-12-08</td>\n",
              "      <td>DAL @ POR</td>\n",
              "      <td>W</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1</td>\n",
              "      <td>POR</td>\n",
              "      <td>POR</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>91</td>\n",
              "      <td>0.032967</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>117.172853</td>\n",
              "      <td>110.954684</td>\n",
              "      <td>103.672</td>\n",
              "      <td>117.172853</td>\n",
              "      <td>115.883515</td>\n",
              "      <td>103.930</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>SG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300299</td>\n",
              "      <td>2023-12-11</td>\n",
              "      <td>DAL @ MEM</td>\n",
              "      <td>W</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1</td>\n",
              "      <td>MEM</td>\n",
              "      <td>MEM</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.628268</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>86</td>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.044645</td>\n",
              "      <td>118.389897</td>\n",
              "      <td>113.679259</td>\n",
              "      <td>102.652</td>\n",
              "      <td>118.389897</td>\n",
              "      <td>119.208900</td>\n",
              "      <td>102.326</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>DAL</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-08</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SEASON_ID  PLAYER_ID  PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION         TEAM_NAME   GAME_ID  GAME_DATE      MATCHUP WL  MIN  FGM  FGA  FG_PCT  FG3M  FG3A  \\\n",
              "0      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300277 2023-12-01  DAL vs. MEM  L    4    0    1   0.000     0     1   \n",
              "1      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300287 2023-12-02  DAL vs. OKC  L   19    4   10   0.400     3     7   \n",
              "2      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301213 2023-12-06  DAL vs. UTA  W    7    2    2   1.000     0     0   \n",
              "3      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301226 2023-12-08    DAL @ POR  W    7    1    3   0.333     0     2   \n",
              "4      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300299 2023-12-11    DAL @ MEM  W   14    2    7   0.286     0     4   \n",
              "\n",
              "   FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  FANTASY_PTS  VIDEO_AVAILABLE OPPONENT_ABBREVIATION opp_key   TS_game  \\\n",
              "0    0.000    1    2     0.5     0     1    1    0    0    0    0   0    1           4          2.2                1                   MEM     MEM  0.265957   \n",
              "1    0.429    1    2     0.5     0     0    0    2    0    1    0   1   12           9         18.0                1                   OKC     OKC  0.551471   \n",
              "2      NaN    0    0     NaN     1     0    1    0    0    0    0   0    4           7          5.2                1                   UTA     UTA  1.000000   \n",
              "3    0.000    0    0     NaN     0     1    1    0    0    0    0   1    2          -4          3.2                1                   POR     POR  0.333333   \n",
              "4    0.000    0    0     NaN     1     0    1    1    0    0    1   0    4           1          5.7                1                   MEM     MEM  0.285714   \n",
              "\n",
              "   PTS_roll3  REB_roll3  AST_roll3  MIN_roll3  TS_game_roll3  PTS_roll5  REB_roll5  AST_roll5  MIN_roll5  TS_game_roll5  PTS_roll10  REB_roll10  AST_roll10  \\\n",
              "0        NaN        NaN        NaN        NaN            NaN        NaN        NaN        NaN        NaN            NaN         NaN         NaN         NaN   \n",
              "1   1.000000   1.000000   0.000000        4.0       0.265957   1.000000   1.000000   0.000000       4.00       0.265957    1.000000    1.000000    0.000000   \n",
              "2   6.500000   0.500000   1.000000       11.5       0.408714   6.500000   0.500000   1.000000      11.50       0.408714    6.500000    0.500000    1.000000   \n",
              "3   5.666667   0.666667   0.666667       10.0       0.605809   5.666667   0.666667   0.666667      10.00       0.605809    5.666667    0.666667    0.666667   \n",
              "4   6.000000   0.666667   0.666667       11.0       0.628268   4.750000   0.750000   0.500000       9.25       0.537690    4.750000    0.750000    0.500000   \n",
              "\n",
              "   MIN_roll10  TS_game_roll10  PTS_roll20  REB_roll20  AST_roll20  MIN_roll20  TS_game_roll20  teamFGA_game  usage_share  usage_share_roll5  ORtg_g_roll5  \\\n",
              "0         NaN             NaN         NaN         NaN         NaN         NaN             NaN            92     0.010870                NaN     94.719871   \n",
              "1        4.00        0.265957    1.000000    1.000000    0.000000        4.00        0.265957            87     0.114943           0.010870    117.187500   \n",
              "2       11.50        0.408714    6.500000    0.500000    1.000000       11.50        0.408714           101     0.019802           0.062906    139.521640   \n",
              "3       10.00        0.605809    5.666667    0.666667    0.666667       10.00        0.605809            91     0.032967           0.048538    117.172853   \n",
              "4        9.25        0.537690    4.750000    0.750000    0.500000        9.25        0.537690            86     0.081395           0.044645    118.389897   \n",
              "\n",
              "   DRtg_g_roll5  Pace_g_roll5  ORtg_g_roll10  DRtg_g_roll10  Pace_g_roll10  START_POSITION player_key team_key   PER    TS%  USG%  WS/48  BPM  VORP Pos   Age  \\\n",
              "0    111.136901       101.024      94.719871     112.807308         99.830             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0   \n",
              "1    109.794310       103.896     117.187500     115.510621        102.764             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0   \n",
              "2    102.837230       104.280     139.521640     105.263825        103.660             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0   \n",
              "3    110.954684       103.672     117.172853     115.883515        103.930             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0   \n",
              "4    113.679259       102.652     118.389897     119.208900        102.326             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0   \n",
              "\n",
              "   HOME  prev_date  days_rest  is_b2b  PTS_next  REB_next  AST_next  MIN_next dvp_position  \n",
              "0     1        NaT        NaN       0      12.0       0.0       2.0      19.0           SG  \n",
              "1     1 2023-12-01        1.0       0       4.0       1.0       0.0       7.0           SG  \n",
              "2     1 2023-12-02        4.0       0       2.0       1.0       0.0       7.0           SG  \n",
              "3     0 2023-12-06        2.0       0       4.0       1.0       1.0      14.0           SG  \n",
              "4     0 2023-12-08        3.0       0       0.0       0.0       0.0       0.0           SG  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SEASON_ID</th>\n",
              "      <th>PLAYER_ID</th>\n",
              "      <th>PLAYER_NAME</th>\n",
              "      <th>TEAM_ID</th>\n",
              "      <th>TEAM_ABBREVIATION</th>\n",
              "      <th>TEAM_NAME</th>\n",
              "      <th>GAME_ID</th>\n",
              "      <th>GAME_DATE</th>\n",
              "      <th>MATCHUP</th>\n",
              "      <th>WL</th>\n",
              "      <th>MIN</th>\n",
              "      <th>FGM</th>\n",
              "      <th>FGA</th>\n",
              "      <th>FG_PCT</th>\n",
              "      <th>FG3M</th>\n",
              "      <th>FG3A</th>\n",
              "      <th>FG3_PCT</th>\n",
              "      <th>FTM</th>\n",
              "      <th>FTA</th>\n",
              "      <th>FT_PCT</th>\n",
              "      <th>OREB</th>\n",
              "      <th>DREB</th>\n",
              "      <th>REB</th>\n",
              "      <th>AST</th>\n",
              "      <th>STL</th>\n",
              "      <th>BLK</th>\n",
              "      <th>TOV</th>\n",
              "      <th>PF</th>\n",
              "      <th>PTS</th>\n",
              "      <th>PLUS_MINUS</th>\n",
              "      <th>FANTASY_PTS</th>\n",
              "      <th>VIDEO_AVAILABLE</th>\n",
              "      <th>OPPONENT_ABBREVIATION</th>\n",
              "      <th>opp_key</th>\n",
              "      <th>TS_game</th>\n",
              "      <th>PTS_roll3</th>\n",
              "      <th>REB_roll3</th>\n",
              "      <th>AST_roll3</th>\n",
              "      <th>MIN_roll3</th>\n",
              "      <th>TS_game_roll3</th>\n",
              "      <th>PTS_roll5</th>\n",
              "      <th>REB_roll5</th>\n",
              "      <th>AST_roll5</th>\n",
              "      <th>MIN_roll5</th>\n",
              "      <th>TS_game_roll5</th>\n",
              "      <th>PTS_roll10</th>\n",
              "      <th>REB_roll10</th>\n",
              "      <th>AST_roll10</th>\n",
              "      <th>MIN_roll10</th>\n",
              "      <th>TS_game_roll10</th>\n",
              "      <th>PTS_roll20</th>\n",
              "      <th>REB_roll20</th>\n",
              "      <th>AST_roll20</th>\n",
              "      <th>MIN_roll20</th>\n",
              "      <th>TS_game_roll20</th>\n",
              "      <th>teamFGA_game</th>\n",
              "      <th>usage_share</th>\n",
              "      <th>usage_share_roll5</th>\n",
              "      <th>ORtg_g_roll5</th>\n",
              "      <th>DRtg_g_roll5</th>\n",
              "      <th>Pace_g_roll5</th>\n",
              "      <th>ORtg_g_roll10</th>\n",
              "      <th>DRtg_g_roll10</th>\n",
              "      <th>Pace_g_roll10</th>\n",
              "      <th>START_POSITION</th>\n",
              "      <th>player_key</th>\n",
              "      <th>PER</th>\n",
              "      <th>TS%</th>\n",
              "      <th>USG%</th>\n",
              "      <th>WS/48</th>\n",
              "      <th>BPM</th>\n",
              "      <th>VORP</th>\n",
              "      <th>Pos</th>\n",
              "      <th>Age</th>\n",
              "      <th>HOME</th>\n",
              "      <th>prev_date</th>\n",
              "      <th>days_rest</th>\n",
              "      <th>is_b2b</th>\n",
              "      <th>PTS_next</th>\n",
              "      <th>REB_next</th>\n",
              "      <th>AST_next</th>\n",
              "      <th>MIN_next</th>\n",
              "      <th>dvp_position</th>\n",
              "      <th>season</th>\n",
              "      <th>matchup_score_pts</th>\n",
              "      <th>matchup_score_reb</th>\n",
              "      <th>matchup_score_ast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300277</td>\n",
              "      <td>2023-12-01</td>\n",
              "      <td>DAL vs. MEM</td>\n",
              "      <td>L</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1</td>\n",
              "      <td>MEM</td>\n",
              "      <td>MEM</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>92</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94.719871</td>\n",
              "      <td>111.136901</td>\n",
              "      <td>101.024</td>\n",
              "      <td>94.719871</td>\n",
              "      <td>112.807308</td>\n",
              "      <td>99.830</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>20023-20024</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300287</td>\n",
              "      <td>2023-12-02</td>\n",
              "      <td>DAL vs. OKC</td>\n",
              "      <td>L</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0.400</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.429</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>OKC</td>\n",
              "      <td>OKC</td>\n",
              "      <td>0.551471</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>87</td>\n",
              "      <td>0.114943</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>117.187500</td>\n",
              "      <td>109.794310</td>\n",
              "      <td>103.896</td>\n",
              "      <td>117.187500</td>\n",
              "      <td>115.510621</td>\n",
              "      <td>102.764</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-12-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>20023-20024</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22301213</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>DAL vs. UTA</td>\n",
              "      <td>W</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1</td>\n",
              "      <td>UTA</td>\n",
              "      <td>UTA</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0.408714</td>\n",
              "      <td>101</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>0.062906</td>\n",
              "      <td>139.521640</td>\n",
              "      <td>102.837230</td>\n",
              "      <td>104.280</td>\n",
              "      <td>139.521640</td>\n",
              "      <td>105.263825</td>\n",
              "      <td>103.660</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-12-02</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>20023-20024</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22301226</td>\n",
              "      <td>2023-12-08</td>\n",
              "      <td>DAL @ POR</td>\n",
              "      <td>W</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1</td>\n",
              "      <td>POR</td>\n",
              "      <td>POR</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.605809</td>\n",
              "      <td>91</td>\n",
              "      <td>0.032967</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>117.172853</td>\n",
              "      <td>110.954684</td>\n",
              "      <td>103.672</td>\n",
              "      <td>117.172853</td>\n",
              "      <td>115.883515</td>\n",
              "      <td>103.930</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>20023-20024</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22023</td>\n",
              "      <td>1630639</td>\n",
              "      <td>A.J. Lawson</td>\n",
              "      <td>1610612742</td>\n",
              "      <td>DAL</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>22300299</td>\n",
              "      <td>2023-12-11</td>\n",
              "      <td>DAL @ MEM</td>\n",
              "      <td>W</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1</td>\n",
              "      <td>MEM</td>\n",
              "      <td>MEM</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.628268</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.537690</td>\n",
              "      <td>86</td>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.044645</td>\n",
              "      <td>118.389897</td>\n",
              "      <td>113.679259</td>\n",
              "      <td>102.652</td>\n",
              "      <td>118.389897</td>\n",
              "      <td>119.208900</td>\n",
              "      <td>102.326</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj lawson</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0.519</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>SG</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-08</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>20023-20024</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SEASON_ID  PLAYER_ID  PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION         TEAM_NAME   GAME_ID  GAME_DATE      MATCHUP WL  MIN  FGM  FGA  FG_PCT  FG3M  FG3A  \\\n",
              "0      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300277 2023-12-01  DAL vs. MEM  L    4    0    1   0.000     0     1   \n",
              "1      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300287 2023-12-02  DAL vs. OKC  L   19    4   10   0.400     3     7   \n",
              "2      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301213 2023-12-06  DAL vs. UTA  W    7    2    2   1.000     0     0   \n",
              "3      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301226 2023-12-08    DAL @ POR  W    7    1    3   0.333     0     2   \n",
              "4      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300299 2023-12-11    DAL @ MEM  W   14    2    7   0.286     0     4   \n",
              "\n",
              "   FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  FANTASY_PTS  VIDEO_AVAILABLE OPPONENT_ABBREVIATION opp_key   TS_game  \\\n",
              "0    0.000    1    2     0.5     0     1    1    0    0    0    0   0    1           4          2.2                1                   MEM     MEM  0.265957   \n",
              "1    0.429    1    2     0.5     0     0    0    2    0    1    0   1   12           9         18.0                1                   OKC     OKC  0.551471   \n",
              "2      NaN    0    0     NaN     1     0    1    0    0    0    0   0    4           7          5.2                1                   UTA     UTA  1.000000   \n",
              "3    0.000    0    0     NaN     0     1    1    0    0    0    0   1    2          -4          3.2                1                   POR     POR  0.333333   \n",
              "4    0.000    0    0     NaN     1     0    1    1    0    0    1   0    4           1          5.7                1                   MEM     MEM  0.285714   \n",
              "\n",
              "   PTS_roll3  REB_roll3  AST_roll3  MIN_roll3  TS_game_roll3  PTS_roll5  REB_roll5  AST_roll5  MIN_roll5  TS_game_roll5  PTS_roll10  REB_roll10  AST_roll10  \\\n",
              "0        NaN        NaN        NaN        NaN            NaN        NaN        NaN        NaN        NaN            NaN         NaN         NaN         NaN   \n",
              "1   1.000000   1.000000   0.000000        4.0       0.265957   1.000000   1.000000   0.000000       4.00       0.265957    1.000000    1.000000    0.000000   \n",
              "2   6.500000   0.500000   1.000000       11.5       0.408714   6.500000   0.500000   1.000000      11.50       0.408714    6.500000    0.500000    1.000000   \n",
              "3   5.666667   0.666667   0.666667       10.0       0.605809   5.666667   0.666667   0.666667      10.00       0.605809    5.666667    0.666667    0.666667   \n",
              "4   6.000000   0.666667   0.666667       11.0       0.628268   4.750000   0.750000   0.500000       9.25       0.537690    4.750000    0.750000    0.500000   \n",
              "\n",
              "   MIN_roll10  TS_game_roll10  PTS_roll20  REB_roll20  AST_roll20  MIN_roll20  TS_game_roll20  teamFGA_game  usage_share  usage_share_roll5  ORtg_g_roll5  \\\n",
              "0         NaN             NaN         NaN         NaN         NaN         NaN             NaN            92     0.010870                NaN     94.719871   \n",
              "1        4.00        0.265957    1.000000    1.000000    0.000000        4.00        0.265957            87     0.114943           0.010870    117.187500   \n",
              "2       11.50        0.408714    6.500000    0.500000    1.000000       11.50        0.408714           101     0.019802           0.062906    139.521640   \n",
              "3       10.00        0.605809    5.666667    0.666667    0.666667       10.00        0.605809            91     0.032967           0.048538    117.172853   \n",
              "4        9.25        0.537690    4.750000    0.750000    0.500000        9.25        0.537690            86     0.081395           0.044645    118.389897   \n",
              "\n",
              "   DRtg_g_roll5  Pace_g_roll5  ORtg_g_roll10  DRtg_g_roll10  Pace_g_roll10  START_POSITION player_key   PER    TS%  USG%  WS/48  BPM  VORP Pos   Age  HOME  \\\n",
              "0    111.136901       101.024      94.719871     112.807308         99.830             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     1   \n",
              "1    109.794310       103.896     117.187500     115.510621        102.764             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     1   \n",
              "2    102.837230       104.280     139.521640     105.263825        103.660             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     1   \n",
              "3    110.954684       103.672     117.172853     115.883515        103.930             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     0   \n",
              "4    113.679259       102.652     118.389897     119.208900        102.326             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     0   \n",
              "\n",
              "   prev_date  days_rest  is_b2b  PTS_next  REB_next  AST_next  MIN_next dvp_position       season matchup_score_pts matchup_score_reb matchup_score_ast  \n",
              "0        NaT        NaN       0      12.0       0.0       2.0      19.0           SG  20023-20024               NaN               NaN               NaN  \n",
              "1 2023-12-01        1.0       0       4.0       1.0       0.0       7.0           SG  20023-20024               NaN               NaN               NaN  \n",
              "2 2023-12-02        4.0       0       2.0       1.0       0.0       7.0           SG  20023-20024               NaN               NaN               NaN  \n",
              "3 2023-12-06        2.0       0       4.0       1.0       1.0      14.0           SG  20023-20024               NaN               NaN               NaN  \n",
              "4 2023-12-08        3.0       0       0.0       0.0       0.0       0.0           SG  20023-20024               NaN               NaN               NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# üß± Normalize team and position keys in matchup_df\n",
        "df_combined[\"team_key\"] = df_combined[\"name\"].str.upper().str.replace(\" \", \"\")\n",
        "df_combined[\"position\"] = df_combined[\"position\"].map({\"G\": \"PG\", \"F\": \"SF\", \"C\": \"C\"})\n",
        "display(df_combined.head())\n",
        "display(features_all.head())\n",
        "# üß± Map season_id to readable string\n",
        "season_id_map = {\n",
        "    25: \"2025-26\",\n",
        "    19: \"2024-25\",\n",
        "    13: \"2023-24\"\n",
        "}\n",
        "df_combined[\"season\"] = df_combined[\"season_id\"].map(season_id_map)\n",
        "\n",
        "# üß± Normalize keys in features_all\n",
        "features_all[\"opp_key\"] = features_all[\"OPPONENT_ABBREVIATION\"].astype(str).str.upper().str.replace(\" \", \"\")\n",
        "features_all[\"dvp_position\"] = features_all[\"Pos\"].copy()\n",
        "features_all[\"season\"] = features_all[\"SEASON_ID\"].astype(int).apply(lambda x: f\"{x - 20000}-{x - 19999}\")\n",
        "features_all[\"season\"] = features_all[\"season\"].astype(str)\n",
        "\n",
        "# üß© Safe merge function that drops prior columns if they exist\n",
        "def merge_matchup_stat(df_base, stat: str, suffix: str):\n",
        "    score_col = f\"matchup_score_{suffix}\"\n",
        "\n",
        "    # Remove any previously merged version of the same stat\n",
        "    df_base = df_base.drop(columns=[score_col, \"team_key\", \"position\"], errors=\"ignore\")\n",
        "\n",
        "    # Prepare stat-specific df\n",
        "    df_stat = df_combined[df_combined[\"stat_type\"] == stat].copy()\n",
        "    df_stat = df_stat.rename(columns={\"all\": score_col})\n",
        "    df_stat = df_stat[[\"team_key\", \"position\", \"season\", score_col]]\n",
        "\n",
        "    # Merge\n",
        "    df_merged = pd.merge(\n",
        "        df_base,\n",
        "        df_stat,\n",
        "        left_on=[\"opp_key\", \"dvp_position\", \"season\"],\n",
        "        right_on=[\"team_key\", \"position\", \"season\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "    return df_merged.drop(columns=[\"team_key\", \"position\"], errors=\"ignore\")\n",
        "\n",
        "# ‚úÖ Apply matchup stats\n",
        "features_all = merge_matchup_stat(features_all, \"PTS\", \"pts\")\n",
        "features_all = merge_matchup_stat(features_all, \"REB\", \"reb\")\n",
        "features_all = merge_matchup_stat(features_all, \"AST\", \"ast\")\n",
        "\n",
        "# üßπ Keep only the final matchup score columns\n",
        "features_all = features_all.drop(columns=[\n",
        "    col for col in features_all.columns \n",
        "    if col.startswith(\"matchup_score_\") and col not in [\n",
        "        \"matchup_score_pts\", \"matchup_score_reb\", \"matchup_score_ast\"\n",
        "    ]\n",
        "])\n",
        "\n",
        "\n",
        "# ‚úÖ Check result\n",
        "display(features_all.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab68815",
      "metadata": {},
      "outputs": [],
      "source": [
        "# cell 13a: Add data validation checks\n",
        "def validate_features(features_df):\n",
        "    \"\"\"Validate feature dataframe for modeling\"\"\"\n",
        "    required_cols = ['PLAYER_NAME', 'GAME_DATE', 'PTS', 'REB', 'AST', 'MIN']\n",
        "    missing_cols = [col for col in required_cols if col not in features_df.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "    \n",
        "    # Check for data freshness\n",
        "    latest_date = pd.to_datetime(features_all['GAME_DATE']).max()\n",
        "    days_old = (pd.Timestamp.now() - latest_date).days\n",
        "    if days_old > 30:\n",
        "        print(f\"‚ö†Ô∏è Warning: Data is {days_old} days old\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "# Add to Cell 12 after loading features_all\n",
        "validate_features(features_all)\n",
        "\n",
        "print(pd.to_datetime(features_all['GAME_DATE']).max())\n",
        "print(pd.Timestamp.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa474de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- Cell 13b: Build TODAY minutes features (starter/injury ‚Üí minutes signals) --\n",
        "import os, re, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Expect df_lineups (Cell 3), mnp_df (Cell 5), and starter_flags_df / injury_flags_df (Cell 7)\n",
        "assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
        "    \"features_all must exist (Cell 12).\"\n",
        "assert 'starter_flags_df' in globals(), \"starter_flags_df missing (Cell 7).\"\n",
        "assert 'injury_flags_df' in globals(),  \"injury_flags_df missing (Cell 7).\"\n",
        "\n",
        "def _norm_player(name: str) -> str:\n",
        "    if not isinstance(name, str): return \"\"\n",
        "    s = re.sub(r\"[.\\-`'‚Äô]\", \"\", name).strip().lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "# Latest row per player for context\n",
        "keep_cols = [\n",
        "    \"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\"GAME_DATE\",\n",
        "    \"MIN_roll5\",\"MIN_roll10\",\"days_rest\",\"is_b2b\",\"HOME\",\n",
        "    \"USG%\",\"TS%\",\"PER\",\"BPM\"\n",
        "]\n",
        "keep_cols = [c for c in keep_cols if c in features_all.columns]\n",
        "\n",
        "latest = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "                     .groupby(\"PLAYER_NAME\", as_index=False)\n",
        "                     .tail(1)[keep_cols]\n",
        "                     .copy())\n",
        "\n",
        "# Fabricate PLAYER_ID if missing (rare)\n",
        "if \"PLAYER_ID\" not in latest.columns:\n",
        "    latest[\"PLAYER_ID\"] = latest[\"PLAYER_NAME\"].factorize()[0] + 1\n",
        "\n",
        "latest[\"player_key\"] = latest[\"PLAYER_NAME\"].map(_norm_player)\n",
        "latest = latest.rename(columns={\n",
        "    \"TEAM_ABBREVIATION\": \"team\",\n",
        "    \"OPPONENT_ABBREVIATION\": \"opponent\"\n",
        "})\n",
        "\n",
        "# Normalize and merge flags\n",
        "sf = starter_flags_df.copy()\n",
        "sf[\"player_key\"] = sf[\"player\"].map(_norm_player)\n",
        "sf[\"team\"] = sf[\"team\"].astype(str).str.upper().str.strip()\n",
        "\n",
        "inj = injury_flags_df.copy()\n",
        "inj[\"player_key\"] = inj[\"player\"].map(_norm_player)\n",
        "\n",
        "# Merge starter and injury flags into today frame\n",
        "today = (latest.merge(sf[[\"player_key\",\"team\",\"is_starter\",\"start_prob\"]],\n",
        "                      on=[\"player_key\",\"team\"], how=\"left\")\n",
        "               .merge(inj[[\"player_key\",\"may_not_play\",\"injury_prob\"]],\n",
        "                      on=\"player_key\", how=\"left\"))\n",
        "\n",
        "today[\"is_starter\"]   = today[\"is_starter\"].fillna(0).astype(int)\n",
        "today[\"start_prob\"]   = today[\"start_prob\"].fillna(0.70)\n",
        "today[\"may_not_play\"] = today[\"may_not_play\"].fillna(0).astype(int)\n",
        "today[\"injury_prob\"]  = today[\"injury_prob\"].fillna(0.0)\n",
        "\n",
        "# ========== ‚úÖ NEW FIXED: Teammate absence proxy from full team rosters ==========\n",
        "\n",
        "# Build full roster from latest features\n",
        "roster_all = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "                         .groupby(\"PLAYER_NAME\", as_index=False)\n",
        "                         .tail(1)[[\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"USG%\"]].copy())\n",
        "roster_all[\"player_key\"] = roster_all[\"PLAYER_NAME\"].map(_norm_player)\n",
        "roster_all = roster_all.rename(columns={\"TEAM_ABBREVIATION\": \"team\"})\n",
        "\n",
        "# Merge in injury flags\n",
        "inj = injury_flags_df.copy()\n",
        "inj[\"player_key\"] = inj[\"player\"].map(_norm_player)\n",
        "roster_all = roster_all.merge(inj[[\"player_key\",\"injury_prob\"]], on=\"player_key\", how=\"left\")\n",
        "roster_all[\"injury_prob\"] = roster_all[\"injury_prob\"].fillna(0.0)\n",
        "\n",
        "# Calculate expected missing usage per team\n",
        "roster_all[\"usg_missing_expected\"] = roster_all[\"USG%\"].fillna(0.0) * roster_all[\"injury_prob\"].clip(0, 1)\n",
        "\n",
        "by_team_abs = roster_all.groupby(\"team\", as_index=False).agg(\n",
        "    teammates_out=(\"injury_prob\", lambda s: float((s > 0).sum())),\n",
        "    missing_usage_share=(\"usg_missing_expected\",\"sum\")\n",
        ")\n",
        "\n",
        "# Merge team-level features into today\n",
        "today = today.merge(by_team_abs, on=\"team\", how=\"left\")\n",
        "today[\"teammates_out\"] = today[\"teammates_out\"].fillna(0.0)\n",
        "today[\"missing_usage_share\"] = today[\"missing_usage_share\"].fillna(0.0)\n",
        "\n",
        "# Final output expected by minutes model\n",
        "minutes_today = today.rename(columns={\"GAME_DATE\":\"last_game_date\"})[[\n",
        "    \"PLAYER_ID\",\"PLAYER_NAME\",\"team\",\"opponent\",\n",
        "    \"is_starter\",\"start_prob\",\"may_not_play\",\"injury_prob\",\n",
        "    \"teammates_out\",\"missing_usage_share\",\n",
        "    *(c for c in [\"MIN_roll5\",\"MIN_roll10\",\"days_rest\",\"is_b2b\",\"HOME\",\"USG%\",\"TS%\",\"PER\",\"BPM\"] if c in today.columns),\n",
        "]].copy()\n",
        "\n",
        "print(\"‚úÖ minutes_today shape:\", minutes_today.shape)\n",
        "print(minutes_today.head(30).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52db04c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- Cell 14: bridge/standardize minutes_today -------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def _find_minutes_df():\n",
        "    # Search for likely minutes tables already created\n",
        "    candidates = []\n",
        "    for name, obj in globals().items():\n",
        "        if not isinstance(obj, pd.DataFrame):\n",
        "            continue\n",
        "        lname = name.lower()\n",
        "        if re.search(r\"(minutes|mins)\", lname) and re.search(r\"(today|pred|proj|features)\", lname):\n",
        "            candidates.append((name, obj))\n",
        "    # heuristic: prefer names containing \"minutes_today\" or \"features_today_minutes\"\n",
        "    prio = [\"minutes_today\", \"features_today_minutes\", \"minutes_pred\", \"minutes_predictions\", \"df_minutes_today\"]\n",
        "    for p in prio:\n",
        "        for name, df in candidates:\n",
        "            if name == p:\n",
        "                return name, df\n",
        "    return candidates[0] if candidates else (None, None)\n",
        "\n",
        "name, df_src = _find_minutes_df()\n",
        "print(f\"Detected minutes source: {name or 'None'}\")\n",
        "\n",
        "if df_src is None or df_src.empty:\n",
        "    # Build a conservative fallback from latest features (MIN_roll5 etc.)\n",
        "    latest = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "                        .groupby(\"PLAYER_NAME\", as_index=False).tail(1).copy())\n",
        "\n",
        "    # Fallback minutes = clipped MIN_roll5; higher if starter flags are available\n",
        "    base_min = latest.get(\"MIN_roll5\", pd.Series(24, index=latest.index)).fillna(24)\n",
        "    base_min = base_min.clip(lower=10, upper=38)\n",
        "\n",
        "    minutes_today = latest[[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]].copy()\n",
        "    minutes_today[\"pred_minutes\"] = base_min\n",
        "\n",
        "    # If you created starter/injury flags earlier, merge them in\n",
        "    for flags_name in [\"starter_flags_df\", \"injury_flags_df\"]:\n",
        "        if flags_name in globals() and isinstance(globals()[flags_name], pd.DataFrame):\n",
        "            flags = globals()[flags_name]\n",
        "            key_cols = [c for c in [\"PLAYER_ID\",\"PLAYER_NAME\"] if c in flags.columns]\n",
        "            if key_cols:\n",
        "                minutes_today = minutes_today.merge(\n",
        "                    flags.drop_duplicates(subset=key_cols),\n",
        "                    on=key_cols, how=\"left\"\n",
        "                )\n",
        "\n",
        "    # Reasonable defaults\n",
        "    minutes_today[\"start_prob\"]  = minutes_today.get(\"start_prob\", 0.75)\n",
        "    minutes_today[\"is_starter\"]  = minutes_today.get(\"is_starter\", 0).fillna(0).astype(int)\n",
        "    minutes_today[\"may_not_play\"]= minutes_today.get(\"may_not_play\", 0).fillna(0).astype(int)\n",
        "    minutes_today[\"injury_prob\"] = minutes_today.get(\"injury_prob\", 0.0).fillna(0.0)\n",
        "\n",
        "else:\n",
        "    # Standardize from detected df\n",
        "    df = df_src.copy()\n",
        "\n",
        "    # Column mappers\n",
        "    cmap = {}\n",
        "    for c in df.columns:\n",
        "        cl = c.lower()\n",
        "        if cl in [\"player_id\",\"id\"]: cmap[c] = \"PLAYER_ID\"\n",
        "        elif cl in [\"player_name\",\"player\",\"name\"]: cmap[c] = \"PLAYER_NAME\"\n",
        "        elif cl in [\"team\",\"team_abbreviation\",\"team_abbr\",\"tm\"]: cmap[c] = \"TEAM_ABBREVIATION\"\n",
        "        elif cl in [\"opponent\",\"opp\",\"opponent_abbreviation\",\"opp_abbr\"]: cmap[c] = \"OPPONENT_ABBREVIATION\"\n",
        "        elif cl in [\"pred_minutes\",\"projected_minutes\",\"minutes\",\"mins\",\"min_pred\"]: cmap[c] = \"pred_minutes\"\n",
        "        elif cl in [\"start_prob\",\"starter_prob\",\"prob_start\"]: cmap[c] = \"start_prob\"\n",
        "        elif cl in [\"is_starter\",\"starter_flag\",\"starter\"]: cmap[c] = \"is_starter\"\n",
        "        elif cl in [\"may_not_play\",\"dnp_flag\",\"out_flag\",\"likely_out\"]: cmap[c] = \"may_not_play\"\n",
        "        elif cl in [\"injury_prob\",\"inj_prob\",\"p_injury\"]: cmap[c] = \"injury_prob\"\n",
        "\n",
        "    df = df.rename(columns=cmap)\n",
        "\n",
        "    # If PLAYER_ID missing, merge from features_all by name\n",
        "    if \"PLAYER_ID\" not in df.columns or df[\"PLAYER_ID\"].isna().all():\n",
        "        latest = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "                            .groupby(\"PLAYER_NAME\", as_index=False).tail(1)[\n",
        "                                [\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]\n",
        "                            ])\n",
        "        on_cols = [c for c in [\"PLAYER_NAME\"] if c in df.columns]\n",
        "        df = df.merge(latest, on=on_cols, how=\"left\")\n",
        "\n",
        "    # Ensure required columns exist with defaults\n",
        "    req = [\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\n",
        "           \"pred_minutes\",\"start_prob\",\"is_starter\",\"may_not_play\",\"injury_prob\"]\n",
        "    for r in req:\n",
        "        if r not in df.columns:\n",
        "            if r == \"pred_minutes\":\n",
        "                # fallback from features_all MIN_roll5\n",
        "                base = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "                                 .groupby(\"PLAYER_NAME\", as_index=False).tail(1))\n",
        "                base = base[[\"PLAYER_NAME\",\"MIN_roll5\"]].rename(columns={\"MIN_roll5\":\"pred_minutes\"})\n",
        "                df = df.merge(base, on=\"PLAYER_NAME\", how=\"left\")\n",
        "                df[\"pred_minutes\"] = df[\"pred_minutes\"].fillna(24).clip(10, 38)\n",
        "            elif r in [\"start_prob\",\"injury_prob\"]:\n",
        "                df[r] = 0.75 if r==\"start_prob\" else 0.0\n",
        "            elif r in [\"is_starter\",\"may_not_play\"]:\n",
        "                df[r] = 0\n",
        "            else:\n",
        "                df[r] = np.nan\n",
        "\n",
        "    # Clean types\n",
        "    df[\"pred_minutes\"] = pd.to_numeric(df[\"pred_minutes\"], errors=\"coerce\").fillna(24).clip(0,48)\n",
        "    df[\"is_starter\"]   = df[\"is_starter\"].fillna(0).astype(int)\n",
        "    df[\"may_not_play\"] = df[\"may_not_play\"].fillna(0).astype(int)\n",
        "    df[\"start_prob\"]   = df[\"start_prob\"].fillna(0.75)\n",
        "    df[\"injury_prob\"]  = df[\"injury_prob\"].fillna(0.0)\n",
        "\n",
        "    minutes_today = df[[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\n",
        "                        \"pred_minutes\",\"start_prob\",\"is_starter\",\"may_not_play\",\"injury_prob\"]].copy()\n",
        "\n",
        "print(\"minutes_today rows:\", len(minutes_today))\n",
        "print(minutes_today.head(30).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3902c66c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- Cell 15: per-minute rate models + today projections -----------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 0) Safety checks / inputs from previous cells\n",
        "# ---------------------------------------------------------------------------\n",
        "assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
        "    \"features_all missing. Run Cell 7 + Cell 0_data first.\"\n",
        "assert 'minutes_today' in globals() and isinstance(minutes_today, pd.DataFrame) and not minutes_today.empty, \\\n",
        "    \"minutes_today missing. Run Cells 5‚Äì7 first.\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1) Build leakage-safe rate targets for training\n",
        "#    We predict per-minute rates (not raw totals); later multiply by pred_minutes.\n",
        "# ---------------------------------------------------------------------------\n",
        "train = features_all.copy()\n",
        "\n",
        "# Ensure numeric MIN\n",
        "if \"MIN\" not in train.columns:\n",
        "    raise RuntimeError(\"MIN column not found in features_all.\")\n",
        "train[\"MIN\"] = pd.to_numeric(train[\"MIN\"], errors=\"coerce\")\n",
        "\n",
        "# Filter out super-low minute games (noisy rate)\n",
        "train = train[train[\"MIN\"].fillna(0) >= 6].copy()\n",
        "\n",
        "# Targets as same-day rates (no look-ahead)\n",
        "for stat in [\"PTS\",\"REB\",\"AST\"]:\n",
        "    if stat not in train.columns:\n",
        "        train[stat] = np.nan\n",
        "    train[f\"{stat}_per_min\"] = train[stat] / train[\"MIN\"].replace(0, np.nan)\n",
        "\n",
        "# Drop impossible rows\n",
        "for stat in [\"PTS_per_min\",\"REB_per_min\",\"AST_per_min\"]:\n",
        "    train = train[~np.isinf(train[stat])].copy()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2) Feature set for rate models\n",
        "#    Avoid using future minutes; keep context/skill/opponent/usage style features.\n",
        "# ---------------------------------------------------------------------------\n",
        "CANDIDATE_FEATURES = [\n",
        "    # form / efficiency (all must be shift(1) upstream in features_all)\n",
        "    \"TS_game_roll5\",\"TS_game_roll10\",\n",
        "    \"MIN_roll5\",\"MIN_roll10\",            # ok: proxy for role, but target is rate not minutes\n",
        "    \"PTS_roll5\",\"PTS_roll10\",\n",
        "    \"REB_roll5\",\"REB_roll10\",\n",
        "    \"AST_roll5\",\"AST_roll10\",\n",
        "    \"usage_share_roll5\",\n",
        "\n",
        "    # season labels\n",
        "    \"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\n",
        "\n",
        "    # team/matchup context (shifted rolling at team level)\n",
        "    \"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
        "\n",
        "    # optional opponent allowances by position (if present from Cell 7)\n",
        "    # Common column names look like: PTS_allowed_roll10_PG, AST_allowed_roll10_C, etc.\n",
        "    # We'll auto-include any *_allowed_roll10_* columns if present:\n",
        "] + [c for c in features_all.columns if \"_allowed_roll10_\" in c]\n",
        "\n",
        "# Situational flags (can influence rate a bit)\n",
        "SITUATIONAL = [\"HOME\",\"days_rest\",\"is_b2b\"]\n",
        "CANDIDATE_FEATURES += [c for c in SITUATIONAL if c in features_all.columns]\n",
        "\n",
        "# Robust final feature list (present in the dataframe)\n",
        "RATE_FEATURES = [c for c in CANDIDATE_FEATURES if c in train.columns]\n",
        "\n",
        "print(f\"Using {len(RATE_FEATURES)} features for rate models.\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3) Train one model per stat rate with GroupKFold by player\n",
        "# ---------------------------------------------------------------------------\n",
        "models_rate = {}\n",
        "cv_scores_rate = {}\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "def train_rate_model(df: pd.DataFrame, target_col: str, feat_cols: list[str]):\n",
        "    df_ = df.dropna(subset=feat_cols + [target_col, \"PLAYER_ID\"]).copy()\n",
        "    X = df_[feat_cols]\n",
        "    y = df_[target_col]\n",
        "    groups = df_[\"PLAYER_ID\"]\n",
        "\n",
        "    fold_mae = []\n",
        "    for tr, te in gkf.split(X, y, groups):\n",
        "        Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
        "        ytr, yte = y.iloc[tr], y.iloc[te]\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=5,\n",
        "            subsample=0.9,\n",
        "            colsample_bytree=0.9,\n",
        "            reg_lambda=1.0,\n",
        "            reg_alpha=0.0,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbosity=0\n",
        "        )\n",
        "        model.fit(Xtr, ytr)\n",
        "        pred = model.predict(Xte)\n",
        "        fold_mae.append(mean_absolute_error(yte, pred))\n",
        "\n",
        "    model.fit(X, y)  # final fit\n",
        "    return model, float(np.mean(fold_mae)), float(np.std(fold_mae))\n",
        "\n",
        "for stat in [\"PTS\",\"REB\",\"AST\"]:\n",
        "    target = f\"{stat}_per_min\"\n",
        "    model, m, s = train_rate_model(train, target, RATE_FEATURES)\n",
        "    models_rate[stat] = model\n",
        "    cv_scores_rate[stat] = (m, s)\n",
        "    print(f\"üìè {stat}_per_min MAE: {m:.4f} ¬± {s:.4f}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4) Project TODAY's rates and totals = rate * predicted minutes\n",
        "# ---------------------------------------------------------------------------\n",
        "# Build today's feature frame: take latest per player and align with RATE_FEATURES.\n",
        "latest_today = (\n",
        "    features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "                .groupby(\"PLAYER_NAME\", as_index=False)\n",
        "                .tail(1)\n",
        "                .copy()\n",
        ")\n",
        "\n",
        "# Ensure all feature columns exist; if not, fill with neutral values\n",
        "for c in RATE_FEATURES:\n",
        "    if c not in latest_today.columns:\n",
        "        latest_today[c] = 0.0\n",
        "\n",
        "X_today = latest_today[RATE_FEATURES].copy()\n",
        "\n",
        "# Join minutes prediction\n",
        "mt = minutes_today.rename(columns={\"PLAYER_NAME\":\"PLAYER_NAME_mins\"})\n",
        "proj_base = latest_today.merge(\n",
        "    mt[[\"PLAYER_ID\",\"pred_minutes\",\"start_prob\",\"is_starter\",\"may_not_play\",\"injury_prob\"]],\n",
        "    on=\"PLAYER_ID\", how=\"left\"\n",
        ")\n",
        "\n",
        "# If a player lacks a minutes prediction, give a conservative fallback\n",
        "proj_base[\"pred_minutes\"] = proj_base[\"pred_minutes\"].fillna(proj_base.get(\"MIN_roll5\", 24)).clip(0, 48)\n",
        "\n",
        "# Predict rates\n",
        "out_frames = []\n",
        "for stat in [\"PTS\",\"REB\",\"AST\"]:\n",
        "    mu_rate = models_rate[stat].predict(X_today)\n",
        "\n",
        "    # Simple uncertainty model:\n",
        "    #   - empirical residual SD in rate space per stat (global)\n",
        "    #   - then combine with minutes variance (approx) for total SD\n",
        "    # Build residual SD once from training data\n",
        "    df_t = train.dropna(subset=RATE_FEATURES + [f\"{stat}_per_min\",\"PLAYER_ID\"]).copy()\n",
        "    pred_rate_t = models_rate[stat].predict(df_t[RATE_FEATURES])\n",
        "    resid = (df_t[f\"{stat}_per_min\"] - pred_rate_t).values\n",
        "    sd_rate = np.nanstd(resid, ddof=1) if len(resid) > 8 else 0.0\n",
        "\n",
        "    # Minutes uncertainty proxy from minutes model signals:\n",
        "    #   baseline 3.0 min SD, boosted if not confirmed starter or has injury_prob\n",
        "    min_sd = 3.0 \\\n",
        "             + 4.0*(1.0 - proj_base[\"start_prob\"].fillna(0.7).values) \\\n",
        "             + 4.0*(proj_base[\"injury_prob\"].fillna(0.0).values)\n",
        "\n",
        "    # Combine:\n",
        "    #   Var(total) ‚âà Var(rate*min) ‚âà E[min]^2 * Var(rate) + E[rate]^2 * Var(min)\n",
        "    pred_min = proj_base[\"pred_minutes\"].values\n",
        "    var_total = (pred_min**2) * (sd_rate**2) + (mu_rate**2) * (min_sd**2)\n",
        "    sd_total = np.sqrt(np.maximum(var_total, 1e-6))\n",
        "\n",
        "    totals = mu_rate * pred_min\n",
        "\n",
        "    df_out = pd.DataFrame({\n",
        "        \"PLAYER_ID\": proj_base[\"PLAYER_ID\"],\n",
        "        \"PLAYER_NAME\": proj_base[\"PLAYER_NAME\"],\n",
        "        \"TEAM_ABBREVIATION\": proj_base[\"TEAM_ABBREVIATION\"],\n",
        "        \"OPPONENT_ABBREVIATION\": proj_base[\"OPPONENT_ABBREVIATION\"],\n",
        "        \"market\": stat,\n",
        "        \"projection_mean\": totals,\n",
        "        \"projection_sd\": sd_total,\n",
        "        \"pred_minutes\": pred_min,\n",
        "        \"pred_rate\": mu_rate,\n",
        "        \"start_prob\": proj_base[\"start_prob\"].round(2),\n",
        "        \"is_starter\": proj_base[\"is_starter\"].fillna(0).astype(int),\n",
        "        \"may_not_play\": proj_base[\"may_not_play\"].fillna(0).astype(int),\n",
        "        \"injury_prob\": proj_base[\"injury_prob\"].fillna(0.0).round(2)\n",
        "    })\n",
        "    out_frames.append(df_out)\n",
        "\n",
        "proj_base[\"OPPONENT_ABBREVIATION\"] = proj_base[\"OPPONENT_ABBREVIATION\"].fillna(\"UNK\").astype(str)\n",
        "\n",
        "df_projections_all = pd.concat(out_frames, ignore_index=True)\n",
        "\n",
        "# Normalize export columns like your Cell 16 pipeline expects\n",
        "df_projections_all = df_projections_all.rename(columns={\n",
        "    \"PLAYER_NAME\": \"player\",\n",
        "    \"TEAM_ABBREVIATION\": \"team\",\n",
        "    \"OPPONENT_ABBREVIATION\": \"opponent\",\n",
        "    \"pred_minutes\": \"projected_minutes\"\n",
        "})\n",
        "df_projections_all[\"game_date\"] = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "print(\"‚úÖ Projections ready:\")\n",
        "print(df_projections_all.groupby(\"market\")[\"player\"].count().to_dict())\n",
        "print(df_projections_all.head(40).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361328fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for stat, model in models_rate.items():\n",
        "    importance = model.feature_importances_\n",
        "    sorted_idx = np.argsort(importance)[::-1]\n",
        "    sorted_feats = [RATE_FEATURES[i] for i in sorted_idx]\n",
        "    sorted_imp = importance[sorted_idx]\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.title(f\"Feature Importance: {stat}_per_min\")\n",
        "    plt.barh(sorted_feats[:12][::-1], sorted_imp[:12][::-1])  # Top 12\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1a823e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Features used in rate models:\\n\", RATE_FEATURES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87786090",
      "metadata": {},
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05885691",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # -- cell 8_rate_model ---------------------------------------------------------\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import TimeSeriesSplit\n",
        "# from sklearn.metrics import mean_absolute_error\n",
        "# from xgboost import XGBRegressor\n",
        "\n",
        "# # ---------------------------------------------------------------------------\n",
        "# # 0) Safety checks\n",
        "# # ---------------------------------------------------------------------------\n",
        "# assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
        "#     \"features_all missing. Run Cell 7 + Cell 0_data first.\"\n",
        "# assert 'minutes_today' in globals() and isinstance(minutes_today, pd.DataFrame) and not minutes_today.empty, \\\n",
        "#     \"minutes_today missing. Build your base minutes first.\"\n",
        "\n",
        "# fa = features_all.copy()\n",
        "# if \"GAME_DATE\" in fa.columns:\n",
        "#     fa[\"GAME_DATE\"] = pd.to_datetime(fa[\"GAME_DATE\"])\n",
        "\n",
        "# # Minimal id keys (best-effort)\n",
        "# if \"PLAYER_ID\" not in fa.columns:\n",
        "#     # fabricate a stable id per name if you don't have PLAYER_ID\n",
        "#     fa[\"PLAYER_ID\"] = fa[\"PLAYER_NAME\"].factorize()[0] + 1\n",
        "\n",
        "# # ---------------------------------------------------------------------------\n",
        "# # 1) Build leakage-safe RATE targets using next game's totals/minutes\n",
        "# #    target_rate(stat) = stat_next / max(MIN_next, 1)\n",
        "# # ---------------------------------------------------------------------------\n",
        "# fa = fa.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).copy()\n",
        "# for col in [\"MIN\",\"PTS\",\"REB\",\"AST\"]:\n",
        "#     if col not in fa.columns:\n",
        "#         fa[col] = np.nan\n",
        "\n",
        "# fa[\"MIN_next\"] = fa.groupby(\"PLAYER_NAME\")[\"MIN\"].shift(-1)\n",
        "# fa[\"PTS_next\"] = fa.groupby(\"PLAYER_NAME\")[\"PTS\"].shift(-1)\n",
        "# fa[\"REB_next\"] = fa.groupby(\"PLAYER_NAME\")[\"REB\"].shift(-1)\n",
        "# fa[\"AST_next\"] = fa.groupby(\"PLAYER_NAME\")[\"AST\"].shift(-1)\n",
        "\n",
        "# def _rate_next(numer_next, min_next):\n",
        "#     m = np.maximum(min_next.astype(float), 1.0)\n",
        "#     return numer_next.astype(float) / m\n",
        "\n",
        "# fa[\"PTS_rate_next\"] = _rate_next(fa[\"PTS_next\"], fa[\"MIN_next\"])\n",
        "# fa[\"REB_rate_next\"] = _rate_next(fa[\"REB_next\"], fa[\"MIN_next\"])\n",
        "# fa[\"AST_rate_next\"] = _rate_next(fa[\"AST_next\"], fa[\"MIN_next\"])\n",
        "\n",
        "# # ---------------------------------------------------------------------------\n",
        "# # 2) Feature set (reuse what you already engineered if present)\n",
        "# #    Keep it robust to missing columns.\n",
        "# # ---------------------------------------------------------------------------\n",
        "# BASE_FEATURES = [\n",
        "#     \"MIN_roll5\",\"MIN_roll10\",\"TS_game_roll5\",\"TS_game_roll10\",\n",
        "#     \"usage_share_roll5\",\"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
        "#     \"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\n",
        "#     \"days_rest\",\"HOME\",\n",
        "#     # Extras if your pipeline created them:\n",
        "#     \"PTS_roll5\",\"PTS_roll10\",\"REB_roll5\",\"REB_roll10\",\"AST_roll5\",\"AST_roll10\",\n",
        "#     \"PTS_trend\",\"REB_trend\",\"AST_trend\",\n",
        "#     \"PTS_roll5_std\",\"REB_roll5_std\",\"AST_roll5_std\",\n",
        "#     \"usage_minutes_interact\",\"ts_usage_interact\",\n",
        "#     \"opp_ORtg_g_roll5\",\"opp_DRtg_g_roll5\",\"opp_Pace_g_roll5\",\"pace_diff5\"\n",
        "# ]\n",
        "# TARGETS = {\n",
        "#     \"PTS\": \"PTS_rate_next\",\n",
        "#     \"REB\": \"REB_rate_next\",\n",
        "#     \"AST\": \"AST_rate_next\",\n",
        "# }\n",
        "\n",
        "# def _present(cols): \n",
        "#     return [c for c in cols if c in fa.columns]\n",
        "\n",
        "# # ---------------------------------------------------------------------------\n",
        "# # 3) Train XGBRegressor per stat on RATE targets (time-ordered CV)\n",
        "# # ---------------------------------------------------------------------------\n",
        "# models_rate = {}\n",
        "# cv_scores = {}\n",
        "# tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# for stat, tgt in TARGETS.items():\n",
        "#     feat_cols = _present(BASE_FEATURES)\n",
        "#     need = feat_cols + [\"PLAYER_ID\",\"GAME_DATE\",\"MIN_next\", tgt]\n",
        "#     data = fa.dropna(subset=[c for c in need if c in fa.columns]).copy()\n",
        "\n",
        "#     # Optional: restrict to games where next minutes >= 6 to reduce noisy targets\n",
        "#     data = data[data[\"MIN_next\"] >= 6].copy()\n",
        "\n",
        "#     if data.empty:\n",
        "#         print(f\"‚ö†Ô∏è No training data for {stat}. Skipping.\")\n",
        "#         continue\n",
        "\n",
        "#     data = data.sort_values(\"GAME_DATE\")\n",
        "#     X = data[feat_cols].fillna(0.0)\n",
        "#     y = data[tgt].astype(float)\n",
        "\n",
        "#     fold_mae=[]\n",
        "#     for tr_idx, te_idx in tscv.split(X):\n",
        "#         Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
        "#         ytr, yte = y.iloc[tr_idx], y.iloc[te_idx]\n",
        "#         model = XGBRegressor(\n",
        "#             n_estimators=500, learning_rate=0.05, max_depth=5,\n",
        "#             subsample=0.85, colsample_bytree=0.9,\n",
        "#             reg_lambda=1.0, reg_alpha=0.0,\n",
        "#             random_state=42, n_jobs=-1, verbosity=0\n",
        "#         )\n",
        "#         model.fit(Xtr, ytr)\n",
        "#         pred = model.predict(Xte)\n",
        "#         fold_mae.append(mean_absolute_error(yte, pred))\n",
        "#     cv_scores[stat] = (float(np.mean(fold_mae)), float(np.std(fold_mae)))\n",
        "#     print(f\"Rate {stat} MAE (TimeSeries CV): {np.mean(fold_mae):.3f} ¬± {np.std(fold_mae):.3f}\")\n",
        "\n",
        "#     final_model = XGBRegressor(\n",
        "#         n_estimators=600, learning_rate=0.045, max_depth=5,\n",
        "#         subsample=0.9, colsample_bytree=0.9,\n",
        "#         reg_lambda=1.0, reg_alpha=0.0,\n",
        "#         random_state=42, n_jobs=-1, verbosity=0\n",
        "#     )\n",
        "#     final_model.fit(X, y)\n",
        "#     models_rate[stat] = (final_model, feat_cols)\n",
        "\n",
        "# # ---------------------------------------------------------------------------\n",
        "# # 4) Build today's feature rows and merge with minutes_today\n",
        "# #    Use each player's latest historical row as \"today context\".\n",
        "# # ---------------------------------------------------------------------------\n",
        "# latest = (\n",
        "#     fa.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "#       .groupby(\"PLAYER_NAME\", as_index=False)\n",
        "#       .tail(1)\n",
        "#       .copy()\n",
        "# )\n",
        "\n",
        "# # Normalize team/opponent keys\n",
        "# for c in [\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]:\n",
        "#     if c not in latest.columns:\n",
        "#         latest[c] = np.nan\n",
        "\n",
        "# # align to players we have minutes for today\n",
        "# key_cols = [\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]\n",
        "# mt = minutes_today.copy()\n",
        "# if \"PLAYER_ID\" not in mt.columns:\n",
        "#     # map PLAYER_ID from latest by name when missing\n",
        "#     name_to_id = latest.set_index(\"PLAYER_NAME\")[\"PLAYER_ID\"].to_dict()\n",
        "#     mt[\"PLAYER_ID\"] = mt[\"PLAYER_NAME\"].map(name_to_id)\n",
        "\n",
        "# today = pd.merge(\n",
        "#     latest,\n",
        "#     mt[[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\n",
        "#         \"pred_minutes\",\"start_prob\"]].drop_duplicates(\"PLAYER_ID\"),\n",
        "#     on=[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"],\n",
        "#     how=\"inner\",\n",
        "#     suffixes=(\"\",\"\")\n",
        "# )\n",
        "\n",
        "# if today.empty:\n",
        "#     raise RuntimeError(\"No overlap between latest history and minutes_today. Check name/team keys.\")\n",
        "\n",
        "# # ---------------------------------------------------------------------------\n",
        "# # 5) Predict per-minute rates ‚Üí multiply by predicted minutes ‚Üí totals\n",
        "# #    Also compute a reasonable per-player SD per market.\n",
        "# # ---------------------------------------------------------------------------\n",
        "# proj_frames = []\n",
        "# for stat, (model, feat_cols) in models_rate.items():\n",
        "#     cols = [c for c in feat_cols if c in today.columns]\n",
        "#     if not cols:\n",
        "#         print(f\"‚ö†Ô∏è No features present for {stat}. Skipping.\")\n",
        "#         continue\n",
        "\n",
        "#     Xp = today[cols].fillna(0.0)\n",
        "#     rate_hat = model.predict(Xp)                      # predicted stat per minute\n",
        "#     mins_hat = today[\"pred_minutes\"].astype(float).clip(lower=0, upper=48).values\n",
        "#     total_hat = np.clip(rate_hat * mins_hat, 0, None)\n",
        "\n",
        "#     # SD heuristic:\n",
        "#     # - player-specific per-minute volatility from last 10 games\n",
        "#     # - scaled by predicted minutes\n",
        "#     # - floor to avoid zero SD\n",
        "#     hist = (\n",
        "#         fa.assign(rate=lambda d: np.where(d[\"MIN\"]>0, d[stat] / d[\"MIN\"], np.nan))\n",
        "#           .sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
        "#     )\n",
        "#     sd_map = (\n",
        "#         hist.groupby(\"PLAYER_NAME\")[\"rate\"]\n",
        "#             .apply(lambda s: s.tail(10).std(ddof=1))\n",
        "#             .replace([np.inf,-np.inf], np.nan)\n",
        "#     ).to_dict()\n",
        "#     sd_rate = today[\"PLAYER_NAME\"].map(sd_map).astype(float).fillna(0.10)   # fallback 0.10 per min\n",
        "#     sd_total = (sd_rate.values * np.sqrt(np.maximum(mins_hat, 1.0))).clip(0.75, None)\n",
        "\n",
        "#     dfp = pd.DataFrame({\n",
        "#         \"player\": today[\"PLAYER_NAME\"],\n",
        "#         \"team\": today[\"TEAM_ABBREVIATION\"],\n",
        "#         \"opponent\": today[\"OPPONENT_ABBREVIATION\"],\n",
        "#         \"game_date\": pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\"),\n",
        "#         \"market\": stat,\n",
        "#         \"projected_minutes\": mins_hat,\n",
        "#         \"start_prob\": today.get(\"start_prob\", pd.Series(0.75, index=today.index)).fillna(0.75).values,\n",
        "#         \"projection_mean\": total_hat,\n",
        "#         \"projection_sd\": sd_total\n",
        "#     })\n",
        "#     proj_frames.append(dfp)\n",
        "\n",
        "# df_projections_all = pd.concat(proj_frames, ignore_index=True) if proj_frames else pd.DataFrame()\n",
        "# df_projections_pts = df_projections_all[df_projections_all[\"market\"].eq(\"PTS\")].copy() if not df_projections_all.empty else pd.DataFrame()\n",
        "# df_projections_reb = df_projections_all[df_projections_all[\"market\"].eq(\"REB\")].copy() if not df_projections_all.empty else pd.DataFrame()\n",
        "# df_projections_ast = df_projections_all[df_projections_all[\"market\"].eq(\"AST\")].copy() if not df_projections_all.empty else pd.DataFrame()\n",
        "\n",
        "# print(\"\\n‚úÖ Rate models trained and projections built.\")\n",
        "# print(\"CV (MAE on rate targets):\", cv_scores)\n",
        "# print(\"Projection rows by market:\", df_projections_all[\"market\"].value_counts().to_dict() if not df_projections_all.empty else {})\n",
        "# print(df_projections_all.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6fc8992",
      "metadata": {},
      "outputs": [],
      "source": [
        "# #--cell 8--#\n",
        "# from sklearn.model_selection import TimeSeriesSplit\n",
        "# from sklearn.metrics import mean_absolute_error\n",
        "# from xgboost import XGBRegressor\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- Load your logs and enriched season files ---\n",
        "# logs_2324 = pd.read_csv(\"nba_boxscores_2023-24.csv\")\n",
        "# logs_2425 = pd.read_csv(\"nba_boxscores_2024-25.csv\")\n",
        "# enriched_2324 = pd.read_csv(\"nba_player_stats_2023_24_enriched.csv\")\n",
        "# enriched_2425 = pd.read_csv(\"nba_player_stats_2024_25_enriched.csv\")\n",
        "\n",
        "# # --- Build feature tables per season and concatenate ---\n",
        "# feat_2324 = assemble_player_game_features(logs_2324, enriched_2324)\n",
        "# feat_2425 = assemble_player_game_features(logs_2425, enriched_2425)\n",
        "# features_all = pd.concat([feat_2324, feat_2425], ignore_index=True)\n",
        "\n",
        "# # --- Base feature pool ---\n",
        "# BASE_FEATURES = [\n",
        "#     \"MIN_roll5\", \"MIN_roll10\", \"TS_game_roll5\", \"TS_game_roll10\", \"usage_share_roll5\",\n",
        "#     \"ORtg_g_roll5\", \"DRtg_g_roll5\", \"Pace_g_roll5\",\n",
        "#     \"PER\", \"TS%\", \"USG%\", \"ORtg\", \"DRtg\", \"WS/48\", \"BPM\", \"VORP\",\n",
        "#     \"days_rest\", \"HOME\"\n",
        "# ]\n",
        "# STAT_ROLLING = {\n",
        "#     \"PTS\": [\"PTS_roll5\", \"PTS_roll10\"],\n",
        "#     \"REB\": [\"REB_roll5\", \"REB_roll10\"],\n",
        "#     \"AST\": [\"AST_roll5\", \"AST_roll10\"],\n",
        "# }\n",
        "# TARGETS = {\n",
        "#     \"PTS\": \"PTS_next\",\n",
        "#     \"REB\": \"REB_next\",\n",
        "#     \"AST\": \"AST_next\",\n",
        "# }\n",
        "\n",
        "# models = {}\n",
        "# feature_cols_by_stat = {}\n",
        "# cv_scores = {}\n",
        "# tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# for stat, target_col in TARGETS.items():\n",
        "#     cand_feats = BASE_FEATURES + STAT_ROLLING[stat]\n",
        "#     feat_cols = [c for c in cand_feats if c in features_all.columns]\n",
        "#     feature_cols_by_stat[stat] = feat_cols\n",
        "\n",
        "#     data = features_all.dropna(subset=feat_cols + [target_col]).copy()\n",
        "#     if data.empty:\n",
        "#         print(f\"‚ö†Ô∏è No training data for {stat}. Skipping.\")\n",
        "#         continue\n",
        "\n",
        "#     data_sorted = data.sort_values(\"GAME_DATE\")\n",
        "#     X = data_sorted[feat_cols]\n",
        "#     y = data_sorted[target_col]\n",
        "\n",
        "#     maes = []\n",
        "#     for train_idx, test_idx in tscv.split(X):\n",
        "#         Xtr, Xte = X.iloc[train_idx], X.iloc[test_idx]\n",
        "#         ytr, yte = y.iloc[train_idx], y.iloc[test_idx]\n",
        "#         model = XGBRegressor(\n",
        "#             n_estimators=300,\n",
        "#             learning_rate=0.1,\n",
        "#             max_depth=4,\n",
        "#             subsample=0.8,\n",
        "#             colsample_bytree=0.8,\n",
        "#             random_state=42,\n",
        "#             n_jobs=-1,\n",
        "#             verbosity=0\n",
        "#         )\n",
        "#         model.fit(Xtr, ytr)\n",
        "#         pred = model.predict(Xte)\n",
        "#         maes.append(mean_absolute_error(yte, pred))\n",
        "\n",
        "#     cv_scores[stat] = (float(np.mean(maes)), float(np.std(maes)))\n",
        "#     print(f\"XGBoost Player {stat} MAE (TimeSeries CV): {np.mean(maes):.2f} ¬± {np.std(maes):.2f}\")\n",
        "\n",
        "#     final_model = XGBRegressor(\n",
        "#         n_estimators=300,\n",
        "#         learning_rate=0.1,\n",
        "#         max_depth=4,\n",
        "#         subsample=0.8,\n",
        "#         colsample_bytree=0.8,\n",
        "#         random_state=42,\n",
        "#         n_jobs=-1,\n",
        "#         verbosity=0\n",
        "#     )\n",
        "#     final_model.fit(X, y)\n",
        "#     models[stat] = final_model\n",
        "\n",
        "# if \"PTS\" in models:\n",
        "#     model = models[\"PTS\"]\n",
        "#     feature_cols = feature_cols_by_stat[\"PTS\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de4ad9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- cell 16 (feature importances ‚Äî robust for models_rate/models_mean/models) ---\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from IPython.display import display\n",
        "except Exception:\n",
        "    def display(x): print(x)\n",
        "\n",
        "# 1) Detect trained models + their feature maps\n",
        "_models = None\n",
        "_feat_map = {}\n",
        "\n",
        "def _is_tuple_model(v):\n",
        "    # supports (model, feat_cols) or [model, feat_cols]\n",
        "    return isinstance(v, (tuple, list)) and len(v) >= 1\n",
        "\n",
        "if \"models_rate\" in globals() and isinstance(models_rate, dict) and models_rate:\n",
        "    # models_rate can be {\"PTS\": model} OR {\"PTS\": (model, feat_cols)}\n",
        "    _models = {}\n",
        "    _feat_map = {}\n",
        "    for k, v in models_rate.items():\n",
        "        if _is_tuple_model(v):\n",
        "            _models[k] = v[0]\n",
        "            _feat_map[k] = list(v[1]) if len(v) > 1 else []\n",
        "        else:\n",
        "            _models[k] = v\n",
        "            # fallback: use RATE_FEATURES if present, else empty\n",
        "            _feat_map[k] = list(globals().get(\"RATE_FEATURES\", []))\n",
        "elif \"models_mean\" in globals() and isinstance(models_mean, dict) and models_mean:\n",
        "    _models = models_mean\n",
        "    if \"feature_bags\" in globals() and isinstance(feature_bags, dict):\n",
        "        _feat_map = feature_bags\n",
        "    else:\n",
        "        # fallback: use RATE_FEATURES if present\n",
        "        rf = list(globals().get(\"RATE_FEATURES\", []))\n",
        "        _feat_map = {k: rf for k in _models.keys()}\n",
        "elif \"models\" in globals() and isinstance(models, dict) and models:\n",
        "    _models = models\n",
        "    if \"feature_cols_by_stat\" in globals() and isinstance(feature_cols_by_stat, dict):\n",
        "        _feat_map = feature_cols_by_stat\n",
        "    else:\n",
        "        rf = list(globals().get(\"RATE_FEATURES\", []))\n",
        "        _feat_map = {k: rf for k in _models.keys()}\n",
        "\n",
        "if not _models:\n",
        "    raise RuntimeError(\"No trained models found (expected models_rate / models_mean / models). Train first.\")\n",
        "\n",
        "# 2) Importance extractor for XGBoost (gain -> weight -> sklearn attr)\n",
        "def _xgb_importances(mdl, feat_cols):\n",
        "    # Try booster-based importances\n",
        "    booster = None\n",
        "    try:\n",
        "        booster = mdl.get_booster()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    if booster is not None:\n",
        "        # prefer 'gain', else 'weight'\n",
        "        try:\n",
        "            raw = booster.get_score(importance_type=\"gain\")\n",
        "        except Exception:\n",
        "            raw = booster.get_score(importance_type=\"weight\")\n",
        "\n",
        "        s = pd.Series(raw, dtype=float)\n",
        "        if not s.empty:\n",
        "            # Map f0,f1,... to actual names if available\n",
        "            feat_names = None\n",
        "            try:\n",
        "                feat_names = booster.feature_names\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            if feat_names and all(isinstance(x, str) for x in feat_names):\n",
        "                if all(k.startswith(\"f\") and k[1:].isdigit() for k in s.index):\n",
        "                    idx_map = {f\"f{i}\": feat_names[i] for i in range(len(feat_names))}\n",
        "                    s.index = [idx_map.get(k, k) for k in s.index]\n",
        "            elif feat_cols:\n",
        "                # last-resort: align by index order if keys look like f0,f1,...\n",
        "                if all(k.startswith(\"f\") and k[1:].isdigit() for k in s.index) and len(feat_cols) >= len(s):\n",
        "                    idx_map = {f\"f{i}\": feat_cols[i] for i in range(len(feat_cols))}\n",
        "                    s.index = [idx_map.get(k, k) for k in s.index]\n",
        "            return s.sort_values(ascending=False)\n",
        "\n",
        "    # Fallback to sklearn-style attribute\n",
        "    if hasattr(mdl, \"feature_importances_\") and feat_cols:\n",
        "        s = pd.Series(mdl.feature_importances_, index=feat_cols, dtype=float)\n",
        "        return s.sort_values(ascending=False)\n",
        "\n",
        "    # Last fallback: return empty\n",
        "    return pd.Series(dtype=float)\n",
        "\n",
        "# 3) Build & display per-stat importances\n",
        "rows = []\n",
        "print(\"=== Feature Importances (top 15 by stat) ===\")\n",
        "for stat, mdl in _models.items():\n",
        "    feat_cols = _feat_map.get(stat, [])\n",
        "    imp = _xgb_importances(mdl, feat_cols)\n",
        "\n",
        "    print(f\"\\nTop 15 ‚Äî {stat}:\")\n",
        "    if imp.empty:\n",
        "        print(\"(no importance info available)\")\n",
        "        continue\n",
        "\n",
        "    display(imp.head(15))\n",
        "    for feat, val in imp.items():\n",
        "        rows.append({\"stat\": stat, \"feature\": feat, \"importance\": float(val)})\n",
        "\n",
        "# 4) Save tidy CSV + normalized pivot\n",
        "imp_df = pd.DataFrame(rows)\n",
        "if not imp_df.empty:\n",
        "    out_dir = \"model_outputs_rate\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    imp_df[\"importance_norm\"] = (\n",
        "        imp_df.groupby(\"stat\")[\"importance\"].transform(lambda x: x / (x.sum() if x.sum() else 1.0))\n",
        "    )\n",
        "\n",
        "    ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    out_path = os.path.join(out_dir, f\"feature_importances_{ts}.csv\")\n",
        "    imp_df.sort_values([\"stat\", \"importance\"], ascending=[True, False]).to_csv(out_path, index=False)\n",
        "    print(f\"\\n‚úÖ Saved importances to: {out_path}\")\n",
        "\n",
        "    feature_importance_wide = imp_df.pivot_table(\n",
        "        index=\"feature\", columns=\"stat\", values=\"importance_norm\", aggfunc=\"max\", fill_value=0.0\n",
        "    ).sort_values(by=list(_models.keys())[0] if _models else None, ascending=False)\n",
        "    print(\"\\n(Preview) Normalized importance wide table:\")\n",
        "    display(feature_importance_wide.head(20))\n",
        "else:\n",
        "    print(\"\\n‚ÑπÔ∏è Nothing to export ‚Äî no importances produced.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a40247d",
      "metadata": {},
      "source": [
        "## team-level predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bf580f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# #--cell 10--#\n",
        "# # Team game table\n",
        "# team_games = features_all.groupby([\"GAME_DATE\",\"TEAM_ABBREVIATION\"], as_index=False)\\\n",
        "#     .agg(\n",
        "#         team_pts=(\"PTS\",\"sum\"),\n",
        "#         team_pts_next=(\"PTS_next\",\"sum\"),\n",
        "#         or5=(\"ORtg_g_roll5\",\"mean\"),\n",
        "#         dr5=(\"DRtg_g_roll5\",\"mean\"),\n",
        "#         pace5=(\"Pace_g_roll5\",\"mean\"),\n",
        "#     )\n",
        "\n",
        "# # Join opponent features (same date)\n",
        "# opp = team_games.rename(columns={\n",
        "#     \"TEAM_ABBREVIATION\":\"OPPONENT_ABBREVIATION\",\n",
        "#     \"team_pts\":\"opp_pts\",\n",
        "#     \"team_pts_next\":\"opp_pts_next\",\n",
        "#     \"or5\":\"opp_or5\",\"dr5\":\"opp_dr5\",\"pace5\":\"opp_pace5\"\n",
        "# })\n",
        "# team_matchups = team_games.merge(opp, on=[\"GAME_DATE\"], how=\"inner\")\n",
        "\n",
        "# # Simple features for team total prediction\n",
        "# team_feature_cols = [\"or5\",\"dr5\",\"pace5\",\"opp_or5\",\"opp_dr5\",\"opp_pace5\"]\n",
        "# tm = team_matchups.dropna(subset=team_feature_cols + [\"team_pts_next\"]).copy()\n",
        "\n",
        "# from sklearn.linear_model import Ridge\n",
        "# X_tm = tm[team_feature_cols]\n",
        "# y_tm = tm[\"team_pts_next\"]\n",
        "# ridge = Ridge(alpha=5.0).fit(X_tm, y_tm)\n",
        "# print(\"Team PTS baseline R^2:\", ridge.score(X_tm, y_tm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c2e17e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#-- Cell 17 (value bet finder) --\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "def american_to_prob(odds):\n",
        "    if pd.isna(odds): return np.nan\n",
        "    o = float(odds)\n",
        "    return 100.0/(o+100.0) if o>0 else (-o)/(-o+100.0)\n",
        "\n",
        "def devig_pair(p_over, p_under):\n",
        "    if pd.isna(p_over) or pd.isna(p_under): return (np.nan, np.nan)\n",
        "    s = p_over + p_under\n",
        "    if s <= 0: return (np.nan, np.nan)\n",
        "    return (p_over/s, p_under/s)\n",
        "\n",
        "def kelly_fraction(p, american_odds, cap=0.25):\n",
        "    if pd.isna(p) or pd.isna(american_odds): return 0.0\n",
        "    o = float(american_odds)\n",
        "    b = o/100.0 if o>0 else 100.0/(-o)\n",
        "    f = (p*(b+1)-1)/b\n",
        "    return float(max(0.0, min(f, cap)))\n",
        "\n",
        "def ev_flat_over(p, american_odds):\n",
        "    if pd.isna(p) or pd.isna(american_odds): return np.nan\n",
        "    o = float(american_odds)\n",
        "    win = o/100.0 if o>0 else 100.0/(-o)\n",
        "    lose = 1.0\n",
        "    return p*win - (1-p)*lose\n",
        "\n",
        "# Normal CDF helper (if SciPy available) to turn mean/sd into p_over\n",
        "try:\n",
        "    from scipy.stats import norm\n",
        "    def p_over_from_normal(mu, sd, line):\n",
        "        if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: return np.nan\n",
        "        return 1.0 - norm.cdf((line - mu)/sd)\n",
        "except Exception:\n",
        "    def p_over_from_normal(mu, sd, line): return np.nan\n",
        "\n",
        "def build_value_bets_excel(\n",
        "    df_projections, df_odds, outfile_path=None,\n",
        "    join_keys=(\"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\"game_date\"),\n",
        "    cap_kelly=0.25\n",
        "):\n",
        "    def _norm(x): return None if pd.isna(x) else str(x).strip()\n",
        "    proj, odds = df_projections.copy(), df_odds.copy()\n",
        "    for k in join_keys:\n",
        "        if k in proj: proj[k] = proj[k].map(_norm)\n",
        "        if k in odds: odds[k] = odds[k].map(_norm)\n",
        "\n",
        "    merged = proj.merge(odds, on=list(join_keys), how=\"inner\", suffixes=(\"\", \"_odds\"))\n",
        "\n",
        "    if \"p_over_model\" not in merged.columns or merged[\"p_over_model\"].isna().all():\n",
        "        merged[\"p_over_model\"] = merged.apply(\n",
        "            lambda r: p_over_from_normal(r.get(\"projection_mean\"), r.get(\"projection_sd\"), r.get(\"line\")), axis=1\n",
        "        )\n",
        "\n",
        "    merged[\"p_over_imp\"]  = merged[\"over_odds\"].map(american_to_prob)\n",
        "    merged[\"p_under_imp\"] = merged[\"under_odds\"].map(american_to_prob)\n",
        "    merged[[\"p_over_fair\",\"p_under_fair\"]] = merged.apply(\n",
        "        lambda r: pd.Series(devig_pair(r[\"p_over_imp\"], r[\"p_under_imp\"])), axis=1\n",
        "    )\n",
        "\n",
        "    merged[\"edge_over\"]       = merged[\"p_over_model\"] - merged[\"p_over_fair\"]\n",
        "    merged[\"kelly_frac_over\"] = merged.apply(lambda r: kelly_fraction(r[\"p_over_model\"], r[\"over_odds\"], cap=cap_kelly), axis=1)\n",
        "    merged[\"EV_over_1u\"]      = merged.apply(lambda r: ev_flat_over(r[\"p_over_model\"], r[\"over_odds\"]), axis=1)\n",
        "    merged[\"asof_date\"]       = merged.get(\"asof_date\") if \"asof_date\" in merged else datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    preferred = [\n",
        "        \"asof_date\",\"game_date\",\"book\",\"player\",\"team\",\"opponent\",\"market\",\"line\",\"lineup_status\",\n",
        "        \"over_odds\",\"under_odds\",\"p_over_imp\",\"p_under_imp\",\"p_over_fair\",\"p_under_fair\",\"p_over_model\",\n",
        "        \"edge_over\",\"kelly_frac_over\",\"EV_over_1u\",\n",
        "        \"projected_minutes\",\"projection_mean\",\"projection_sd\",\"start_prob\",\n",
        "        \"opponent_allowance_idx\",\"team_orating\",\"opp_drating\",\n",
        "    ]\n",
        "    cols = [c for c in preferred if c in merged.columns] + [c for c in merged.columns if c not in preferred]\n",
        "    bets = merged[cols].sort_values([\"edge_over\",\"EV_over_1u\"], ascending=False).reset_index(drop=True)\n",
        "\n",
        "    summary = pd.DataFrame({\n",
        "        \"n_bets\":[len(bets)],\n",
        "        \"avg_edge_pp\":[bets[\"edge_over\"].mean()*100.0 if len(bets) else np.nan],\n",
        "        \"avg_kelly_pct\":[bets[\"kelly_frac_over\"].mean()*100.0 if len(bets) else np.nan],\n",
        "        \"avg_ev_1u\":[bets[\"EV_over_1u\"].mean() if len(bets) else np.nan],\n",
        "    })\n",
        "    by_market = bets.groupby(\"market\", dropna=False).agg(\n",
        "        n=(\"player\",\"count\"),\n",
        "        avg_edge_pp=(\"edge_over\", lambda x: 100.0*x.mean()),\n",
        "        avg_kelly_pct=(\"kelly_frac_over\", lambda x: 100.0*x.mean()),\n",
        "        avg_ev_1u=(\"EV_over_1u\",\"mean\")\n",
        "    ).reset_index()\n",
        "    by_book = bets.groupby(\"book\", dropna=False).agg(\n",
        "        n=(\"player\",\"count\"),\n",
        "        avg_edge_pp=(\"edge_over\", lambda x: 100.0*x.mean()),\n",
        "        avg_ev_1u=(\"EV_over_1u\",\"mean\")\n",
        "    ).reset_index()\n",
        "\n",
        "    if outfile_path is None:\n",
        "        outfile_path = f\"nba_value_bets_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "    with pd.ExcelWriter(outfile_path, engine=\"openpyxl\") as w:\n",
        "        bets.to_excel(w, sheet_name=\"Bets\", index=False)\n",
        "        summary.to_excel(w, sheet_name=\"Summary\", index=False, startrow=0)\n",
        "        by_market.to_excel(w, sheet_name=\"Summary\", index=False, startrow=5)\n",
        "        by_book.to_excel(w, sheet_name=\"Summary\", index=False, startrow=5+len(by_market)+3)\n",
        "\n",
        "        dd = pd.DataFrame([\n",
        "            (\"asof_date\",\"UTC run date\"), (\"game_date\",\"Game date\"),\n",
        "            (\"player\",\"Player\"), (\"team\",\"Team abbr\"), (\"opponent\",\"Opponent abbr\"),\n",
        "            (\"market\",\"PTS/REB/AST/3PM/PRA etc.\"), (\"line\",\"Book line\"), (\"book\",\"Sportsbook id\"),\n",
        "            (\"lineup_status\",\"EXPECTED/CONFIRMED/UNKNOWN\"),\n",
        "            (\"over_odds\",\"American odds Over\"), (\"under_odds\",\"American odds Under\"),\n",
        "            (\"p_over_imp\",\"Implied prob Over (pre-vig)\"), (\"p_under_imp\",\"Implied prob Under (pre-vig)\"),\n",
        "            (\"p_over_fair\",\"De-vigged prob Over\"), (\"p_under_fair\",\"De-vigged prob Under\"),\n",
        "            (\"p_over_model\",\"Model prob Over\"), (\"edge_over\",\"p_model ‚àí p_fair\"),\n",
        "            (\"kelly_frac_over\",\"Kelly fraction (cap)\"), (\"EV_over_1u\",\"EV if staking 1u\"),\n",
        "            (\"projected_minutes\",\"Projected minutes\"), (\"projection_mean\",\"Projected mean\"),\n",
        "            (\"projection_sd\",\"Projected stdev\"), (\"start_prob\",\"Start probability\"),\n",
        "            (\"opponent_allowance_idx\",\"Opponent allowance index\"),\n",
        "            (\"team_orating\",\"Team ORtg\"), (\"opp_drating\",\"Opponent DRtg\"),\n",
        "        ], columns=[\"column\",\"description\"])\n",
        "        dd.to_excel(w, sheet_name=\"Data_Dictionary\", index=False)\n",
        "\n",
        "    return bets, outfile_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b1786e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import TimeSeriesSplit\n",
        "# from sklearn.metrics import mean_absolute_error\n",
        "# from xgboost import XGBRegressor\n",
        "\n",
        "# # Safety: need features_all built (from your Cell 7 + 0_data)\n",
        "# assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
        "#     \"features_all missing. Run Cell 7 + 0_data first.\"\n",
        "\n",
        "# # Ensure GAME_DATE is datetime and sort\n",
        "# if \"GAME_DATE\" in features_all.columns:\n",
        "#     features_all[\"GAME_DATE\"] = pd.to_datetime(features_all[\"GAME_DATE\"])\n",
        "# features_all = features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).copy()\n",
        "\n",
        "# # ---------------- Features / Targets ----------------\n",
        "# BASE_FEATURES = [\n",
        "#     \"MIN_roll5\",\"MIN_roll10\",\n",
        "#     \"TS_game_roll5\",\"TS_game_roll10\",\n",
        "#     \"usage_share_roll5\",\n",
        "#     \"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
        "#     \"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\n",
        "#     \"days_rest\",\"HOME\"\n",
        "# ]\n",
        "# STAT_ROLLING = {\n",
        "#     \"PTS\": [\"PTS_roll5\",\"PTS_roll10\"],\n",
        "#     \"REB\": [\"REB_roll5\",\"REB_roll10\"],\n",
        "#     \"AST\": [\"AST_roll5\",\"AST_roll10\"],\n",
        "# }\n",
        "# TARGETS = {\n",
        "#     \"PTS\": \"PTS_next\",\n",
        "#     \"REB\": \"REB_next\",\n",
        "#     \"AST\": \"AST_next\",\n",
        "# }\n",
        "\n",
        "# models = {}\n",
        "# feature_cols_by_stat = {}\n",
        "# cv_scores = {}\n",
        "\n",
        "# # Time-aware CV across all players chronologically\n",
        "# tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# for stat, target_col in TARGETS.items():\n",
        "#     # pick available cols only\n",
        "#     cand = BASE_FEATURES + STAT_ROLLING[stat]\n",
        "#     feat_cols = [c for c in cand if c in features_all.columns]\n",
        "#     feature_cols_by_stat[stat] = feat_cols\n",
        "\n",
        "#     # drop rows missing features/target\n",
        "#     data = features_all.dropna(subset=feat_cols + [target_col]).copy()\n",
        "#     if data.empty:\n",
        "#         print(f\"‚ö†Ô∏è No training data for {stat}. Skipping.\")\n",
        "#         continue\n",
        "\n",
        "#     data = data.sort_values(\"GAME_DATE\")\n",
        "#     X = data[feat_cols]\n",
        "#     y = data[target_col]\n",
        "\n",
        "#     # CV MAE for sanity\n",
        "#     fold_mae = []\n",
        "#     for tr, te in tscv.split(X):\n",
        "#         Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
        "#         ytr, yte = y.iloc[tr], y.iloc[te]\n",
        "#         model = XGBRegressor(\n",
        "#             n_estimators=400,\n",
        "#             learning_rate=0.05,\n",
        "#             max_depth=5,\n",
        "#             subsample=0.85,\n",
        "#             colsample_bytree=0.9,\n",
        "#             reg_lambda=1.0,\n",
        "#             reg_alpha=0.0,\n",
        "#             random_state=42,\n",
        "#             n_jobs=-1,\n",
        "#             verbosity=0\n",
        "#         )\n",
        "#         model.fit(Xtr, ytr)\n",
        "#         pred = model.predict(Xte)\n",
        "#         fold_mae.append(mean_absolute_error(yte, pred))\n",
        "\n",
        "#     cv_scores[stat] = (float(np.mean(fold_mae)), float(np.std(fold_mae)))\n",
        "#     print(f\"‚úî {stat} MAE (TimeSeries CV): {np.mean(fold_mae):.2f} ¬± {np.std(fold_mae):.2f}\")\n",
        "\n",
        "#     # Fit final model on all data\n",
        "#     final_model = XGBRegressor(\n",
        "#         n_estimators=400,\n",
        "#         learning_rate=0.05,\n",
        "#         max_depth=5,\n",
        "#         subsample=0.85,\n",
        "#         colsample_bytree=0.9,\n",
        "#         reg_lambda=1.0,\n",
        "#         reg_alpha=0.0,\n",
        "#         random_state=42,\n",
        "#         n_jobs=-1,\n",
        "#         verbosity=0\n",
        "#     )\n",
        "#     final_model.fit(X, y)\n",
        "#     models[stat] = final_model\n",
        "\n",
        "# print(\"\\nDone. Trained models:\", list(models.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe88486d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # === Cell 16: projections for PTS/REB/AST using your trained RF models ===\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from datetime import datetime\n",
        "\n",
        "# # Safety checks\n",
        "# if \"models\" not in globals() or not models:\n",
        "#     raise RuntimeError(\"No trained models found. Run Cell 7 first to populate `models` and `feature_cols_by_stat`.\")\n",
        "\n",
        "# # We'll project for these markets\n",
        "# MARKETS = [\"PTS\", \"REB\", \"AST\"]\n",
        "\n",
        "# # Latest row per player as basis for \"next game\"\n",
        "# latest = features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).groupby(\"PLAYER_NAME\").tail(1).copy()\n",
        "\n",
        "# # Helper: per-stat stdev from last N actual games\n",
        "# def _player_sd_map(stat: str, n=10):\n",
        "#     def _sd(g):\n",
        "#         s = g[stat].tail(n)\n",
        "#         if s.notna().sum() >= 4:\n",
        "#             return float(s.std(ddof=1))\n",
        "#         return float(features_all[stat].std(ddof=1))\n",
        "#     return features_all.groupby(\"PLAYER_NAME\").apply(_sd)\n",
        "\n",
        "# # Normalize export keys common to all markets\n",
        "# base_cols = {\n",
        "#     \"PLAYER_NAME\": \"player\",\n",
        "#     \"TEAM_ABBREVIATION\": \"team\",\n",
        "#     \"OPPONENT_ABBREVIATION\": \"opponent\",\n",
        "# }\n",
        "# base_out = latest.rename(columns=base_cols)[[\"player\",\"team\",\"opponent\"]].copy()\n",
        "# base_out[\"game_date\"] = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "# base_out[\"projected_minutes\"] = latest.get(\"MIN_roll5\", pd.Series(index=latest.index)).fillna(30).clip(lower=10, upper=40).values\n",
        "# base_out[\"start_prob\"] = 0.90\n",
        "# base_out[\"lineup_status\"] = \"EXPECTED\"\n",
        "\n",
        "# # Build one projection frame per market\n",
        "# proj_frames = {}\n",
        "# for stat in MARKETS:\n",
        "#     if stat not in models:\n",
        "#         print(f\"‚ö†Ô∏è Skipping {stat}: model not found in `models`.\")\n",
        "#         continue\n",
        "#     feat_cols = feature_cols_by_stat.get(stat, [])\n",
        "#     if not feat_cols:\n",
        "#         print(f\"‚ö†Ô∏è Skipping {stat}: no feature columns recorded in `feature_cols_by_stat`.\")\n",
        "#         continue\n",
        "\n",
        "#     X_pred = latest[feat_cols].fillna(method=\"ffill\").fillna(0)\n",
        "#     pred_mean = models[stat].predict(X_pred)\n",
        "\n",
        "#     # per-player SD\n",
        "#     sd_map = _player_sd_map(stat)\n",
        "#     pred_sd = latest[\"PLAYER_NAME\"].map(sd_map)\n",
        "#     # conservative fallback SD = 15% of mean (min 1.0)\n",
        "#     sd_fallback = np.maximum(np.abs(pred_mean) * 0.15, 1.0)\n",
        "#     pred_sd = np.where(np.isnan(pred_sd), sd_fallback, pred_sd)\n",
        "\n",
        "#     dfp = base_out.copy()\n",
        "#     dfp[\"projection_mean\"] = pred_mean\n",
        "#     dfp[\"projection_sd\"] = pred_sd\n",
        "#     dfp[\"market\"] = stat\n",
        "\n",
        "#     # Expose per-market frames\n",
        "#     proj_frames[stat] = dfp[[\"player\",\"team\",\"opponent\",\"game_date\",\"market\",\n",
        "#                              \"projection_mean\",\"projection_sd\",\"projected_minutes\",\"start_prob\",\"lineup_status\"]].copy()\n",
        "\n",
        "# # Individual frames (kept for backward compatibility)\n",
        "# df_projections_pts = proj_frames.get(\"PTS\", pd.DataFrame())\n",
        "# df_projections_reb = proj_frames.get(\"REB\", pd.DataFrame())\n",
        "# df_projections_ast = proj_frames.get(\"AST\", pd.DataFrame())\n",
        "\n",
        "# # Combined projections across markets\n",
        "# df_projections_all = pd.concat(list(proj_frames.values()), ignore_index=True) if proj_frames else pd.DataFrame()\n",
        "\n",
        "# print(\"Projection rows by market:\",\n",
        "#       {k: len(v) for k, v in proj_frames.items()})\n",
        "\n",
        "\n",
        "# display(df_projections_all.head(9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a69d29",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # --- Cell 18: Helper: turn wide props (per-book columns) into a long, tidy table ---\n",
        "# import re\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# def odds_wide_to_long_from_columns(\n",
        "#     wide_df: pd.DataFrame,\n",
        "#     *,\n",
        "#     books: tuple[str, ...] = (\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\",\"espnbet\",\"hardrock\"),\n",
        "#     markets: tuple[str, ...] = (\"PTS\",\"REB\",\"AST\"),\n",
        "#     player_cols=(\"name\",\"player\",\"PLAYER_NAME\"),\n",
        "#     team_cols=(\"team\",\"TEAM\",\"team_name\",\"TEAM_ABBREVIATION\"),\n",
        "#     opp_cols=(\"opponent\",\"opp\",\"OPPONENT\",\"OPPONENT_ABBREVIATION\"),\n",
        "#     date_cols=(\"game_date\",\"GAME_DATE\",\"date\")\n",
        "# ) -> pd.DataFrame:\n",
        "#     \"\"\"\n",
        "#     Convert a 'wide' props frame into a tidy long format:\n",
        "#     one row per (player, market, book), with numeric line and American odds.\n",
        "\n",
        "#     Expected column patterns (flexible by regex):\n",
        "#       <book>_<suffix>                 -> the line (e.g., mgm_pts, fanduel_ast)\n",
        "#       <book>_<suffix>_over_odds       -> over odds (American)\n",
        "#       <book>_<suffix>_under_odds      -> under odds (American)\n",
        "\n",
        "#     Suffixes recognized per market:\n",
        "#       PTS:  'pts','points'\n",
        "#       REB:  'reb','rebounds'\n",
        "#       AST:  'ast','assists'\n",
        "#     \"\"\"\n",
        "#     df = wide_df.copy()\n",
        "\n",
        "#     # Identify reference columns\n",
        "#     def _first_col(cands):\n",
        "#         for c in cands:\n",
        "#             if c in df.columns: return c\n",
        "#         return None\n",
        "\n",
        "#     player_col = _first_col(player_cols)\n",
        "#     team_col   = _first_col(team_cols)\n",
        "#     opp_col    = _first_col(opp_cols)\n",
        "#     date_col   = _first_col(date_cols)\n",
        "\n",
        "#     # Fallbacks if totally missing\n",
        "#     if player_col is None:\n",
        "#         raise ValueError(\"Could not find a player name column in wide_df. \"\n",
        "#                          f\"Tried {player_cols}. Got columns: {list(df.columns)[:20]}...\")\n",
        "\n",
        "#     # Normalize helpers\n",
        "#     def _num_float(x):\n",
        "#         if pd.isna(x): return np.nan\n",
        "#         m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
        "#         return float(m.group()) if m else np.nan\n",
        "\n",
        "#     def _num_int(x):\n",
        "#         if pd.isna(x): return np.nan\n",
        "#         m = re.search(r\"[-+]?\\d+\", str(x))\n",
        "#         return int(m.group()) if m else np.nan\n",
        "\n",
        "#     # Market suffix map (flex)\n",
        "#     market_suffixes = {\n",
        "#         \"PTS\": (\"pts\",\"points\"),\n",
        "#         \"REB\": (\"reb\",\"rebounds\"),\n",
        "#         \"AST\": (\"ast\",\"assists\"),\n",
        "#     }\n",
        "\n",
        "#     # Build long rows\n",
        "#     long_rows = []\n",
        "#     # Iterate rows once; pull columns per book/market dynamically\n",
        "#     for _, row in df.iterrows():\n",
        "#         base = {\n",
        "#             \"player\": row[player_col],\n",
        "#             \"team\": row[team_col] if team_col else np.nan,\n",
        "#             \"opponent\": row[opp_col] if opp_col else np.nan,\n",
        "#             \"game_date\": row[date_col] if date_col else np.nan,\n",
        "#         }\n",
        "#         for mkt in markets:\n",
        "#             suffixes = market_suffixes.get(mkt, ())\n",
        "#             for b in books:\n",
        "#                 # Find the *line* column by trying allowed suffixes\n",
        "#                 line_val = np.nan\n",
        "#                 over_val = np.nan\n",
        "#                 under_val = np.nan\n",
        "#                 line_col_used = None\n",
        "\n",
        "#                 for suf in suffixes:\n",
        "#                     # exact line column (most common)\n",
        "#                     c_line = f\"{b}_{suf}\"\n",
        "#                     if c_line in df.columns and pd.notna(row[c_line]):\n",
        "#                         line_val = row[c_line]\n",
        "#                         line_col_used = c_line\n",
        "#                         # odds columns (several sites use these names)\n",
        "#                         for over_name in (f\"{b}_{suf}_over_odds\", f\"{b}_{suf}_o_odds\", f\"{b}_{suf}_over\"):\n",
        "#                             if over_name in df.columns:\n",
        "#                                 over_val = row[over_name]\n",
        "#                                 break\n",
        "#                         for under_name in (f\"{b}_{suf}_under_odds\", f\"{b}_{suf}_u_odds\", f\"{b}_{suf}_under\"):\n",
        "#                             if under_name in df.columns:\n",
        "#                                 under_val = row[under_name]\n",
        "#                                 break\n",
        "#                         break  # found a suffix match\n",
        "\n",
        "#                 # If not found, try a looser search (e.g., 'mgm_pts_line')\n",
        "#                 if (isinstance(line_val, float) and np.isnan(line_val)) or line_col_used is None:\n",
        "#                     pat = re.compile(rf\"^{re.escape(b)}_({ '|'.join(map(re.escape, suffixes)) })(_line)?$\", re.I)\n",
        "#                     for c in df.columns:\n",
        "#                         if pat.match(str(c)) and pd.notna(row[c]):\n",
        "#                             line_val = row[c]\n",
        "#                             line_col_used = c\n",
        "#                             # odds columns with same base\n",
        "#                             base_prefix = re.sub(r\"(_line)?$\", \"\", c)\n",
        "#                             for over_name in (f\"{base_prefix}_over_odds\", f\"{base_prefix}_o_odds\", f\"{base_prefix}_over\"):\n",
        "#                                 if over_name in df.columns:\n",
        "#                                     over_val = row[over_name]\n",
        "#                                     break\n",
        "#                             for under_name in (f\"{base_prefix}_under_odds\", f\"{base_prefix}_u_odds\", f\"{base_prefix}_under\"):\n",
        "#                                 if under_name in df.columns:\n",
        "#                                     under_val = row[under_name]\n",
        "#                                     break\n",
        "#                             break\n",
        "\n",
        "#                 # Only emit a row if we actually found a line\n",
        "#                 if pd.notna(line_val):\n",
        "#                     long_rows.append({\n",
        "#                         **base,\n",
        "#                         \"market\": mkt,\n",
        "#                         \"book\": b,\n",
        "#                         \"line\": _num_float(line_val),\n",
        "#                         \"over_odds\": _num_int(over_val),\n",
        "#                         \"under_odds\": _num_int(under_val),\n",
        "#                     })\n",
        "\n",
        "#     out = pd.DataFrame(long_rows)\n",
        "\n",
        "#     # Clean up: drop obviously invalid lines\n",
        "#     if not out.empty:\n",
        "#         out = out[pd.notna(out[\"line\"])]\n",
        "#         # remove zero/negative lines that can't be real for these markets (optional)\n",
        "#         out = out[out[\"line\"] > 0]\n",
        "\n",
        "#         # De-duplicate best-effort (sometimes the page contains duplicates per book)\n",
        "#         out = (out.sort_values([\"player\",\"market\",\"book\",\"line\"])\n",
        "#                   .drop_duplicates(subset=[\"player\",\"market\",\"book\"], keep=\"last\")\n",
        "#                   .reset_index(drop=True))\n",
        "\n",
        "#     return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "898a4608",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # --- Cell 19: robust wide->long adapter for Rotowire props ---\n",
        "# import re\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# def odds_wide_to_long_rotowire(\n",
        "#     wide_df: pd.DataFrame,\n",
        "#     *,\n",
        "#     books=(\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\",\"espnbet\",\"hardrock\"),\n",
        "#     markets=(\"PTS\",\"REB\",\"AST\"),\n",
        "#     player_cols=(\"name\",\"player\",\"PLAYER_NAME\"),\n",
        "#     team_cols=(\"team\",\"TEAM_ABBREVIATION\"),\n",
        "#     opp_cols=(\"opponent\",\"opp\",\"OPPONENT_ABBREVIATION\"),\n",
        "#     date_cols=(\"game_date\",\"GAME_DATE\")\n",
        "# ) -> pd.DataFrame:\n",
        "#     df = wide_df.copy()\n",
        "\n",
        "#     def _first_col(cols):\n",
        "#         for c in cols:\n",
        "#             if c in df.columns: return c\n",
        "#         return None\n",
        "\n",
        "#     ply = _first_col(player_cols)\n",
        "#     tm  = _first_col(team_cols)\n",
        "#     opp = _first_col(opp_cols)\n",
        "#     dt  = _first_col(date_cols)\n",
        "#     if ply is None:\n",
        "#         raise ValueError(f\"No player column found. Tried {player_cols}. Got sample: {list(df.columns)[:25]}\")\n",
        "\n",
        "#     # market suffixes we‚Äôll search (order matters)\n",
        "#     suffixes = {\"PTS\": (\"pts\",\"p\",\"points\"),\n",
        "#                 \"REB\": (\"reb\",\"rebounds\"),\n",
        "#                 \"AST\": (\"ast\",\"assists\")}\n",
        "\n",
        "#     # helpers\n",
        "#     def _num_float(x):\n",
        "#         if pd.isna(x): return np.nan\n",
        "#         m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
        "#         return float(m.group()) if m else np.nan\n",
        "\n",
        "#     def _num_int(x):\n",
        "#         if pd.isna(x): return np.nan\n",
        "#         m = re.search(r\"[-+]?\\d+\", str(x))\n",
        "#         return int(m.group()) if m else np.nan\n",
        "\n",
        "#     cols_lc = {c.lower(): c for c in df.columns}  # lower->actual\n",
        "\n",
        "#     def _find(name_like: str):\n",
        "#         return cols_lc.get(name_like.lower())\n",
        "\n",
        "#     rows = []\n",
        "#     for _, r in df.iterrows():\n",
        "#         base = {\n",
        "#             \"player\": r[ply],\n",
        "#             \"team\": r[tm] if tm else np.nan,\n",
        "#             \"opponent\": r[opp] if opp else np.nan,\n",
        "#             \"game_date\": r[dt] if dt else np.nan,\n",
        "#         }\n",
        "#         for mkt in markets:\n",
        "#             for book in books:\n",
        "#                 ln = np.nan; ov = np.nan; un = np.nan; used = None\n",
        "#                 # find the line column (e.g. mgm_pts / fanduel_p / caesars_ast)\n",
        "#                 for suf in suffixes[mkt]:\n",
        "#                     for cand in (f\"{book}_{suf}\", f\"{book}_{suf}_line\"):\n",
        "#                         real = _find(cand)\n",
        "#                         if real and pd.notna(r.get(real)):\n",
        "#                             ln = r[real]; used = real\n",
        "#                             break\n",
        "#                     if used: break\n",
        "\n",
        "#                 if used:\n",
        "#                     # odds columns around that base; support camel & underscore\n",
        "#                     base_prefix = re.sub(r\"_line$\", \"\", used, flags=re.I)\n",
        "#                     over_cands  = [f\"{base_prefix}Over\", f\"{base_prefix}_over\",\n",
        "#                                    f\"{base_prefix}_o\", f\"{base_prefix}_over_odds\"]\n",
        "#                     under_cands = [f\"{base_prefix}Under\", f\"{base_prefix}_under\",\n",
        "#                                    f\"{base_prefix}_u\", f\"{base_prefix}_under_odds\"]\n",
        "#                     for oc in over_cands:\n",
        "#                         c = _find(oc)\n",
        "#                         if c and pd.notna(r.get(c)): ov = r[c]; break\n",
        "#                     for uc in under_cands:\n",
        "#                         c = _find(uc)\n",
        "#                         if c and pd.notna(r.get(c)): un = r[c]; break\n",
        "\n",
        "#                     rows.append({\n",
        "#                         **base,\n",
        "#                         \"market\": mkt,\n",
        "#                         \"book\": book,\n",
        "#                         \"line\": _num_float(ln),\n",
        "#                         \"over_odds\": _num_int(ov),\n",
        "#                         \"under_odds\": _num_int(un),\n",
        "#                     })\n",
        "\n",
        "#     out = pd.DataFrame(rows)\n",
        "#     if not out.empty:\n",
        "#         out = out[pd.notna(out[\"line\"]) & (out[\"line\"] > 0)]\n",
        "#         out = (out.sort_values([\"player\",\"market\",\"book\",\"line\"])\n",
        "#                  .drop_duplicates(subset=[\"player\",\"market\",\"book\"], keep=\"last\")\n",
        "#                  .reset_index(drop=True))\n",
        "#         if \"game_date\" in out and out[\"game_date\"].isna().all():\n",
        "#             out[\"game_date\"] = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
        "#     return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92fd901",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Cell 20 (fixed): wide‚Üílong with robust Over/Under detection ===\n",
        "import re, numpy as np, pandas as pd\n",
        "\n",
        "def odds_wide_to_long_rotowire_final_v2(\n",
        "    wide_df: pd.DataFrame,\n",
        "    *,\n",
        "    books=(\"mgm\",\"draftkings\",\"fanduel\",\"betrivers\"),  # focus on these\n",
        "    markets=(\"PTS\",\"REB\",\"AST\"),\n",
        "    player_cols=(\"name\",\"player\",\"PLAYER_NAME\"),\n",
        "    team_cols=(\"team\",\"TEAM_ABBREVIATION\",\"TEAM\"),\n",
        "    opp_cols=(\"opponent\",\"opp\",\"OPPONENT_ABBREVIATION\",\"OPPONENT\"),\n",
        "    date_cols=(\"game_date\",\"GAME_DATE\",\"asof_date\"),\n",
        ") -> pd.DataFrame:\n",
        "    df = wide_df.copy()\n",
        "    if df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # ‚Äî‚Äî‚Äî helpers to pick identity columns ‚Äî‚Äî‚Äî\n",
        "    def _first_col(cands):\n",
        "        for c in cands:\n",
        "            if c in df.columns:\n",
        "                return c\n",
        "        return None\n",
        "\n",
        "    ply = _first_col(player_cols)\n",
        "    tm  = _first_col(team_cols)\n",
        "    opp = _first_col(opp_cols)\n",
        "    dt  = _first_col(date_cols)\n",
        "    if ply is None:\n",
        "        raise ValueError(\"No player column found in wide odds frame.\")\n",
        "\n",
        "    # market suffixes we‚Äôll search (ALL of them, not just the first)\n",
        "    suf_map = {\n",
        "        \"PTS\": (\"pts\", \"points\", \"p\"),\n",
        "        \"REB\": (\"reb\", \"rebounds\"),\n",
        "        \"AST\": (\"ast\", \"assists\"),\n",
        "    }\n",
        "\n",
        "    # numeric cleaners\n",
        "    def _num_float(x):\n",
        "        if pd.isna(x): return np.nan\n",
        "        m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
        "        return float(m.group()) if m else np.nan\n",
        "\n",
        "    def _num_int(x):\n",
        "        if pd.isna(x): return np.nan\n",
        "        m = re.search(r\"[-+]?\\d+\", str(x))\n",
        "        return int(m.group()) if m else np.nan\n",
        "\n",
        "    # prebuild a case-insensitive lookup for columns\n",
        "    lc_to_real = {c.lower(): c for c in df.columns}\n",
        "\n",
        "    def _get_series_any(names):\n",
        "        \"\"\"return the first non-missing column among name list (case-insensitive)\"\"\"\n",
        "        for n in names:\n",
        "            key = n.lower()\n",
        "            if key in lc_to_real:\n",
        "                return df[lc_to_real[key]]\n",
        "        return pd.Series([np.nan] * len(df))\n",
        "\n",
        "    rows = []\n",
        "    # iterate rows once; for each book+market pick the most plausible columns\n",
        "    for idx, r in df.iterrows():\n",
        "        base = {\n",
        "            \"player\":   r[ply],\n",
        "            \"team\":     (r[tm]  if tm  else np.nan),\n",
        "            \"opponent\": (r[opp] if opp else np.nan),\n",
        "            \"game_date\":(r[dt]  if dt  else np.nan),\n",
        "        }\n",
        "\n",
        "        for mkt in markets:\n",
        "            suffixes = suf_map[mkt]\n",
        "            # --- line column candidates, e.g. mgm_pts / draftkings_points ---\n",
        "            for book in books:\n",
        "                line = np.nan\n",
        "                over = np.nan\n",
        "                under = np.nan\n",
        "\n",
        "                # 1) try explicit line columns\n",
        "                line_names = []\n",
        "                for suf in suffixes:\n",
        "                    line_names += [f\"{book}_{suf}\", f\"{book}_{suf}_line\"]\n",
        "                # pick the first present\n",
        "                for nm in line_names:\n",
        "                    key = nm.lower()\n",
        "                    if key in lc_to_real and pd.notna(r[lc_to_real[key]]):\n",
        "                        line = r[lc_to_real[key]]\n",
        "                        break\n",
        "\n",
        "                # 2) over/under with lots of spellings (camel + underscore + *_odds)\n",
        "                # build patterns that include ANY of the suffixes\n",
        "                # e.g. ^mgm_.*(pts|points)\\w*(over(_odds)?|overodds)?$\n",
        "                suf_pat = \"(\" + \"|\".join(map(re.escape, suffixes)) + \")\"\n",
        "                # scan all columns once; pick the first non-na for over/under\n",
        "                for c in df.columns:\n",
        "                    cl = c.lower()\n",
        "                    if cl.startswith(book + \"_\"):\n",
        "                        if re.search(suf_pat, cl):\n",
        "                            if re.search(r\"(over)(_odds|odds)?$\", cl):\n",
        "                                if pd.notna(r[c]) and pd.isna(over):\n",
        "                                    over = r[c]\n",
        "                            elif re.search(r\"(under)(_odds|odds)?$\", cl):\n",
        "                                if pd.notna(r[c]) and pd.isna(under):\n",
        "                                    under = r[c]\n",
        "\n",
        "                # skip if absolutely nothing present for this book+market on this row\n",
        "                if pd.isna(line) and pd.isna(over) and pd.isna(under):\n",
        "                    continue\n",
        "\n",
        "                rows.append({\n",
        "                    **base,\n",
        "                    \"market\": mkt,\n",
        "                    \"book\": book,\n",
        "                    \"line\": _num_float(line),\n",
        "                    \"over_odds\": _num_int(over),\n",
        "                    \"under_odds\": _num_int(under),\n",
        "                })\n",
        "\n",
        "    out = pd.DataFrame(rows)\n",
        "\n",
        "    if out.empty:\n",
        "        return out\n",
        "\n",
        "    # keep ONLY rows with a real line and at least one price\n",
        "    has_line = out[\"line\"].notna()\n",
        "    has_price = out[\"over_odds\"].notna() | out[\"under_odds\"].notna()\n",
        "    out = out[has_line & has_price].copy()\n",
        "\n",
        "    # positive / plausible lines\n",
        "    out = out[out[\"line\"] > 0]\n",
        "\n",
        "    # dedupe within (player, market, book) keeping the most recent non-na price/line\n",
        "    out = (out.sort_values([\"player\", \"market\", \"book\", \"line\"])\n",
        "              .drop_duplicates(subset=[\"player\", \"market\", \"book\"], keep=\"last\")\n",
        "              .reset_index(drop=True))\n",
        "\n",
        "    # fill missing dates with today if needed\n",
        "    if \"game_date\" in out and out[\"game_date\"].isna().all():\n",
        "        out[\"game_date\"] = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Cell 21 (fixed): fetch odds for multiple books ‚Üí long ‚Üí join with projections ===\n",
        "from datetime import datetime\n",
        "import re, unicodedata, numpy as np, pandas as pd\n",
        "from statistics import NormalDist\n",
        "\n",
        "BOOKS = (\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\")\n",
        "\n",
        "scraper = NBAOddsScraper()\n",
        "\n",
        "# 1) Scrape EACH book and convert to long immediately (avoids NaN rows for non-present books)\n",
        "long_parts = []\n",
        "for b in BOOKS:\n",
        "    wide_b = scraper.get_player_props_odds_wide_raw(book=b)\n",
        "    if wide_b.empty:\n",
        "        print(f\"‚ö†Ô∏è {b}: no rows scraped.\")\n",
        "        continue\n",
        "    # Use the converter that already works for you in Cell 2\n",
        "    long_b = odds_wide_to_long_from_columns(wide_b, books=(b,), markets=(\"PTS\",\"REB\",\"AST\"))\n",
        "    if long_b.empty:\n",
        "        print(f\"‚ö†Ô∏è {b}: long table empty after conversion.\")\n",
        "    else:\n",
        "        long_parts.append(long_b)\n",
        "\n",
        "odds_long = pd.concat(long_parts, ignore_index=True) if long_parts else pd.DataFrame()\n",
        "print(f\"‚úÖ Combined long odds rows: {len(odds_long)}\")\n",
        "\n",
        "# 2) Row-level fallback line within each (player, market, game_date) group\n",
        "if not odds_long.empty:\n",
        "    grp = [\"player\",\"market\",\"game_date\"]\n",
        "    # take the first non-null line within the group\n",
        "    line_fallback = odds_long.groupby(grp)[\"line\"].transform(lambda s: s.dropna().iloc[0] if s.dropna().size else np.nan)\n",
        "    missing_before = odds_long[\"line\"].isna().sum()\n",
        "    odds_long[\"line\"] = odds_long[\"line\"].fillna(line_fallback)\n",
        "    missing_after  = odds_long[\"line\"].isna().sum()\n",
        "    print(f\"üõü Filled {missing_before - missing_after} missing lines via group fallback.\")\n",
        "\n",
        "    # Keep only rows with a usable line and at least one price\n",
        "    odds_long = odds_long[(odds_long[\"line\"].notna()) & ( (odds_long[\"over_odds\"].notna()) | (odds_long[\"under_odds\"].notna()) )].copy()\n",
        "    print(f\"‚úÖ Usable odds rows after filters: {len(odds_long)}\")\n",
        "\n",
        "# 3) Join with projections\n",
        "if \"df_projections_all\" not in globals() or df_projections_all.empty:\n",
        "    raise RuntimeError(\"df_projections_all missing ‚Äì run the projection cell first.\")\n",
        "\n",
        "def _norm_player(s):\n",
        "    if not isinstance(s, str): return \"\"\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    s = re.sub(r\"[.\\-`'‚Äô]\", \"\", s).strip().lower()\n",
        "    s = re.sub(r\"\\s+\",\" \", s)\n",
        "    return s\n",
        "\n",
        "odds_long[\"player_key\"] = odds_long[\"player\"].map(_norm_player)\n",
        "df_projections_all[\"player_key\"] = df_projections_all[\"player\"].map(_norm_player)\n",
        "\n",
        "def p_over_from_normal(mu, sd, line):\n",
        "    if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: return np.nan\n",
        "    z = (line - mu) / sd\n",
        "    return 1.0 - NormalDist().cdf(z)\n",
        "\n",
        "def implied_prob(a):\n",
        "    if pd.isna(a): return np.nan\n",
        "    a = float(a)\n",
        "    return (-a)/(-a+100.0) if a < 0 else 100.0/(a+100.0)\n",
        "\n",
        "joined = []\n",
        "for mkt in (\"PTS\",\"REB\",\"AST\"):\n",
        "    proj = df_projections_all.query(\"market == @mkt\")\n",
        "    odds = odds_long.query(\"market == @mkt\")\n",
        "    if proj.empty or odds.empty:\n",
        "        print(f\"‚ö†Ô∏è Skipping {mkt} (proj empty? {proj.empty}, odds empty? {odds.empty})\")\n",
        "        continue\n",
        "\n",
        "    dfj = proj.merge(\n",
        "        odds,\n",
        "        on=[\"player_key\",\"market\"],\n",
        "        how=\"inner\",\n",
        "        suffixes=(\"_proj\",\"_odds\")\n",
        "    )\n",
        "    if dfj.empty:\n",
        "        print(f\"‚ö†Ô∏è No matches for {mkt} after merge.\")\n",
        "        continue\n",
        "\n",
        "    # model P(over)\n",
        "    dfj[\"p_over_model\"] = dfj.apply(\n",
        "        lambda r: p_over_from_normal(r[\"projection_mean\"], r[\"projection_sd\"], r[\"line\"]),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # market implied\n",
        "    dfj[\"p_over_imp\"]  = dfj[\"over_odds\"].map(implied_prob)\n",
        "    dfj[\"p_under_imp\"] = dfj[\"under_odds\"].map(implied_prob)\n",
        "\n",
        "    # edge vs implied (de-vig will happen in Cell 22)\n",
        "    dfj[\"edge_over\"] = dfj[\"p_over_model\"] - dfj[\"p_over_imp\"]\n",
        "\n",
        "    joined.append(dfj)\n",
        "\n",
        "df_proj_join_all = pd.concat(joined, ignore_index=True) if joined else pd.DataFrame()\n",
        "\n",
        "print(f\"üîó Joined frame size: {len(df_proj_join_all)}\")\n",
        "print(odds_long.head(10))\n",
        "print(df_proj_join_all.head(10))\n",
        "\n",
        "# Optional: export a trace file to inspect later\n",
        "df_proj_join_all.to_csv(f\"nba_player_props_joined_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee8bf0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def peek_cols(df, book, key=\"pts\"):\n",
        "#     cols = [c for c in df.columns if re.match(fr\"^{book}_.{{0,12}}{key}\", c, re.I) or c.lower().startswith(f\"{book}_{key}\")]\n",
        "#     print(book, key, \"->\", cols[:20])\n",
        "\n",
        "# peek_cols(wide_raw, \"mgm\", \"pts\")\n",
        "# peek_cols(wide_raw, \"fanduel\", \"p\")     # note the short 'p'\n",
        "# peek_cols(wide_raw, \"caesars\", \"ast\")\n",
        "\n",
        "# print(df_proj_join_all['under_odds'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6db0195",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Cell 22 (Final) ‚Äî Price, Edge, EV & Kelly Calculations ==================\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from statistics import NormalDist\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 0Ô∏è‚É£ Safety check\n",
        "# ---------------------------------------------------------------------\n",
        "assert \"df_proj_join_all\" in globals() and not df_proj_join_all.empty, \\\n",
        "    \"Run Cell 21 first to build df_proj_join_all.\"\n",
        "\n",
        "df = df_proj_join_all.copy()\n",
        "print(f\"üìà Starting pricing with {len(df):,} merged projection/odds rows...\")\n",
        "print(df.head(20))\n",
        "# ---------------------------------------------------------------------\n",
        "# 1Ô∏è‚É£ Normalize & coalesce entity columns\n",
        "# ---------------------------------------------------------------------\n",
        "def _coalesce(df_, target, candidates):\n",
        "    s = pd.Series(index=df_.index, dtype=object)\n",
        "    for c in candidates:\n",
        "        if c in df_:\n",
        "            s = s.fillna(df_[c])\n",
        "    df_[target] = s\n",
        "\n",
        "_coalesce(df, \"player\",   [\"player_odds\",\"player_proj\",\"player\"])\n",
        "_coalesce(df, \"team\",     [\"team_odds\",\"team_proj\",\"team\"])\n",
        "_coalesce(df, \"opponent\", [\"opponent_odds\",\"opponent_proj\",\"opponent\"])\n",
        "_coalesce(df, \"game_date\",[\"game_date_odds\",\"game_date_proj\",\"game_date\"])\n",
        "\n",
        "# drop duplicate versions of these columns\n",
        "to_drop = [c for c in [\n",
        "    \"player_odds\",\"player_proj\",\"team_odds\",\"team_proj\",\n",
        "    \"opponent_odds\",\"opponent_proj\",\"game_date_odds\",\"game_date_proj\"\n",
        "] if c in df.columns]\n",
        "df.drop(columns=to_drop, inplace=True, errors=\"ignore\")\n",
        "\n",
        "# deduplicate columns\n",
        "df = df.loc[:, ~df.columns.duplicated()].copy()\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2Ô∏è‚É£ Filter to rows with valid odds\n",
        "# ---------------------------------------------------------------------\n",
        "if not {\"over_odds\",\"under_odds\"}.issubset(df.columns):\n",
        "    raise RuntimeError(\"Missing odds columns. Re-run Cell 21 to rebuild df_proj_join_all.\")\n",
        "\n",
        "priced = df.dropna(subset=[\"over_odds\",\"under_odds\"], how=\"all\").copy()\n",
        "print(f\"‚úÖ {len(priced):,} rows with valid odds available for pricing.\")\n",
        "print(priced.head(5))\n",
        "# ---------------------------------------------------------------------\n",
        "# 3Ô∏è‚É£ Numeric coercion helpers\n",
        "# ---------------------------------------------------------------------\n",
        "def _num_int(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    m = re.search(r\"[-+]?\\d+\", str(x))\n",
        "    return int(m.group()) if m else np.nan\n",
        "\n",
        "def _num_float(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
        "    return float(m.group()) if m else np.nan\n",
        "\n",
        "for c in [\"line\",\"projection_mean\",\"projection_sd\"]:\n",
        "    if c in priced.columns:\n",
        "        priced[c] = priced[c].apply(_num_float)\n",
        "for c in [\"over_odds\",\"under_odds\"]:\n",
        "    if c in priced.columns:\n",
        "        priced[c] = priced[c].apply(_num_int)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4Ô∏è‚É£ Handle missing SD (fallback 15% of mean, min = 1.0)\n",
        "# ---------------------------------------------------------------------\n",
        "if (\"projection_sd\" not in priced.columns) or priced[\"projection_sd\"].fillna(0).eq(0).all():\n",
        "    priced[\"projection_sd\"] = (priced[\"projection_mean\"].abs() * 0.15).clip(lower=1.0)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5Ô∏è‚É£ Model probability: P(over) from Normal(Œº, œÉ)\n",
        "# ---------------------------------------------------------------------\n",
        "def p_over_from_normal(mu, sd, line):\n",
        "    if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: \n",
        "        return np.nan\n",
        "    z = (line - mu) / sd\n",
        "    return 1.0 - NormalDist().cdf(z)\n",
        "\n",
        "priced[\"p_over_model\"] = priced.apply(\n",
        "    lambda r: p_over_from_normal(r[\"projection_mean\"], r[\"projection_sd\"], r[\"line\"]), axis=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6Ô∏è‚É£ Market-implied probabilities + de-vig + edge\n",
        "# ---------------------------------------------------------------------\n",
        "def implied_prob(a):\n",
        "    if pd.isna(a): return np.nan\n",
        "    a = float(a)\n",
        "    return (-a)/(-a+100.0) if a < 0 else 100.0/(a+100.0)\n",
        "\n",
        "priced[\"p_over_imp\"]  = priced[\"over_odds\"].map(implied_prob)\n",
        "priced[\"p_under_imp\"] = priced[\"under_odds\"].map(implied_prob)\n",
        "\n",
        "def devig_pair(p_o, p_u):\n",
        "    if pd.isna(p_o) or pd.isna(p_u): return (np.nan, np.nan)\n",
        "    s = p_o + p_u\n",
        "    if s <= 0: return (np.nan, np.nan)\n",
        "    return (p_o/s, p_u/s)\n",
        "\n",
        "fair = priced.apply(\n",
        "    lambda r: pd.Series(devig_pair(r[\"p_over_imp\"], r[\"p_under_imp\"]),\n",
        "                        index=[\"p_over_fair\",\"p_under_fair\"]),\n",
        "    axis=1\n",
        ")\n",
        "priced = pd.concat([priced, fair], axis=1)\n",
        "\n",
        "priced[\"edge_over\"] = np.where(\n",
        "    priced[\"p_over_fair\"].notna(),\n",
        "    priced[\"p_over_model\"] - priced[\"p_over_fair\"],\n",
        "    priced[\"p_over_model\"] - priced[\"p_over_imp\"]\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7Ô∏è‚É£ EV and Kelly (capped ‚â§ 25%)\n",
        "# ---------------------------------------------------------------------\n",
        "def kelly_fraction(p, american, cap=0.25):\n",
        "    if pd.isna(p) or pd.isna(american): return 0.0\n",
        "    a = float(american)\n",
        "    b = (a/100.0) if a > 0 else (100.0/abs(a))\n",
        "    f = (p*(b+1)-1)/b\n",
        "    return float(max(0.0, min(f, cap)))\n",
        "\n",
        "def ev_flat_over(p, american):\n",
        "    if pd.isna(p) or pd.isna(american): return np.nan\n",
        "    a = float(american)\n",
        "    win = (a/100.0) if a > 0 else (100.0/abs(a))\n",
        "    lose = 1.0\n",
        "    return p*win - (1-p)*lose\n",
        "\n",
        "priced[\"kelly_frac_over\"] = priced.apply(lambda r: kelly_fraction(r[\"p_over_model\"], r[\"over_odds\"]), axis=1)\n",
        "priced[\"EV_over_1u\"]      = priced.apply(lambda r: ev_flat_over(r[\"p_over_model\"], r[\"over_odds\"]), axis=1)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 8Ô∏è‚É£ Clean duplicates and column conflicts\n",
        "# ---------------------------------------------------------------------\n",
        "if priced.columns.duplicated().any():\n",
        "    print(\"‚ö†Ô∏è Duplicate columns detected ‚Äî removing duplicates.\")\n",
        "    priced = priced.loc[:, ~priced.columns.duplicated()].copy()\n",
        "\n",
        "if priced.columns.duplicated().any():\n",
        "    raise RuntimeError(\"Column duplication persists ‚Äî please inspect DataFrame.\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 9Ô∏è‚É£ Build sorted slates\n",
        "# ---------------------------------------------------------------------\n",
        "cols_keep = [\n",
        "    \"game_date\",\"book\",\"player\",\"team\",\"opponent\",\"market\",\"line\",\"lineup_status\",\n",
        "    \"over_odds\",\"under_odds\",\"p_over_imp\",\"p_under_imp\",\"p_over_fair\",\"p_under_fair\",\n",
        "    \"p_over_model\",\"edge_over\",\"EV_over_1u\",\"kelly_frac_over\",\n",
        "    \"projected_minutes\",\"projection_mean\",\"projection_sd\",\"start_prob\"\n",
        "]\n",
        "cols_keep = [c for c in cols_keep if c in priced.columns]\n",
        "\n",
        "priced_sorted = priced.sort_values([\"player\",\"market\",\"edge_over\"], ascending=[True,True,False])\n",
        "best_per_player = priced_sorted.drop_duplicates(subset=[\"player\",\"market\"], keep=\"first\")[cols_keep].reset_index(drop=True)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# üîü Filtering thresholds for ‚Äúvalue slate‚Äù\n",
        "# ---------------------------------------------------------------------\n",
        "EDGE_MIN   = 0.02   # ‚â• 2% model edge\n",
        "EV_MIN     = 0.00   # non-negative EV\n",
        "KELLY_MIN  = 0.01   # ‚â• 1% Kelly fraction\n",
        "MIN_MINUTES= 14\n",
        "START_PROB = 0.50\n",
        "\n",
        "slate = best_per_player[\n",
        "    (best_per_player[\"edge_over\"] >= EDGE_MIN) &\n",
        "    (best_per_player[\"EV_over_1u\"] >= EV_MIN) &\n",
        "    (best_per_player[\"kelly_frac_over\"] >= KELLY_MIN) &\n",
        "    (best_per_player[\"projected_minutes\"].fillna(0) >= MIN_MINUTES) &\n",
        "    (best_per_player[\"start_prob\"].fillna(1.0) >= START_PROB)\n",
        "].sort_values([\"edge_over\",\"EV_over_1u\"], ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Final value slate built ‚Äî {len(slate)} bets meet thresholds.\")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£  Save outputs\n",
        "# ---------------------------------------------------------------------\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "os.makedirs(\"data/bets\", exist_ok=True)\n",
        "csv_all   = f\"data/bets/nba_priced_candidates_{stamp}.csv\"\n",
        "csv_slate = f\"data/bets/nba_priced_slate_{stamp}.csv\"\n",
        "xlsx_path = f\"data/bets/nba_priced_{stamp}.xlsx\"\n",
        "\n",
        "best_per_player.to_csv(csv_all, index=False)\n",
        "slate.to_csv(csv_slate, index=False)\n",
        "with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as w:\n",
        "    best_per_player.to_excel(w, sheet_name=\"Candidates\", index=False)\n",
        "    slate.to_excel(w, sheet_name=\"Slate\", index=False)\n",
        "\n",
        "print(\"\\nüìÅ Files saved:\")\n",
        "print(f\"  ‚Ä¢ {csv_all}\")\n",
        "print(f\"  ‚Ä¢ {csv_slate}\")\n",
        "print(f\"  ‚Ä¢ {xlsx_path}\")\n",
        "\n",
        "# expose to later cells\n",
        "df_best = best_per_player.copy()\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# ‚úÖ  Quick summary preview\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"\\nEdge quantiles:\")\n",
        "print(best_per_player[\"edge_over\"].quantile([0.1,0.25,0.5,0.75,0.9]))\n",
        "\n",
        "print(\"\\nTop 10 by edge:\")\n",
        "display(best_per_player.sort_values(\"edge_over\", ascending=False).head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a468138",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Cell 23: Diagnostics + more-forgiving slate builder (FIXED) ===\n",
        "import os\n",
        "import numpy as np, pandas as pd\n",
        "from statistics import NormalDist\n",
        "\n",
        "assert 'df_best' in globals() and isinstance(df_best, pd.DataFrame), \"Run the priced-slate cell first.\"\n",
        "\n",
        "ND = NormalDist()\n",
        "dfD = df_best.copy()\n",
        "\n",
        "# --- Helpers -----------------------------------------------------------------\n",
        "def american_to_decimal(a):\n",
        "    \"\"\"Convert American odds to Decimal odds; return NaN if not valid.\"\"\"\n",
        "    if pd.isna(a): return np.nan\n",
        "    a = float(a)\n",
        "    if a == 0: return np.nan\n",
        "    return 1.0 + (a/100.0 if a > 0 else 100.0/abs(a))\n",
        "\n",
        "def implied_from_decimal(d):\n",
        "    \"\"\"Break-even probability from decimal odds.\"\"\"\n",
        "    return np.nan if (pd.isna(d) or d <= 1) else 1.0 / d\n",
        "\n",
        "def kelly_fraction_decimal(p, dec_odds, cap=0.25):\n",
        "    if pd.isna(p) or pd.isna(dec_odds) or dec_odds <= 1: return 0.0\n",
        "    b = dec_odds - 1.0\n",
        "    f = (p*(b+1) - 1) / b\n",
        "    return float(max(0.0, min(f, cap)))\n",
        "\n",
        "def ev_flat_decimal(p, dec_odds):\n",
        "    if pd.isna(p) or pd.isna(dec_odds) or dec_odds <= 1: return np.nan\n",
        "    return p*(dec_odds-1) - (1-p)*1.0\n",
        "\n",
        "def p_over_from_normal(mu, sd, line):\n",
        "    if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: return np.nan\n",
        "    z = (line - mu) / sd\n",
        "    return 1.0 - ND.cdf(z)\n",
        "\n",
        "# --- Ensure we have decimal odds columns -------------------------------------\n",
        "# Build from American odds if missing\n",
        "if \"over_dec\" not in dfD.columns:\n",
        "    dfD[\"over_dec\"] = dfD.get(\"over_odds\").map(american_to_decimal)\n",
        "if \"under_dec\" not in dfD.columns:\n",
        "    dfD[\"under_dec\"] = dfD.get(\"under_odds\").map(american_to_decimal)\n",
        "\n",
        "# --- Quick coverage checks ----------------------------------------------------\n",
        "have_over  = dfD['over_dec'].notna()  & (dfD['over_dec']  > 1.0)\n",
        "have_under = dfD['under_dec'].notna() & (dfD['under_dec'] > 1.0)\n",
        "print(\"Coverage:\")\n",
        "print(f\"  with over_dec:  {have_over.sum()} / {len(dfD)}\")\n",
        "print(f\"  with under_dec: {have_under.sum()} / {len(dfD)}\")\n",
        "print(f\"  both prices:    {(have_over & have_under).sum()} / {len(dfD)}\")\n",
        "\n",
        "# --- Edge distribution snapshot ----------------------------------------------\n",
        "q = dfD['edge_over'].dropna().quantile([0.1,0.25,0.5,0.75,0.9]) if 'edge_over' in dfD else pd.Series(dtype=float)\n",
        "print(\"\\nEdge quantiles (model - fair/imp):\")\n",
        "print(q.to_string())\n",
        "\n",
        "# --- Top 20 by edge (even if below your threshold) ---------------------------\n",
        "cols_preview = [c for c in [\n",
        "    \"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\n",
        "    \"over_dec\",\"under_dec\",\"p_over_model\",\"p_over_fair\",\"p_over_imp\",\"edge_over\",\"EV_over_1u\",\"kelly_frac_over\"\n",
        "] if c in dfD.columns]\n",
        "print(\"\\nTop by edge (first 20):\")\n",
        "print(dfD.sort_values('edge_over', ascending=False).head(20)[cols_preview].to_string(index=False))\n",
        "\n",
        "# =========================\n",
        "# Alternative slates\n",
        "# =========================\n",
        "\n",
        "# 1) EV-positive slate (uses model p_over and OVER decimal price)\n",
        "MIN_EV  = 0.01   # > 0.01u per 1u stake\n",
        "MIN_DEC = 1.01   # must have a real price\n",
        "slate_ev = dfD[\n",
        "    (dfD[\"EV_over_1u\"] > MIN_EV) &\n",
        "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
        "].copy()\n",
        "\n",
        "# 2) Lower-edge slate (relax edge threshold)\n",
        "MIN_EDGE_RELAXED = 0.005   # 0.5%\n",
        "slate_edge_relaxed = dfD[\n",
        "    (dfD[\"edge_over\"] >= MIN_EDGE_RELAXED) &\n",
        "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
        "].copy()\n",
        "\n",
        "# 3) Price-only slate (ignore de-vig; compare model vs break-even p from OVER decimal)\n",
        "dfD[\"p_over_price\"] = dfD[\"over_dec\"].map(implied_from_decimal)\n",
        "dfD[\"edge_vs_price\"] = dfD[\"p_over_model\"] - dfD[\"p_over_price\"]\n",
        "MIN_EDGE_PRICE = 0.01  # 1% vs break-even\n",
        "slate_price_only = dfD[\n",
        "    (dfD[\"edge_vs_price\"] >= MIN_EDGE_PRICE) &\n",
        "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
        "].copy()\n",
        "\n",
        "# 4) Sensitivity slate: try a slightly tighter SD (10% of mean) if SD looked fallback-ish\n",
        "need_sd_tighten = dfD[\"projection_sd\"].isna() | (dfD[\"projection_sd\"] <= 0)\n",
        "sd_tight = (dfD[\"projection_mean\"].abs() * 0.10).clip(lower=0.75)\n",
        "p_model_tight = []\n",
        "for mu, sd, line, tight_sd in zip(dfD[\"projection_mean\"], dfD[\"projection_sd\"], dfD[\"line\"], sd_tight):\n",
        "    use_sd = sd if pd.notna(sd) and sd > 0 else tight_sd\n",
        "    p_model_tight.append(p_over_from_normal(mu, use_sd, line))\n",
        "dfD[\"p_over_model_tight\"] = p_model_tight\n",
        "dfD[\"EV_over_1u_tight\"] = dfD.apply(lambda r: ev_flat_decimal(r[\"p_over_model_tight\"], r[\"over_dec\"]), axis=1)\n",
        "dfD[\"edge_over_tight\"] = np.where(dfD[\"p_over_fair\"].notna(),\n",
        "                                  dfD[\"p_over_model_tight\"] - dfD[\"p_over_fair\"],\n",
        "                                  dfD[\"p_over_model_tight\"] - dfD[\"p_over_imp\"])\n",
        "slate_tight = dfD[\n",
        "    (dfD[\"EV_over_1u_tight\"] > MIN_EV) &\n",
        "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
        "].copy()\n",
        "\n",
        "def _keep_cols(d):\n",
        "    keep = [c for c in [\n",
        "        \"asof_date\",\"game_date\",\"book\",\"player\",\"team\",\"opponent\",\"market\",\"line\",\"lineup_status\",\n",
        "        \"over_dec\",\"under_dec\",\n",
        "        \"p_over_imp\",\"p_under_imp\",\"p_over_fair\",\"p_under_fair\",\n",
        "        \"p_over_model\",\"edge_over\",\"EV_over_1u\",\"kelly_frac_over\",\n",
        "        \"p_over_price\",\"edge_vs_price\",\n",
        "        \"p_over_model_tight\",\"edge_over_tight\",\"EV_over_1u_tight\",\n",
        "        \"projected_minutes\",\"projection_mean\",\"projection_sd\",\"start_prob\"\n",
        "    ] if c in d.columns]\n",
        "    return d[keep].sort_values([\"market\",\"edge_over\"], ascending=[True, False])\n",
        "\n",
        "print(\"\\nSlate sizes:\")\n",
        "print(f\"  EV-positive (>{MIN_EV:.2f}u):           {len(slate_ev)}\")\n",
        "print(f\"  Relaxed edge (‚â•{MIN_EDGE_RELAXED*100:.1f}%): {len(slate_edge_relaxed)}\")\n",
        "print(f\"  Price-only edge (‚â•{MIN_EDGE_PRICE*100:.1f}%): {len(slate_price_only)}\")\n",
        "print(f\"  Tight-SD EV-positive:                  {len(slate_tight)}\")\n",
        "\n",
        "# Preview a few from each\n",
        "for name, slate_df in [\n",
        "    (\"EV-positive\", slate_ev),\n",
        "    (\"Relaxed-edge\", slate_edge_relaxed),\n",
        "    (\"Price-only\", slate_price_only),\n",
        "    (\"Tight-SD EV+\", slate_tight),\n",
        "]:\n",
        "    if not slate_df.empty:\n",
        "        print(f\"\\n{name} ‚Äî top 10\")\n",
        "        print(_keep_cols(slate_df).head(10).to_string(index=False))\n",
        "\n",
        "# Save all variants\n",
        "ts = pd.Timestamp.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "os.makedirs(\"data/bets\", exist_ok=True)\n",
        "_keep_cols(slate_ev).to_csv(f\"data/bets/nba_slate_evpos_{ts}.csv\", index=False)\n",
        "_keep_cols(slate_edge_relaxed).to_csv(f\"data/bets/nba_slate_edge_relaxed_{ts}.csv\", index=False)\n",
        "_keep_cols(slate_price_only).to_csv(f\"data/bets/nba_slate_price_only_{ts}.csv\", index=False)\n",
        "_keep_cols(slate_tight).to_csv(f\"data/bets/nba_slate_tightsd_{ts}.csv\", index=False)\n",
        "print(f\"\\nSaved CSVs with the four slate variants (timestamp {ts}).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203f6194",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -- Cell 24: Export clean value-bets CSV (adds PUnderModel) --\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Merge (already built earlier): best_per_player + dfD on [\"player\",\"market\"]\n",
        "merged_df = best_per_player.merge(\n",
        "    dfD, on=[\"player\", \"market\"], how=\"inner\", suffixes=(\"_best\", \"_dfD\")\n",
        ")\n",
        "\n",
        "# Optional quick peek that this column exists\n",
        "if \"p_over_model_dfD\" in merged_df.columns:\n",
        "    display(merged_df[\"p_over_model_dfD\"].head())\n",
        "\n",
        "# Columns we want to keep from the merge\n",
        "# NOTE: use line_dfD (from dfD) as the line source since that's what you previewed\n",
        "selected_columns = [\n",
        "    \"player\",\n",
        "    \"team_best\",\n",
        "    \"opponent_best\",\n",
        "    \"market\",\n",
        "    \"line_dfD\",                 # keep dfD line\n",
        "    \"over_odds_best\",\n",
        "    \"under_odds_best\",\n",
        "    \"p_over_imp_best\",\n",
        "    \"p_under_imp_best\",\n",
        "    \"p_over_fair_best\",\n",
        "    \"p_under_fair_best\",\n",
        "    \"projected_minutes_best\",\n",
        "    \"projection_mean_best\",\n",
        "    \"projection_sd_best\",\n",
        "    \"p_over_model_dfD\",\n",
        "]\n",
        "\n",
        "# Clean column names for output\n",
        "column_rename = {\n",
        "    \"player\": \"Player\",\n",
        "    \"team_best\": \"Team\",\n",
        "    \"opponent_best\": \"Opponent\",\n",
        "    \"market\": \"Market\",\n",
        "    \"line_dfD\": \"Line\",                 # map dfD line -> Line\n",
        "    \"over_odds_best\": \"OverOdds\",\n",
        "    \"under_odds_best\": \"UnderOdds\",\n",
        "    \"p_over_imp_best\": \"POverImp\",\n",
        "    \"p_under_imp_best\": \"PUnderImp\",\n",
        "    \"p_over_fair_best\": \"POverFair\",\n",
        "    \"p_under_fair_best\": \"PUnderFair\",\n",
        "    \"projected_minutes_best\": \"ProjMins\",\n",
        "    \"projection_mean_best\": \"ProjMean\",\n",
        "    \"projection_sd_best\": \"ProjSD\",\n",
        "    \"p_over_model_dfD\": \"POverModel\",\n",
        "}\n",
        "\n",
        "# Build clean frame\n",
        "missing = [c for c in selected_columns if c not in merged_df.columns]\n",
        "if missing:\n",
        "    raise KeyError(f\"Missing expected columns in merged_df: {missing}\")\n",
        "\n",
        "merged_df_clean = merged_df[selected_columns].rename(columns=column_rename)\n",
        "\n",
        "# Add PUnderModel = 1 - POverModel (clip to [0,1] for safety)\n",
        "merged_df_clean[\"PUnderModel\"] = (1.0 - merged_df_clean[\"POverModel\"]).clip(lower=0.0, upper=1.0)\n",
        "\n",
        "# Export\n",
        "os.makedirs(\"data/bets\", exist_ok=True)\n",
        "csv_path = os.path.join(\"data/bets\", f\"value_bets_top100_{datetime.now().strftime('%Y%m%d')}.csv\")\n",
        "merged_df_clean.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Saved clean value bets to: {csv_path}\")\n",
        "print(f\"Columns: {list(merged_df_clean.columns)}\")\n",
        "print(f\"Rows: {len(merged_df_clean)}\")\n",
        "print(\"\\nPreview:\")\n",
        "print(merged_df_clean.head().to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48c57ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Convert American odds ‚Üí Decimal odds and save ===\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Load latest value bets CSV (use today‚Äôs date automatically) ---\n",
        "today_str = datetime.now().strftime(\"%Y%m%d\")\n",
        "input_path = f\"data/bets/value_bets_top100_{today_str}.csv\"\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "# --- Convert American ‚Üí Decimal ---\n",
        "def american_to_decimal(american):\n",
        "    \"\"\"Convert American odds to decimal odds.\"\"\"\n",
        "    if pd.isna(american):\n",
        "        return None\n",
        "    try:\n",
        "        american = float(american)\n",
        "        if american > 0:\n",
        "            return 1 + (american / 100)\n",
        "        elif american < 0:\n",
        "            return 1 + (100 / abs(american))\n",
        "        else:\n",
        "            return None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# Apply conversion\n",
        "df[\"OverDecimal\"] = df[\"OverOdds\"].apply(american_to_decimal)\n",
        "df[\"UnderDecimal\"] = df[\"UnderOdds\"].apply(american_to_decimal)\n",
        "\n",
        "# --- Option A: keep both versions (recommended) ---\n",
        "# rename old odds for clarity\n",
        "df.rename(columns={\"OverOdds\": \"OverOdds_American\", \"UnderOdds\": \"UnderOdds_American\"}, inplace=True)\n",
        "\n",
        "# --- Option B: if you really want to remove them, uncomment this ---\n",
        "# df.drop(columns=[\"OverOdds\", \"UnderOdds\"], inplace=True)\n",
        "\n",
        "# --- Save updated CSV ---\n",
        "output_path = f\"data/bets/value_bets_top100_{today_str}_decimal.csv\"\n",
        "os.makedirs(\"data/bets\", exist_ok=True)\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Converted odds and saved to: {output_path}\")\n",
        "print(\"Preview:\")\n",
        "print(df[[\"Player\", \"Market\", \"OverDecimal\", \"UnderDecimal\"]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d86b905",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Visual diagnostics for model vs decimal odds (with market labels) ===\n",
        "import os, glob, re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# ---------- Load latest decimal CSV ----------\n",
        "cand = sorted(glob.glob(\"data/bets/value_bets_top100_*_decimal.csv\"))\n",
        "if not cand:\n",
        "    cand = sorted(glob.glob(\"data/bets/value_bets_top100_*.csv\"))\n",
        "    if not cand:\n",
        "        raise FileNotFoundError(\"No value bets file found in data/bets.\")\n",
        "path = cand[-1]\n",
        "print(f\"Using file: {path}\")\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# ---------- Inspect columns ----------\n",
        "print(\"All columns in CSV:\", list(df.columns))\n",
        "\n",
        "# ---------- Map column names (robustly) ----------\n",
        "def find_col(df, candidates):\n",
        "    cols_lc = {c.lower(): c for c in df.columns}\n",
        "    for name in candidates:\n",
        "        c = cols_lc.get(name.lower())\n",
        "        if c: return c\n",
        "    return None\n",
        "\n",
        "col_player   = find_col(df, [\"Player\"])\n",
        "col_team     = find_col(df, [\"Team\"])\n",
        "col_opp      = find_col(df, [\"Opponent\"])\n",
        "col_market   = find_col(df, [\"Market\"])\n",
        "col_line     = find_col(df, [\"Line\", \"line_dfD\", \"posted_line\"])\n",
        "col_p_model  = find_col(df, [\"POverModel\",\"p_over_model\",\"P_over_model\",\"pModel\",\"p_model\"])\n",
        "col_over_dec = find_col(df, [\"OverDecimal\",\"over_dec\",\"OverDec\",\"OverDecimalOdds\"])\n",
        "\n",
        "required = [col_player, col_market, col_p_model, col_over_dec]\n",
        "if any(x is None for x in required):\n",
        "    missing = [n for n, x in zip(\n",
        "        [\"Player\",\"Market\",\"POverModel\",\"OverDecimal\"], required) if x is None]\n",
        "    raise KeyError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "# ---------- Build working frame ----------\n",
        "opt_cols = [col_team, col_opp, col_line, find_col(df, [\"ProjMean\"]), find_col(df, [\"ProjSD\"]), \"ProjMins\", \"POverImp\", \"POverFair\"]\n",
        "keep = [c for c in [col_player, col_market, col_over_dec, col_p_model] + opt_cols if c and c in df.columns]\n",
        "d = df[keep].copy()\n",
        "\n",
        "# Coerce numerics (robust)\n",
        "def _to_float(s):\n",
        "    try:\n",
        "        return float(s)\n",
        "    except Exception:\n",
        "        m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(s))\n",
        "        return float(m.group()) if m else np.nan\n",
        "\n",
        "for c in [col_over_dec, col_p_model, col_line] if col_line else [col_over_dec, col_p_model]:\n",
        "    d[c] = d[c].apply(_to_float)\n",
        "\n",
        "# ---------- Derived metrics ----------\n",
        "d[\"p_over_price\"] = 1.0 / d[col_over_dec]\n",
        "d[\"edge_over\"]    = d[col_p_model] - d[\"p_over_price\"]\n",
        "d[\"EV_over_1u\"]   = d[col_p_model] * (d[col_over_dec] - 1.0) - (1.0 - d[col_p_model])\n",
        "\n",
        "# Label like \"Player o7.5\"\n",
        "def fmt_line(x):\n",
        "    return \"\" if pd.isna(x) else f\"{x:g}\"\n",
        "d[\"label\"] = d.apply(\n",
        "    lambda r: f\"{r[col_player]} o{fmt_line(r[col_line])}\" if col_line else f\"{r[col_player]}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Filter usable rows\n",
        "viz = d[\n",
        "    d[col_over_dec].notna() &\n",
        "    d[col_p_model].notna() &\n",
        "    (d[col_over_dec] > 1.0) &\n",
        "    (d[col_p_model].between(0.01, 0.99))\n",
        "].copy()\n",
        "\n",
        "print(\"Usable rows for visuals:\", len(viz))\n",
        "if viz.empty:\n",
        "    print(\"No usable rows to visualize. Sample:\")\n",
        "    print(d.head(10))\n",
        "else:\n",
        "    # ---------- Output paths ----------\n",
        "    outdir = \"data/bets/visuals\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # ---------- Color by market ----------\n",
        "    color_map = {\"PTS\": \"C0\", \"REB\": \"C1\", \"AST\": \"C2\"}\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    for mkt, grp in viz.groupby(col_market):\n",
        "        ax.scatter(\n",
        "            grp[col_over_dec], grp[col_p_model],\n",
        "            alpha=0.65, s=40, label=mkt, c=color_map.get(str(mkt), \"C3\")\n",
        "        )\n",
        "\n",
        "    ax.set_xlabel(\"Over decimal odds\")\n",
        "    ax.set_ylabel(\"Model P(Over)\")\n",
        "    ax.set_title(f\"Model Probability vs Over Decimal Odds\\n({len(viz)} bets)\")\n",
        "\n",
        "    # Break-even curve & shaded \"value zone\"\n",
        "    x_min = max(1.01, float(viz[col_over_dec].min()))\n",
        "    x_max = float(viz[col_over_dec].max())\n",
        "    x = np.linspace(x_min, x_max, 300)\n",
        "    y = 1.0 / x\n",
        "    ax.plot(x, y, color=\"red\", linewidth=2, label=\"Break-even line\")\n",
        "    ax.fill_between(x, y, 1.0, color=\"green\", alpha=0.08, label=\"Value zone\")\n",
        "\n",
        "    # Label top N by edge\n",
        "    TOP_N_LABELS = 20\n",
        "    to_label = viz.sort_values(\"edge_over\", ascending=False).head(TOP_N_LABELS)\n",
        "    for _, r in to_label.iterrows():\n",
        "        ax.annotate(\n",
        "            r[\"label\"],\n",
        "            (r[col_over_dec], r[col_p_model]),\n",
        "            textcoords=\"offset points\", xytext=(5, 4),\n",
        "            fontsize=8, color=\"black\"\n",
        "        )\n",
        "\n",
        "    ax.legend(loc=\"best\", title=\"Market\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    fig.tight_layout()\n",
        "    scatter_path = os.path.join(outdir, f\"prob_vs_decimal_{stamp}.png\")\n",
        "    fig.savefig(scatter_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"Saved:\", scatter_path)\n",
        "\n",
        "    # ---------- Calibration plot ----------\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    viz_cal = viz.copy()\n",
        "    viz_cal[\"p_market_over\"] = 1.0 / viz_cal[col_over_dec]\n",
        "    for mkt, grp in viz_cal.groupby(col_market):\n",
        "        ax.scatter(\n",
        "            grp[\"p_market_over\"], grp[col_p_model],\n",
        "            alpha=0.65, s=40, label=mkt, c=color_map.get(str(mkt), \"C3\")\n",
        "        )\n",
        "    ax.plot([0, 1], [0, 1], color=\"red\", linewidth=2, label=\"Perfect calibration\")\n",
        "    ax.set_xlabel(\"Market implied P(Over) = 1 / OverDecimal\")\n",
        "    ax.set_ylabel(\"Model P(Over)\")\n",
        "    ax.set_title(f\"Calibration: Model vs Market\\n({len(viz_cal)} bets)\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(loc=\"best\", title=\"Market\")\n",
        "    fig.tight_layout()\n",
        "    calib_path = os.path.join(outdir, f\"calibration_{stamp}.png\")\n",
        "    fig.savefig(calib_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"Saved:\", calib_path)\n",
        "\n",
        "    # ---------- Edge distribution ----------\n",
        "    edges = viz[\"edge_over\"].dropna()\n",
        "    if not edges.empty:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ax.hist(edges, bins=30, alpha=0.75, edgecolor=\"black\")\n",
        "        ax.set_xlabel(\"Edge = Model P(Over) - Market implied P\")\n",
        "        ax.set_ylabel(\"Count\")\n",
        "        ax.set_title(f\"Edge Distribution (mean={edges.mean():.3f}, sd={edges.std():.3f})\")\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        fig.tight_layout()\n",
        "        hist_path = os.path.join(outdir, f\"edge_distribution_{stamp}.png\")\n",
        "        fig.savefig(hist_path, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "        print(\"Saved:\", hist_path)\n",
        "\n",
        "    # ---------- Top 20 preview + export ----------\n",
        "    top = viz.sort_values(\"edge_over\", ascending=False).head(50).copy()\n",
        "    show_cols = [c for c in [\n",
        "        col_player, col_team, col_opp, col_market, col_line,\n",
        "        col_over_dec, col_p_model, \"p_over_price\", \"edge_over\", \"EV_over_1u\"\n",
        "    ] if c in top.columns]\n",
        "    print(\"\\nTop 20 value bets (by edge):\")\n",
        "    if not top.empty:\n",
        "        print(top.head(20)[show_cols].to_string(index=False,\n",
        "              float_format=lambda x: f\"{x:.3f}\" if isinstance(x, float) else str(x)))\n",
        "    outdir_csv = os.path.join(\"data/bets/visuals\")\n",
        "    os.makedirs(outdir_csv, exist_ok=True)\n",
        "    top_path = os.path.join(outdir_csv, f\"top_value_{stamp}.csv\")\n",
        "    top.to_csv(top_path, index=False)\n",
        "    print(\"Saved ranked value table ‚Üí\", top_path)\n",
        "\n",
        "print(\"\\nVisualization complete. Check the 'data/bets/visuals' folder for results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e51407c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Visual: Model P(Under) vs Under Decimal Odds ‚Äî color by market with legend (top 20 labels) ===\n",
        "import os, glob, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# -------- 1) Load latest decimal bets file --------\n",
        "cands = sorted(glob.glob(\"data/bets/value_bets_top100_*_decimal.csv\"))\n",
        "if not cands:\n",
        "    cands = sorted(glob.glob(\"data/bets/value_bets_top100_*.csv\"))\n",
        "    if not cands:\n",
        "        raise FileNotFoundError(\"No value bets files found in data/bets/\")\n",
        "path = cands[-1]\n",
        "print(\"Using:\", path)\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# -------- 2) Column resolution (tolerant to naming) --------\n",
        "def find_col(dframe, names):\n",
        "    cols = {re.sub(r\"[\\W_]+\",\"\", c).lower(): c for c in dframe.columns.astype(str)}\n",
        "    for n in names:\n",
        "        k = re.sub(r\"[\\W_]+\",\"\", n).lower()\n",
        "        if k in cols: return cols[k]\n",
        "    return None\n",
        "\n",
        "col_player = find_col(df, [\"Player\"])\n",
        "col_market = find_col(df, [\"Market\"])\n",
        "col_line   = find_col(df, [\"Line\",\"line_dfD\",\"posted_line\",\"line\"])\n",
        "col_punder = find_col(df, [\"PUnderModel\",\"p_under_model\"])\n",
        "col_pover  = find_col(df, [\"POverModel\",\"p_over_model\"])  # fallback to compute p_under\n",
        "col_underD = find_col(df, [\"UnderDecimal\",\"under_dec\",\"UnderDec\",\"UnderDecimalOdds\"])\n",
        "col_underUS= find_col(df, [\"UnderOdds_American\",\"UnderOdds\",\"under_odds\"])  # for conversion if needed\n",
        "\n",
        "# American ‚Üí decimal (fallback)\n",
        "def american_to_decimal(a):\n",
        "    if pd.isna(a): return np.nan\n",
        "    try:\n",
        "        a = float(a)\n",
        "    except Exception:\n",
        "        m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(a))\n",
        "        a = float(m.group()) if m else np.nan\n",
        "    if pd.isna(a): return np.nan\n",
        "    return 1.0 + (a/100.0) if a > 0 else 1.0 + (100.0/abs(a))\n",
        "\n",
        "# Build UnderDecimal if missing\n",
        "if col_underD is None and col_underUS is not None:\n",
        "    df[\"UnderDecimal_fallback\"] = df[col_underUS].map(american_to_decimal)\n",
        "    col_underD = \"UnderDecimal_fallback\"\n",
        "\n",
        "need = [col_player, col_market, col_line, col_underD]\n",
        "miss = [n for n,v in zip([\"Player\",\"Market\",\"Line\",\"UnderDecimal\"], need) if v is None]\n",
        "if miss:\n",
        "    raise KeyError(f\"Missing required columns in file: {miss}\")\n",
        "\n",
        "# Canonicalize core columns\n",
        "df = df.rename(columns={\n",
        "    col_player:\"player\",\n",
        "    col_market:\"market\",\n",
        "    col_line:\"line\",\n",
        "    col_underD:\"under_dec\",\n",
        "})\n",
        "\n",
        "# p_under_model: use direct column if present, else 1 - p_over_model\n",
        "if col_punder:\n",
        "    df = df.rename(columns={col_punder:\"p_under_model\"})\n",
        "    df[\"p_under_model\"] = pd.to_numeric(df[\"p_under_model\"], errors=\"coerce\")\n",
        "elif col_pover:\n",
        "    df[\"p_under_model\"] = 1.0 - pd.to_numeric(df[col_pover], errors=\"coerce\")\n",
        "else:\n",
        "    raise KeyError(\"Need either PUnderModel/p_under_model or POverModel/p_over_model to derive P(Under).\")\n",
        "\n",
        "# Ensure numeric types\n",
        "for c in [\"line\",\"under_dec\"]:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# -------- 3) Metrics & filter for plotting --------\n",
        "df[\"p_under_price\"] = 1.0 / df[\"under_dec\"]\n",
        "df[\"edge_under\"]    = df[\"p_under_model\"] - df[\"p_under_price\"]\n",
        "\n",
        "viz = df[\n",
        "    df[\"under_dec\"].notna() & (df[\"under_dec\"] > 1.0) &\n",
        "    df[\"p_under_model\"].between(0.01, 0.99)\n",
        "].copy()\n",
        "\n",
        "if viz.empty:\n",
        "    raise SystemExit(\"No usable rows to plot (need UnderDecimal>1 and valid PUnderModel).\")\n",
        "\n",
        "# Short label \"Player u7.5\"\n",
        "def fmt_line(x):\n",
        "    return \"\" if pd.isna(x) else f\"{x:g}\"\n",
        "viz[\"label\"] = viz.apply(lambda r: f\"{r['player']} u{fmt_line(r['line'])}\", axis=1)\n",
        "\n",
        "# -------- 4) Scatter colored by market with legend (mirrors Over plot style) --------\n",
        "MARKETS = [\"PTS\",\"REB\",\"AST\"]\n",
        "color_map = {\"PTS\": \"C0\", \"REB\": \"C1\", \"AST\": \"C2\"}  # consistent with OVER plot\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "for mkt, grp in viz.groupby(viz[\"market\"].astype(str).str.upper()):\n",
        "    ax.scatter(\n",
        "        grp[\"under_dec\"], grp[\"p_under_model\"],\n",
        "        s=40, alpha=0.65, label=mkt, c=color_map.get(mkt, \"C3\")\n",
        "    )\n",
        "\n",
        "ax.set_xlabel(\"Under decimal odds\")\n",
        "ax.set_ylabel(\"Model P(Under)\")\n",
        "ax.set_title(f\"Model Probability vs Under Decimal Odds\\n({len(viz)} bets)\")\n",
        "\n",
        "# Break-even line and shaded \"value zone\" for UNDERS (y > 1/x)\n",
        "x_min = max(1.01, float(viz[\"under_dec\"].min()))\n",
        "x_max = float(viz[\"under_dec\"].max())\n",
        "x = np.linspace(x_min, x_max, 300)\n",
        "y = 1.0 / x\n",
        "ax.plot(x, y, color=\"red\", linewidth=2, label=\"Break-even line\")\n",
        "ax.fill_between(x, y, 1.0, color=\"green\", alpha=0.08, label=\"Value zone\")\n",
        "\n",
        "# Label only the top 20 by edge_under\n",
        "TOP_N_LABELS = 20\n",
        "to_label = viz.sort_values(\"edge_under\", ascending=False).head(TOP_N_LABELS)\n",
        "for _, r in to_label.iterrows():\n",
        "    ax.annotate(\n",
        "        r[\"label\"],\n",
        "        (r[\"under_dec\"], r[\"p_under_model\"]),\n",
        "        textcoords=\"offset points\", xytext=(5, 4),\n",
        "        fontsize=8, color=\"black\"\n",
        "    )\n",
        "\n",
        "ax.legend(loc=\"best\", title=\"Market\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "fig.tight_layout()\n",
        "\n",
        "# Save\n",
        "outdir = \"data/bets/visuals\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_path = os.path.join(outdir, f\"prob_vs_under_decimal_{stamp}.png\")\n",
        "fig.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"Saved:\", out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3662135",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EVALUATE YESTERDAY'S BETS (Europe/Athens) ‚Äî model-driven suggestions (OVER/UNDER) ===\n",
        "import os, re, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "# ------------------ settings: yesterday in Europe/Athens ------------------\n",
        "TZ = ZoneInfo(\"Europe/Athens\")\n",
        "today_local = datetime.now(TZ).date()\n",
        "ydate = today_local - timedelta(days=1)\n",
        "ystr = ydate.strftime(\"%Y%m%d\")\n",
        "print(f\"Evaluating bets for YESTERDAY (Europe/Athens): {ydate} ({ystr})\")\n",
        "print(f\"Today is: {today_local}\")\n",
        "\n",
        "# where to save evaluation CSVs\n",
        "os.makedirs(\"data/eval\", exist_ok=True)\n",
        "\n",
        "# ------------------ helpers ------------------\n",
        "def _norm_player(s):\n",
        "    if not isinstance(s, str): return \"\"\n",
        "    return re.sub(r\"[.`'‚Äô\\-]\", \"\", s.strip()).lower()\n",
        "\n",
        "def pick_col(df, candidates, default=np.nan):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return df[c]\n",
        "    return pd.Series([default]*len(df))\n",
        "\n",
        "def _first_float(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
        "    return float(m.group()) if m else np.nan\n",
        "\n",
        "def infer_opponent(df):\n",
        "    if \"OPPONENT_ABBREVIATION\" in df.columns:\n",
        "        return df[\"OPPONENT_ABBREVIATION\"]\n",
        "    matchup = pick_col(df, [\"MATCHUP\",\"Matchup\"])\n",
        "    team = pick_col(df, [\"TEAM_ABBREVIATION\",\"TEAM\"])\n",
        "    out = []\n",
        "    for t, m in zip(team.fillna(\"\"), matchup.fillna(\"\")):\n",
        "        opp = np.nan\n",
        "        if isinstance(m, str) and m:\n",
        "            parts = re.split(r\"[@vVsS]+\\.*\", m)\n",
        "            if len(parts) >= 2:\n",
        "                cand = parts[-1].strip().upper()\n",
        "                if cand == str(t).upper() and len(parts) >= 2:\n",
        "                    cand = parts[0].strip().upper()\n",
        "                opp = cand\n",
        "        out.append(opp)\n",
        "    return pd.Series(out, index=df.index)\n",
        "\n",
        "def parse_date8_from_name(path):\n",
        "    m = re.search(r\"(20\\d{6})\", os.path.basename(path))\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "# ------------------ 1) Find the bets file in data/bets with the requested structure ------------------\n",
        "required_cols = {\n",
        "    \"Player\",\"Team\",\"Opponent\",\"Market\",\"Line\",\n",
        "    \"OverOdds_American\",\"UnderOdds_American\",\"POverImp\",\"PUnderImp\",\n",
        "    \"POverFair\",\"PUnderFair\",\"ProjMins\",\"ProjMean\",\"ProjSD\",\n",
        "    \"POverModel\",\"PUnderModel\",\"OverDecimal\",\"UnderDecimal\"\n",
        "}\n",
        "\n",
        "# Accept case-insensitive match and allow underscores vs camel\n",
        "def has_required_columns(path):\n",
        "    try:\n",
        "        if path.lower().endswith(\".csv\"):\n",
        "            head = pd.read_csv(path, nrows=0)\n",
        "        else:\n",
        "            with pd.ExcelFile(path) as xf:\n",
        "                head = pd.read_excel(path, sheet_name=xf.sheet_names[0], nrows=0)\n",
        "        cols_norm = {re.sub(r\"[\\W_]+\", \"\", c).lower() for c in head.columns.astype(str)}\n",
        "        need_norm = {re.sub(r\"[\\W_]+\", \"\", c).lower() for c in required_cols}\n",
        "        return need_norm.issubset(cols_norm)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "candidates = sorted(\n",
        "    glob.glob(\"data/bets/*.csv\") + glob.glob(\"data/bets/*.xlsx\")\n",
        ")\n",
        "\n",
        "# Filter to files that have the required columns\n",
        "candidates = [p for p in candidates if has_required_columns(p)]\n",
        "if not candidates:\n",
        "    raise FileNotFoundError(\n",
        "        \"No bets files in data/bets matching the required columns: \"\n",
        "        \"Player, Team, Opponent, Market, Line, OverOdds_American, UnderOdds_American, \"\n",
        "        \"POverImp, PUnderImp, POverFair, PUnderFair, ProjMins, ProjMean, ProjSD, \"\n",
        "        \"POverModel, PUnderModel, OverDecimal, UnderDecimal\"\n",
        "    )\n",
        "\n",
        "print(f\"Found {len(candidates)} candidate files with required columns:\")\n",
        "for c in candidates:\n",
        "    print(f\"  - {os.path.basename(c)}\")\n",
        "\n",
        "# Look for bets file with the SAME date as yesterday\n",
        "bets_path = None\n",
        "for p in candidates:\n",
        "    ds = parse_date8_from_name(p)\n",
        "    if ds == ystr:  # Exact match for yesterday's date\n",
        "        bets_path = p\n",
        "        print(f\"Found exact match for yesterday: {os.path.basename(bets_path)}\")\n",
        "        break\n",
        "\n",
        "# If no exact match, use the most recent file BEFORE yesterday\n",
        "if bets_path is None:\n",
        "    dated_files = []\n",
        "    for p in candidates:\n",
        "        ds = parse_date8_from_name(p)\n",
        "        if ds and ds <= ystr:  # Only consider files dated on or before yesterday\n",
        "            dated_files.append((ds, p))\n",
        "    \n",
        "    if dated_files:\n",
        "        dated_files.sort(key=lambda x: x[0])\n",
        "        bets_path = dated_files[-1][1]  # Use the most recent one\n",
        "        print(f\"Warning: No bets file found for {ystr}. Using most recent available: {os.path.basename(bets_path)}\")\n",
        "    else:\n",
        "        # Fallback to latest file (even if future dated)\n",
        "        bets_path = candidates[-1]\n",
        "        print(f\"Warning: No dated bets files found. Using: {os.path.basename(bets_path)}\")\n",
        "\n",
        "print(\"Using bets file:\", os.path.basename(bets_path))\n",
        "\n",
        "# ------------------ 2) Load bets ------------------\n",
        "if bets_path.lower().endswith(\".csv\"):\n",
        "    bets = pd.read_csv(bets_path)\n",
        "else:\n",
        "    with pd.ExcelFile(bets_path) as xf:\n",
        "        bets = pd.read_excel(bets_path, sheet_name=xf.sheet_names[0])\n",
        "\n",
        "print(f\"Loaded bets rows: {len(bets)}\")\n",
        "\n",
        "# Map to canonical names using EXACT column names from your file\n",
        "cols = {c.lower(): c for c in bets.columns}\n",
        "def col(name_variants):\n",
        "    for v in name_variants:\n",
        "        key = v.lower()\n",
        "        if key in cols: return cols[key]\n",
        "    return None\n",
        "\n",
        "# Use the exact column names from your file\n",
        "cn_player = col([\"Player\"])\n",
        "cn_team   = col([\"Team\"])\n",
        "cn_opp    = col([\"Opponent\"])\n",
        "cn_mkt    = col([\"Market\"])\n",
        "cn_line   = col([\"Line\"])\n",
        "cn_pom    = col([\"POverModel\"])\n",
        "cn_pum    = col([\"PUnderModel\"])\n",
        "cn_od     = col([\"OverDecimal\"])\n",
        "cn_ud     = col([\"UnderDecimal\"])\n",
        "\n",
        "# Check for required columns\n",
        "need = [cn_player, cn_team, cn_opp, cn_mkt, cn_line, cn_pom, cn_od, cn_ud]\n",
        "if any(x is None for x in need):\n",
        "    missing = [n for n, x in zip(\n",
        "        [\"Player\",\"Team\",\"Opponent\",\"Market\",\"Line\",\"POverModel\",\"OverDecimal\",\"UnderDecimal\"], need) if x is None]\n",
        "    raise KeyError(f\"Missing expected columns in bets file: {missing}\")\n",
        "\n",
        "# Rename columns to standard names for processing\n",
        "bets = bets.rename(columns={\n",
        "    cn_player: \"player\",\n",
        "    cn_team: \"team\", \n",
        "    cn_opp: \"opponent\",\n",
        "    cn_mkt: \"market\", \n",
        "    cn_line: \"line\",\n",
        "    cn_pom: \"p_over_model\", \n",
        "    cn_pum: \"p_under_model\",\n",
        "    cn_od: \"over_dec\", \n",
        "    cn_ud: \"under_dec\"\n",
        "})\n",
        "\n",
        "# Convert numeric columns\n",
        "bets[\"line\"] = pd.to_numeric(bets[\"line\"], errors=\"coerce\")\n",
        "bets[\"p_over_model\"] = pd.to_numeric(bets[\"p_over_model\"], errors=\"coerce\")\n",
        "bets[\"p_under_model\"] = pd.to_numeric(bets[\"p_under_model\"], errors=\"coerce\")\n",
        "bets[\"over_dec\"] = pd.to_numeric(bets[\"over_dec\"], errors=\"coerce\")\n",
        "bets[\"under_dec\"] = pd.to_numeric(bets[\"under_dec\"], errors=\"coerce\")\n",
        "\n",
        "# Add key for joining to box scores\n",
        "bets[\"player_key\"] = bets[\"player\"].map(_norm_player)\n",
        "\n",
        "# ------------------ 3) Load boxscores for yesterday (from data_raw/) ------------------\n",
        "BOXSCORE_DIR = \"data_raw\"\n",
        "\n",
        "def load_boxscores_for_date(target_date):\n",
        "    \"\"\"Load boxscores for a specific date, handling various file naming patterns\"\"\"\n",
        "    target_date_str = target_date.strftime(\"%Y%m%d\")\n",
        "    \n",
        "    # Try multiple file patterns\n",
        "    patterns = [\n",
        "        f\"nba_boxscores_{target_date_str}.csv\",\n",
        "        f\"nba_boxscores_*{target_date_str}*.csv\",\n",
        "        \"nba_boxscores_*.csv\"  # season file\n",
        "    ]\n",
        "    \n",
        "    for pattern in patterns:\n",
        "        matches = glob.glob(os.path.join(BOXSCORE_DIR, pattern))\n",
        "        if matches:\n",
        "            # Use the most recent file if multiple matches\n",
        "            box_file = sorted(matches)[-1]\n",
        "            box = pd.read_csv(box_file)\n",
        "            print(f\"Loaded boxscores from: {os.path.basename(box_file)}\")\n",
        "            \n",
        "            # Filter to target date\n",
        "            date_cols = [\"GAME_DATE\", \"GAME_DATE_EST\", \"GAME_DATE_LCL\", \"Date\", \"date\"]\n",
        "            for date_col in date_cols:\n",
        "                if date_col in box.columns:\n",
        "                    box_dates = pd.to_datetime(box[date_col], errors='coerce').dt.date\n",
        "                    filtered = box[box_dates == target_date].copy()\n",
        "                    if len(filtered) > 0:\n",
        "                        print(f\"Filtered to {target_date} using column '{date_col}': {len(filtered)} rows\")\n",
        "                        return filtered\n",
        "            \n",
        "            # If no date filtering worked but we have data, return all\n",
        "            if len(box) > 0:\n",
        "                print(f\"Warning: Could not filter by date. Using all {len(box)} rows.\")\n",
        "                return box\n",
        "    \n",
        "    raise FileNotFoundError(f\"No boxscore data found for {target_date}\")\n",
        "\n",
        "try:\n",
        "    box = load_boxscores_for_date(ydate)\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n",
        "    # Create empty evaluation file\n",
        "    eval_out = os.path.join(\"data/eval\", f\"value_bets_eval_{ystr}.csv\")\n",
        "    bets.assign(\n",
        "        actual=np.nan, suggestion=\"NO BET\", suggested_prob=np.nan, result_model=\"NA\"\n",
        "    ).to_csv(eval_out, index=False)\n",
        "    print(f\"Saved empty evaluation to: {eval_out}\")\n",
        "    raise SystemExit\n",
        "\n",
        "# ------------------ 4) Normalize box & join ------------------\n",
        "box = box.copy()\n",
        "box[\"player\"] = pick_col(box, [\"PLAYER_NAME\",\"Player\"])\n",
        "box[\"player_key\"] = box[\"player\"].map(_norm_player)\n",
        "box[\"PTS\"] = pd.to_numeric(pick_col(box, [\"PTS\",\"Points\"]), errors=\"coerce\")\n",
        "box[\"REB\"] = pd.to_numeric(pick_col(box, [\"REB\",\"Rebounds\"]), errors=\"coerce\")\n",
        "box[\"AST\"] = pd.to_numeric(pick_col(box, [\"AST\",\"Assists\"]), errors=\"coerce\")\n",
        "box[\"TEAM_ABBREVIATION\"] = pick_col(box, [\"TEAM_ABBREVIATION\",\"TEAM\"])\n",
        "box[\"OPPONENT_ABBREVIATION\"] = infer_opponent(box)\n",
        "\n",
        "joined = bets.merge(\n",
        "    box[[\"player_key\",\"PTS\",\"REB\",\"AST\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]],\n",
        "    on=\"player_key\", how=\"left\", suffixes=(\"\",\"_box\")\n",
        ")\n",
        "\n",
        "def pick_actual(row):\n",
        "    m = str(row.get(\"market\",\"\")).upper()\n",
        "    return row.get(m, np.nan) if m in [\"PTS\",\"REB\",\"AST\"] else np.nan\n",
        "\n",
        "joined[\"actual\"] = joined.apply(pick_actual, axis=1)\n",
        "\n",
        "# ------------------ 5) Model suggestion & grading ------------------\n",
        "THRESH = 0.59  # model-confidence threshold\n",
        "\n",
        "def suggest_side(row):\n",
        "    po = row.get(\"p_over_model\", np.nan)\n",
        "    pu = row.get(\"p_under_model\", np.nan)\n",
        "    # If both are NaN ‚Üí NO BET\n",
        "    if pd.isna(po) and pd.isna(pu):\n",
        "        return \"NO BET\", np.nan\n",
        "    # Determine which side meets threshold and pick the higher prob if both do\n",
        "    cand = []\n",
        "    if pd.notna(po) and po >= THRESH:\n",
        "        cand.append((\"OVER\", float(po)))\n",
        "    if pd.notna(pu) and pu >= THRESH:\n",
        "        cand.append((\"UNDER\", float(pu)))\n",
        "    if not cand:\n",
        "        return \"NO BET\", max([v for v in [po, pu] if pd.notna(v)] + [np.nan])\n",
        "    # pick the larger probability among the qualifying sides\n",
        "    cand.sort(key=lambda x: x[1], reverse=True)\n",
        "    return cand[0]\n",
        "\n",
        "joined[[\"suggestion\",\"suggested_prob\"]] = joined.apply(\n",
        "    lambda r: pd.Series(suggest_side(r)), axis=1\n",
        ")\n",
        "\n",
        "def grade_row(row):\n",
        "    side = row.get(\"suggestion\", \"NO BET\")\n",
        "    act  = row.get(\"actual\", np.nan)\n",
        "    line = row.get(\"line\", np.nan)\n",
        "    if side == \"NO BET\" or pd.isna(act) or pd.isna(line):\n",
        "        return \"NA\"\n",
        "    if side == \"OVER\":\n",
        "        if act > line:  return \"WIN\"\n",
        "        if act == line: return \"PUSH\"\n",
        "        return \"LOSS\"\n",
        "    if side == \"UNDER\":\n",
        "        if act < line:  return \"WIN\"\n",
        "        if act == line: return \"PUSH\"\n",
        "        return \"LOSS\"\n",
        "    return \"NA\"\n",
        "\n",
        "joined[\"result_model\"] = joined.apply(grade_row, axis=1)\n",
        "\n",
        "# ------------------ 6) Summary & save ------------------\n",
        "is_bet = joined[\"suggestion\"].isin([\"OVER\",\"UNDER\"])\n",
        "graded = joined.loc[is_bet & joined[\"result_model\"].isin([\"WIN\",\"LOSS\",\"PUSH\"])]\n",
        "\n",
        "wins   = (graded[\"result_model\"]==\"WIN\").sum()\n",
        "losses = (graded[\"result_model\"]==\"LOSS\").sum()\n",
        "pushes = (graded[\"result_model\"]==\"PUSH\").sum()\n",
        "hitrate = wins / max(wins+losses, 1)\n",
        "\n",
        "print(f\"Suggested bets (THRESH={THRESH:.2f}): {is_bet.sum()} of {len(joined)} rows\")\n",
        "print(f\"Graded bets: {len(graded)}  (WIN={wins}, LOSS={losses}, PUSH={pushes})\")\n",
        "print(f\"Hit rate (excl. pushes): {hitrate:.1%}\")\n",
        "\n",
        "# Side-specific breakdown\n",
        "graded_over  = graded.loc[joined[\"suggestion\"]==\"OVER\"]\n",
        "graded_under = graded.loc[joined[\"suggestion\"]==\"UNDER\"]\n",
        "def _rate(g):\n",
        "    w = (g[\"result_model\"]==\"WIN\").sum()\n",
        "    l = (g[\"result_model\"]==\"LOSS\").sum()\n",
        "    return w / max(w+l,1)\n",
        "\n",
        "print(f\"OVER bets graded:  {len(graded_over)}  | Hit: {_rate(graded_over):.1%}\")\n",
        "print(f\"UNDER bets graded: {len(graded_under)} | Hit: {_rate(graded_under):.1%}\")\n",
        "\n",
        "eval_out = os.path.join(\"data/eval\", f\"value_bets_eval_{ystr}.csv\")\n",
        "joined.to_csv(eval_out, index=False)\n",
        "print(f\"Saved evaluation to: {eval_out}\")\n",
        "\n",
        "# Preview a few rows with the actual column names from your file\n",
        "cols_preview = [\n",
        "    \"player\",\"team\",\"opponent\",\"market\",\"line\",\"actual\",\n",
        "    \"p_over_model\",\"p_under_model\",\"over_dec\",\"under_dec\",\n",
        "    \"suggestion\",\"suggested_prob\",\"result_model\",\n",
        "    \"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"\n",
        "]\n",
        "print(\"\\nPreview:\")\n",
        "print(joined[ [c for c in cols_preview if c in joined.columns] ].head(25).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6238c7f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load feature importance file\n",
        "fi = pd.read_csv(\"model_outputs_rate/feature_importances_20251106_140212.csv\")\n",
        "\n",
        "# Preview to see what columns exist\n",
        "print(fi.head())\n",
        "\n",
        "# Normalize and compute mean importance\n",
        "cols = [c for c in fi.columns if \"importance\" in c.lower()]\n",
        "fi[\"mean_importance\"] = fi[cols].mean(axis=1)\n",
        "fi = fi.sort_values(\"mean_importance\", ascending=False)\n",
        "\n",
        "# Show top & bottom\n",
        "print(\"üèÜ Top 20 most important features:\")\n",
        "print(fi.head(20).to_string(index=False))\n",
        "\n",
        "print(\"\\nü™∂ Bottom 20 least important features:\")\n",
        "print(fi.tail(20).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "892c1379",
      "metadata": {},
      "outputs": [],
      "source": [
        "low_importance = fi[fi[\"mean_importance\"] < 0.001][\"feature\"].tolist()\n",
        "medium_importance = fi[fi[\"mean_importance\"].between(0.001, 0.005)][\"feature\"].tolist()\n",
        "high_importance = fi[fi[\"mean_importance\"] >= 0.005][\"feature\"].tolist()\n",
        "\n",
        "print(f\"Drop candidates ({len(low_importance)}): {low_importance}\")\n",
        "print(f\"Keep ({len(high_importance)}): {high_importance[:15]} ...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec101ad0",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
