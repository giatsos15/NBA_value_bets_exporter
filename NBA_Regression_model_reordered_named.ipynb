{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2a745b",
   "metadata": {},
   "source": [
    "## NBA Analytics and Betting Value Analysis Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07decdf1",
   "metadata": {
    "id": "07decdf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Env ready | DATA_DIR: data_raw | DEBUG_DIR: _rotowire_debug | EXPORT_DIR: exports\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 01: imports, config, folders -----------------------------------------\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display & randomness\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Folders\n",
    "DATA_DIR = \"data_raw\"\n",
    "DEBUG_DIR = \"_rotowire_debug\"\n",
    "EXPORT_DIR = \"exports\"\n",
    "\n",
    "for d in (DATA_DIR, DEBUG_DIR, EXPORT_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Env ready | DATA_DIR:\", DATA_DIR, \"| DEBUG_DIR:\", DEBUG_DIR, \"| EXPORT_DIR:\", EXPORT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01631fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fetched 1138 odds rows | 264 columns | book=mgm\n",
      "\n",
      "üîé Long odds preview:\n",
      "         player team opponent  game_date market book  line  over_odds  under_odds\n",
      "    Luka Doncic  LAL      UTA 2025-11-18    PTS  mgm  31.5     -115.0      -115.0\n",
      "   Devin Booker  PHX     @POR 2025-11-18    PTS  mgm  29.5     -120.0      -110.0\n",
      "   Jaylen Brown  BOS     @BKN 2025-11-18    PTS  mgm  26.5     -110.0      -120.0\n",
      "Cade Cunningham  DET     @ATL 2025-11-18    PTS  mgm  27.5     -110.0      -120.0\n",
      "  Stephen Curry  GSW     @ORL 2025-11-18    PTS  mgm  26.5     -120.0      -110.0\n",
      "Lauri Markkanen  UTA     @LAL 2025-11-18    PTS  mgm  26.5     -115.0      -118.0\n",
      "   De'Aaron Fox  SAS      MEM 2025-11-18    PTS  mgm  25.5     -115.0      -115.0\n",
      "    Deni Avdija  POR      PHX 2025-11-18    PTS  mgm  25.5     -105.0      -125.0\n",
      " Shaedon Sharpe  POR      PHX 2025-11-18    PTS  mgm  25.5     -105.0      -125.0\n",
      "   Franz Wagner  ORL      GSW 2025-11-18    PTS  mgm  24.5     -115.0      -115.0\n",
      " Michael Porter  BKN      BOS 2025-11-18    PTS  mgm  23.5     -125.0      -110.0\n",
      "  Austin Reaves  LAL      UTA 2025-11-18    PTS  mgm  23.5     -118.0      -110.0\n",
      "\n",
      "üíæ Saved: data_raw/rotowire_odds_wide_mgm_20251118_183249.csv\n",
      "üíæ Saved: data_raw/rotowire_odds_long_mgm_20251118_183249.csv\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 02: odds scraper + wide->long helper ---------------------------------\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class NBAOddsScraper:\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.setup_headers()\n",
    "\n",
    "    def setup_headers(self):\n",
    "        self.headers = {\n",
    "            \"accept\": \"*/*\",\n",
    "            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/130.0.0.0 Safari/537.36\",\n",
    "            \"referer\": \"https://www.rotowire.com/\",\n",
    "        }\n",
    "\n",
    "    def get_player_props_odds_wide_raw(self, book: str = \"mgm\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Pulls the RotoWire player-props page for a single book and extracts all JSON 'data: [...]' blobs.\n",
    "        Returns a single wide DataFrame with the raw columns RotoWire emits.\n",
    "        \"\"\"\n",
    "        url = f\"https://www.rotowire.com/betting/nba/player-props.php?book={book}\"\n",
    "        try:\n",
    "            r = self.session.get(url, headers=self.headers, timeout=20)\n",
    "            r.raise_for_status()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to GET odds page: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        matches = re.findall(r\"data:\\s*(\\[\\{.*?\\}\\])\", r.text, flags=re.DOTALL)\n",
    "        frames = []\n",
    "        for m in matches:\n",
    "            try:\n",
    "                rows = json.loads(m)\n",
    "                if isinstance(rows, list) and rows:\n",
    "                    frames.append(pd.DataFrame(rows))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not frames:\n",
    "            print(\"‚ö†Ô∏è No odds JSON blocks found.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "        # Normalize a few columns\n",
    "        base_cols = [c for c in [\"name\",\"gameID\",\"playerID\",\"firstName\",\"lastName\",\"team\",\"opp\",\"logo\",\"playerLink\"] if c in df.columns]\n",
    "        other_cols = [c for c in df.columns if c not in base_cols]\n",
    "        df = df[base_cols + other_cols]\n",
    "\n",
    "        if \"opp\" in df.columns and \"opponent\" not in df.columns:\n",
    "            df = df.rename(columns={\"opp\": \"opponent\"})\n",
    "\n",
    "        df[\"asof_date\"] = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "        if \"game_date\" not in df.columns:\n",
    "            df[\"game_date\"] = df[\"asof_date\"]\n",
    "        df[\"book\"] = book\n",
    "\n",
    "        print(f\"‚úÖ Fetched {len(df)} odds rows | {len(df.columns)} columns | book={book}\")\n",
    "        return df\n",
    "\n",
    "def odds_wide_to_long_from_columns(wide: pd.DataFrame,\n",
    "                                   books=(\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\",\"espnbet\",\"hardrock\"),\n",
    "                                   markets=(\"PTS\",\"REB\",\"AST\")) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert the scraped wide odds table into tidy long format:\n",
    "    columns: player, team, opponent, game_date, market, book, line, over_odds, under_odds\n",
    "    Works by scanning for patterns like '{book}_{suffix}' where suffix in {'pts','reb','ast'}.\n",
    "    \"\"\"\n",
    "    if wide.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # base identity cols best-effort\n",
    "    base_map = {\n",
    "        \"name\": \"player\",\n",
    "        \"team\": \"team\",\n",
    "        \"opponent\": \"opponent\",\n",
    "        \"game_date\": \"game_date\",\n",
    "    }\n",
    "    present_keys = [src for src in base_map if src in wide.columns]\n",
    "    base = wide[present_keys].rename(columns={k: base_map[k] for k in present_keys}).copy()\n",
    "\n",
    "    rows = []\n",
    "    suffix_map = {\"PTS\":\"pts\",\"REB\":\"reb\",\"AST\":\"ast\"}\n",
    "\n",
    "    for m in markets:\n",
    "        suf = suffix_map[m]\n",
    "        for b in books:\n",
    "            line_col  = f\"{b}_{suf}\"\n",
    "            over_col  = f\"{b}_{suf}Over\"\n",
    "            under_col = f\"{b}_{suf}Under\"\n",
    "\n",
    "            if line_col not in wide.columns:\n",
    "                continue  # this book-market not present\n",
    "\n",
    "            # Use get to avoid KeyErrors if over/under missing\n",
    "            sub = pd.DataFrame({\n",
    "                \"player\":   base.get(\"player\", pd.Series([\"\"]*len(wide))),\n",
    "                \"team\":     base.get(\"team\", pd.Series([\"\"]*len(wide))),\n",
    "                \"opponent\": base.get(\"opponent\", pd.Series([\"\"]*len(wide))),\n",
    "                \"game_date\":base.get(\"game_date\", pd.Series([\"\"]*len(wide))),\n",
    "                \"market\":   m,\n",
    "                \"book\":     b,\n",
    "                \"line\":     wide[line_col],\n",
    "                \"over_odds\":wide.get(over_col),\n",
    "                \"under_odds\":wide.get(under_col),\n",
    "            })\n",
    "            rows.append(sub)\n",
    "\n",
    "    out = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "    # numeric cleaning\n",
    "    def _num_float(x):\n",
    "        try:\n",
    "            if pd.isna(x): return np.nan\n",
    "            s = str(x).strip()\n",
    "            if s==\"\" or s.lower()==\"none\": return np.nan\n",
    "            return float(re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", s).group())\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    def _num_int(x):\n",
    "        try:\n",
    "            if pd.isna(x): return np.nan\n",
    "            s = str(x).strip()\n",
    "            if s==\"\" or s.lower()==\"none\": return np.nan\n",
    "            return int(re.search(r\"[-+]?\\d+\", s).group())\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    if not out.empty:\n",
    "        out[\"line\"] = out[\"line\"].apply(_num_float)\n",
    "        if \"over_odds\" in out.columns:\n",
    "            out[\"over_odds\"] = out[\"over_odds\"].apply(_num_int)\n",
    "        if \"under_odds\" in out.columns:\n",
    "            out[\"under_odds\"] = out[\"under_odds\"].apply(_num_int)\n",
    "        out = out.dropna(subset=[\"line\"]).reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---- Run scrape + save -------------------------------------------------------\n",
    "scraper = NBAOddsScraper()\n",
    "odds_wide_mgm = scraper.get_player_props_odds_wide_raw(book=\"mgm\")\n",
    "odds_long = odds_wide_to_long_from_columns(odds_wide_mgm)\n",
    "\n",
    "print(\"\\nüîé Long odds preview:\")\n",
    "print(odds_long.head(12).to_string(index=False))\n",
    "\n",
    "# Save both forms\n",
    "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "wide_path = f\"{DATA_DIR}/rotowire_odds_wide_mgm_{stamp}.csv\"\n",
    "long_path = f\"{DATA_DIR}/rotowire_odds_long_mgm_{stamp}.csv\"\n",
    "odds_wide_mgm.to_csv(wide_path, index=False)\n",
    "odds_long.to_csv(long_path, index=False)\n",
    "print(f\"\\nüíæ Saved: {wide_path}\\nüíæ Saved: {long_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e40802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnostics: lineup blocks=9, player nodes=103\n",
      "‚úÖ Shape: (12, 11)\n",
      "game_time team side lineup_status                                                                       starters     starter_1           starter_2     starter_3     starter_4     starter_5  lineup_confirmed\n",
      "               AWAY      EXPECTED             [Stephen Curry, Will Richard, Moses Moody, Jimmy Butler, D. Green] Stephen Curry        Will Richard   Moses Moody  Jimmy Butler      D. Green                 0\n",
      "               AWAY      EXPECTED              [C. Cunningham, D. Robinson, A. Thompson, T. Harris, Jalen Duren] C. Cunningham         D. Robinson   A. Thompson     T. Harris   Jalen Duren                 0\n",
      "               AWAY      EXPECTED       [Derrick White, P. Pritchard, Jaylen Brown, Jordan Walsh, Neemias Queta] Derrick White        P. Pritchard  Jaylen Brown  Jordan Walsh Neemias Queta                 0\n",
      "               AWAY      EXPECTED           [Cam Spencer, Jaylen Wells, Cedric Coward, Jaren Jackson, Zach Edey]   Cam Spencer        Jaylen Wells Cedric Coward Jaren Jackson     Zach Edey                 0\n",
      "               AWAY      EXPECTED             [K. George, S. Mykhailiuk, Ace Bailey, L. Markkanen, Jusuf Nurkic]     K. George       S. Mykhailiuk    Ace Bailey  L. Markkanen  Jusuf Nurkic                 0\n",
      "               AWAY      EXPECTED         [Devin Booker, Ryan Dunn, Dillon Brooks, Royce O'Neale, Mark Williams]  Devin Booker           Ryan Dunn Dillon Brooks Royce O'Neale Mark Williams                 0\n",
      "               HOME      EXPECTED                 [J. Suggs, Desmond Bane, Franz Wagner, T. da Silva, W. Carter]      J. Suggs        Desmond Bane  Franz Wagner   T. da Silva     W. Carter                 0\n",
      "               HOME      EXPECTED [Dyson Daniels, N. Alexander-Walker, Z. Risacher, Jalen Johnson, K. Porzingis] Dyson Daniels N. Alexander-Walker   Z. Risacher Jalen Johnson  K. Porzingis                 0\n",
      "               HOME      EXPECTED               [Egor Demin, Terance Mann, M. Porter, Noah Clowney, Nic Claxton]    Egor Demin        Terance Mann     M. Porter  Noah Clowney   Nic Claxton                 0\n",
      "               HOME      EXPECTED           [De'Aaron Fox, Devin Vassell, J. Champagnie, H. Barnes, Luke Kornet]  De'Aaron Fox       Devin Vassell J. Champagnie     H. Barnes   Luke Kornet                 0\n",
      "               HOME      EXPECTED       [Luka Doncic, Austin Reaves, Marcus Smart, Rui Hachimura, Deandre Ayton]   Luka Doncic       Austin Reaves  Marcus Smart Rui Hachimura Deandre Ayton                 0\n",
      "               HOME      EXPECTED                  [S. Sharpe, T. Camara, Jerami Grant, Deni Avdija, D. Clingan]     S. Sharpe           T. Camara  Jerami Grant   Deni Avdija    D. Clingan                 0\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium webdriver-manager bs4 pandas lxml\n",
    "\n",
    "import os, re, time, pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "\n",
    "def _clean_list(xs):\n",
    "    return [re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", x) for x in xs]\n",
    "\n",
    "def _try_click_consent(driver, timeout=6):\n",
    "    XPATHS = [\n",
    "        \"//button[contains(.,'Accept')]\",\n",
    "        \"//button[contains(.,'I Agree')]\",\n",
    "        \"//button[contains(.,'Agree')]\",\n",
    "        \"//button[contains(.,'ŒëœÄŒøŒ¥ŒøœáŒÆ')]\",\n",
    "        \"//button[contains(.,'Œ£œÖŒºœÜœâŒΩœé')]\",\n",
    "    ]\n",
    "    end = time.time() + timeout\n",
    "    for xp in XPATHS:\n",
    "        try:\n",
    "            btn = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, xp)))\n",
    "            btn.click()\n",
    "            return True\n",
    "        except Exception:\n",
    "            if time.time() > end: break\n",
    "    return False\n",
    "\n",
    "def _progress_scroll(driver, steps=10, pause=0.8):\n",
    "    h = driver.execute_script(\"return document.body.scrollHeight || document.documentElement.scrollHeight;\")\n",
    "    for i in range(1, steps + 1):\n",
    "        y = int(h * i / steps)\n",
    "        driver.execute_script(f\"window.scrollTo(0, {y});\")\n",
    "        time.sleep(pause)\n",
    "\n",
    "def _extract_team(side):\n",
    "    team_el = side.select_one(\".lineup__abbr, .lineup__team-name, .lineup__name\")\n",
    "    if team_el:\n",
    "        return team_el.get_text(strip=True)\n",
    "    logo = side.select_one(\"img[alt]\")\n",
    "    return (logo.get(\"alt\") or \"\").strip() if logo else \"\"\n",
    "\n",
    "def _extract_status(side):\n",
    "    status_el = side.select_one(\".lineup__status\")\n",
    "    txt = (status_el.get_text(\" \", strip=True) if status_el else \"\").upper()\n",
    "    if \"CONFIRM\" in txt:  return \"CONFIRMED\"\n",
    "    if \"EXPECT\" in txt or \"PROBABLE\" in txt: return \"EXPECTED\"\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "def _extract_starters(side):\n",
    "    # Try several variants for starters content\n",
    "    containers = side.select(\".lineup__list--starters, .lineup__list, .lineup__players\")\n",
    "    if not containers:\n",
    "        containers = [side]\n",
    "\n",
    "    names = []\n",
    "    for blk in containers:\n",
    "        for a in blk.select(\"a.lineup__player-link, .lineup__player a\"):\n",
    "            t = a.get_text(\" \", strip=True)\n",
    "            if t: names.append(t)\n",
    "        if not names:\n",
    "            for row in blk.select(\".lineup__player\"):\n",
    "                t = row.get_text(\" \", strip=True)\n",
    "                if re.match(r\"^(PG|SG|SF|PF|C)\\b\", t): names.append(t)\n",
    "        if not names:\n",
    "            for li in blk.select(\"li\"):\n",
    "                t = li.get_text(\" \", strip=True)\n",
    "                if re.match(r\"^(PG|SG|SF|PF|C)\\b\", t): names.append(t)\n",
    "\n",
    "    if not names:\n",
    "        txt = side.get_text(\"\\n\", strip=True)\n",
    "        names = re.findall(r\"(?:^|\\n)(?:PG|SG|SF|PF|C)\\s+[^\\n]+\", txt)\n",
    "\n",
    "    return _clean_list(names)[:5]\n",
    "\n",
    "# ---------------- main ----------------\n",
    "\n",
    "def fetch_rotowire_lineups_selenium(date: str | None = None,\n",
    "                                    wait_sec: float = 14.0,\n",
    "                                    headless: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Render Rotowire lineups & parse BOTH sides per game (global side selectors).\n",
    "    Returns:\n",
    "      game_time, team, side (AWAY/HOME), lineup_status, starters,\n",
    "      starter_1..starter_5, lineup_confirmed (0/1)\n",
    "    \"\"\"\n",
    "    base = \"https://www.rotowire.com/basketball/nba-lineups.php\"\n",
    "    url = base if not date else f\"{base}?date={date}\"\n",
    "\n",
    "    opts = Options()\n",
    "    if headless: opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--window-size=1400,1000\")\n",
    "    opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    opts.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    opts.add_argument(\"--lang=en-US,en;q=0.9\")\n",
    "    opts.add_argument(\n",
    "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "    driver.get(url)\n",
    "\n",
    "    _try_click_consent(driver, timeout=6)\n",
    "    time.sleep(1.2)\n",
    "    try:\n",
    "        WebDriverWait(driver, int(wait_sec)).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".lineup, .lineup.is-nba\"))\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    _progress_scroll(driver, steps=10, pause=0.8)\n",
    "    time.sleep(1.0)\n",
    "\n",
    "    # quick diagnostics\n",
    "    blocks = driver.find_elements(By.CSS_SELECTOR, \".lineup.is-nba, .lineup\")\n",
    "    players = driver.find_elements(By.CSS_SELECTOR, \".lineup__player, a.lineup__player-link\")\n",
    "    print(f\"diagnostics: lineup blocks={len(blocks)}, player nodes={len(players)}\")\n",
    "\n",
    "    html = driver.page_source\n",
    "    os.makedirs(\"_rotowire_debug\", exist_ok=True)\n",
    "    with open(\"_rotowire_debug/last_lineups.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    try:\n",
    "        driver.save_screenshot(\"_rotowire_debug/last_lineups.png\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    driver.quit()\n",
    "\n",
    "    # -------- parse globally by side classes ----------\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    # game time map: find each game container time\n",
    "    game_time_map = {}\n",
    "    for gi, g in enumerate(soup.select(\".lineup__main, .lineup.is-nba, .lineup\")):\n",
    "        t = g.select_one(\".lineup__time, .game-time\")\n",
    "        game_time_map[id(g)] = t.get_text(strip=True) if t else \"\"\n",
    "\n",
    "    # Select **visit/away** & **home** side boxes explicitly\n",
    "    visit_sel = (\n",
    "        '[class*=\"lineup__box\"][class*=\"is-visit\"], '\n",
    "        '[class*=\"lineup__team\"][class*=\"is-visit\"], '\n",
    "        '[class*=\"lineup__side\"][class*=\"is-visit\"], '\n",
    "        '[class*=\"visit\"]'\n",
    "    )\n",
    "    home_sel = (\n",
    "        '[class*=\"lineup__box\"][class*=\"is-home\"], '\n",
    "        '[class*=\"lineup__team\"][class*=\"is-home\"], '\n",
    "        '[class*=\"lineup__side\"][class*=\"is-home\"], '\n",
    "        '[class*=\"home\"]'\n",
    "    )\n",
    "\n",
    "    visit_boxes = soup.select(visit_sel)\n",
    "    home_boxes  = soup.select(home_sel)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    def add_rows(boxes, side_label):\n",
    "        for box in boxes:\n",
    "            # nearest parent game container for time\n",
    "            parent = box.find_parent(lambda tag: tag.has_attr(\"class\") and any(\n",
    "                c in {\"lineup__main\",\"lineup\",\"lineup is-nba\"} for c in tag.get(\"class\", [])\n",
    "            ))\n",
    "            game_time = game_time_map.get(id(parent), \"\") if parent else \"\"\n",
    "            team = _extract_team(box)\n",
    "            starters = _extract_starters(box)\n",
    "            status = _extract_status(box)\n",
    "            if starters or team:\n",
    "                rows.append({\n",
    "                    \"game_time\": game_time,\n",
    "                    \"team\": team,\n",
    "                    \"side\": side_label,\n",
    "                    \"lineup_status\": status,\n",
    "                    \"starters\": starters,\n",
    "                    \"starter_1\": starters[0] if len(starters)>0 else None,\n",
    "                    \"starter_2\": starters[1] if len(starters)>1 else None,\n",
    "                    \"starter_3\": starters[2] if len(starters)>2 else None,\n",
    "                    \"starter_4\": starters[3] if len(starters)>3 else None,\n",
    "                    \"starter_5\": starters[4] if len(starters)>4 else None,\n",
    "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
    "                })\n",
    "\n",
    "    add_rows(visit_boxes, \"AWAY\")\n",
    "    add_rows(home_boxes,  \"HOME\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(\n",
    "            subset=[\"game_time\",\"team\",\"side\",\"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]\n",
    "        )\n",
    "        all_na = df[[\"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]].isna().all(axis=1)\n",
    "        df = df[~all_na].reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Parsed zero rows. Check _rotowire_debug/last_lineups.html & .png\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- run it ----------\n",
    "df_lineups = fetch_rotowire_lineups_selenium(wait_sec=14.0, headless=False)\n",
    "print(\"‚úÖ Shape:\", df_lineups.shape)\n",
    "print(df_lineups.sort_values([\"game_time\",\"side\"]).head(12).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a4ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOM diagnostics: {'lineup__teams': 6, 'ul.lineup__list': 12, 'ul.is-visit': 6, 'ul.is-home': 6, 'see-proj-minutes buttons': 12, 'header abbr': 0, 'header team': 0, 'player anchors': 103, 'MNP titles': 12}\n",
      "Fallback B: scanning all ul.lineup__list globally...\n",
      "‚Üí Parsed rows: 12\n",
      "üíæ Saved parsed lineups to data_raw/lineups_parsed_20251118_183337.csv\n",
      "\n",
      "‚úÖ Preview:\n",
      "game_time team side lineup_status  may_not_play_count     starter_1           starter_2     starter_3     starter_4           starter_5\n",
      "           BOS AWAY      EXPECTED                   6 Derrick White        P. Pritchard  Jaylen Brown  Jordan Walsh       Neemias Queta\n",
      "           DET AWAY      EXPECTED                  11   D. Robinson         Jalen Duren C. Cunningham   D. Robinson         A. Thompson\n",
      "           GSW AWAY      EXPECTED                   8 Stephen Curry        Will Richard   Moses Moody  Jimmy Butler            D. Green\n",
      "           MEM AWAY      EXPECTED                  10   Cam Spencer        Jaylen Wells Cedric Coward Jaren Jackson           Zach Edey\n",
      "           PHX AWAY      EXPECTED                   7  Devin Booker           Ryan Dunn Dillon Brooks Royce O'Neale       Mark Williams\n",
      "           UTA AWAY      EXPECTED                  10     K. George       S. Mykhailiuk    Ace Bailey  L. Markkanen        Jusuf Nurkic\n",
      "           ATL HOME      EXPECTED                   9 Dyson Daniels N. Alexander-Walker Jalen Johnson Dyson Daniels N. Alexander-Walker\n",
      "           BKN HOME      EXPECTED                   8    Egor Demin        Terance Mann     M. Porter  Noah Clowney         Nic Claxton\n",
      "           LAL HOME      EXPECTED                   7   Luka Doncic       Austin Reaves  Marcus Smart Rui Hachimura       Deandre Ayton\n",
      "           ORL HOME      EXPECTED                   8  Desmond Bane        Franz Wagner   T. da Silva     W. Carter            J. Suggs\n",
      "           POR HOME      EXPECTED                   5     S. Sharpe           T. Camara  Jerami Grant   Deni Avdija          D. Clingan\n",
      "           SAS HOME      EXPECTED                   9  De'Aaron Fox       Devin Vassell J. Champagnie     H. Barnes         Luke Kornet\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 03: parse saved HTML to starters + MNP count --------------------------\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def _txt(x):\n",
    "    return re.sub(r\"\\s+\", \" \", x.get_text(\" \", strip=True)) if x else \"\"\n",
    "\n",
    "def _clean_player(n):\n",
    "    if not n:\n",
    "        return n\n",
    "    n = re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", n).strip()\n",
    "    n = re.sub(r\"^(PG|SG|SF|PF|C)\\s+\", \"\", n, flags=re.I)\n",
    "    return n\n",
    "\n",
    "def _get_mnp_from_ul(ul):\n",
    "    \"\"\"Extract 'May Not Play' entries from a team UL.\"\"\"\n",
    "    mnp = []\n",
    "    title = ul.find(\"li\", class_=lambda c: c and \"lineup__title\" in c and re.search(\n",
    "        r\"may\\s+not\\s+play\", _txt(ul.find(\"li\", class_=c)) if ul.find(\"li\", class_=c) else \"\", re.I\n",
    "    ))\n",
    "    if title:\n",
    "        for li in title.find_all_next(\"li\"):\n",
    "            if \"lineup__title\" in (li.get(\"class\") or []):\n",
    "                break\n",
    "            if \"lineup__player\" in (li.get(\"class\") or []):\n",
    "                a = li.select_one(\"a\")\n",
    "                tag = li.select_one(\".lineup__inj\")\n",
    "                nm = _txt(a) if a else \"\"\n",
    "                if nm:\n",
    "                    mnp.append(f\"{nm} ({_txt(tag)})\" if tag else nm)\n",
    "        return [_clean_player(x) for x in mnp if x and x.lower() != \"none\"]\n",
    "\n",
    "    for li in ul.select(\".lineup__notplay li, .lineup__status--out, .lineup__inj-list li\"):\n",
    "        nm = _txt(li)\n",
    "        if nm:\n",
    "            mnp.append(_clean_player(nm))\n",
    "    return [x for x in mnp if x and x.lower() != \"none\"]\n",
    "\n",
    "def _extract_starters_from_ul(ul):\n",
    "    names = []\n",
    "    for li in ul.select(\"li.lineup__player.is-pct-play-100 a\"):\n",
    "        nm = _txt(li)\n",
    "        if nm:\n",
    "            names.append(nm)\n",
    "    if len(names) < 5:\n",
    "        for li in ul.select(\"li.lineup__player a\"):\n",
    "            nm = _txt(li)\n",
    "            if nm:\n",
    "                names.append(nm)\n",
    "            if len(names) >= 5:\n",
    "                break\n",
    "    names = [_clean_player(n) for n in names]\n",
    "    return names[:5]\n",
    "\n",
    "def _lineup_status(ul):\n",
    "    st = _txt(ul.select_one(\".lineup__status\"))\n",
    "    stU = st.upper()\n",
    "    if \"CONFIRM\" in stU: return \"CONFIRMED\"\n",
    "    if \"EXPECT\" in stU or \"PROBABLE\" in stU: return \"EXPECTED\"\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "def parse_rotowire_lineups_flexible(html_path: str) -> pd.DataFrame:\n",
    "    with open(html_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        html = f.read()\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    diag = {\n",
    "        \"lineup__teams\": len(soup.select(\"div.lineup__teams\")),\n",
    "        \"ul.lineup__list\": len(soup.select(\"ul.lineup__list\")),\n",
    "        \"ul.is-visit\": len(soup.select(\"ul.lineup__list.is-visit\")),\n",
    "        \"ul.is-home\": len(soup.select(\"ul.lineup__list.is-home\")),\n",
    "        \"see-proj-minutes buttons\": len(soup.select(\"button.see-proj-minutes\")),\n",
    "        \"header abbr\": len(soup.select(\".lineup__hdr .lineup__abbr\")),\n",
    "        \"header team\": len(soup.select(\".lineup__hdr .lineup__team\")),\n",
    "        \"player anchors\": len(soup.select(\"a.lineup__player-link, .lineup__player a\")),\n",
    "        \"MNP titles\": len(soup.find_all(string=re.compile(r\"^\\s*may\\s+not\\s+play\\s*$\", re.I))),\n",
    "    }\n",
    "    print(\"DOM diagnostics:\", diag)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Strategy A: by matchup blocks\n",
    "    for teams_div in soup.select(\"div.lineup__teams\"):\n",
    "        time_el = teams_div.find_previous(\"div\", class_=\"lineup__time\")\n",
    "        game_time = _txt(time_el)\n",
    "\n",
    "        uls = teams_div.select(\"ul.lineup__list\")\n",
    "        if len(uls) < 1:\n",
    "            continue\n",
    "\n",
    "        away_ul = None\n",
    "        home_ul = None\n",
    "        for ul in uls:\n",
    "            classes = \" \".join(ul.get(\"class\", [])).lower()\n",
    "            if \"is-visit\" in classes or \"visit\" in classes or \"away\" in classes:\n",
    "                away_ul = ul\n",
    "            if \"is-home\" in classes or \"home\" in classes:\n",
    "                home_ul = home_ul or ul\n",
    "\n",
    "        if away_ul is None and home_ul is None and len(uls) >= 2:\n",
    "            away_ul, home_ul = uls[0], uls[1]\n",
    "        elif away_ul is None and len(uls) >= 1:\n",
    "            away_ul = uls[0]\n",
    "        elif home_ul is None and len(uls) >= 2:\n",
    "            home_ul = next((u for u in uls if u is not away_ul), None)\n",
    "\n",
    "        header_abbrs = [_txt(el) for el in teams_div.select(\".lineup__abbr\") if _txt(el)]\n",
    "        if not header_abbrs:\n",
    "            parent_main = teams_div.find_parent([\"div\",\"section\"])\n",
    "            if parent_main:\n",
    "                header_abbrs = [_txt(el) for el in parent_main.select(\".lineup__abbr\") if _txt(el)]\n",
    "\n",
    "        for idx, (side, ul) in enumerate([(\"AWAY\", away_ul), (\"HOME\", home_ul)]):\n",
    "            if not ul:\n",
    "                continue\n",
    "            btn = ul.select_one(\"button.see-proj-minutes\")\n",
    "            team = btn[\"data-team\"].strip().upper() if btn and btn.has_attr(\"data-team\") else None\n",
    "            if not team and header_abbrs and idx < len(header_abbrs):\n",
    "                team = header_abbrs[idx].upper()\n",
    "\n",
    "            starters = _extract_starters_from_ul(ul)\n",
    "            mnp = _get_mnp_from_ul(ul)\n",
    "            status = _lineup_status(ul)\n",
    "\n",
    "            if team or starters or mnp:\n",
    "                rows.append({\n",
    "                    \"game_time\": game_time,\n",
    "                    \"team\": team,\n",
    "                    \"side\": side,\n",
    "                    \"lineup_status\": status,\n",
    "                    \"starters\": starters,\n",
    "                    \"may_not_play\": mnp,\n",
    "                    \"may_not_play_count\": len(mnp),\n",
    "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
    "                })\n",
    "\n",
    "    # Strategy B: global scan if A found nothing\n",
    "    if not rows:\n",
    "        print(\"Fallback B: scanning all ul.lineup__list globally...\")\n",
    "        for ul in soup.select(\"ul.lineup__list\"):\n",
    "            side = \"AWAY\" if \"is-visit\" in (ul.get(\"class\") or []) else (\"HOME\" if \"is-home\" in (ul.get(\"class\") or []) else None)\n",
    "            btn = ul.select_one(\"button.see-proj-minutes\")\n",
    "            team = btn[\"data-team\"].strip().upper() if btn and btn.has_attr(\"data-team\") else None\n",
    "            starters = _extract_starters_from_ul(ul)\n",
    "            mnp = _get_mnp_from_ul(ul)\n",
    "            status = _lineup_status(ul)\n",
    "\n",
    "            if side and (team or starters or mnp):\n",
    "                rows.append({\n",
    "                    \"game_time\": \"\",\n",
    "                    \"team\": team,\n",
    "                    \"side\": side,\n",
    "                    \"lineup_status\": status,\n",
    "                    \"starters\": starters,\n",
    "                    \"may_not_play\": mnp,\n",
    "                    \"may_not_play_count\": len(mnp),\n",
    "                    \"lineup_confirmed\": int(status == \"CONFIRMED\"),\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    for i in range(5):\n",
    "        col = f\"starter_{i+1}\"\n",
    "        if \"starters\" in df.columns:\n",
    "            df[col] = df[\"starters\"].apply(lambda xs: xs[i] if isinstance(xs, list) and len(xs) > i else None)\n",
    "\n",
    "    print(f\"‚Üí Parsed rows: {len(df)}\")\n",
    "\n",
    "    # Save a copy for downstream\n",
    "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = f\"{DATA_DIR}/lineups_parsed_{stamp}.csv\"\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"üíæ Saved parsed lineups to {out_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---- RUN IT (point to the saved HTML) ----\n",
    "HTML_PATH = f\"{DEBUG_DIR}/last_lineups.html\"\n",
    "if not os.path.exists(HTML_PATH) and os.path.exists(\"last_lineups.html\"):\n",
    "    HTML_PATH = \"last_lineups.html\"\n",
    "\n",
    "df_lineups = parse_rotowire_lineups_flexible(HTML_PATH)\n",
    "\n",
    "if df_lineups.empty:\n",
    "    print(\"\\n‚ö†Ô∏è Still empty. Check DOM diagnostics and ensure Cell 3 ran successfully.\")\n",
    "else:\n",
    "    cols = [\"game_time\",\"team\",\"side\",\"lineup_status\",\"may_not_play_count\",\n",
    "            \"starter_1\",\"starter_2\",\"starter_3\",\"starter_4\",\"starter_5\"]\n",
    "    print(\"\\n‚úÖ Preview:\")\n",
    "    print(df_lineups[cols].sort_values([\"game_time\",\"side\",\"team\"], na_position=\"last\").to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8974b977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 games in HTML.\n",
      "‚úÖ Parsed 43 'May Not Play' players across 12 teams.\n",
      "  game_time team side position        player status            title_text  likelihood_pct\n",
      "10:30 PM ET  UTA AWAY        F      G. Niang    Out Very Unlikely To Play               0\n",
      "10:30 PM ET  UTA AWAY        F   K. Anderson   Ques       Toss Up To Play              50\n",
      "10:30 PM ET  UTA AWAY        C K. Filipowski   Ques       Toss Up To Play              50\n",
      "10:30 PM ET  UTA AWAY        F  T. Hendricks   Ques       Toss Up To Play              50\n",
      "10:30 PM ET  UTA AWAY        C    W. Kessler    OFS   Very Likely To Play               0\n",
      "10:30 PM ET  LAL HOME        G    G. Vincent   Ques       Toss Up To Play              50\n",
      "10:30 PM ET  LAL HOME        F      L. James   Ques       Toss Up To Play              50\n",
      "11:00 PM ET  PHX AWAY        G      G. Allen    Out Very Unlikely To Play               0\n",
      "11:00 PM ET  PHX AWAY        G      J. Green    Out Very Unlikely To Play               0\n",
      "11:00 PM ET  POR HOME        G     B. Wesley    Out Very Unlikely To Play               0\n",
      "11:00 PM ET  POR HOME        G    D. Lillard    OFS   Very Likely To Play               0\n",
      "11:00 PM ET  POR HOME        G    J. Holiday  Doubt      Unlikely To Play              25\n",
      "11:00 PM ET  POR HOME        F   M. Thybulle    Out Very Unlikely To Play               0\n",
      "11:00 PM ET  POR HOME        G  S. Henderson    Out Very Unlikely To Play               0\n",
      " 7:00 PM ET  GSW AWAY        G      B. Hield   Prob        Likely To Play              75\n",
      " 7:00 PM ET  GSW AWAY        G     D. Melton    Out Very Unlikely To Play               0\n",
      " 7:00 PM ET  GSW AWAY        F    J. Kuminga    Out Very Unlikely To Play               0\n",
      " 7:00 PM ET  ORL HOME        G      J. Suggs   Ques       Toss Up To Play              50\n",
      " 7:00 PM ET  ORL HOME        C     M. Wagner    Out Very Unlikely To Play               0\n",
      " 7:00 PM ET  ORL HOME        F   P. Banchero    Out Very Unlikely To Play               0\n",
      " 7:30 PM ET  BOS AWAY        F      J. Tatum    Out Very Unlikely To Play               0\n",
      " 7:30 PM ET  DET AWAY        F   A. Thompson   Ques       Toss Up To Play              50\n",
      " 7:30 PM ET  DET AWAY        F   B. Klintman    Out Very Unlikely To Play               0\n",
      " 7:30 PM ET  DET AWAY        G C. Cunningham   Ques       Toss Up To Play              50\n",
      " 7:30 PM ET  DET AWAY        G    Jaden Ivey    Out Very Unlikely To Play               0\n",
      " 7:30 PM ET  DET AWAY        G     M. Sasser    Out Very Unlikely To Play               0\n",
      " 7:30 PM ET  DET AWAY        F     T. Harris   Ques       Toss Up To Play              50\n",
      " 7:30 PM ET  ATL HOME        C  K. Porzingis   Ques       Toss Up To Play              50\n",
      " 7:30 PM ET  ATL HOME        C    O. Okongwu   Ques       Toss Up To Play              50\n",
      " 7:30 PM ET  ATL HOME        G    Trae Young    Out Very Unlikely To Play               0\n",
      "\n",
      "üíæ Saved: data_raw/may_not_play_players_20251118_183338.csv\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 04: Parse \"May Not Play\" (MNP) from saved HTML -----------------------\n",
    "# pip install bs4 lxml pandas\n",
    "import os, re, pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# Folders (fallbacks, in case Cell 1 wasn't run)\n",
    "DATA_DIR = \"data_raw\"; DEBUG_DIR = \"_rotowire_debug\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True); os.makedirs(DEBUG_DIR, exist_ok=True)\n",
    "\n",
    "HTML_PATH = f\"{DEBUG_DIR}/last_lineups.html\" if os.path.exists(f\"{DEBUG_DIR}/last_lineups.html\") else \"last_lineups.html\"\n",
    "\n",
    "LIKELIHOOD_MAP = {\n",
    "    \"is-pct-play-100\": 100, \"is-pct-play-90\": 90, \"is-pct-play-75\": 75,\n",
    "    \"is-pct-play-60\": 60, \"is-pct-play-50\": 50, \"is-pct-play-40\": 40,\n",
    "    \"is-pct-play-25\": 25, \"is-pct-play-10\": 10, \"is-pct-play-0\": 0\n",
    "}\n",
    "\n",
    "def _txt(node): \n",
    "    return re.sub(r\"\\s+\", \" \", node.get_text(\" \", strip=True)) if node else \"\"\n",
    "\n",
    "def _likelihood_from_classes(classes):\n",
    "    for c in classes or []:\n",
    "        if c in LIKELIHOOD_MAP:\n",
    "            return LIKELIHOOD_MAP[c]\n",
    "    return None\n",
    "\n",
    "def _clean_player(n):\n",
    "    if not n: return n\n",
    "    n = re.sub(r\"\\s+\\(.*?\\)\\s*$\", \"\", n).strip()\n",
    "    n = re.sub(r\"^(PG|SG|SF|PF|C)\\s+\", \"\", n, flags=re.I)\n",
    "    return n\n",
    "\n",
    "def parse_rotowire_mnp_final(html_path: str) -> pd.DataFrame:\n",
    "    with open(html_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        soup = BeautifulSoup(f.read(), \"lxml\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Primary structure\n",
    "    games = soup.select(\"div.lineup.is-nba[data-lnum]\")\n",
    "    print(f\"Found {len(games)} games in HTML.\")\n",
    "\n",
    "    for game in games:\n",
    "        game_time = _txt(game.select_one(\".lineup__time\"))\n",
    "        # Pair teams by .lineup__team, then iterate their ULs\n",
    "        team_blocks = game.select(\".lineup__team\")\n",
    "        teams = []\n",
    "        for tb in team_blocks:\n",
    "            abbr = _txt(tb.select_one(\".lineup__abbr\")) or _txt(tb.select_one(\".lineup__team-name\"))\n",
    "            side = \"AWAY\" if \"is-visit\" in (tb.get(\"class\") or []) else (\"HOME\" if \"is-home\" in (tb.get(\"class\") or []) else None)\n",
    "            teams.append((abbr, side))\n",
    "\n",
    "        ul_lists = game.select(\"ul.lineup__list\")\n",
    "        for idx, ul in enumerate(ul_lists):\n",
    "            team, side = (teams[idx] if idx < len(teams) else (None, None))\n",
    "            # Find the MNP title in this UL\n",
    "            mnp_title = ul.find(\"li\", class_=\"lineup__title\", string=lambda s: s and \"MAY NOT PLAY\" in s.upper())\n",
    "            if not mnp_title:\n",
    "                continue\n",
    "\n",
    "            for li in mnp_title.find_next_siblings(\"li\"):\n",
    "                classes = li.get(\"class\") or []\n",
    "                if \"lineup__title\" in classes:\n",
    "                    break\n",
    "                if \"lineup__player\" not in classes:\n",
    "                    continue\n",
    "\n",
    "                pos = _txt(li.select_one(\".lineup__pos\"))\n",
    "                a = li.select_one(\"a\")\n",
    "                player = _clean_player(_txt(a))\n",
    "                if not player:\n",
    "                    continue\n",
    "\n",
    "                status = _txt(li.select_one(\".lineup__inj\"))\n",
    "                title_text = (li.get(\"title\") or \"\").strip()\n",
    "                likelihood_pct = _likelihood_from_classes(classes)\n",
    "\n",
    "                rows.append({\n",
    "                    \"game_time\": game_time,\n",
    "                    \"team\": team,\n",
    "                    \"side\": side,\n",
    "                    \"position\": pos,\n",
    "                    \"player\": player,\n",
    "                    \"status\": status,\n",
    "                    \"title_text\": title_text,\n",
    "                    \"likelihood_pct\": likelihood_pct\n",
    "                })\n",
    "\n",
    "    # Fallback: global scan (if nothing found in primary structure)\n",
    "    if not rows:\n",
    "        print(\"Fallback: global MNP scan‚Ä¶\")\n",
    "        for ul in soup.select(\"ul.lineup__list\"):\n",
    "            title = ul.find(\"li\", class_=\"lineup__title\", string=lambda s: s and \"MAY NOT PLAY\" in s.upper())\n",
    "            if not title:\n",
    "                continue\n",
    "            for li in title.find_next_siblings(\"li\"):\n",
    "                classes = li.get(\"class\") or []\n",
    "                if \"lineup__title\" in classes:\n",
    "                    break\n",
    "                if \"lineup__player\" not in classes:\n",
    "                    continue\n",
    "                player = _clean_player(_txt(li.select_one(\"a\")))\n",
    "                if not player:\n",
    "                    continue\n",
    "                rows.append({\n",
    "                    \"game_time\": \"\",\n",
    "                    \"team\": None,\n",
    "                    \"side\": None,\n",
    "                    \"position\": _txt(li.select_one(\".lineup__pos\")),\n",
    "                    \"player\": player,\n",
    "                    \"status\": _txt(li.select_one(\".lineup__inj\")),\n",
    "                    \"title_text\": (li.get(\"title\") or \"\").strip(),\n",
    "                    \"likelihood_pct\": _likelihood_from_classes(classes)\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è No 'May Not Play' players found. Check if Rotowire changed markup or re-run Cell 3.\")\n",
    "        return df\n",
    "\n",
    "    df = df.sort_values([\"game_time\",\"side\",\"team\",\"player\"], na_position=\"last\").reset_index(drop=True)\n",
    "    print(f\"‚úÖ Parsed {len(df)} 'May Not Play' players across {df['team'].nunique(dropna=True)} teams.\")\n",
    "    return df\n",
    "\n",
    "# ---- RUN ----\n",
    "mnp_df = parse_rotowire_mnp_final(HTML_PATH)\n",
    "if not mnp_df.empty:\n",
    "    print(mnp_df.head(30).to_string(index=False))\n",
    "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_csv = f\"{DATA_DIR}/may_not_play_players_{stamp}.csv\"\n",
    "    mnp_df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nüíæ Saved: {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a19799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 05: NBA betting analysis functions -------------------------------------\n",
    "def get_daily_matchups(date=None):\n",
    "    \"\"\"Get NBA games for a specific date\"\"\"\n",
    "    if date is None:\n",
    "        date = datetime.now().strftime('%Y-%m-%d')\n",
    "    # Placeholder demo; replace with a real schedule API if desired\n",
    "    sample_matchups = [\n",
    "        {'home_team': 'GSW', 'away_team': 'LAL', 'time': '7:30 PM ET'},\n",
    "        {'home_team': 'BOS', 'away_team': 'MIA', 'time': '8:00 PM ET'},\n",
    "        {'home_team': 'DEN', 'away_team': 'DAL', 'time': '9:00 PM ET'},\n",
    "    ]\n",
    "    return sample_matchups\n",
    "\n",
    "def calculate_player_correlations(player_a_logs, player_b_logs):\n",
    "    \"\"\"Calculate correlation between two players' performances\"\"\"\n",
    "    merged = pd.merge(player_a_logs, player_b_logs, on='GAME_DATE', suffixes=('_a', '_b'))\n",
    "    correlations = {}\n",
    "    for stat in ['PTS', 'REB', 'AST']:\n",
    "        if f'{stat}_a' in merged.columns and f'{stat}_b' in merged.columns:\n",
    "            corr = merged[f'{stat}_a'].corr(merged[f'{stat}_b'])\n",
    "            correlations[stat] = corr\n",
    "    return correlations\n",
    "\n",
    "# Export results to Excel\n",
    "def export_analysis(results, filename='nba_betting_analysis.xlsx'):\n",
    "    \"\"\"Export analysis results to Excel\"\"\"\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        if 'value_bets' in results:\n",
    "            pd.DataFrame(results['value_bets']).to_excel(writer, sheet_name='Value_Bets', index=False)\n",
    "        if 'predictions' in results:\n",
    "            predictions_df = pd.DataFrame.from_dict(results['predictions'], orient='index')\n",
    "            predictions_df.to_excel(writer, sheet_name='Player_Predictions')\n",
    "    print(f\"Analysis exported to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782cf0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 57 starter probability rows.\n",
      "‚úÖ Starter flags sample:\n",
      "       player team  is_starter  start_prob\n",
      "Stephen Curry  GSW           1        0.70\n",
      " Will Richard  GSW           1        0.70\n",
      "  Moses Moody  GSW           1        0.70\n",
      " Jimmy Butler  GSW           1        0.70\n",
      "     D. Green  GSW           1        0.70\n",
      " Desmond Bane  ORL           1        0.70\n",
      " Franz Wagner  ORL           1        0.70\n",
      "  T. da Silva  ORL           1        0.70\n",
      "    W. Carter  ORL           1        0.70\n",
      "     J. Suggs  ORL           1        0.42\n",
      "\n",
      "‚úÖ Injury flags sample:\n",
      "       player  may_not_play  injury_prob\n",
      "     G. Niang           1.0          1.0\n",
      "  K. Anderson           1.0          0.5\n",
      "K. Filipowski           1.0          0.5\n",
      " T. Hendricks           1.0          0.5\n",
      "   W. Kessler           0.0          0.0\n",
      "   G. Vincent           1.0          0.5\n",
      "     L. James           1.0          0.5\n",
      "     G. Allen           1.0          1.0\n",
      "     J. Green           1.0          1.0\n",
      "    B. Wesley           1.0          1.0\n",
      "\n",
      "üíæ Saved starter flags ‚Üí data_raw/starter_flags_20251118_183338.csv\n",
      "üíæ Saved injury flags ‚Üí data_raw/injury_flags_20251118_183338.csv\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 06: starter flags (time-aware) + injury flags ------------------------\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folders (fallbacks, in case Cell 1 wasn't run)\n",
    "DATA_DIR = \"data_raw\"; os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def compute_time_based_prob(game_time_str: str, lineup_status: str) -> float:\n",
    "    \"\"\"Rough start probability based on status and hours to tip (ET).\"\"\"\n",
    "    try:\n",
    "        if not game_time_str:\n",
    "            return 0.7\n",
    "        game_time_clean = game_time_str.replace(\"ET\", \"\").strip()\n",
    "        base_dt = datetime.strptime(game_time_clean, \"%I:%M %p\")\n",
    "        now_et = datetime.now(pytz.timezone(\"US/Eastern\"))\n",
    "        game_dt = now_et.replace(hour=base_dt.hour, minute=base_dt.minute, second=0, microsecond=0)\n",
    "        hours_to_tip = (game_dt - now_et).total_seconds() / 3600.0\n",
    "        if hours_to_tip < -3:\n",
    "            game_dt += timedelta(days=1)\n",
    "            hours_to_tip = (game_dt - now_et).total_seconds() / 3600.0\n",
    "    except Exception:\n",
    "        hours_to_tip = 6.0\n",
    "\n",
    "    st = (lineup_status or \"\").upper()\n",
    "    if \"CONFIRM\" in st:\n",
    "        return 1.0\n",
    "    if \"EXPECT\" in st or \"PROBABLE\" in st:\n",
    "        if hours_to_tip > 6: return 0.70\n",
    "        if hours_to_tip > 2: return 0.85\n",
    "        return 0.95\n",
    "    # unknown\n",
    "    return 0.60 if hours_to_tip > 4 else 0.80\n",
    "\n",
    "def build_starter_flags_timeaware(df_lineups: pd.DataFrame, mnp_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"From df_lineups (with 'starters' list per row), emit per-player start_prob.\"\"\"\n",
    "    mnp_players = set(mnp_df[\"player\"].str.strip()) if (isinstance(mnp_df, pd.DataFrame) and not mnp_df.empty) else set()\n",
    "    rows = []\n",
    "\n",
    "    if df_lineups is None or df_lineups.empty or \"starters\" not in df_lineups.columns:\n",
    "        return pd.DataFrame(columns=[\"player\",\"team\",\"is_starter\",\"start_prob\"])\n",
    "\n",
    "    for _, row in df_lineups.iterrows():\n",
    "        team = row.get(\"team\", None)\n",
    "        lineup_status = row.get(\"lineup_status\", \"\")\n",
    "        game_time = row.get(\"game_time\", \"\")\n",
    "        starters = row.get(\"starters\", [])\n",
    "        starters = starters if isinstance(starters, list) else []\n",
    "\n",
    "        for p in starters:\n",
    "            p_clean = (p or \"\").strip()\n",
    "            if not p_clean:\n",
    "                continue\n",
    "            prob = compute_time_based_prob(game_time, lineup_status)\n",
    "            if p_clean in mnp_players:\n",
    "                prob *= 0.6  # penalize if on MNP\n",
    "            rows.append({\n",
    "                \"player\": p_clean,\n",
    "                \"team\": team,\n",
    "                \"is_starter\": 1,\n",
    "                \"start_prob\": round(float(np.clip(prob, 0.0, 1.0)), 2),\n",
    "            })\n",
    "\n",
    "    df_out = pd.DataFrame(rows).drop_duplicates(subset=[\"player\"])\n",
    "    print(f\"‚úÖ Created {len(df_out)} starter probability rows.\")\n",
    "    return df_out\n",
    "\n",
    "def build_injury_flags(mnp_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return DataFrame with may_not_play flag and injury_prob derived from status.\"\"\"\n",
    "    if mnp_df is None or mnp_df.empty:\n",
    "        return pd.DataFrame(columns=[\"player\",\"may_not_play\",\"injury_prob\"])\n",
    "\n",
    "    def map_status_to_prob(status: str):\n",
    "        \"\"\"Map injury status string to (may_not_play, injury_prob).\"\"\"\n",
    "        status = str(status).lower().strip()\n",
    "        if \"out\" in status:\n",
    "            return 1, 1.0\n",
    "        elif \"ques\" in status or \"doubt\" in status:\n",
    "            return 1, 0.5\n",
    "        elif \"prob\" in status:\n",
    "            return 0, 0.25\n",
    "        return 0, 0.0\n",
    "\n",
    "    mapped = mnp_df.dropna(subset=[\"player\"]).copy()\n",
    "    mapped[\"player\"] = mapped[\"player\"].str.strip()\n",
    "\n",
    "    if \"status\" in mapped.columns:\n",
    "        mapped[[\"may_not_play\", \"injury_prob\"]] = mapped[\"status\"].apply(\n",
    "            lambda s: pd.Series(map_status_to_prob(s))\n",
    "        )\n",
    "    else:\n",
    "        mapped[\"injury_prob\"] = mapped[\"likelihood_pct\"].fillna(40) / 100.0\n",
    "        mapped[\"may_not_play\"] = 1\n",
    "\n",
    "    return mapped[[\"player\", \"may_not_play\", \"injury_prob\"]].drop_duplicates(subset=[\"player\"])\n",
    "\n",
    "# ---- RUN (expects df_lineups from Cell 3 and mnp_df from Cell 5) ------------\n",
    "starter_flags_df = build_starter_flags_timeaware(df_lineups, mnp_df)\n",
    "injury_flags_df = build_injury_flags(mnp_df)\n",
    "\n",
    "print(\"‚úÖ Starter flags sample:\")\n",
    "print(starter_flags_df.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ Injury flags sample:\")\n",
    "print(injury_flags_df.head(10).to_string(index=False))\n",
    "\n",
    "# Save outputs\n",
    "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "sf_path  = f\"{DATA_DIR}/starter_flags_{stamp}.csv\"\n",
    "inj_path = f\"{DATA_DIR}/injury_flags_{stamp}.csv\"\n",
    "starter_flags_df.to_csv(sf_path, index=False)\n",
    "injury_flags_df.to_csv(inj_path, index=False)\n",
    "print(f\"\\nüíæ Saved starter flags ‚Üí {sf_path}\\nüíæ Saved injury flags ‚Üí {inj_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0368a",
   "metadata": {},
   "source": [
    "## NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4896f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÄ Fetching NBA stats for 2023-24‚Ä¶\n",
      "‚Üí Attempt 1 fetching 2023-24‚Ä¶\n",
      "‚úÖ 2023-24: saved 572 rows ‚Üí data_raw/nba_player_stats_2023_24.csv\n",
      "\n",
      "üèÄ Fetching NBA stats for 2024-25‚Ä¶\n",
      "‚Üí Attempt 1 fetching 2024-25‚Ä¶\n",
      "‚úÖ 2024-25: saved 569 rows ‚Üí data_raw/nba_player_stats_2024_25.csv\n",
      "\n",
      "üèÄ Fetching NBA stats for 2025-26‚Ä¶\n",
      "‚Üí Attempt 1 fetching 2025-26‚Ä¶\n",
      "‚úÖ 2025-26: saved 468 rows ‚Üí data_raw/nba_player_stats_2025_26.csv\n",
      "\n",
      "üéâ Done! Saved: ['data_raw/nba_player_stats_2023_24.csv', 'data_raw/nba_player_stats_2024_25.csv', 'data_raw/nba_player_stats_2025_26.csv']\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 07: Download per-season player stats from NBA Stats API --------------\n",
    "# (Be polite: retries + small random delays)\n",
    "import os, time, random, requests, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Folders (fallbacks)\n",
    "DATA_DIR = \"data_raw\"; os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "URL = \"https://stats.nba.com/stats/leaguedashplayerstats\"\n",
    "\n",
    "BASE_PARAMS = {\n",
    "    \"College\": \"\", \"Conference\": \"\", \"Country\": \"\", \"DateFrom\": \"\", \"DateTo\": \"\",\n",
    "    \"Division\": \"\", \"DraftPick\": \"\", \"DraftYear\": \"\", \"GameScope\": \"\", \"GameSegment\": \"\",\n",
    "    \"Height\": \"\", \"ISTRound\": \"\", \"LastNGames\": \"0\", \"LeagueID\": \"00\", \"Location\": \"\",\n",
    "    \"MeasureType\": \"Base\", \"Month\": \"0\", \"OpponentTeamID\": \"0\", \"Outcome\": \"\",\n",
    "    \"PORound\": \"0\", \"PaceAdjust\": \"N\", \"PerMode\": \"PerGame\", \"Period\": \"0\",\n",
    "    \"PlayerExperience\": \"\", \"PlayerPosition\": \"\", \"PlusMinus\": \"N\", \"Rank\": \"N\",\n",
    "    \"SeasonSegment\": \"\", \"SeasonType\": \"Regular Season\", \"ShotClockRange\": \"\",\n",
    "    \"StarterBench\": \"\", \"TeamID\": \"0\", \"VsConference\": \"\", \"VsDivision\": \"\", \"Weight\": \"\"\n",
    "}\n",
    "\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json, text/plain, */*\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Origin\": \"https://www.nba.com\",\n",
    "    \"Referer\": \"https://www.nba.com/\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
    "    \"x-nba-stats-origin\": \"stats\",\n",
    "    \"x-nba-stats-token\": \"true\"\n",
    "}\n",
    "\n",
    "SEASONS = [\"2023-24\", \"2024-25\", \"2025-26\"]\n",
    "\n",
    "def fetch_season(season: str, retries: int = 3) -> pd.DataFrame:\n",
    "    params = BASE_PARAMS.copy()\n",
    "    params[\"Season\"] = season\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            print(f\"‚Üí Attempt {attempt} fetching {season}‚Ä¶\")\n",
    "            r = requests.get(URL, headers=HEADERS, params=params, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            js = r.json()\n",
    "            rs = js[\"resultSets\"][0]\n",
    "            df = pd.DataFrame(rs[\"rowSet\"], columns=rs[\"headers\"])\n",
    "            return df\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"‚ö†Ô∏è Timeout {attempt}/{retries}; retrying‚Ä¶\")\n",
    "            time.sleep(2 * attempt)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Error {attempt}/{retries}: {e}\"); time.sleep(2 * attempt)\n",
    "    raise RuntimeError(f\"Failed to fetch {season} after {retries} attempts.\")\n",
    "\n",
    "all_paths = []\n",
    "for season in SEASONS:\n",
    "    print(f\"\\nüèÄ Fetching NBA stats for {season}‚Ä¶\")\n",
    "    df = fetch_season(season)\n",
    "    path = f\"{DATA_DIR}/nba_player_stats_{season.replace('-','_')}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"‚úÖ {season}: saved {len(df)} rows ‚Üí {path}\")\n",
    "    all_paths.append(path)\n",
    "    time.sleep(random.uniform(3, 6))  # throttle politely\n",
    "\n",
    "print(\"\\nüéâ Done! Saved:\", all_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a76b7",
   "metadata": {},
   "source": [
    "## GAME LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e080d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2023-24‚Ä¶\n",
      "‚úÖ Saved 26401 records ‚Üí data_raw/nba_boxscores_2023-24.csv\n",
      "Fetching 2024-25‚Ä¶\n",
      "‚úÖ Saved 26306 records ‚Üí data_raw/nba_boxscores_2024-25.csv\n",
      "Fetching 2025-26‚Ä¶\n",
      "‚úÖ Saved 4605 records ‚Üí data_raw/nba_boxscores_2025-26.csv\n",
      "\n",
      "üéâ Box score downloads complete.\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 08: Download player game logs (box scores) by season ------------------\n",
    "import os, time, requests, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Folders (fallbacks)\n",
    "DATA_DIR = \"data_raw\"; os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def get_box_scores(season: str, season_type: str = \"Regular Season\") -> pd.DataFrame:\n",
    "    url = \"https://stats.nba.com/stats/leaguegamelog\"\n",
    "    params = {\n",
    "        \"Counter\": 1000, \"DateFrom\": \"\", \"DateTo\": \"\", \"Direction\": \"DESC\",\n",
    "        \"ISTRound\": \"\", \"LeagueID\": \"00\", \"PlayerOrTeam\": \"P\",\n",
    "        \"Season\": season, \"SeasonType\": season_type, \"Sorter\": \"DATE\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.nba.com/\", \"Origin\": \"https://www.nba.com\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\"\n",
    "    }\n",
    "    r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"resultSets\"][0]\n",
    "    df = pd.DataFrame(data[\"rowSet\"], columns=data[\"headers\"])\n",
    "    return df\n",
    "\n",
    "SEASONS = [\"2023-24\",\"2024-25\",\"2025-26\"]\n",
    "# already saved once season: [\"2023-24\", \"2024-25\"]\n",
    "saved = []\n",
    "for season in SEASONS:\n",
    "    print(f\"Fetching {season}‚Ä¶\")\n",
    "    df = get_box_scores(season)\n",
    "    path = f\"{DATA_DIR}/nba_boxscores_{season}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"‚úÖ Saved {len(df)} records ‚Üí {path}\")\n",
    "    saved.append(path)\n",
    "    time.sleep(2)  # polite delay\n",
    "\n",
    "print(\"\\nüéâ Box score downloads complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49f8cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: data_enriched\\nba_player_stats_2023_24_enriched.csv\n",
      "‚úÖ Saved: data_enriched\\nba_player_stats_2024_25_enriched.csv\n",
      "‚úÖ Saved: data_enriched\\nba_player_stats_2025_26_enriched.csv\n",
      "üèÄ Combined ‚Üí data_enriched\\nba_player_stats_2023_25_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 09: Fetch BBRef Advanced tables, align, and enrich season CSVs -------\n",
    "import os, io, unicodedata, requests, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Folders (work even if Cell 1 didn't run)\n",
    "DATA_DIR   = \"data_raw\"\n",
    "ENRICH_DIR = \"data_enriched\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(ENRICH_DIR, exist_ok=True)\n",
    "\n",
    "ADV_COLS_KEEP = [\n",
    "    \"Player\",\"Pos\",\"Age\",\"Tm\",\"G\",\"MP\",\n",
    "    \"PER\",\"TS%\",\"3PAr\",\"FTr\",\n",
    "    \"ORB%\",\"DRB%\",\"TRB%\",\n",
    "    \"AST%\",\"STL%\",\"BLK%\",\n",
    "    \"TOV%\",\"USG%\",\n",
    "    \"ORtg\",\"DRtg\",\n",
    "    \"OWS\",\"DWS\",\"WS\",\"WS/48\",\n",
    "    \"OBPM\",\"DBPM\",\"BPM\",\"VORP\"\n",
    "]\n",
    "\n",
    "TEAM_ABBR_MAP = {\n",
    "    \"BRK\": \"BKN\",\n",
    "    \"PHO\": \"PHX\",\n",
    "    \"CHO\": \"CHA\",\n",
    "    \"UTH\": \"UTA\",\n",
    "    \"NJN\": \"BKN\",\n",
    "    \"SEA\": \"OKC\",\n",
    "    \"VAN\": \"MEM\",\n",
    "}\n",
    "\n",
    "def normalize_name(s: str):\n",
    "    if pd.isna(s): return s\n",
    "    s = str(s).strip().lower()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    for ch in [\".\",\"'\",\"`\",\"‚Äô\",\"‚Äú\",\"‚Äù\",\",\"]:\n",
    "        s = s.replace(ch, \"\")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def fetch_advanced_table(season_end_year: int, retries: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    season_end_year=2025 -> https://www.basketball-reference.com/leagues/NBA_2025_advanced.html\n",
    "    \"\"\"\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season_end_year}_advanced.html\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/120.0.0.0 Safari/537.36\")\n",
    "    }\n",
    "    last_err = None\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            tables = pd.read_html(io.StringIO(r.text), header=0)\n",
    "            if not tables:\n",
    "                raise RuntimeError(\"No tables parsed from page.\")\n",
    "            df = tables[0].copy()\n",
    "            # Drop duplicate header rows\n",
    "            if \"Rk\" in df.columns:\n",
    "                df = df[df[\"Rk\"] != \"Rk\"].copy()\n",
    "                df.drop(columns=[\"Rk\"], inplace=True, errors=\"ignore\")\n",
    "            df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "            # Ensure team column name\n",
    "            team_col = None\n",
    "            for c in df.columns:\n",
    "                if c.lower() in (\"tm\",\"team\",\"team_name\"):\n",
    "                    team_col = c; break\n",
    "            if not team_col:\n",
    "                raise KeyError(f\"Team column not found. Columns: {df.columns.tolist()}\")\n",
    "            df.rename(columns={team_col: \"Tm\"}, inplace=True)\n",
    "\n",
    "            keep = [c for c in ADV_COLS_KEEP if c in df.columns]\n",
    "            df = df[keep].copy()\n",
    "\n",
    "            for c in df.columns:\n",
    "                if c not in {\"Player\",\"Pos\",\"Tm\"}:\n",
    "                    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "            df[\"Tm\"] = df[\"Tm\"].replace(TEAM_ABBR_MAP)\n",
    "            df[\"player_key\"] = df[\"Player\"].map(normalize_name)\n",
    "            df[\"team_key\"] = df[\"Tm\"].astype(str).str.strip().str.upper()\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise last_err\n",
    "\n",
    "def load_averages_csv(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    # map columns to canonical 'Player' and 'Team'\n",
    "    col_map = {}\n",
    "    for c in df.columns:\n",
    "        cl = c.strip().lower()\n",
    "        if cl == \"player_name\": col_map[c] = \"Player\"\n",
    "        elif cl in (\"team_abbreviation\",\"tm\",\"team\"): col_map[c] = \"Team\"\n",
    "    df = df.rename(columns=col_map)\n",
    "    if \"Player\" not in df.columns or \"Team\" not in df.columns:\n",
    "        raise ValueError(f\"'Player' and 'Team' required. Got: {list(df.columns)}\")\n",
    "    df[\"player_key\"] = df[\"Player\"].map(normalize_name)\n",
    "    df[\"team_key\"]   = df[\"Team\"].astype(str).str.strip().str.upper()\n",
    "    return df\n",
    "\n",
    "def merge_advanced_into_averages(df_avg: pd.DataFrame, df_adv: pd.DataFrame) -> pd.DataFrame:\n",
    "    adv_team = df_adv[df_adv[\"Tm\"] != \"TOT\"].copy()\n",
    "    adv_tot  = df_adv[df_adv[\"Tm\"] == \"TOT\"].copy()\n",
    "\n",
    "    adv_cols = [c for c in df_adv.columns if c not in {\"Player\",\"Pos\",\"Age\",\"Tm\",\"player_key\",\"team_key\"}]\n",
    "    meta_cols = [c for c in [\"Pos\",\"Age\"] if c in df_adv.columns]\n",
    "    add_cols = meta_cols + adv_cols\n",
    "\n",
    "    merged = df_avg.merge(\n",
    "        adv_team[[\"player_key\",\"team_key\"] + add_cols],\n",
    "        on=[\"player_key\",\"team_key\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Fill gaps from TOT by player\n",
    "    probe = \"PER\" if \"PER\" in merged.columns else (\"WS/48\" if \"WS/48\" in merged.columns else None)\n",
    "    missing = merged[probe].isna() if probe else merged.isna().any(axis=1)\n",
    "    if missing.any() and not adv_tot.empty:\n",
    "        fb = merged.loc[missing, [\"player_key\"]].merge(\n",
    "            adv_tot[[\"player_key\"] + add_cols], on=\"player_key\", how=\"left\"\n",
    "        )\n",
    "        for col in add_cols:\n",
    "            if col in merged.columns and col in fb.columns:\n",
    "                merged.loc[missing, col] = merged.loc[missing, col].fillna(fb[col])\n",
    "    return merged\n",
    "\n",
    "# --- Build both seasons and save into ENRICH_DIR ------------------------------\n",
    "# Map: \"2023-24\" -> 2024, \"2024-25\" -> 2025\n",
    "pairs = [\n",
    "    (\"2023_24\", 2024),\n",
    "    (\"2024_25\", 2025),\n",
    "    (\"2025_26\", 2026),\n",
    "]\n",
    "out_paths = []\n",
    "for tag, yr in pairs:\n",
    "    avg_path = os.path.join(DATA_DIR, f\"nba_player_stats_{tag}.csv\")\n",
    "    if not os.path.exists(avg_path):\n",
    "        raise FileNotFoundError(f\"Missing averages CSV: {avg_path}. Run Cell 8 first.\")\n",
    "    df_avg = load_averages_csv(avg_path)\n",
    "    df_adv = fetch_advanced_table(yr)\n",
    "    df_enriched = merge_advanced_into_averages(df_avg, df_adv)\n",
    "\n",
    "    outp = os.path.join(ENRICH_DIR, f\"nba_player_stats_{tag}_enriched.csv\")\n",
    "    df_enriched.to_csv(outp, index=False)\n",
    "    print(f\"‚úÖ Saved: {outp}\")\n",
    "    out_paths.append(outp)\n",
    "\n",
    "# Optional combined\n",
    "combined = pd.concat([pd.read_csv(p) for p in out_paths], ignore_index=True)\n",
    "combined.to_csv(os.path.join(ENRICH_DIR, \"nba_player_stats_2023_25_combined.csv\"), index=False)\n",
    "print(\"üèÄ Combined ‚Üí\", os.path.join(ENRICH_DIR, \"nba_player_stats_2023_25_combined.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86805666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 10: Game-log ‚Üí features (rolling, team ratings, opponent allowances) -\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_logs_cols(df_logs: pd.DataFrame) -> pd.DataFrame:\n",
    "    colmap = {}\n",
    "    for c in df_logs.columns:\n",
    "        cl = c.strip().lower()\n",
    "        if cl in {\"game_date\",\"game_date_est\",\"date\"}: colmap[c] = \"GAME_DATE\"\n",
    "        elif cl in {\"player\",\"player_name\"}: colmap[c] = \"PLAYER_NAME\"\n",
    "        elif cl in {\"team\",\"team_abbreviation\",\"tm\"}: colmap[c] = \"TEAM_ABBREVIATION\"\n",
    "        elif cl in {\"opp\",\"opponent\",\"opponent_abbreviation\"}: colmap[c] = \"OPPONENT_ABBREVIATION\"\n",
    "        elif cl in {\"min\",\"minutes\"}: colmap[c] = \"MIN\"\n",
    "    df = df_logs.rename(columns=colmap).copy()\n",
    "    df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
    "    df = df.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "    return df\n",
    "\n",
    "def add_shooting_efficiency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in [\"FGA\",\"FTA\",\"PTS\"]:\n",
    "        if col not in df.columns: df[col] = 0.0\n",
    "    denom = 2 * (df[\"FGA\"].astype(float) + 0.44 * df[\"FTA\"].astype(float))\n",
    "    df[\"TS_game\"] = np.where(denom > 0, df[\"PTS\"].astype(float)/denom, np.nan)\n",
    "    return df\n",
    "\n",
    "def rolling_player_form(df: pd.DataFrame, windows=(3,5,10,20)) -> pd.DataFrame:\n",
    "    df = df.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).copy()\n",
    "    g = df.groupby(\"PLAYER_NAME\", group_keys=False)\n",
    "    for w in windows:\n",
    "        for stat in [\"PTS\",\"REB\",\"AST\",\"MIN\",\"TS_game\"]:\n",
    "            if stat not in df.columns: df[stat] = np.nan\n",
    "            df[f\"{stat}_roll{w}\"] = g[stat].shift(1).rolling(w, min_periods=1).mean()\n",
    "    if {\"FGA\",\"TEAM_ABBREVIATION\"}.issubset(df.columns):\n",
    "        df[\"teamFGA_game\"] = df.groupby([\"TEAM_ABBREVIATION\",\"GAME_DATE\"])[\"FGA\"].transform(\"sum\")\n",
    "        df[\"usage_share\"] = np.where(df[\"teamFGA_game\"]>0, df[\"FGA\"]/df[\"teamFGA_game\"], np.nan)\n",
    "        df[\"usage_share_roll5\"] = g[\"usage_share\"].shift(1).rolling(5, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def team_daily_ratings(df: pd.DataFrame, windows=(5,10)) -> pd.DataFrame:\n",
    "    # Poss ‚âà FGA + 0.44*FTA - OREB + TOV  (OREB optional)\n",
    "    for c in [\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\"GAME_DATE\",\"PTS\",\"FGA\",\"FTA\",\"TOV\",\"OREB\"]:\n",
    "        if c not in df.columns: df[c] = 0.0\n",
    "\n",
    "    g = df.groupby([\"GAME_DATE\",\"TEAM_ABBREVIATION\"], as_index=False).agg(\n",
    "        PTS_team=(\"PTS\",\"sum\"), FGA=(\"FGA\",\"sum\"), FTA=(\"FTA\",\"sum\"),\n",
    "        TOV=(\"TOV\",\"sum\"), OREB=(\"OREB\",\"sum\")\n",
    "    )\n",
    "    g[\"poss\"] = g[\"FGA\"] + 0.44*g[\"FTA\"] - g[\"OREB\"] + g[\"TOV\"]\n",
    "\n",
    "    opp = g.rename(columns={\n",
    "        \"TEAM_ABBREVIATION\":\"OPPONENT_ABBREVIATION\",\n",
    "        \"PTS_team\":\"PTS_opp\", \"poss\":\"poss_opp\"\n",
    "    })[[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\",\"PTS_opp\",\"poss_opp\"]]\n",
    "\n",
    "    g2 = g.merge(opp, on=[\"GAME_DATE\"], how=\"left\")\n",
    "    g2[\"ORtg_g\"] = np.where(g2[\"poss\"]>0, 100*g2[\"PTS_team\"]/g2[\"poss\"], np.nan)\n",
    "    g2[\"DRtg_g\"] = np.where(g2[\"poss_opp\"]>0, 100*g2[\"PTS_opp\"]/g2[\"poss_opp\"], np.nan)\n",
    "    g2[\"Pace_g\"] = (g2[\"poss\"] + g2[\"poss_opp\"]) / 2.0\n",
    "\n",
    "    g2 = g2.sort_values([\"TEAM_ABBREVIATION\",\"GAME_DATE\"])\n",
    "    for w in windows:\n",
    "        for stat in [\"ORtg_g\",\"DRtg_g\",\"Pace_g\"]:\n",
    "            g2[f\"{stat}_roll{w}\"] = (\n",
    "                g2.groupby(\"TEAM_ABBREVIATION\")[stat].shift(1).rolling(w, min_periods=1).mean()\n",
    "            )\n",
    "    keep = [\"GAME_DATE\",\"TEAM_ABBREVIATION\",\"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
    "            \"ORtg_g_roll10\",\"DRtg_g_roll10\",\"Pace_g_roll10\"]\n",
    "    return g2[keep].drop_duplicates(subset=[\"GAME_DATE\",\"TEAM_ABBREVIATION\"], keep=\"last\")\n",
    "\n",
    "def opponent_position_allowances(df: pd.DataFrame, window=10) -> pd.DataFrame:\n",
    "    if \"START_POSITION\" not in df.columns:\n",
    "        df[\"START_POSITION\"] = np.nan\n",
    "    base = (df.groupby([\"GAME_DATE\",\"OPPONENT_ABBREVIATION\",\"START_POSITION\"], as_index=False)\n",
    "              .agg(PTS_allowed=(\"PTS\",\"sum\"), AST_allowed=(\"AST\",\"sum\"), REB_allowed=(\"REB\",\"sum\"))\n",
    "              .sort_values([\"OPPONENT_ABBREVIATION\",\"START_POSITION\",\"GAME_DATE\"]))\n",
    "    for stat in [\"PTS_allowed\",\"AST_allowed\",\"REB_allowed\"]:\n",
    "        base[f\"{stat}_roll{window}\"] = (\n",
    "            base.groupby([\"OPPONENT_ABBREVIATION\",\"START_POSITION\"])[stat]\n",
    "                .shift(1).rolling(window, min_periods=3).mean()\n",
    "        )\n",
    "    wide = base.pivot_table(\n",
    "        index=[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\"],\n",
    "        columns=\"START_POSITION\",\n",
    "        values=[f\"PTS_allowed_roll{window}\",f\"AST_allowed_roll{window}\",f\"REB_allowed_roll{window}\"]\n",
    "    )\n",
    "    wide.columns = [f\"{a}_{b}\" for a,b in wide.columns.to_flat_index()]\n",
    "    return wide.reset_index()\n",
    "\n",
    "def assemble_player_game_features(df_logs: pd.DataFrame, df_enriched_season: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = standardize_logs_cols(df_logs)\n",
    "    # Extract OPPONENT_ABBREVIATION from MATCHUP column\n",
    "    df[\"OPPONENT_ABBREVIATION\"] = df[\"MATCHUP\"].str.extract(r\"(?:vs\\.|@)\\s+([A-Z]+)\")\n",
    "    # Normalize opp_key from abbreviation\n",
    "    abbrev_to_key = {\n",
    "        \"ATL\": \"ATLANTAHAWKS\", \"BOS\": \"BOSTONCELTICS\", \"BKN\": \"BROOKLYNNETS\", \"CHA\": \"CHARLOTTEHORNETS\",\n",
    "        \"CHI\": \"CHICAGOBULLS\", \"CLE\": \"CAVALIERS\", \"DAL\": \"DALLASMAVERICKS\", \"DEN\": \"DENVERNUGGETS\",\n",
    "        \"DET\": \"DETPISTONS\", \"GSW\": \"WARRIORS\", \"HOU\": \"ROCKETS\", \"IND\": \"PACERS\",\n",
    "        \"LAC\": \"CLIPPERS\", \"LAL\": \"LAKERS\", \"MEM\": \"GRIZZLIES\", \"MIA\": \"HEAT\",\n",
    "        \"MIL\": \"BUCKS\", \"MIN\": \"TIMBERWOLVES\", \"NOP\": \"PELICANS\", \"NYK\": \"KNICKS\",\n",
    "        \"OKC\": \"THUNDER\", \"ORL\": \"MAGIC\", \"PHI\": \"SIXERS\", \"PHX\": \"SUNS\",\n",
    "        \"POR\": \"BLAZERS\", \"SAC\": \"KINGS\", \"SAS\": \"SPURS\", \"TOR\": \"RAPTORS\",\n",
    "        \"UTA\": \"UTAHJAZZ\", \"WAS\": \"WASHINGTONWIZARDS\"\n",
    "    }\n",
    "\n",
    "    df[\"opp_key\"] = df[\"OPPONENT_ABBREVIATION\"].map(abbrev_to_key)\n",
    "    \n",
    "    df = add_shooting_efficiency(df)\n",
    "    df = rolling_player_form(df)\n",
    "\n",
    "    tr = team_daily_ratings(df)\n",
    "    df = df.merge(tr, on=[\"GAME_DATE\",\"TEAM_ABBREVIATION\"], how=\"left\")\n",
    "\n",
    "    oppw = opponent_position_allowances(df)\n",
    "    df = df.merge(oppw, on=[\"GAME_DATE\",\"OPPONENT_ABBREVIATION\"], how=\"left\")\n",
    "\n",
    "    # Merge season-enriched (PER/TS%/USG%/ORtg/DRtg/etc.)\n",
    "    def _norm(s):\n",
    "        s = str(s).strip().lower()\n",
    "        s = unicodedata.normalize(\"NFKD\", s)\n",
    "        s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "        for ch in [\".\",\"'\",\"`\",\"‚Äô\",\"‚Äú\",\"‚Äù\",\",\"]:\n",
    "            s = s.replace(ch,\"\")\n",
    "        return \" \".join(s.split())\n",
    "\n",
    "    tmp = df_enriched_season.copy()\n",
    "    df[\"player_key\"] = df[\"PLAYER_NAME\"].map(_norm)\n",
    "    df[\"team_key\"]   = df[\"TEAM_ABBREVIATION\"].astype(str).str.upper()\n",
    "    tmp[\"player_key\"] = tmp[\"Player\"].map(_norm)\n",
    "    tmp[\"team_key\"]   = tmp[\"Team\"].astype(str).str.upper()\n",
    "\n",
    "    keep_adv = [c for c in [\"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\"Pos\",\"Age\"] if c in tmp.columns]\n",
    "    df = df.merge(tmp[[\"player_key\",\"team_key\"] + keep_adv], on=[\"player_key\",\"team_key\"], how=\"left\")\n",
    "\n",
    "    # Situational flags\n",
    "    if \"MATCHUP\" in df.columns:\n",
    "        df[\"HOME\"] = df[\"MATCHUP\"].str.contains(\" vs. \", regex=False).astype(int)\n",
    "    else:\n",
    "        df[\"HOME\"] = np.nan\n",
    "\n",
    "    # Rest flags + next-game targets (minutes too)\n",
    "    df = df.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "    df[\"prev_date\"] = df.groupby(\"PLAYER_NAME\")[\"GAME_DATE\"].shift(1)\n",
    "    df[\"days_rest\"] = (df[\"GAME_DATE\"] - df[\"prev_date\"]).dt.days\n",
    "    df[\"is_b2b\"]    = (df[\"days_rest\"] == 0).astype(int)\n",
    "\n",
    "    for target, src in [(\"PTS_next\",\"PTS\"), (\"REB_next\",\"REB\"), (\"AST_next\",\"AST\"), (\"MIN_next\",\"MIN\")]:\n",
    "        if src not in df.columns: df[src] = np.nan\n",
    "        df[target] = df.groupby(\"PLAYER_NAME\")[src].shift(-1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600ad827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Total records: 810\n",
      "Columns: ['id', 'name', 'l3', 'l5', 'l10', 'all', 'season_id', 'stats_id', 'position_id', 'stat_type', 'position']\n",
      "  id               name     l3     l5    l10    all  season_id  stats_id  position_id stat_type position\n",
      "0  1      Atlanta Hawks  20.67  21.25  19.92  19.11         25         4            1       PTS        G\n",
      "1  2     Boston Celtics  16.00  16.00  16.35  18.32         25         4            1       PTS        G\n",
      "2  3      Brooklyn Nets  18.50  19.14  18.31  18.90         25         4            1       PTS        G\n",
      "3  4  Charlotte Hornets  18.40  19.40  17.47  17.88         25         4            1       PTS        G\n",
      "4  5      Chicago Bulls  20.57  20.91  20.33  18.75         25         4            1       PTS        G\n",
      "\n",
      "üíæ Saved to defense_vs_position_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# -- cell 12a --\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Base URL\n",
    "url = \"https://www.dunkest.com/api/stats/defense-vs-position\"\n",
    "\n",
    "# Define the combinations with corrected mappings\n",
    "stats_ids = [4, 26, 5]  # 4: pts, 26: reb, 5: ast\n",
    "position_ids = [1, 2, 3]  # 1: G, 2: F, 3: C\n",
    "season_ids = [25, 19, 13]  # 25: 2025‚Äì26, 19: 2024‚Äì25, 13: 2023‚Äì24\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for season_id in season_ids:\n",
    "    for stats_id in stats_ids:\n",
    "        for position_id in position_ids:\n",
    "            params = {\n",
    "                \"season_id\": season_id,\n",
    "                \"stats_id\": stats_id,\n",
    "                \"position_id\": position_id\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(url, params=params, headers=headers)\n",
    "                data = response.json()\n",
    "                \n",
    "                # Add identifiers to each record\n",
    "                for record in data:\n",
    "                    record['season_id'] = season_id   # ‚úÖ FIXED: correct single season_id\n",
    "                    record['stats_id'] = stats_id\n",
    "                    record['position_id'] = position_id\n",
    "\n",
    "                    # Map IDs to readable names\n",
    "                    stat_names = {4: 'PTS', 26: 'REB', 5: 'AST'}\n",
    "                    position_names = {1: 'G', 2: 'F', 3: 'C'}\n",
    "\n",
    "                    record['stat_type'] = stat_names.get(stats_id, f'unknown_{stats_id}')\n",
    "                    record['position'] = position_names.get(position_id, f'unknown_{position_id}')\n",
    "                \n",
    "                all_data.extend(data)\n",
    "                \n",
    "                time.sleep(0.5)  # be polite to API\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error fetching stats_id={stats_id}, position_id={position_id}, season_id={season_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_combined = pd.DataFrame(all_data)\n",
    "\n",
    "print(f\"\\n‚úÖ Total records: {len(df_combined)}\")\n",
    "print(f\"Columns: {df_combined.columns.tolist()}\")\n",
    "print(df_combined.head())\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df_combined.to_csv('defense_vs_position_combined.csv', index=False)\n",
    "print(f\"\\nüíæ Saved to defense_vs_position_combined.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8906fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>FANTASY_PTS</th>\n",
       "      <th>VIDEO_AVAILABLE</th>\n",
       "      <th>OPPONENT_ABBREVIATION</th>\n",
       "      <th>opp_key</th>\n",
       "      <th>TS_game</th>\n",
       "      <th>PTS_roll3</th>\n",
       "      <th>REB_roll3</th>\n",
       "      <th>AST_roll3</th>\n",
       "      <th>MIN_roll3</th>\n",
       "      <th>TS_game_roll3</th>\n",
       "      <th>PTS_roll5</th>\n",
       "      <th>REB_roll5</th>\n",
       "      <th>AST_roll5</th>\n",
       "      <th>MIN_roll5</th>\n",
       "      <th>TS_game_roll5</th>\n",
       "      <th>PTS_roll10</th>\n",
       "      <th>REB_roll10</th>\n",
       "      <th>AST_roll10</th>\n",
       "      <th>MIN_roll10</th>\n",
       "      <th>TS_game_roll10</th>\n",
       "      <th>PTS_roll20</th>\n",
       "      <th>REB_roll20</th>\n",
       "      <th>AST_roll20</th>\n",
       "      <th>MIN_roll20</th>\n",
       "      <th>TS_game_roll20</th>\n",
       "      <th>teamFGA_game</th>\n",
       "      <th>usage_share</th>\n",
       "      <th>usage_share_roll5</th>\n",
       "      <th>ORtg_g_roll5</th>\n",
       "      <th>DRtg_g_roll5</th>\n",
       "      <th>Pace_g_roll5</th>\n",
       "      <th>ORtg_g_roll10</th>\n",
       "      <th>DRtg_g_roll10</th>\n",
       "      <th>Pace_g_roll10</th>\n",
       "      <th>START_POSITION</th>\n",
       "      <th>player_key</th>\n",
       "      <th>team_key</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>HOME</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>is_b2b</th>\n",
       "      <th>PTS_next</th>\n",
       "      <th>REB_next</th>\n",
       "      <th>AST_next</th>\n",
       "      <th>MIN_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300277</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>DAL vs. MEM</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>MEM</td>\n",
       "      <td>GRIZZLIES</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.719871</td>\n",
       "      <td>111.136901</td>\n",
       "      <td>101.024</td>\n",
       "      <td>94.719871</td>\n",
       "      <td>112.807308</td>\n",
       "      <td>99.830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300287</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>DAL vs. OKC</td>\n",
       "      <td>L</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.400</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>OKC</td>\n",
       "      <td>THUNDER</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>87</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>117.187500</td>\n",
       "      <td>109.794310</td>\n",
       "      <td>103.896</td>\n",
       "      <td>117.187500</td>\n",
       "      <td>115.510621</td>\n",
       "      <td>102.764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22301213</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>DAL vs. UTA</td>\n",
       "      <td>W</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>UTA</td>\n",
       "      <td>UTAHJAZZ</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>101</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.062906</td>\n",
       "      <td>139.521640</td>\n",
       "      <td>102.837230</td>\n",
       "      <td>104.280</td>\n",
       "      <td>139.521640</td>\n",
       "      <td>105.263825</td>\n",
       "      <td>103.660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22301226</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>DAL @ POR</td>\n",
       "      <td>W</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>POR</td>\n",
       "      <td>BLAZERS</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>91</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.048538</td>\n",
       "      <td>117.172853</td>\n",
       "      <td>110.954684</td>\n",
       "      <td>103.672</td>\n",
       "      <td>117.172853</td>\n",
       "      <td>115.883515</td>\n",
       "      <td>103.930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300299</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>DAL @ MEM</td>\n",
       "      <td>W</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>MEM</td>\n",
       "      <td>GRIZZLIES</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.628268</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>86</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.044645</td>\n",
       "      <td>118.389897</td>\n",
       "      <td>113.679259</td>\n",
       "      <td>102.652</td>\n",
       "      <td>118.389897</td>\n",
       "      <td>119.208900</td>\n",
       "      <td>102.326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON_ID  PLAYER_ID  PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION         TEAM_NAME   GAME_ID  GAME_DATE      MATCHUP WL  MIN  FGM  FGA  FG_PCT  FG3M  FG3A  \\\n",
       "0      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300277 2023-12-01  DAL vs. MEM  L    4    0    1   0.000     0     1   \n",
       "1      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300287 2023-12-02  DAL vs. OKC  L   19    4   10   0.400     3     7   \n",
       "2      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301213 2023-12-06  DAL vs. UTA  W    7    2    2   1.000     0     0   \n",
       "3      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301226 2023-12-08    DAL @ POR  W    7    1    3   0.333     0     2   \n",
       "4      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300299 2023-12-11    DAL @ MEM  W   14    2    7   0.286     0     4   \n",
       "\n",
       "   FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  FANTASY_PTS  VIDEO_AVAILABLE OPPONENT_ABBREVIATION    opp_key  \\\n",
       "0    0.000    1    2     0.5     0     1    1    0    0    0    0   0    1           4          2.2                1                   MEM  GRIZZLIES   \n",
       "1    0.429    1    2     0.5     0     0    0    2    0    1    0   1   12           9         18.0                1                   OKC    THUNDER   \n",
       "2      NaN    0    0     NaN     1     0    1    0    0    0    0   0    4           7          5.2                1                   UTA   UTAHJAZZ   \n",
       "3    0.000    0    0     NaN     0     1    1    0    0    0    0   1    2          -4          3.2                1                   POR    BLAZERS   \n",
       "4    0.000    0    0     NaN     1     0    1    1    0    0    1   0    4           1          5.7                1                   MEM  GRIZZLIES   \n",
       "\n",
       "    TS_game  PTS_roll3  REB_roll3  AST_roll3  MIN_roll3  TS_game_roll3  PTS_roll5  REB_roll5  AST_roll5  MIN_roll5  TS_game_roll5  PTS_roll10  REB_roll10  \\\n",
       "0  0.265957        NaN        NaN        NaN        NaN            NaN        NaN        NaN        NaN        NaN            NaN         NaN         NaN   \n",
       "1  0.551471   1.000000   1.000000   0.000000        4.0       0.265957   1.000000   1.000000   0.000000       4.00       0.265957    1.000000    1.000000   \n",
       "2  1.000000   6.500000   0.500000   1.000000       11.5       0.408714   6.500000   0.500000   1.000000      11.50       0.408714    6.500000    0.500000   \n",
       "3  0.333333   5.666667   0.666667   0.666667       10.0       0.605809   5.666667   0.666667   0.666667      10.00       0.605809    5.666667    0.666667   \n",
       "4  0.285714   6.000000   0.666667   0.666667       11.0       0.628268   4.750000   0.750000   0.500000       9.25       0.537690    4.750000    0.750000   \n",
       "\n",
       "   AST_roll10  MIN_roll10  TS_game_roll10  PTS_roll20  REB_roll20  AST_roll20  MIN_roll20  TS_game_roll20  teamFGA_game  usage_share  usage_share_roll5  \\\n",
       "0         NaN         NaN             NaN         NaN         NaN         NaN         NaN             NaN            92     0.010870                NaN   \n",
       "1    0.000000        4.00        0.265957    1.000000    1.000000    0.000000        4.00        0.265957            87     0.114943           0.010870   \n",
       "2    1.000000       11.50        0.408714    6.500000    0.500000    1.000000       11.50        0.408714           101     0.019802           0.062906   \n",
       "3    0.666667       10.00        0.605809    5.666667    0.666667    0.666667       10.00        0.605809            91     0.032967           0.048538   \n",
       "4    0.500000        9.25        0.537690    4.750000    0.750000    0.500000        9.25        0.537690            86     0.081395           0.044645   \n",
       "\n",
       "   ORtg_g_roll5  DRtg_g_roll5  Pace_g_roll5  ORtg_g_roll10  DRtg_g_roll10  Pace_g_roll10  START_POSITION player_key team_key   PER    TS%  USG%  WS/48  BPM  \\\n",
       "0     94.719871    111.136901       101.024      94.719871     112.807308         99.830             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "1    117.187500    109.794310       103.896     117.187500     115.510621        102.764             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "2    139.521640    102.837230       104.280     139.521640     105.263825        103.660             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "3    117.172853    110.954684       103.672     117.172853     115.883515        103.930             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "4    118.389897    113.679259       102.652     118.389897     119.208900        102.326             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "\n",
       "   VORP Pos   Age  HOME  prev_date  days_rest  is_b2b  PTS_next  REB_next  AST_next  MIN_next  \n",
       "0  -0.2  SG  23.0     1        NaT        NaN       0      12.0       0.0       2.0      19.0  \n",
       "1  -0.2  SG  23.0     1 2023-12-01        1.0       0       4.0       1.0       0.0       7.0  \n",
       "2  -0.2  SG  23.0     1 2023-12-02        4.0       0       2.0       1.0       0.0       7.0  \n",
       "3  -0.2  SG  23.0     0 2023-12-06        2.0       0       4.0       1.0       1.0      14.0  \n",
       "4  -0.2  SG  23.0     0 2023-12-08        3.0       0       0.0       0.0       0.0       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Cell 11: Load logs + build features_all with season weights ------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR   = \"data_raw\"\n",
    "ENRICH_DIR = \"data_enriched\"\n",
    "\n",
    "paths = {\n",
    "    \"logs_2324\": os.path.join(DATA_DIR, \"nba_boxscores_2023-24.csv\"),\n",
    "    \"logs_2425\": os.path.join(DATA_DIR, \"nba_boxscores_2024-25.csv\"),\n",
    "    \"logs_2526\": os.path.join(DATA_DIR, \"nba_boxscores_2025-26.csv\"),\n",
    "    \"enr_2324\":  os.path.join(ENRICH_DIR, \"nba_player_stats_2023_24_enriched.csv\"),\n",
    "    \"enr_2425\":  os.path.join(ENRICH_DIR, \"nba_player_stats_2024_25_enriched.csv\"),\n",
    "    \"enr_2526\":  os.path.join(ENRICH_DIR, \"nba_player_stats_2025_26_enriched.csv\")\n",
    "}\n",
    "\n",
    "# Check all required files exist\n",
    "for k, p in paths.items():\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Missing required file {p} (from earlier cells).\")\n",
    "\n",
    "# Load boxscores + enriched stats\n",
    "logs_2324     = pd.read_csv(paths[\"logs_2324\"])\n",
    "logs_2425     = pd.read_csv(paths[\"logs_2425\"])\n",
    "logs_2526     = pd.read_csv(paths[\"logs_2526\"])\n",
    "enriched_2324 = pd.read_csv(paths[\"enr_2324\"])\n",
    "enriched_2425 = pd.read_csv(paths[\"enr_2425\"])\n",
    "enriched_2526 = pd.read_csv(paths[\"enr_2526\"])\n",
    "\n",
    "# Apply weights to enriched stats before combining\n",
    "enriched_2324[\"season_weight\"] = 0.1\n",
    "enriched_2425[\"season_weight\"] = 0.3\n",
    "enriched_2526[\"season_weight\"] = 0.6\n",
    "\n",
    "# Optionally mark source season (if needed later)\n",
    "enriched_2324[\"season\"] = \"2023-24\"\n",
    "enriched_2425[\"season\"] = \"2024-25\"\n",
    "enriched_2526[\"season\"] = \"2025-26\"\n",
    "\n",
    "# Feature engineering\n",
    "feat_2324 = assemble_player_game_features(logs_2324, enriched_2324)\n",
    "feat_2425 = assemble_player_game_features(logs_2425, enriched_2425)\n",
    "feat_2526 = assemble_player_game_features(logs_2526, enriched_2526)\n",
    "\n",
    "# Combine all seasons\n",
    "features_all = pd.concat([feat_2324, feat_2425, feat_2526], ignore_index=True)\n",
    "\n",
    "# Parse game dates\n",
    "if \"GAME_DATE\" in features_all.columns:\n",
    "    features_all[\"GAME_DATE\"] = pd.to_datetime(features_all[\"GAME_DATE\"])\n",
    "\n",
    "display(features_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8036d12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>l3</th>\n",
       "      <th>l5</th>\n",
       "      <th>l10</th>\n",
       "      <th>all</th>\n",
       "      <th>season_id</th>\n",
       "      <th>stats_id</th>\n",
       "      <th>position_id</th>\n",
       "      <th>stat_type</th>\n",
       "      <th>position</th>\n",
       "      <th>team_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>20.67</td>\n",
       "      <td>21.25</td>\n",
       "      <td>19.92</td>\n",
       "      <td>19.11</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>PTS</td>\n",
       "      <td>PG</td>\n",
       "      <td>ATLANTAHAWKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.35</td>\n",
       "      <td>18.32</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>PTS</td>\n",
       "      <td>PG</td>\n",
       "      <td>BOSTONCELTICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>18.50</td>\n",
       "      <td>19.14</td>\n",
       "      <td>18.31</td>\n",
       "      <td>18.90</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>PTS</td>\n",
       "      <td>PG</td>\n",
       "      <td>BROOKLYNNETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>18.40</td>\n",
       "      <td>19.40</td>\n",
       "      <td>17.47</td>\n",
       "      <td>17.88</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>PTS</td>\n",
       "      <td>PG</td>\n",
       "      <td>CHARLOTTEHORNETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>20.57</td>\n",
       "      <td>20.91</td>\n",
       "      <td>20.33</td>\n",
       "      <td>18.75</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>PTS</td>\n",
       "      <td>PG</td>\n",
       "      <td>CHICAGOBULLS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id               name     l3     l5    l10    all  season_id  stats_id  position_id stat_type position          team_key\n",
       "0  1      Atlanta Hawks  20.67  21.25  19.92  19.11         25         4            1       PTS       PG      ATLANTAHAWKS\n",
       "1  2     Boston Celtics  16.00  16.00  16.35  18.32         25         4            1       PTS       PG     BOSTONCELTICS\n",
       "2  3      Brooklyn Nets  18.50  19.14  18.31  18.90         25         4            1       PTS       PG      BROOKLYNNETS\n",
       "3  4  Charlotte Hornets  18.40  19.40  17.47  17.88         25         4            1       PTS       PG  CHARLOTTEHORNETS\n",
       "4  5      Chicago Bulls  20.57  20.91  20.33  18.75         25         4            1       PTS       PG      CHICAGOBULLS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>FANTASY_PTS</th>\n",
       "      <th>VIDEO_AVAILABLE</th>\n",
       "      <th>OPPONENT_ABBREVIATION</th>\n",
       "      <th>opp_key</th>\n",
       "      <th>TS_game</th>\n",
       "      <th>PTS_roll3</th>\n",
       "      <th>REB_roll3</th>\n",
       "      <th>AST_roll3</th>\n",
       "      <th>MIN_roll3</th>\n",
       "      <th>TS_game_roll3</th>\n",
       "      <th>PTS_roll5</th>\n",
       "      <th>REB_roll5</th>\n",
       "      <th>AST_roll5</th>\n",
       "      <th>MIN_roll5</th>\n",
       "      <th>TS_game_roll5</th>\n",
       "      <th>PTS_roll10</th>\n",
       "      <th>REB_roll10</th>\n",
       "      <th>AST_roll10</th>\n",
       "      <th>MIN_roll10</th>\n",
       "      <th>TS_game_roll10</th>\n",
       "      <th>PTS_roll20</th>\n",
       "      <th>REB_roll20</th>\n",
       "      <th>AST_roll20</th>\n",
       "      <th>MIN_roll20</th>\n",
       "      <th>TS_game_roll20</th>\n",
       "      <th>teamFGA_game</th>\n",
       "      <th>usage_share</th>\n",
       "      <th>usage_share_roll5</th>\n",
       "      <th>ORtg_g_roll5</th>\n",
       "      <th>DRtg_g_roll5</th>\n",
       "      <th>Pace_g_roll5</th>\n",
       "      <th>ORtg_g_roll10</th>\n",
       "      <th>DRtg_g_roll10</th>\n",
       "      <th>Pace_g_roll10</th>\n",
       "      <th>START_POSITION</th>\n",
       "      <th>player_key</th>\n",
       "      <th>team_key</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>HOME</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>is_b2b</th>\n",
       "      <th>PTS_next</th>\n",
       "      <th>REB_next</th>\n",
       "      <th>AST_next</th>\n",
       "      <th>MIN_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300277</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>DAL vs. MEM</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>MEM</td>\n",
       "      <td>GRIZZLIES</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.719871</td>\n",
       "      <td>111.136901</td>\n",
       "      <td>101.024</td>\n",
       "      <td>94.719871</td>\n",
       "      <td>112.807308</td>\n",
       "      <td>99.830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300287</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>DAL vs. OKC</td>\n",
       "      <td>L</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.400</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>OKC</td>\n",
       "      <td>THUNDER</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>87</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>117.187500</td>\n",
       "      <td>109.794310</td>\n",
       "      <td>103.896</td>\n",
       "      <td>117.187500</td>\n",
       "      <td>115.510621</td>\n",
       "      <td>102.764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22301213</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>DAL vs. UTA</td>\n",
       "      <td>W</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>UTA</td>\n",
       "      <td>UTAHJAZZ</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>101</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.062906</td>\n",
       "      <td>139.521640</td>\n",
       "      <td>102.837230</td>\n",
       "      <td>104.280</td>\n",
       "      <td>139.521640</td>\n",
       "      <td>105.263825</td>\n",
       "      <td>103.660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22301226</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>DAL @ POR</td>\n",
       "      <td>W</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>POR</td>\n",
       "      <td>BLAZERS</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>91</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.048538</td>\n",
       "      <td>117.172853</td>\n",
       "      <td>110.954684</td>\n",
       "      <td>103.672</td>\n",
       "      <td>117.172853</td>\n",
       "      <td>115.883515</td>\n",
       "      <td>103.930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300299</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>DAL @ MEM</td>\n",
       "      <td>W</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>MEM</td>\n",
       "      <td>GRIZZLIES</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.628268</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>86</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.044645</td>\n",
       "      <td>118.389897</td>\n",
       "      <td>113.679259</td>\n",
       "      <td>102.652</td>\n",
       "      <td>118.389897</td>\n",
       "      <td>119.208900</td>\n",
       "      <td>102.326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>DAL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON_ID  PLAYER_ID  PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION         TEAM_NAME   GAME_ID  GAME_DATE      MATCHUP WL  MIN  FGM  FGA  FG_PCT  FG3M  FG3A  \\\n",
       "0      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300277 2023-12-01  DAL vs. MEM  L    4    0    1   0.000     0     1   \n",
       "1      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300287 2023-12-02  DAL vs. OKC  L   19    4   10   0.400     3     7   \n",
       "2      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301213 2023-12-06  DAL vs. UTA  W    7    2    2   1.000     0     0   \n",
       "3      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301226 2023-12-08    DAL @ POR  W    7    1    3   0.333     0     2   \n",
       "4      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300299 2023-12-11    DAL @ MEM  W   14    2    7   0.286     0     4   \n",
       "\n",
       "   FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  FANTASY_PTS  VIDEO_AVAILABLE OPPONENT_ABBREVIATION    opp_key  \\\n",
       "0    0.000    1    2     0.5     0     1    1    0    0    0    0   0    1           4          2.2                1                   MEM  GRIZZLIES   \n",
       "1    0.429    1    2     0.5     0     0    0    2    0    1    0   1   12           9         18.0                1                   OKC    THUNDER   \n",
       "2      NaN    0    0     NaN     1     0    1    0    0    0    0   0    4           7          5.2                1                   UTA   UTAHJAZZ   \n",
       "3    0.000    0    0     NaN     0     1    1    0    0    0    0   1    2          -4          3.2                1                   POR    BLAZERS   \n",
       "4    0.000    0    0     NaN     1     0    1    1    0    0    1   0    4           1          5.7                1                   MEM  GRIZZLIES   \n",
       "\n",
       "    TS_game  PTS_roll3  REB_roll3  AST_roll3  MIN_roll3  TS_game_roll3  PTS_roll5  REB_roll5  AST_roll5  MIN_roll5  TS_game_roll5  PTS_roll10  REB_roll10  \\\n",
       "0  0.265957        NaN        NaN        NaN        NaN            NaN        NaN        NaN        NaN        NaN            NaN         NaN         NaN   \n",
       "1  0.551471   1.000000   1.000000   0.000000        4.0       0.265957   1.000000   1.000000   0.000000       4.00       0.265957    1.000000    1.000000   \n",
       "2  1.000000   6.500000   0.500000   1.000000       11.5       0.408714   6.500000   0.500000   1.000000      11.50       0.408714    6.500000    0.500000   \n",
       "3  0.333333   5.666667   0.666667   0.666667       10.0       0.605809   5.666667   0.666667   0.666667      10.00       0.605809    5.666667    0.666667   \n",
       "4  0.285714   6.000000   0.666667   0.666667       11.0       0.628268   4.750000   0.750000   0.500000       9.25       0.537690    4.750000    0.750000   \n",
       "\n",
       "   AST_roll10  MIN_roll10  TS_game_roll10  PTS_roll20  REB_roll20  AST_roll20  MIN_roll20  TS_game_roll20  teamFGA_game  usage_share  usage_share_roll5  \\\n",
       "0         NaN         NaN             NaN         NaN         NaN         NaN         NaN             NaN            92     0.010870                NaN   \n",
       "1    0.000000        4.00        0.265957    1.000000    1.000000    0.000000        4.00        0.265957            87     0.114943           0.010870   \n",
       "2    1.000000       11.50        0.408714    6.500000    0.500000    1.000000       11.50        0.408714           101     0.019802           0.062906   \n",
       "3    0.666667       10.00        0.605809    5.666667    0.666667    0.666667       10.00        0.605809            91     0.032967           0.048538   \n",
       "4    0.500000        9.25        0.537690    4.750000    0.750000    0.500000        9.25        0.537690            86     0.081395           0.044645   \n",
       "\n",
       "   ORtg_g_roll5  DRtg_g_roll5  Pace_g_roll5  ORtg_g_roll10  DRtg_g_roll10  Pace_g_roll10  START_POSITION player_key team_key   PER    TS%  USG%  WS/48  BPM  \\\n",
       "0     94.719871    111.136901       101.024      94.719871     112.807308         99.830             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "1    117.187500    109.794310       103.896     117.187500     115.510621        102.764             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "2    139.521640    102.837230       104.280     139.521640     105.263825        103.660             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "3    117.172853    110.954684       103.672     117.172853     115.883515        103.930             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "4    118.389897    113.679259       102.652     118.389897     119.208900        102.326             NaN  aj lawson      DAL  11.2  0.519  20.0  0.036 -4.6   \n",
       "\n",
       "   VORP Pos   Age  HOME  prev_date  days_rest  is_b2b  PTS_next  REB_next  AST_next  MIN_next  \n",
       "0  -0.2  SG  23.0     1        NaT        NaN       0      12.0       0.0       2.0      19.0  \n",
       "1  -0.2  SG  23.0     1 2023-12-01        1.0       0       4.0       1.0       0.0       7.0  \n",
       "2  -0.2  SG  23.0     1 2023-12-02        4.0       0       2.0       1.0       0.0       7.0  \n",
       "3  -0.2  SG  23.0     0 2023-12-06        2.0       0       4.0       1.0       1.0      14.0  \n",
       "4  -0.2  SG  23.0     0 2023-12-08        3.0       0       0.0       0.0       0.0       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>FANTASY_PTS</th>\n",
       "      <th>VIDEO_AVAILABLE</th>\n",
       "      <th>OPPONENT_ABBREVIATION</th>\n",
       "      <th>opp_key</th>\n",
       "      <th>TS_game</th>\n",
       "      <th>PTS_roll3</th>\n",
       "      <th>REB_roll3</th>\n",
       "      <th>AST_roll3</th>\n",
       "      <th>MIN_roll3</th>\n",
       "      <th>TS_game_roll3</th>\n",
       "      <th>PTS_roll5</th>\n",
       "      <th>REB_roll5</th>\n",
       "      <th>AST_roll5</th>\n",
       "      <th>MIN_roll5</th>\n",
       "      <th>TS_game_roll5</th>\n",
       "      <th>PTS_roll10</th>\n",
       "      <th>REB_roll10</th>\n",
       "      <th>AST_roll10</th>\n",
       "      <th>MIN_roll10</th>\n",
       "      <th>TS_game_roll10</th>\n",
       "      <th>PTS_roll20</th>\n",
       "      <th>REB_roll20</th>\n",
       "      <th>AST_roll20</th>\n",
       "      <th>MIN_roll20</th>\n",
       "      <th>TS_game_roll20</th>\n",
       "      <th>teamFGA_game</th>\n",
       "      <th>usage_share</th>\n",
       "      <th>usage_share_roll5</th>\n",
       "      <th>ORtg_g_roll5</th>\n",
       "      <th>DRtg_g_roll5</th>\n",
       "      <th>Pace_g_roll5</th>\n",
       "      <th>ORtg_g_roll10</th>\n",
       "      <th>DRtg_g_roll10</th>\n",
       "      <th>Pace_g_roll10</th>\n",
       "      <th>START_POSITION</th>\n",
       "      <th>player_key</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>HOME</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>is_b2b</th>\n",
       "      <th>PTS_next</th>\n",
       "      <th>REB_next</th>\n",
       "      <th>AST_next</th>\n",
       "      <th>MIN_next</th>\n",
       "      <th>dvp_position</th>\n",
       "      <th>season</th>\n",
       "      <th>matchup_score_pts</th>\n",
       "      <th>matchup_score_reb</th>\n",
       "      <th>matchup_score_ast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300277</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>DAL vs. MEM</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>MEM</td>\n",
       "      <td>MEM</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.719871</td>\n",
       "      <td>111.136901</td>\n",
       "      <td>101.024</td>\n",
       "      <td>94.719871</td>\n",
       "      <td>112.807308</td>\n",
       "      <td>99.830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>2023-2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300287</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>DAL vs. OKC</td>\n",
       "      <td>L</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.400</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>OKC</td>\n",
       "      <td>OKC</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>87</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>117.187500</td>\n",
       "      <td>109.794310</td>\n",
       "      <td>103.896</td>\n",
       "      <td>117.187500</td>\n",
       "      <td>115.510621</td>\n",
       "      <td>102.764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>2023-2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22301213</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>DAL vs. UTA</td>\n",
       "      <td>W</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>UTA</td>\n",
       "      <td>UTA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.408714</td>\n",
       "      <td>101</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.062906</td>\n",
       "      <td>139.521640</td>\n",
       "      <td>102.837230</td>\n",
       "      <td>104.280</td>\n",
       "      <td>139.521640</td>\n",
       "      <td>105.263825</td>\n",
       "      <td>103.660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>2023-2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22301226</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>DAL @ POR</td>\n",
       "      <td>W</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>POR</td>\n",
       "      <td>POR</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.605809</td>\n",
       "      <td>91</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.048538</td>\n",
       "      <td>117.172853</td>\n",
       "      <td>110.954684</td>\n",
       "      <td>103.672</td>\n",
       "      <td>117.172853</td>\n",
       "      <td>115.883515</td>\n",
       "      <td>103.930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>2023-2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22023</td>\n",
       "      <td>1630639</td>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>22300299</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>DAL @ MEM</td>\n",
       "      <td>W</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>MEM</td>\n",
       "      <td>MEM</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.628268</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.537690</td>\n",
       "      <td>86</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.044645</td>\n",
       "      <td>118.389897</td>\n",
       "      <td>113.679259</td>\n",
       "      <td>102.652</td>\n",
       "      <td>118.389897</td>\n",
       "      <td>119.208900</td>\n",
       "      <td>102.326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aj lawson</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.519</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>2023-2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON_ID  PLAYER_ID  PLAYER_NAME     TEAM_ID TEAM_ABBREVIATION         TEAM_NAME   GAME_ID  GAME_DATE      MATCHUP WL  MIN  FGM  FGA  FG_PCT  FG3M  FG3A  \\\n",
       "0      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300277 2023-12-01  DAL vs. MEM  L    4    0    1   0.000     0     1   \n",
       "1      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300287 2023-12-02  DAL vs. OKC  L   19    4   10   0.400     3     7   \n",
       "2      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301213 2023-12-06  DAL vs. UTA  W    7    2    2   1.000     0     0   \n",
       "3      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22301226 2023-12-08    DAL @ POR  W    7    1    3   0.333     0     2   \n",
       "4      22023    1630639  A.J. Lawson  1610612742               DAL  Dallas Mavericks  22300299 2023-12-11    DAL @ MEM  W   14    2    7   0.286     0     4   \n",
       "\n",
       "   FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  FANTASY_PTS  VIDEO_AVAILABLE OPPONENT_ABBREVIATION opp_key   TS_game  \\\n",
       "0    0.000    1    2     0.5     0     1    1    0    0    0    0   0    1           4          2.2                1                   MEM     MEM  0.265957   \n",
       "1    0.429    1    2     0.5     0     0    0    2    0    1    0   1   12           9         18.0                1                   OKC     OKC  0.551471   \n",
       "2      NaN    0    0     NaN     1     0    1    0    0    0    0   0    4           7          5.2                1                   UTA     UTA  1.000000   \n",
       "3    0.000    0    0     NaN     0     1    1    0    0    0    0   1    2          -4          3.2                1                   POR     POR  0.333333   \n",
       "4    0.000    0    0     NaN     1     0    1    1    0    0    1   0    4           1          5.7                1                   MEM     MEM  0.285714   \n",
       "\n",
       "   PTS_roll3  REB_roll3  AST_roll3  MIN_roll3  TS_game_roll3  PTS_roll5  REB_roll5  AST_roll5  MIN_roll5  TS_game_roll5  PTS_roll10  REB_roll10  AST_roll10  \\\n",
       "0        NaN        NaN        NaN        NaN            NaN        NaN        NaN        NaN        NaN            NaN         NaN         NaN         NaN   \n",
       "1   1.000000   1.000000   0.000000        4.0       0.265957   1.000000   1.000000   0.000000       4.00       0.265957    1.000000    1.000000    0.000000   \n",
       "2   6.500000   0.500000   1.000000       11.5       0.408714   6.500000   0.500000   1.000000      11.50       0.408714    6.500000    0.500000    1.000000   \n",
       "3   5.666667   0.666667   0.666667       10.0       0.605809   5.666667   0.666667   0.666667      10.00       0.605809    5.666667    0.666667    0.666667   \n",
       "4   6.000000   0.666667   0.666667       11.0       0.628268   4.750000   0.750000   0.500000       9.25       0.537690    4.750000    0.750000    0.500000   \n",
       "\n",
       "   MIN_roll10  TS_game_roll10  PTS_roll20  REB_roll20  AST_roll20  MIN_roll20  TS_game_roll20  teamFGA_game  usage_share  usage_share_roll5  ORtg_g_roll5  \\\n",
       "0         NaN             NaN         NaN         NaN         NaN         NaN             NaN            92     0.010870                NaN     94.719871   \n",
       "1        4.00        0.265957    1.000000    1.000000    0.000000        4.00        0.265957            87     0.114943           0.010870    117.187500   \n",
       "2       11.50        0.408714    6.500000    0.500000    1.000000       11.50        0.408714           101     0.019802           0.062906    139.521640   \n",
       "3       10.00        0.605809    5.666667    0.666667    0.666667       10.00        0.605809            91     0.032967           0.048538    117.172853   \n",
       "4        9.25        0.537690    4.750000    0.750000    0.500000        9.25        0.537690            86     0.081395           0.044645    118.389897   \n",
       "\n",
       "   DRtg_g_roll5  Pace_g_roll5  ORtg_g_roll10  DRtg_g_roll10  Pace_g_roll10  START_POSITION player_key   PER    TS%  USG%  WS/48  BPM  VORP Pos   Age  HOME  \\\n",
       "0    111.136901       101.024      94.719871     112.807308         99.830             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     1   \n",
       "1    109.794310       103.896     117.187500     115.510621        102.764             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     1   \n",
       "2    102.837230       104.280     139.521640     105.263825        103.660             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     1   \n",
       "3    110.954684       103.672     117.172853     115.883515        103.930             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     0   \n",
       "4    113.679259       102.652     118.389897     119.208900        102.326             NaN  aj lawson  11.2  0.519  20.0  0.036 -4.6  -0.2  SG  23.0     0   \n",
       "\n",
       "   prev_date  days_rest  is_b2b  PTS_next  REB_next  AST_next  MIN_next dvp_position     season matchup_score_pts matchup_score_reb matchup_score_ast  \n",
       "0        NaT        NaN       0      12.0       0.0       2.0      19.0           SG  2023-2024               NaN               NaN               NaN  \n",
       "1 2023-12-01        1.0       0       4.0       1.0       0.0       7.0           SG  2023-2024               NaN               NaN               NaN  \n",
       "2 2023-12-02        4.0       0       2.0       1.0       0.0       7.0           SG  2023-2024               NaN               NaN               NaN  \n",
       "3 2023-12-06        2.0       0       4.0       1.0       1.0      14.0           SG  2023-2024               NaN               NaN               NaN  \n",
       "4 2023-12-08        3.0       0       0.0       0.0       0.0       0.0           SG  2023-2024               NaN               NaN               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üß± Normalize team and position keys in matchup_df\n",
    "df_combined[\"team_key\"] = df_combined[\"name\"].str.upper().str.replace(\" \", \"\")\n",
    "df_combined[\"position\"] = df_combined[\"position\"].map({\"G\": \"PG\", \"F\": \"SF\", \"C\": \"C\"})\n",
    "display(df_combined.head())\n",
    "display(features_all.head())\n",
    "# üß± Map season_id to readable string\n",
    "season_id_map = {\n",
    "    25: \"2025-26\",\n",
    "    19: \"2024-25\",\n",
    "    13: \"2023-24\"\n",
    "}\n",
    "df_combined[\"season\"] = df_combined[\"season_id\"].map(season_id_map)\n",
    "\n",
    "# üß± Normalize keys in features_all\n",
    "features_all[\"opp_key\"] = features_all[\"OPPONENT_ABBREVIATION\"].astype(str).str.upper().str.replace(\" \", \"\")\n",
    "features_all[\"dvp_position\"] = features_all[\"Pos\"].copy()\n",
    "features_all[\"season\"] = features_all[\"SEASON_ID\"].astype(int).apply(lambda x: f\"{x - 20000}-{x - 19999}\")\n",
    "features_all[\"season\"] = features_all[\"season\"].astype(str)\n",
    "\n",
    "# üß© Safe merge function that drops prior columns if they exist\n",
    "def merge_matchup_stat(df_base, stat: str, suffix: str):\n",
    "    score_col = f\"matchup_score_{suffix}\"\n",
    "\n",
    "    # Remove any previously merged version of the same stat\n",
    "    df_base = df_base.drop(columns=[score_col, \"team_key\", \"position\"], errors=\"ignore\")\n",
    "\n",
    "    # Prepare stat-specific df\n",
    "    df_stat = df_combined[df_combined[\"stat_type\"] == stat].copy()\n",
    "    df_stat = df_stat.rename(columns={\"all\": score_col})\n",
    "    df_stat = df_stat[[\"team_key\", \"position\", \"season\", score_col]]\n",
    "\n",
    "    # Merge\n",
    "    df_merged = pd.merge(\n",
    "        df_base,\n",
    "        df_stat,\n",
    "        left_on=[\"opp_key\", \"dvp_position\", \"season\"],\n",
    "        right_on=[\"team_key\", \"position\", \"season\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return df_merged.drop(columns=[\"team_key\", \"position\"], errors=\"ignore\")\n",
    "\n",
    "# ‚úÖ Apply matchup stats\n",
    "features_all = merge_matchup_stat(features_all, \"PTS\", \"pts\")\n",
    "features_all = merge_matchup_stat(features_all, \"REB\", \"reb\")\n",
    "features_all = merge_matchup_stat(features_all, \"AST\", \"ast\")\n",
    "\n",
    "# üßπ Keep only the final matchup score columns\n",
    "features_all = features_all.drop(columns=[\n",
    "    col for col in features_all.columns \n",
    "    if col.startswith(\"matchup_score_\") and col not in [\n",
    "        \"matchup_score_pts\", \"matchup_score_reb\", \"matchup_score_ast\"\n",
    "    ]\n",
    "])\n",
    "\n",
    "\n",
    "# ‚úÖ Check result\n",
    "display(features_all.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab68815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 00:00:00\n",
      "2025-11-18 20:34:31.808878\n"
     ]
    }
   ],
   "source": [
    "# cell 13a: Add data validation checks\n",
    "def validate_features(features_df):\n",
    "    \"\"\"Validate feature dataframe for modeling\"\"\"\n",
    "    required_cols = ['PLAYER_NAME', 'GAME_DATE', 'PTS', 'REB', 'AST', 'MIN']\n",
    "    missing_cols = [col for col in required_cols if col not in features_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Check for data freshness\n",
    "    latest_date = pd.to_datetime(features_all['GAME_DATE']).max()\n",
    "    days_old = (pd.Timestamp.now() - latest_date).days\n",
    "    if days_old > 30:\n",
    "        print(f\"‚ö†Ô∏è Warning: Data is {days_old} days old\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Add to Cell 12 after loading features_all\n",
    "validate_features(features_all)\n",
    "\n",
    "print(pd.to_datetime(features_all['GAME_DATE']).max())\n",
    "print(pd.Timestamp.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa474de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ minutes_today shape: (756, 19)\n",
      " PLAYER_ID        PLAYER_NAME team opponent  is_starter  start_prob  may_not_play  injury_prob  teammates_out  missing_usage_share  MIN_roll5  MIN_roll10  days_rest  is_b2b  HOME  USG%   TS%  PER   BPM\n",
      "   1630639        A.J. Lawson  TOR      SAS           0         0.7             0          0.0            0.0                  0.0      24.60   18.900000        2.0       0     0  20.0 0.542 12.7  -2.5\n",
      "   1631260           AJ Green  MIL      CLE           0         0.7             0          0.0            0.0                  0.0      26.20   27.500000        2.0       0     0  12.8 0.713 10.7  -2.2\n",
      "   1631100         AJ Griffin  ATL      IND           0         0.7             0          0.0            1.0                 29.5       6.00    7.700000        2.0       0     0  17.3 0.382  1.2  -9.6\n",
      "   1642358         AJ Johnson  WAS      BKN           0         0.7             0          0.0            0.0                  0.0       5.80    9.555556        9.0       0     1  15.0 0.274  1.3 -12.8\n",
      "    203932       Aaron Gordon  DEN      CHI           0         0.7             0          0.0            0.0                  0.0      30.40   29.500000        2.0       0     1  22.7 0.681 20.8   2.9\n",
      "   1628988      Aaron Holiday  HOU      ORL           0         0.7             0          0.0            0.0                  0.0       7.20   15.555556        2.0       0     1  19.1 0.751 17.0   1.8\n",
      "   1630174      Aaron Nesmith  IND      PHX           0         0.7             0          0.0            0.0                  0.0      31.80   31.400000        2.0       0     0  20.7 0.518 12.2  -2.3\n",
      "   1630598      Aaron Wiggins  OKC      POR           0         0.7             0          0.0            0.0                  0.0      27.40   28.111111        1.0       0     0  21.5 0.578 14.9   0.8\n",
      "   1642846         Ace Bailey  UTA      CHI           1         0.7             0          0.0            0.0                  0.0      25.80   21.800000        3.0       0     1  19.3 0.512 10.0  -5.5\n",
      "   1641745       Adam Flagler  OKC      NOP           0         0.7             0          0.0            0.0                  0.0       8.40    7.700000        2.0       0     0  21.1 0.335  3.7 -10.3\n",
      "   1641766       Adama Sanogo  CHI      CHA           0         0.7             0          0.0            0.0                  0.0      10.25    6.444444       32.0       0     1  15.9 0.571 15.2  -2.6\n",
      "   1641737          Adem Bona  PHI      DET           0         0.7             0          0.0            0.0                  0.0      14.60   15.300000        3.0       0     0   8.0 0.481  9.7  -2.4\n",
      "   1629678  Admiral Schofield  ORL      MIL           0         0.7             0          0.0            0.0                  0.0       4.40    3.400000        3.0       0     0  16.6 0.484  6.0  -4.9\n",
      "   1642876        Adou Thiero  LAL      MIL           0         0.7             0          0.0            0.0                  0.0      12.75   15.666667        NaN       0     0  16.2 1.064 37.1  15.5\n",
      "   1642349      Ajay Mitchell  OKC      NOP           0         0.7             0          0.0            0.0                  0.0      30.20   28.600000        2.0       0     0  25.4 0.547 17.3   0.7\n",
      "    201143         Al Horford  GSW      NOP           0         0.7             0          0.0            0.0                  0.0      21.40   21.777778        2.0       0     0  14.1 0.458  7.9  -2.8\n",
      "    202692         Alec Burks  MIA      NOP           0         0.7             0          0.0            0.0                  0.0      20.20   18.700000        2.0       0     0  16.5 0.608 12.8   0.3\n",
      "   1630197 Aleksej Pokusevski  CHA      CLE           0         0.7             0          0.0            0.0                  0.0      19.20   19.400000        2.0       0     0  17.6 0.552 14.5  -0.5\n",
      "   1627936        Alex Caruso  OKC      CHA           0         0.7             0          0.0            0.0                  0.0      19.80   20.222222        3.0       0     0  15.0 0.531 13.9   3.0\n",
      "   1642505         Alex Ducas  OKC      NOP           0         0.7             0          0.0            0.0                  0.0       7.80    7.300000        2.0       0     0  11.8 0.583 10.1  -2.0\n",
      "   1641788         Alex Fudge  DAL      OKC           0         0.7             0          0.0            0.0                  0.0       4.20   17.444444        2.0       0     0  16.5 0.611 16.2   1.7\n",
      "    203458           Alex Len  LAL      POR           0         0.7             0          0.0            0.0                  0.0      13.60   11.000000       22.0       0     0  11.8 0.463  5.3  -8.9\n",
      "   1642024         Alex Reese  PHI      WAS           0         0.7             0          0.0            0.0                  0.0      17.60   17.300000        2.0       0     0  13.1 0.635 13.6  -1.4\n",
      "   1642259          Alex Sarr  WAS      BKN           0         0.7             0          0.0            0.0                  0.0      31.80   30.100000        4.0       0     1  26.1 0.578 21.1   2.1\n",
      "   1631214   Alondes Williams  DET      ORL           0         0.7             0          0.0            1.0                 26.0      28.75   28.555556        NaN       0     0   NaN   NaN  NaN   NaN\n",
      "   1630578     Alperen Sengun  HOU      ORL           0         0.7             0          0.0            0.0                  0.0      35.00   34.900000        2.0       0     1   NaN   NaN  NaN   NaN\n",
      "   1641735       Amari Bailey  CHA      CLE           0         0.7             0          0.0            0.0                  0.0       5.20    4.555556        2.0       0     0  21.1 0.425  9.7  -8.3\n",
      "   1642873     Amari Williams  BOS      HOU           0         0.7             0          0.0            0.0                  0.0      26.25   31.333333        8.0       0     1  12.1 0.500 21.7   7.2\n",
      "   1641708      Amen Thompson  HOU      ORL           0         0.7             0          0.0            0.0                  0.0      36.40   34.800000        2.0       0     1  21.3 0.534 16.1   0.0\n",
      "   1629599        Amir Coffey  MIL      LAL           0         0.7             0          0.0            0.0                  0.0      11.20   11.100000        3.0       0     1   7.2 0.517  5.8  -5.5\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 12: Build TODAY minutes features (starter/injury ‚Üí minutes signals) --\n",
    "import os, re, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Expect df_lineups (Cell 3), mnp_df (Cell 5), and starter_flags_df / injury_flags_df (Cell 7)\n",
    "assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
    "    \"features_all must exist (Cell 12).\"\n",
    "assert 'starter_flags_df' in globals(), \"starter_flags_df missing (Cell 7).\"\n",
    "assert 'injury_flags_df' in globals(),  \"injury_flags_df missing (Cell 7).\"\n",
    "\n",
    "def _norm_player(name: str) -> str:\n",
    "    if not isinstance(name, str): return \"\"\n",
    "    s = re.sub(r\"[.\\-`'‚Äô]\", \"\", name).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "# Latest row per player for context\n",
    "keep_cols = [\n",
    "    \"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\"GAME_DATE\",\n",
    "    \"MIN_roll5\",\"MIN_roll10\",\"days_rest\",\"is_b2b\",\"HOME\",\n",
    "    \"USG%\",\"TS%\",\"PER\",\"BPM\"\n",
    "]\n",
    "keep_cols = [c for c in keep_cols if c in features_all.columns]\n",
    "\n",
    "latest = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "                     .groupby(\"PLAYER_NAME\", as_index=False)\n",
    "                     .tail(1)[keep_cols]\n",
    "                     .copy())\n",
    "\n",
    "# Fabricate PLAYER_ID if missing (rare)\n",
    "if \"PLAYER_ID\" not in latest.columns:\n",
    "    latest[\"PLAYER_ID\"] = latest[\"PLAYER_NAME\"].factorize()[0] + 1\n",
    "\n",
    "latest[\"player_key\"] = latest[\"PLAYER_NAME\"].map(_norm_player)\n",
    "latest = latest.rename(columns={\n",
    "    \"TEAM_ABBREVIATION\": \"team\",\n",
    "    \"OPPONENT_ABBREVIATION\": \"opponent\"\n",
    "})\n",
    "\n",
    "# Normalize and merge flags\n",
    "sf = starter_flags_df.copy()\n",
    "sf[\"player_key\"] = sf[\"player\"].map(_norm_player)\n",
    "sf[\"team\"] = sf[\"team\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "inj = injury_flags_df.copy()\n",
    "inj[\"player_key\"] = inj[\"player\"].map(_norm_player)\n",
    "\n",
    "# Merge starter and injury flags into today frame\n",
    "today = (latest.merge(sf[[\"player_key\",\"team\",\"is_starter\",\"start_prob\"]],\n",
    "                      on=[\"player_key\",\"team\"], how=\"left\")\n",
    "               .merge(inj[[\"player_key\",\"may_not_play\",\"injury_prob\"]],\n",
    "                      on=\"player_key\", how=\"left\"))\n",
    "\n",
    "today[\"is_starter\"]   = today[\"is_starter\"].fillna(0).astype(int)\n",
    "today[\"start_prob\"]   = today[\"start_prob\"].fillna(0.70)\n",
    "today[\"may_not_play\"] = today[\"may_not_play\"].fillna(0).astype(int)\n",
    "today[\"injury_prob\"]  = today[\"injury_prob\"].fillna(0.0)\n",
    "\n",
    "# ========== ‚úÖ NEW FIXED: Teammate absence proxy from full team rosters ==========\n",
    "\n",
    "# Build full roster from latest features\n",
    "roster_all = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "                         .groupby(\"PLAYER_NAME\", as_index=False)\n",
    "                         .tail(1)[[\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"USG%\"]].copy())\n",
    "roster_all[\"player_key\"] = roster_all[\"PLAYER_NAME\"].map(_norm_player)\n",
    "roster_all = roster_all.rename(columns={\"TEAM_ABBREVIATION\": \"team\"})\n",
    "\n",
    "# Merge in injury flags\n",
    "inj = injury_flags_df.copy()\n",
    "inj[\"player_key\"] = inj[\"player\"].map(_norm_player)\n",
    "roster_all = roster_all.merge(inj[[\"player_key\",\"injury_prob\"]], on=\"player_key\", how=\"left\")\n",
    "roster_all[\"injury_prob\"] = roster_all[\"injury_prob\"].fillna(0.0)\n",
    "\n",
    "# Calculate expected missing usage per team\n",
    "roster_all[\"usg_missing_expected\"] = roster_all[\"USG%\"].fillna(0.0) * roster_all[\"injury_prob\"].clip(0, 1)\n",
    "\n",
    "by_team_abs = roster_all.groupby(\"team\", as_index=False).agg(\n",
    "    teammates_out=(\"injury_prob\", lambda s: float((s > 0).sum())),\n",
    "    missing_usage_share=(\"usg_missing_expected\",\"sum\")\n",
    ")\n",
    "\n",
    "# Merge team-level features into today\n",
    "today = today.merge(by_team_abs, on=\"team\", how=\"left\")\n",
    "today[\"teammates_out\"] = today[\"teammates_out\"].fillna(0.0)\n",
    "today[\"missing_usage_share\"] = today[\"missing_usage_share\"].fillna(0.0)\n",
    "\n",
    "# Final output expected by minutes model\n",
    "minutes_today = today.rename(columns={\"GAME_DATE\":\"last_game_date\"})[[\n",
    "    \"PLAYER_ID\",\"PLAYER_NAME\",\"team\",\"opponent\",\n",
    "    \"is_starter\",\"start_prob\",\"may_not_play\",\"injury_prob\",\n",
    "    \"teammates_out\",\"missing_usage_share\",\n",
    "    *(c for c in [\"MIN_roll5\",\"MIN_roll10\",\"days_rest\",\"is_b2b\",\"HOME\",\"USG%\",\"TS%\",\"PER\",\"BPM\"] if c in today.columns),\n",
    "]].copy()\n",
    "\n",
    "print(\"‚úÖ minutes_today shape:\", minutes_today.shape)\n",
    "print(minutes_today.head(30).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52db04c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected minutes source: minutes_today\n",
      "‚úÖ Finalized minutes_today rows: 756\n",
      " PLAYER_ID        PLAYER_NAME TEAM_ABBREVIATION OPPONENT_ABBREVIATION  pred_minutes  start_prob  is_starter  may_not_play  injury_prob\n",
      "   1630639        A.J. Lawson               TOR                   SAS         24.60         0.7           0             0          0.0\n",
      "   1631260           AJ Green               MIL                   CLE         26.20         0.7           0             0          0.0\n",
      "   1631100         AJ Griffin               ATL                   IND         10.00         0.7           0             0          0.0\n",
      "   1642358         AJ Johnson               WAS                   BKN         10.00         0.7           0             0          0.0\n",
      "    203932       Aaron Gordon               DEN                   CHI         30.40         0.7           0             0          0.0\n",
      "   1628988      Aaron Holiday               HOU                   ORL         10.00         0.7           0             0          0.0\n",
      "   1630174      Aaron Nesmith               IND                   PHX         31.80         0.7           0             0          0.0\n",
      "   1630598      Aaron Wiggins               OKC                   POR         27.40         0.7           0             0          0.0\n",
      "   1642846         Ace Bailey               UTA                   CHI         25.80         0.7           1             0          0.0\n",
      "   1641745       Adam Flagler               OKC                   NOP         10.00         0.7           0             0          0.0\n",
      "   1641766       Adama Sanogo               CHI                   CHA         10.25         0.7           0             0          0.0\n",
      "   1641737          Adem Bona               PHI                   DET         14.60         0.7           0             0          0.0\n",
      "   1629678  Admiral Schofield               ORL                   MIL         10.00         0.7           0             0          0.0\n",
      "   1642876        Adou Thiero               LAL                   MIL         12.75         0.7           0             0          0.0\n",
      "   1642349      Ajay Mitchell               OKC                   NOP         30.20         0.7           0             0          0.0\n",
      "    201143         Al Horford               GSW                   NOP         21.40         0.7           0             0          0.0\n",
      "    202692         Alec Burks               MIA                   NOP         20.20         0.7           0             0          0.0\n",
      "   1630197 Aleksej Pokusevski               CHA                   CLE         19.20         0.7           0             0          0.0\n",
      "   1627936        Alex Caruso               OKC                   CHA         19.80         0.7           0             0          0.0\n",
      "   1642505         Alex Ducas               OKC                   NOP         10.00         0.7           0             0          0.0\n",
      "   1641788         Alex Fudge               DAL                   OKC         10.00         0.7           0             0          0.0\n",
      "    203458           Alex Len               LAL                   POR         13.60         0.7           0             0          0.0\n",
      "   1642024         Alex Reese               PHI                   WAS         17.60         0.7           0             0          0.0\n",
      "   1642259          Alex Sarr               WAS                   BKN         31.80         0.7           0             0          0.0\n",
      "   1631214   Alondes Williams               DET                   ORL         28.75         0.7           0             0          0.0\n",
      "   1630578     Alperen Sengun               HOU                   ORL         35.00         0.7           0             0          0.0\n",
      "   1641735       Amari Bailey               CHA                   CLE         10.00         0.7           0             0          0.0\n",
      "   1642873     Amari Williams               BOS                   HOU         26.25         0.7           0             0          0.0\n",
      "   1641708      Amen Thompson               HOU                   ORL         36.40         0.7           0             0          0.0\n",
      "   1629599        Amir Coffey               MIL                   LAL         11.20         0.7           0             0          0.0\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 13 (Fixed): bridge/standardize minutes_today -------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ‚úÖ Skip processing if minutes_today from Cell 12 already exists with predictions\n",
    "if \"minutes_today\" in globals() and \"pred_minutes\" in minutes_today.columns:\n",
    "    print(\"‚úÖ Reusing minutes_today from Cell 12. Rows:\", len(minutes_today))\n",
    "    print(minutes_today.head(30).to_string(index=False))\n",
    "else:\n",
    "    def _find_minutes_df():\n",
    "        candidates = []\n",
    "        for name, obj in globals().items():\n",
    "            if not isinstance(obj, pd.DataFrame):\n",
    "                continue\n",
    "            lname = name.lower()\n",
    "            if re.search(r\"(minutes|mins)\", lname) and re.search(r\"(today|pred|proj|features)\", lname):\n",
    "                candidates.append((name, obj))\n",
    "        prio = [\"minutes_today\", \"features_today_minutes\", \"minutes_pred\", \"minutes_predictions\", \"df_minutes_today\"]\n",
    "        for p in prio:\n",
    "            for name, df in candidates:\n",
    "                if name == p:\n",
    "                    return name, df\n",
    "        return candidates[0] if candidates else (None, None)\n",
    "\n",
    "    name, df_src = _find_minutes_df()\n",
    "    print(f\"Detected minutes source: {name or 'None'}\")\n",
    "\n",
    "    if df_src is None or df_src.empty:\n",
    "        print(\"‚ö†Ô∏è No minutes_today found; building fallback from features_all.\")\n",
    "        latest = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "                            .groupby(\"PLAYER_NAME\", as_index=False).tail(1).copy())\n",
    "\n",
    "        base_min = latest.get(\"MIN_roll5\", pd.Series(24, index=latest.index)).fillna(24).clip(10, 38)\n",
    "\n",
    "        minutes_today = latest[[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]].copy()\n",
    "        minutes_today[\"pred_minutes\"] = base_min\n",
    "\n",
    "        for flags_name in [\"starter_flags_df\", \"injury_flags_df\"]:\n",
    "            if flags_name in globals() and isinstance(globals()[flags_name], pd.DataFrame):\n",
    "                flags = globals()[flags_name]\n",
    "                key_cols = [c for c in [\"PLAYER_ID\",\"PLAYER_NAME\"] if c in flags.columns]\n",
    "                if key_cols:\n",
    "                    minutes_today = minutes_today.merge(\n",
    "                        flags.drop_duplicates(subset=key_cols),\n",
    "                        on=key_cols, how=\"left\"\n",
    "                    )\n",
    "\n",
    "        minutes_today[\"start_prob\"]   = minutes_today.get(\"start_prob\", 0.75)\n",
    "        minutes_today[\"is_starter\"]   = minutes_today.get(\"is_starter\", 0).fillna(0).astype(int)\n",
    "        minutes_today[\"may_not_play\"] = minutes_today.get(\"may_not_play\", 0).fillna(0).astype(int)\n",
    "        minutes_today[\"injury_prob\"]  = minutes_today.get(\"injury_prob\", 0.0).fillna(0.0)\n",
    "\n",
    "    else:\n",
    "        # Standardization logic from detected df_src\n",
    "        df = df_src.copy()\n",
    "        cmap = {}\n",
    "        for c in df.columns:\n",
    "            cl = c.lower()\n",
    "            if cl in [\"player_id\",\"id\"]: cmap[c] = \"PLAYER_ID\"\n",
    "            elif cl in [\"player_name\",\"player\",\"name\"]: cmap[c] = \"PLAYER_NAME\"\n",
    "            elif cl in [\"team\",\"team_abbreviation\"]: cmap[c] = \"TEAM_ABBREVIATION\"\n",
    "            elif cl in [\"opponent\",\"opp\",\"opponent_abbreviation\"]: cmap[c] = \"OPPONENT_ABBREVIATION\"\n",
    "            elif cl in [\"pred_minutes\",\"minutes\",\"min_pred\"]: cmap[c] = \"pred_minutes\"\n",
    "            elif cl in [\"start_prob\",\"starter_prob\"]: cmap[c] = \"start_prob\"\n",
    "            elif cl in [\"is_starter\",\"starter_flag\"]: cmap[c] = \"is_starter\"\n",
    "            elif cl in [\"may_not_play\",\"dnp_flag\"]: cmap[c] = \"may_not_play\"\n",
    "            elif cl in [\"injury_prob\",\"inj_prob\"]: cmap[c] = \"injury_prob\"\n",
    "\n",
    "        df = df.rename(columns=cmap)\n",
    "\n",
    "        if \"PLAYER_ID\" not in df.columns or df[\"PLAYER_ID\"].isna().all():\n",
    "            latest = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "                                .groupby(\"PLAYER_NAME\", as_index=False).tail(1)[\n",
    "                                    [\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]\n",
    "                                ])\n",
    "            df = df.merge(latest, on=\"PLAYER_NAME\", how=\"left\")\n",
    "\n",
    "        req = [\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\n",
    "               \"pred_minutes\",\"start_prob\",\"is_starter\",\"may_not_play\",\"injury_prob\"]\n",
    "        for r in req:\n",
    "            if r not in df.columns:\n",
    "                if r == \"pred_minutes\":\n",
    "                    base = (features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "                                     .groupby(\"PLAYER_NAME\", as_index=False).tail(1))\n",
    "                    base = base[[\"PLAYER_NAME\",\"MIN_roll5\"]].rename(columns={\"MIN_roll5\":\"pred_minutes\"})\n",
    "                    df = df.merge(base, on=\"PLAYER_NAME\", how=\"left\")\n",
    "                    df[\"pred_minutes\"] = df[\"pred_minutes\"].fillna(24).clip(10, 38)\n",
    "                elif r in [\"start_prob\",\"injury_prob\"]:\n",
    "                    df[r] = 0.75 if r == \"start_prob\" else 0.0\n",
    "                elif r in [\"is_starter\",\"may_not_play\"]:\n",
    "                    df[r] = 0\n",
    "                else:\n",
    "                    df[r] = np.nan\n",
    "\n",
    "        df[\"pred_minutes\"] = pd.to_numeric(df[\"pred_minutes\"], errors=\"coerce\").fillna(24).clip(0, 48)\n",
    "        df[\"is_starter\"]   = df[\"is_starter\"].fillna(0).astype(int)\n",
    "        df[\"may_not_play\"] = df[\"may_not_play\"].fillna(0).astype(int)\n",
    "        df[\"start_prob\"]   = df[\"start_prob\"].fillna(0.75)\n",
    "        df[\"injury_prob\"]  = df[\"injury_prob\"].fillna(0.0)\n",
    "\n",
    "        minutes_today = df[[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\n",
    "                            \"pred_minutes\",\"start_prob\",\"is_starter\",\"may_not_play\",\"injury_prob\"]].copy()\n",
    "\n",
    "    print(\"‚úÖ Finalized minutes_today rows:\", len(minutes_today))\n",
    "    print(minutes_today.head(30).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "714bf1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (388, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>raw</th>\n",
       "      <th>id</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>pos</th>\n",
       "      <th>inj</th>\n",
       "      <th>lineup</th>\n",
       "      <th>proj</th>\n",
       "      <th>avg</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>gap</th>\n",
       "      <th>stdev</th>\n",
       "      <th>hasRecentGames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>{'error': 'You must be a paid subscriber to vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3894</td>\n",
       "      <td>Jaylen</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Jaylen Brown</td>\n",
       "      <td>/basketball/player/jaylen-brown-3894</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>SF</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.467175</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4108</td>\n",
       "      <td>Jayson</td>\n",
       "      <td>Tatum</td>\n",
       "      <td>Jayson Tatum</td>\n",
       "      <td>/basketball/player/jayson-tatum-4108</td>\n",
       "      <td>F</td>\n",
       "      <td>Out</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4143</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Boucher</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>/basketball/player/chris-boucher-4143</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4195</td>\n",
       "      <td>Derrick</td>\n",
       "      <td>White</td>\n",
       "      <td>Derrick White</td>\n",
       "      <td>/basketball/player/derrick-white-4195</td>\n",
       "      <td>G</td>\n",
       "      <td>No</td>\n",
       "      <td>PG</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.748043</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4373</td>\n",
       "      <td>Anfernee</td>\n",
       "      <td>Simons</td>\n",
       "      <td>Anfernee Simons</td>\n",
       "      <td>/basketball/player/anfernee-simons-4373</td>\n",
       "      <td>G</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.430470</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5131</td>\n",
       "      <td>Payton</td>\n",
       "      <td>Pritchard</td>\n",
       "      <td>Payton Pritchard</td>\n",
       "      <td>/basketball/player/payton-pritchard-5131</td>\n",
       "      <td>G</td>\n",
       "      <td>No</td>\n",
       "      <td>SG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.238827</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5290</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>Tillman</td>\n",
       "      <td>Xavier Tillman</td>\n",
       "      <td>/basketball/player/xavier-tillman-5290</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.145781</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5333</td>\n",
       "      <td>Neemias</td>\n",
       "      <td>Queta</td>\n",
       "      <td>Neemias Queta</td>\n",
       "      <td>/basketball/player/neemias-queta-5333</td>\n",
       "      <td>C</td>\n",
       "      <td>No</td>\n",
       "      <td>C</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.192302</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5338</td>\n",
       "      <td>Sam</td>\n",
       "      <td>Hauser</td>\n",
       "      <td>Sam Hauser</td>\n",
       "      <td>/basketball/player/sam-hauser-5338</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.318834</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5423</td>\n",
       "      <td>Luka</td>\n",
       "      <td>Garza</td>\n",
       "      <td>Luka Garza</td>\n",
       "      <td>/basketball/player/luka-garza-5423</td>\n",
       "      <td>C</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.261901</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5709</td>\n",
       "      <td>Josh</td>\n",
       "      <td>Minott</td>\n",
       "      <td>Josh Minott</td>\n",
       "      <td>/basketball/player/josh-minott-5709</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.139410</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5942</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Walsh</td>\n",
       "      <td>Jordan Walsh</td>\n",
       "      <td>/basketball/player/jordan-walsh-5942</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>PF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.075207</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6280</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>Scheierman</td>\n",
       "      <td>Baylor Scheierman</td>\n",
       "      <td>/basketball/player/baylor-scheierman-6280</td>\n",
       "      <td>G</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>6.803361</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6553</td>\n",
       "      <td>Hugo</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Hugo Gonzalez</td>\n",
       "      <td>/basketball/player/hugo-gonzalez-6553</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>4.565031</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BKN</td>\n",
       "      <td>{'error': 'You must be a paid subscriber to vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3442</td>\n",
       "      <td>Mason</td>\n",
       "      <td>Plumlee</td>\n",
       "      <td>Mason Plumlee</td>\n",
       "      <td>/basketball/player/mason-plumlee-3442</td>\n",
       "      <td>C</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.043871</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3727</td>\n",
       "      <td>Pat</td>\n",
       "      <td>Connaughton</td>\n",
       "      <td>Pat Connaughton</td>\n",
       "      <td>/basketball/player/pat-connaughton-3727</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.713113</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4383</td>\n",
       "      <td>Miles</td>\n",
       "      <td>Bridges</td>\n",
       "      <td>Miles Bridges</td>\n",
       "      <td>/basketball/player/miles-bridges-4383</td>\n",
       "      <td>F</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>3.355988</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4412</td>\n",
       "      <td>Collin</td>\n",
       "      <td>Sexton</td>\n",
       "      <td>Collin Sexton</td>\n",
       "      <td>/basketball/player/collin-sexton-4412</td>\n",
       "      <td>G</td>\n",
       "      <td>No</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>5.313492</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team                                                raw    id firstname     lastname               name                                       link  pos  \\\n",
       "0   ATL  {'error': 'You must be a paid subscriber to vi...   NaN       NaN          NaN                NaN                                        NaN  NaN   \n",
       "1   BOS                                                NaN  3894    Jaylen        Brown       Jaylen Brown       /basketball/player/jaylen-brown-3894    F   \n",
       "2   BOS                                                NaN  4108    Jayson        Tatum       Jayson Tatum       /basketball/player/jayson-tatum-4108    F   \n",
       "3   BOS                                                NaN  4143     Chris      Boucher      Chris Boucher      /basketball/player/chris-boucher-4143    F   \n",
       "4   BOS                                                NaN  4195   Derrick        White      Derrick White      /basketball/player/derrick-white-4195    G   \n",
       "5   BOS                                                NaN  4373  Anfernee       Simons    Anfernee Simons    /basketball/player/anfernee-simons-4373    G   \n",
       "6   BOS                                                NaN  5131    Payton    Pritchard   Payton Pritchard   /basketball/player/payton-pritchard-5131    G   \n",
       "7   BOS                                                NaN  5290    Xavier      Tillman     Xavier Tillman     /basketball/player/xavier-tillman-5290    F   \n",
       "8   BOS                                                NaN  5333   Neemias        Queta      Neemias Queta      /basketball/player/neemias-queta-5333    C   \n",
       "9   BOS                                                NaN  5338       Sam       Hauser         Sam Hauser         /basketball/player/sam-hauser-5338    F   \n",
       "10  BOS                                                NaN  5423      Luka        Garza         Luka Garza         /basketball/player/luka-garza-5423    C   \n",
       "11  BOS                                                NaN  5709      Josh       Minott        Josh Minott        /basketball/player/josh-minott-5709    F   \n",
       "12  BOS                                                NaN  5942    Jordan        Walsh       Jordan Walsh       /basketball/player/jordan-walsh-5942    F   \n",
       "13  BOS                                                NaN  6280    Baylor   Scheierman  Baylor Scheierman  /basketball/player/baylor-scheierman-6280    G   \n",
       "14  BOS                                                NaN  6553      Hugo     Gonzalez      Hugo Gonzalez      /basketball/player/hugo-gonzalez-6553    F   \n",
       "15  BKN  {'error': 'You must be a paid subscriber to vi...   NaN       NaN          NaN                NaN                                        NaN  NaN   \n",
       "16  CHA                                                NaN  3442     Mason      Plumlee      Mason Plumlee      /basketball/player/mason-plumlee-3442    C   \n",
       "17  CHA                                                NaN  3727       Pat  Connaughton    Pat Connaughton    /basketball/player/pat-connaughton-3727    F   \n",
       "18  CHA                                                NaN  4383     Miles      Bridges      Miles Bridges      /basketball/player/miles-bridges-4383    F   \n",
       "19  CHA                                                NaN  4412    Collin       Sexton      Collin Sexton      /basketball/player/collin-sexton-4412    G   \n",
       "\n",
       "    inj lineup  proj   avg   min   max   gap      stdev hasRecentGames  \n",
       "0   NaN    NaN   NaN   NaN   NaN   NaN   NaN        NaN            NaN  \n",
       "1    No     SF  34.0  33.0  27.0  38.0   1.0   5.467175           True  \n",
       "2   Out     BE   0.0   NaN   NaN   NaN   0.0  15.000000          False  \n",
       "3    No     BE   0.0  12.0   9.0  15.0 -12.0   2.828427           True  \n",
       "4    No     PG  34.0  33.0  27.0  39.0   1.0   5.748043           True  \n",
       "5    No     BE  24.0  21.0  16.0  27.0   3.0   5.430470           True  \n",
       "6    No     SG  31.0  31.0  28.0  34.0   0.0   3.238827           True  \n",
       "7    No     BE   0.0   6.0   2.0  10.0  -6.0   4.145781           True  \n",
       "8    No      C  27.0  26.0  21.0  31.0   1.0   5.192302           True  \n",
       "9    No     BE  18.0  19.0  13.0  24.0  -1.0   5.318834           True  \n",
       "10   No     BE  15.0  15.0  12.0  18.0   0.0   3.261901           True  \n",
       "11   No     BE  18.0  18.0  10.0  26.0   0.0   8.139410           True  \n",
       "12   No     PF  26.0  25.0  15.0  34.0   1.0   9.075207           True  \n",
       "13   No     BE   8.0  13.0   6.0  20.0  -5.0   6.803361           True  \n",
       "14   No     BE   5.0  10.0   6.0  15.0  -5.0   4.565031           True  \n",
       "15  NaN    NaN   NaN   NaN   NaN   NaN   NaN        NaN            NaN  \n",
       "16   No     BE   0.0   6.0   4.0   8.0  -6.0   2.043871           True  \n",
       "17   No     BE   0.0  11.0   7.0  14.0 -11.0   3.713113           True  \n",
       "18   No     BE   0.0  36.0  32.0  39.0 -36.0   3.355988           True  \n",
       "19   No     BE   0.0  26.0  21.0  32.0 -26.0   5.313492           True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## -- Cell 14: Fetch projected minutes from Rotowire -------------------------------\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# Settings\n",
    "# ============================\n",
    "\n",
    "BASE_URL = \"https://www.rotowire.com/basketball/ajax/get-projected-minutes.php\"\n",
    "\n",
    "# All NBA team codes (you can trim this list to just the teams playing today)\n",
    "TEAMS = [\n",
    "    \"ATL\",\"BOS\",\"BKN\",\"CHA\",\"CHI\",\"CLE\",\"DAL\",\"DEN\",\"DET\",\n",
    "    \"GSW\",\"HOU\",\"IND\",\"LAC\",\"LAL\",\"MEM\",\"MIA\",\"MIL\",\"MIN\",\n",
    "    \"NOP\",\"NYK\",\"OKC\",\"ORL\",\"PHI\",\"PHX\",\"POR\",\"SAC\",\"SAS\",\n",
    "    \"TOR\",\"UTA\",\"WAS\"\n",
    "]\n",
    "\n",
    "# Create a session to reuse TCP connection and headers\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; projected-minutes-notebook/1.0)\",\n",
    "    \"Accept\": \"application/json,*/*\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "})\n",
    "\n",
    "all_rows = []         # flattened player rows (if possible)\n",
    "raw_per_team = {}     # raw JSON per team in case you want to inspect it\n",
    "\n",
    "for team in TEAMS:\n",
    "    params = {\"team\": team}\n",
    "    try:\n",
    "        resp = session.get(BASE_URL, params=params, timeout=10)\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed for {team}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Team {team}: HTTP {resp.status_code}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        data = resp.json()\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Team {team}: could not decode JSON\")\n",
    "        continue\n",
    "\n",
    "    raw_per_team[team] = data  # always keep raw, whatever the shape is\n",
    "\n",
    "    # ============================\n",
    "    # Try to flatten into rows\n",
    "    # ============================\n",
    "\n",
    "    # Case 1: endpoint returns a list of player dicts\n",
    "    if isinstance(data, list):\n",
    "        for row in data:\n",
    "            if isinstance(row, dict):\n",
    "                row_with_team = {\"team\": team, **row}\n",
    "                all_rows.append(row_with_team)\n",
    "            else:\n",
    "                # non-dict elements, keep as raw\n",
    "                all_rows.append({\"team\": team, \"raw\": row})\n",
    "\n",
    "    # Case 2: common pattern: {\"players\": [ {...}, {...}, ... ], ...}\n",
    "    elif isinstance(data, dict) and \"players\" in data and isinstance(data[\"players\"], list):\n",
    "        for row in data[\"players\"]:\n",
    "            if isinstance(row, dict):\n",
    "                row_with_team = {\"team\": team, **row}\n",
    "                all_rows.append(row_with_team)\n",
    "            else:\n",
    "                all_rows.append({\"team\": team, \"raw\": row})\n",
    "\n",
    "    # Fallback: unknown structure ‚Üí store whole object in \"raw\" column\n",
    "    else:\n",
    "        all_rows.append({\"team\": team, \"raw\": data})\n",
    "\n",
    "    # Tiny delay to be polite to the server (adjust or remove at your own risk)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "# ============================\n",
    "# Build DataFrame\n",
    "# ============================\n",
    "\n",
    "df_minutes = pd.DataFrame(all_rows)\n",
    "\n",
    "print(\"Shape:\", df_minutes.shape)\n",
    "display(df_minutes.head(20))\n",
    "\n",
    "# If you want to inspect what the raw JSON looks like for a specific team, e.g. LAC:\n",
    "# raw_per_team[\"LAC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01981cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Rotowire players with valid minutes: 61\n",
      "Using logs_2526 for active players, count=468\n",
      "üîç Filtered minutes_today from 756 ‚Üí 468 rows based on active players.\n",
      "‚úÖ minutes_today enriched with blended Rotowire + internal minutes.\n",
      "      PLAYER_NAME team TEAM_ABBREVIATION  pred_minutes_internal  rotowire_minutes  pred_minutes\n",
      "         AJ Green  MIL               MIL                  26.20               NaN         26.20\n",
      "       AJ Johnson  WAS               WAS                  10.00               NaN         10.00\n",
      "     Aaron Gordon  DEN               DEN                  30.40               NaN         30.40\n",
      "    Aaron Holiday  HOU               HOU                  10.00               NaN         10.00\n",
      "    Aaron Nesmith  IND               IND                  31.80               NaN         31.80\n",
      "    Aaron Wiggins  OKC               OKC                  27.40               NaN         27.40\n",
      "       Ace Bailey  UTA               UTA                  25.80              27.0         26.52\n",
      "        Adem Bona  PHI               PHI                  14.60               NaN         14.60\n",
      "      Adou Thiero  LAL               LAL                  12.75               NaN         12.75\n",
      "    Ajay Mitchell  OKC               OKC                  30.20               NaN         30.20\n",
      "       Al Horford  GSW               GSW                  21.40              23.0         22.36\n",
      "      Alex Caruso  OKC               OKC                  19.80               NaN         19.80\n",
      "        Alex Sarr  WAS               WAS                  31.80               NaN         31.80\n",
      "   Alperen Sengun  HOU               HOU                  35.00               NaN         35.00\n",
      "   Amari Williams  BOS               BOS                  26.25               NaN         26.25\n",
      "    Amen Thompson  HOU               HOU                  36.40               NaN         36.40\n",
      "      Amir Coffey  MIL               MIL                  11.20               NaN         11.20\n",
      "   Andre Drummond  PHI               PHI                  29.60               NaN         29.60\n",
      "Andre Jackson Jr.  MIL               MIL                  10.00               NaN         10.00\n",
      "  Andrew Nembhard  IND               IND                  30.20               NaN         30.20\n",
      "   Andrew Wiggins  MIA               MIA                  35.00               NaN         35.00\n",
      "  Anfernee Simons  BOS               BOS                  23.80              24.0         23.92\n",
      "    Anthony Black  ORL               ORL                  25.00               NaN         25.00\n",
      "    Anthony Davis  DAL               DAL                  35.75               NaN         35.75\n",
      "  Anthony Edwards  MIN               MIN                  33.60               NaN         33.60\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 15 (Updated): Inject Rotowire projected minutes into minutes_today ---------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "assert 'df_minutes' in globals(), \"df_minutes (Rotowire results) not found.\"\n",
    "assert 'minutes_today' in globals(), \"minutes_today not found. Run Cells 13b‚Äì14 first.\"\n",
    "\n",
    "def _norm_player_local(name: str) -> str:\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    s = re.sub(r\"[.\\-`'‚Äô]\", \"\", name).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "# Step 1: Prepare Rotowire minutes\n",
    "rw = df_minutes.copy()\n",
    "if \"name\" not in rw.columns:\n",
    "    raise RuntimeError(\"df_minutes must have a 'name' column from Rotowire.\")\n",
    "\n",
    "rw[\"player_key\"] = rw[\"name\"].map(_norm_player_local)\n",
    "rw[\"rotowire_minutes\"] = pd.to_numeric(rw.get(\"proj\", np.nan), errors=\"coerce\")\n",
    "\n",
    "# ‚úÖ Treat 0.0 projections as missing\n",
    "rw[\"rotowire_minutes\"] = rw[\"rotowire_minutes\"].replace(0.0, np.nan)\n",
    "\n",
    "rw = (\n",
    "    rw.dropna(subset=[\"player_key\", \"rotowire_minutes\"])\n",
    "      .groupby(\"player_key\", as_index=False)\n",
    "      .agg(rotowire_minutes=(\"rotowire_minutes\", \"mean\"))\n",
    ")\n",
    "print(f\"‚úÖ Rotowire players with valid minutes: {len(rw)}\")\n",
    "\n",
    "# Step 2: Normalize player keys in minutes_today\n",
    "mt = minutes_today.copy()\n",
    "\n",
    "if \"PLAYER_NAME\" in mt.columns:\n",
    "    mt[\"player_key\"] = mt[\"PLAYER_NAME\"].map(_norm_player_local)\n",
    "elif \"player\" in mt.columns:\n",
    "    mt[\"player_key\"] = mt[\"player\"].map(_norm_player_local)\n",
    "else:\n",
    "    raise RuntimeError(\"minutes_today must have PLAYER_NAME or player column.\")\n",
    "\n",
    "if \"team\" not in mt.columns and \"TEAM_ABBREVIATION\" in mt.columns:\n",
    "    mt[\"team\"] = mt[\"TEAM_ABBREVIATION\"]\n",
    "\n",
    "# Step 2b: Build active player pool\n",
    "active_keys = set(rw[\"player_key\"].dropna())\n",
    "\n",
    "current_logs_name = None\n",
    "for nm in [\"logs_2526\", \"logs_2425\", \"logs_2324\"]:\n",
    "    if nm in globals():\n",
    "        current_logs_name = nm\n",
    "        break\n",
    "\n",
    "if current_logs_name is not None:\n",
    "    logs_df = globals()[current_logs_name]\n",
    "    if isinstance(logs_df, pd.DataFrame) and \"PLAYER_NAME\" in logs_df.columns:\n",
    "        log_keys = logs_df[\"PLAYER_NAME\"].map(_norm_player_local).dropna().unique()\n",
    "        active_keys.update(log_keys)\n",
    "        print(f\"Using {current_logs_name} for active players, count={len(log_keys)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No logs_25xx DataFrame found; active players based only on Rotowire.\")\n",
    "\n",
    "before_n = len(mt)\n",
    "mt = mt[mt[\"player_key\"].isin(active_keys)].copy()\n",
    "after_n = len(mt)\n",
    "print(f\"üîç Filtered minutes_today from {before_n} ‚Üí {after_n} rows based on active players.\")\n",
    "\n",
    "# Step 3: Merge\n",
    "mt = mt.merge(rw, on=\"player_key\", how=\"left\")\n",
    "if \"rotowire_minutes\" not in mt.columns:\n",
    "    mt[\"rotowire_minutes\"] = np.nan\n",
    "\n",
    "# Step 4: Internal projection fallback\n",
    "if \"pred_minutes\" in mt.columns:\n",
    "    mt[\"pred_minutes_internal\"] = mt[\"pred_minutes\"]\n",
    "elif \"projected_minutes\" in mt.columns:\n",
    "    mt[\"pred_minutes_internal\"] = mt[\"projected_minutes\"]\n",
    "else:\n",
    "    mt[\"pred_minutes_internal\"] = np.nan\n",
    "\n",
    "# Step 5: Blend\n",
    "w_rw = 0.6\n",
    "w_internal = 0.4\n",
    "\n",
    "base_internal = mt[\"pred_minutes_internal\"].fillna(mt[\"rotowire_minutes\"])\n",
    "mt[\"pred_minutes\"] = np.where(\n",
    "    mt[\"rotowire_minutes\"].notna(),\n",
    "    w_rw * mt[\"rotowire_minutes\"] + w_internal * base_internal,\n",
    "    base_internal\n",
    ")\n",
    "\n",
    "mt[\"pred_minutes\"] = mt[\"pred_minutes\"].clip(0, 48)\n",
    "\n",
    "# Step 6: Save\n",
    "minutes_today = mt\n",
    "\n",
    "print(\"‚úÖ minutes_today enriched with blended Rotowire + internal minutes.\")\n",
    "cols_to_show = [c for c in [\n",
    "    \"PLAYER_NAME\", \"team\", \"TEAM_ABBREVIATION\",\n",
    "    \"pred_minutes_internal\", \"rotowire_minutes\", \"pred_minutes\"\n",
    "] if c in minutes_today.columns]\n",
    "\n",
    "print(minutes_today[cols_to_show].head(25).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251e9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Applied season average fallback to correct underprojected minutes.\n",
      "          PLAYER_NAME team  pred_minutes_internal  rotowire_minutes  minutes_avg_season  pred_minutes\n",
      "         Tyrese Maxey  PHI                  38.00               NaN           40.461538         38.00\n",
      "        James Wiseman  IND                  38.00               NaN           20.000000         38.00\n",
      "         James Harden  LAC                  38.00               NaN           36.230769         38.00\n",
      "         Cooper Flagg  DAL                  37.60               NaN           33.800000         37.60\n",
      "        Miles Bridges  CHA                  37.20               NaN           35.214286         37.20\n",
      "          Josh Giddey  CHI                  37.00               NaN           34.363636         37.00\n",
      "         Franz Wagner  ORL                  36.80               NaN           35.714286         36.80\n",
      "        Amen Thompson  HOU                  36.40               NaN           35.500000         36.40\n",
      "Giannis Antetokounmpo  MIL                  36.40               NaN           31.846154         36.40\n",
      "       Toumani Camara  POR                  36.20               NaN           34.461538         36.20\n",
      "          Luka Donƒçiƒá  LAL                  36.00               NaN           37.100000         36.00\n",
      "      Trey Murphy III  NOP                  36.00               NaN           35.571429         36.00\n",
      "         Kon Knueppel  CHA                  36.00               NaN           32.714286         36.00\n",
      "         Jrue Holiday  POR                  35.80               NaN           33.333333         35.80\n",
      "        Anthony Davis  DAL                  35.75               NaN           30.000000         35.75\n",
      "         Devin Booker  PHX                  33.80              37.0           35.785714         35.72\n",
      "         Desmond Bane  ORL                  35.60               NaN           32.500000         35.60\n",
      "         VJ Edgecombe  PHI                  35.40               NaN           37.384615         35.40\n",
      "          Ivica Zubac  LAC                  35.40               NaN           31.571429         35.40\n",
      "         Kevin Durant  HOU                  35.00               NaN           36.166667         35.00\n",
      "      Kelly Oubre Jr.  PHI                  35.00               NaN           34.916667         35.00\n",
      "       Andrew Wiggins  MIA                  35.00               NaN           32.928571         35.00\n",
      "       Alperen Sengun  HOU                  35.00               NaN           36.916667         35.00\n",
      "          Deni Avdija  POR                  34.80               NaN           34.076923         34.80\n",
      "         Jamal Murray  DEN                  34.80               NaN           34.333333         34.80\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 15b: Fix low internal minute projections for known starters ------------\n",
    "from collections import defaultdict\n",
    "\n",
    "# Reference to use: current logs like logs_2526\n",
    "log_df = globals().get(\"logs_2526\", None)\n",
    "if log_df is None or not isinstance(log_df, pd.DataFrame):\n",
    "    raise RuntimeError(\"‚ùå logs_2526 not found or invalid.\")\n",
    "\n",
    "log_df[\"player_key\"] = log_df[\"PLAYER_NAME\"].map(_norm_player_local)\n",
    "\n",
    "# Compute full-season average minutes per player\n",
    "season_mins = (\n",
    "    log_df.groupby(\"player_key\")[\"MIN\"]\n",
    "          .mean()\n",
    "          .dropna()\n",
    "          .to_dict()\n",
    ")\n",
    "\n",
    "# Threshold: if pred_minutes_internal < 10 and season avg > 20, then override\n",
    "def should_override(row):\n",
    "    internal = row[\"pred_minutes_internal\"]\n",
    "    season_avg = season_mins.get(row[\"player_key\"], None)\n",
    "    return pd.notna(internal) and internal < 10 and season_avg and season_avg > 20\n",
    "\n",
    "# Apply fix\n",
    "minutes_today[\"minutes_avg_season\"] = minutes_today[\"player_key\"].map(season_mins)\n",
    "minutes_today[\"corrected_pred_minutes\"] = minutes_today.apply(\n",
    "    lambda row: row[\"minutes_avg_season\"] if should_override(row) else row[\"pred_minutes\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "minutes_today[\"pred_minutes\"] = minutes_today[\"corrected_pred_minutes\"].clip(0, 48)\n",
    "minutes_today.drop(columns=[\"corrected_pred_minutes\"], inplace=True)\n",
    "\n",
    "print(\"‚úÖ Applied season average fallback to correct underprojected minutes.\")\n",
    "print(\n",
    "    minutes_today[\n",
    "        [\"PLAYER_NAME\", \"team\", \"pred_minutes_internal\", \"rotowire_minutes\", \"minutes_avg_season\", \"pred_minutes\"]\n",
    "    ]\n",
    "    .sort_values(\"pred_minutes\", ascending=False)\n",
    "    .head(25)\n",
    "    .to_string(index=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5caa1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fetched 1139 odds rows | 264 columns | book=mgm\n",
      "‚úÖ Fetched 1139 odds rows | 264 columns | book=draftkings\n",
      "‚úÖ Fetched 1139 odds rows | 264 columns | book=fanduel\n",
      "‚úÖ Fetched 1139 odds rows | 264 columns | book=caesars\n",
      "‚úÖ Fetched 1139 odds rows | 264 columns | book=betrivers\n",
      "‚úÖ Combined long odds rows: 3057\n",
      "                  player team opponent  game_date market book  line  over_odds  under_odds\n",
      "             Luka Doncic  LAL      UTA 2025-11-18    PTS  mgm  31.5     -120.0      -110.0\n",
      "            Devin Booker  PHX     @POR 2025-11-18    PTS  mgm  29.5     -120.0      -110.0\n",
      "            Jaylen Brown  BOS     @BKN 2025-11-18    PTS  mgm  26.5     -110.0      -120.0\n",
      "           Stephen Curry  GSW     @ORL 2025-11-18    PTS  mgm  26.5     -120.0      -110.0\n",
      "         Lauri Markkanen  UTA     @LAL 2025-11-18    PTS  mgm  26.5     -120.0      -110.0\n",
      "         Cade Cunningham  DET     @ATL 2025-11-18    PTS  mgm  26.5     -120.0      -110.0\n",
      "            De'Aaron Fox  SAS      MEM 2025-11-18    PTS  mgm  25.5     -115.0      -118.0\n",
      "             Deni Avdija  POR      PHX 2025-11-18    PTS  mgm  24.5     -125.0      -105.0\n",
      "          Shaedon Sharpe  POR      PHX 2025-11-18    PTS  mgm  24.5     -125.0      -110.0\n",
      "          Michael Porter  BKN      BOS 2025-11-18    PTS  mgm  23.5     -125.0      -110.0\n",
      "           Austin Reaves  LAL      UTA 2025-11-18    PTS  mgm  23.5     -125.0      -105.0\n",
      "            Franz Wagner  ORL      GSW 2025-11-18    PTS  mgm  24.5     -115.0      -115.0\n",
      "           Jaren Jackson  MEM     @SAS 2025-11-18    PTS  mgm  22.5     -115.0      -115.0\n",
      "          Keyonte George  UTA     @LAL 2025-11-18    PTS  mgm  19.5     -120.0      -110.0\n",
      "           Jalen Johnson  ATL      DET 2025-11-18    PTS  mgm  20.5     -125.0      -105.0\n",
      "            Desmond Bane  ORL      GSW 2025-11-18    PTS  mgm  19.5     -110.0      -120.0\n",
      "            Jimmy Butler  GSW     @ORL 2025-11-18    PTS  mgm  19.5     -125.0      -105.0\n",
      "             Jalen Duren  DET     @ATL 2025-11-18    PTS  mgm  19.5     -125.0      -110.0\n",
      "           Dillon Brooks  PHX     @POR 2025-11-18    PTS  mgm  18.5     -125.0      -105.0\n",
      "Nickeil Alexander-Walker  ATL      DET 2025-11-18    PTS  mgm  18.5     -105.0      -125.0\n",
      "üìÖ today_games_clean (team vs opponent):\n",
      "team opponent\n",
      " LAL      UTA\n",
      " PHX      POR\n",
      " BOS      BKN\n",
      " GSW      ORL\n",
      " DET      ATL\n",
      " SAS      MEM\n",
      " UTA      LAL\n",
      " POR      PHX\n",
      " BKN      BOS\n",
      " ORL      GSW\n",
      " ATL      DET\n",
      " MEM      SAS\n"
     ]
    }
   ],
   "source": [
    "# -- New Cell: Scrape and build odds_long (minimal version) ------------\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "BOOKS = (\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\")\n",
    "scraper = NBAOddsScraper()\n",
    "\n",
    "long_parts = []\n",
    "for b in BOOKS:\n",
    "    wide_b = scraper.get_player_props_odds_wide_raw(book=b)\n",
    "    if wide_b.empty:\n",
    "        print(f\"‚ö†Ô∏è {b}: no rows scraped.\")\n",
    "        continue\n",
    "    long_b = odds_wide_to_long_from_columns(wide_b, books=(b,), markets=(\"PTS\",\"REB\",\"AST\"))\n",
    "    if long_b.empty:\n",
    "        print(f\"‚ö†Ô∏è {b}: long table empty after conversion.\")\n",
    "    else:\n",
    "        long_parts.append(long_b)\n",
    "\n",
    "odds_long = pd.concat(long_parts, ignore_index=True) if long_parts else pd.DataFrame()\n",
    "print(f\"‚úÖ Combined long odds rows: {len(odds_long)}\")\n",
    "\n",
    "print(odds_long.head(20).to_string(index=False))\n",
    "\n",
    "# 1. Normalize opponent names\n",
    "odds_today = odds_long.copy()\n",
    "odds_today[\"opp_clean\"] = odds_today[\"opponent\"].astype(str).str.replace(\"@\", \"\", regex=False).str.upper().str.strip()\n",
    "odds_today[\"team_clean\"] = odds_today[\"team\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "# 2. Create team-opponent matchup (both directions appear)\n",
    "games_raw = odds_today[[\"team_clean\", \"opp_clean\"]].dropna().drop_duplicates()\n",
    "\n",
    "# 3. Create consistent keys by sorting team names alphabetically\n",
    "games_raw[\"match_key\"] = games_raw.apply(\n",
    "    lambda r: \"_vs_\".join(sorted([r[\"team_clean\"], r[\"opp_clean\"]])), axis=1\n",
    ")\n",
    "\n",
    "# 4. Deduplicate using the match_key, and re-expand into team/opponent\n",
    "games_deduped = (\n",
    "    games_raw.drop_duplicates(\"match_key\")[[\"team_clean\", \"opp_clean\"]]\n",
    "    .rename(columns={\"team_clean\": \"team\", \"opp_clean\": \"opponent\"})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "today_games_clean = pd.concat([\n",
    "    games_deduped,\n",
    "    games_deduped.rename(columns={\"team\": \"opponent\", \"opponent\": \"team\"})\n",
    "]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(\"üìÖ today_games_clean (team vs opponent):\")\n",
    "print(today_games_clean.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "541a71ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ today_games_clean ready:\n",
      "           game_id team opponent  home  game_date\n",
      "2025-11-18_LAL_UTA  LAL      UTA     1 2025-11-18\n",
      "2025-11-18_POR_PHX  POR      PHX     1 2025-11-18\n",
      "2025-11-18_BKN_BOS  BKN      BOS     1 2025-11-18\n",
      "2025-11-18_ORL_GSW  ORL      GSW     1 2025-11-18\n",
      "2025-11-18_ATL_DET  ATL      DET     1 2025-11-18\n",
      "2025-11-18_SAS_MEM  SAS      MEM     1 2025-11-18\n",
      "2025-11-18_LAL_UTA  UTA      LAL     0 2025-11-18\n",
      "2025-11-18_POR_PHX  PHX      POR     0 2025-11-18\n",
      "2025-11-18_BKN_BOS  BOS      BKN     0 2025-11-18\n",
      "2025-11-18_ORL_GSW  GSW      ORL     0 2025-11-18\n"
     ]
    }
   ],
   "source": [
    "# -- Rebuild today_games_clean from odds_long with game_id ---------------\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "assert \"odds_long\" in globals(), \"odds_long missing. Run the odds scraping cell first.\"\n",
    "\n",
    "today_str = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "odds_today = odds_long[odds_long[\"game_date\"] == today_str].copy()\n",
    "\n",
    "if odds_today.empty:\n",
    "    raise ValueError(f\"‚ùå No odds found for today ({today_str})\")\n",
    "\n",
    "# Normalize opponent and team\n",
    "odds_today[\"opp_clean\"] = odds_today[\"opponent\"].astype(str).str.replace(\"@\",\"\", regex=False).str.strip()\n",
    "odds_today[\"is_away\"] = odds_today[\"opponent\"].astype(str).str.startswith(\"@\")\n",
    "odds_today[\"home_team\"] = odds_today.apply(lambda r: r[\"opp_clean\"] if r[\"is_away\"] else r[\"team\"], axis=1)\n",
    "odds_today[\"away_team\"] = odds_today.apply(lambda r: r[\"team\"] if r[\"is_away\"] else r[\"opp_clean\"], axis=1)\n",
    "\n",
    "# Create game key\n",
    "odds_today[\"game_key\"] = (\n",
    "    odds_today[\"game_date\"].astype(str) + \"_\" +\n",
    "    odds_today[\"home_team\"] + \"_\" +\n",
    "    odds_today[\"away_team\"]\n",
    ")\n",
    "\n",
    "games_unique = (\n",
    "    odds_today[[\"game_date\", \"game_key\", \"home_team\", \"away_team\"]]\n",
    "    .drop_duplicates(\"game_key\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Final clean table for today\n",
    "today_games_clean = pd.concat([\n",
    "    games_unique.assign(\n",
    "        game_id = games_unique[\"game_key\"],\n",
    "        team = games_unique[\"home_team\"],\n",
    "        opponent = games_unique[\"away_team\"],\n",
    "        home = 1\n",
    "    )[[\"game_id\", \"team\", \"opponent\", \"home\", \"game_date\"]],\n",
    "    games_unique.assign(\n",
    "        game_id = games_unique[\"game_key\"],\n",
    "        team = games_unique[\"away_team\"],\n",
    "        opponent = games_unique[\"home_team\"],\n",
    "        home = 0\n",
    "    )[[\"game_id\", \"team\", \"opponent\", \"home\", \"game_date\"]],\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"‚úÖ today_games_clean ready:\")\n",
    "print(today_games_clean.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42131c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è± Final normalized minutes per team:\n",
      "game_id             team\n",
      "2025-11-18_ATL_DET  ATL     240.0\n",
      "                    DET     240.0\n",
      "2025-11-18_BKN_BOS  BKN     240.0\n",
      "                    BOS     240.0\n",
      "2025-11-18_LAL_UTA  LAL     240.0\n",
      "                    UTA     240.0\n",
      "2025-11-18_ORL_GSW  GSW     240.0\n",
      "                    ORL     240.0\n",
      "2025-11-18_POR_PHX  PHX     240.0\n",
      "                    POR     240.0\n",
      "2025-11-18_SAS_MEM  MEM     240.0\n",
      "                    SAS     240.0\n",
      "‚úÖ minutes_today_clean ready and applied to minutes_today.\n",
      " PLAYER_ID        PLAYER_NAME TEAM_ABBREVIATION OPPONENT_ABBREVIATION  pred_minutes  start_prob  is_starter  may_not_play  injury_prob        player_key team  rotowire_minutes  pred_minutes_internal  minutes_avg_season opponent            game_id\n",
      "   1641739     Toumani Camara               POR                   DAL     28.387518         0.7           0             0          0.0    toumani camara  POR               NaN                   36.2           34.461538      PHX 2025-11-18_POR_PHX\n",
      "    201950       Jrue Holiday               POR                   HOU     28.073844         0.7           0             0          0.0      jrue holiday  POR               NaN                   35.8           33.333333      PHX 2025-11-18_POR_PHX\n",
      "   1630532       Franz Wagner               ORL                   HOU     27.608628         0.7           1             0          0.0      franz wagner  ORL               NaN                   36.8           35.714286      GSW 2025-11-18_ORL_GSW\n",
      "   1630166        Deni Avdija               POR                   DAL     27.289659         0.7           1             0          0.0       deni avdija  POR               NaN                   34.8           34.076923      PHX 2025-11-18_POR_PHX\n",
      "   1630217       Desmond Bane               ORL                   HOU     26.708346         0.7           1             0          0.0      desmond bane  ORL               NaN                   35.6           32.500000      GSW 2025-11-18_ORL_GSW\n",
      "   1628401      Derrick White               BOS                   LAC     26.592445         0.7           1             0          0.0     derrick white  BOS              34.0                   32.6           32.857143      BKN 2025-11-18_BKN_BOS\n",
      "   1629008 Michael Porter Jr.               BKN                   WAS     26.590566         0.7           0             0          0.0 michael porter jr  BKN               NaN                   33.0           32.500000      BOS 2025-11-18_BKN_BOS\n",
      "   1627759       Jaylen Brown               BOS                   LAC     26.147117         0.7           1             0          0.0      jaylen brown  BOS              34.0                   31.2           32.071429      BKN 2025-11-18_BKN_BOS\n",
      "    201939      Stephen Curry               GSW                   NOP     26.059374         0.7           1             0          0.0     stephen curry  GSW              33.0                   30.6           30.666667      ORL 2025-11-18_ORL_GSW\n",
      "   1630552      Jalen Johnson               ATL                   PHX     26.005222         0.7           1             0          0.0     jalen johnson  ATL               NaN                   33.2           32.916667      DET 2025-11-18_ATL_DET\n",
      "   1630700      Dyson Daniels               ATL                   PHX     25.691906         0.7           1             0          0.0     dyson daniels  ATL               NaN                   32.8           32.928571      DET 2025-11-18_ATL_DET\n",
      "   1631094     Paolo Banchero               ORL                   NYK     25.357924         0.7           0             0          0.0    paolo banchero  ORL               NaN                   33.8           32.833333      GSW 2025-11-18_ORL_GSW\n",
      "   1629651        Nic Claxton               BKN                   WAS     25.140171         0.7           1             0          0.0       nic claxton  BKN               NaN                   31.2           29.384615      BOS 2025-11-18_BKN_BOS\n",
      "   1626164       Devin Booker               PHX                   ATL     25.130595         0.7           1             0          0.0      devin booker  PHX              37.0                   33.8           35.785714      POR 2025-11-18_POR_PHX\n",
      "   1628374    Lauri Markkanen               UTA                   CHI     24.875268         0.7           0             0          0.0   lauri markkanen  UTA              35.0                   33.4           36.153846      LAL 2025-11-18_LAL_UTA\n",
      "    202710   Jimmy Butler III               GSW                   NOP     24.725498         0.7           0             0          0.0  jimmy butler iii  GSW               NaN                   30.4           30.857143      ORL 2025-11-18_ORL_GSW\n",
      "   1629029        Luka Donƒçiƒá               LAL                   MIL     24.657534         0.7           0             0          0.0       luka donƒçiƒá  LAL               NaN                   36.0           37.100000      UTA 2025-11-18_LAL_UTA\n",
      "   1630202   Payton Pritchard               BOS                   LAC     24.333996         0.7           0             0          0.0  payton pritchard  BOS              31.0                   30.0           31.928571      BKN 2025-11-18_BKN_BOS\n",
      "   1641718     Keyonte George               UTA                   CHI     24.093391         0.7           0             0          0.0    keyonte george  UTA              34.0                   32.2           34.461538      LAL 2025-11-18_LAL_UTA\n",
      "   1630559      Austin Reaves               LAL                   MIL     23.561644         0.7           1             0          0.0     austin reaves  LAL               NaN                   34.4           36.272727      UTA 2025-11-18_LAL_UTA\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 16: Robust minutes cleaning + 240-min normalization --------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nba_boxscores_2025_26 = pd.read_csv(\"data_raw/nba_boxscores_2025-26.csv\")\n",
    "\n",
    "# Safety checks\n",
    "assert \"minutes_today\" in globals(), \"minutes_today missing ‚Äî run Cells 13b‚Äì14b first.\"\n",
    "assert \"today_games_clean\" in globals(), \"today_games_clean missing ‚Äî run the schedule cell.\"\n",
    "assert \"nba_boxscores_2025_26\" in globals(), \"nba_boxscores_2025_26 missing ‚Äî required for filtering active teams.\"\n",
    "\n",
    "mt = minutes_today.copy()\n",
    "\n",
    "# 1) Standardize 'team' column\n",
    "if \"team\" not in mt.columns:\n",
    "    if \"TEAM_ABBREVIATION\" in mt.columns:\n",
    "        mt[\"team\"] = mt[\"TEAM_ABBREVIATION\"]\n",
    "    else:\n",
    "        raise ValueError(\"minutes_today must have either 'team' or 'TEAM_ABBREVIATION'.\")\n",
    "\n",
    "mt[\"team\"] = mt[\"team\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "# 2) Restrict to teams playing today\n",
    "valid_teams = set(today_games_clean[\"team\"].astype(str).str.upper().unique())\n",
    "mt = mt[mt[\"team\"].isin(valid_teams)].copy()\n",
    "\n",
    "# 3) Filter out teams with no boxscore history this season\n",
    "played_teams = set(nba_boxscores_2025_26[\"TEAM_ABBREVIATION\"].astype(str).str.upper().unique())\n",
    "mt = mt[mt[\"team\"].isin(played_teams)].copy()\n",
    "\n",
    "# 4) Map TODAY's opponent from today_games_clean\n",
    "opp_map = (\n",
    "    today_games_clean\n",
    "    .assign(team=lambda d: d[\"team\"].astype(str).str.upper().str.strip())\n",
    "    .set_index(\"team\")[\"opponent\"]\n",
    "    .to_dict()\n",
    ")\n",
    "mt[\"opponent\"] = mt[\"team\"].map(opp_map)\n",
    "mt = mt.dropna(subset=[\"opponent\"])\n",
    "\n",
    "# 5) Remove duplicate PLAYER_IDs (keep highest minutes)\n",
    "mt = mt.sort_values(\"pred_minutes\", ascending=False)\n",
    "mt = mt.drop_duplicates(subset=[\"PLAYER_ID\"], keep=\"first\")\n",
    "\n",
    "# 6) Remove low-confidence players\n",
    "if \"may_not_play\" in mt.columns:\n",
    "    mt = mt[mt[\"may_not_play\"] == 0]\n",
    "mt = mt[mt[\"pred_minutes\"] > 0].copy()\n",
    "\n",
    "# 7) Map game_id to enable per-game normalization\n",
    "if \"game_id\" not in today_games_clean.columns:\n",
    "    raise ValueError(\"‚ùå today_games_clean must contain 'game_id' column.\")\n",
    "\n",
    "game_team_lookup = today_games_clean.set_index(\"team\")[\"game_id\"].to_dict()\n",
    "mt[\"game_id\"] = mt[\"team\"].map(game_team_lookup)\n",
    "mt = mt.dropna(subset=[\"game_id\"])\n",
    "\n",
    "# 8) Normalize predicted minutes to exactly 240 per team per game\n",
    "def normalize_minutes(df):\n",
    "    total = df[\"pred_minutes\"].sum()\n",
    "    if total < 1:\n",
    "        return df\n",
    "    scale = 240.0 / total\n",
    "    df[\"pred_minutes\"] = df[\"pred_minutes\"] * scale\n",
    "    return df\n",
    "\n",
    "mt = (\n",
    "    mt.groupby([\"game_id\", \"team\"], group_keys=False)\n",
    "      .apply(normalize_minutes)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 9) Final checks\n",
    "mins_team_check = mt.groupby([\"game_id\", \"team\"])[\"pred_minutes\"].sum()\n",
    "print(\"‚è± Final normalized minutes per team:\")\n",
    "print(mins_team_check.round(2).to_string())\n",
    "\n",
    "if not np.allclose(mins_team_check.values, 240.0, atol=0.2):\n",
    "    raise ValueError(\"‚ùå Minutes normalization failed: team totals not ~240.\")\n",
    "\n",
    "# Output\n",
    "minutes_today_clean = mt.copy()\n",
    "minutes_today = minutes_today_clean.copy()  # overwrite for downstream use\n",
    "\n",
    "print(\"‚úÖ minutes_today_clean ready and applied to minutes_today.\")\n",
    "print(minutes_today_clean.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3902c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 23 features for rate models.\n",
      "üìè PTS_per_min MAE: 0.1620 ¬± 0.0021\n",
      "üìè REB_per_min MAE: 0.0774 ¬± 0.0028\n",
      "üìè AST_per_min MAE: 0.0568 ¬± 0.0014\n",
      "‚úÖ Projections ready:\n",
      "{'AST': 756, 'PTS': 756, 'REB': 756}\n",
      " PLAYER_ID             player team opponent market  projection_mean  projection_sd  projected_minutes  pred_rate  start_prob  is_starter  may_not_play  injury_prob  game_date\n",
      "   1630639        A.J. Lawson  TOR      SAS    PTS        11.208425       4.996829          24.600000   0.455627         NaN           0             0          0.0 2025-11-18\n",
      "   1631260           AJ Green  MIL      CLE    PTS         8.700673       5.110123          26.200000   0.332087         NaN           0             0          0.0 2025-11-18\n",
      "   1631100         AJ Griffin  ATL      IND    PTS         2.273416       1.949360           6.000000   0.378903         NaN           0             0          0.0 2025-11-18\n",
      "   1642358         AJ Johnson  WAS      BKN    PTS         1.466789       1.520712           5.800000   0.252895         NaN           0             0          0.0 2025-11-18\n",
      "    203932       Aaron Gordon  DEN      CHI    PTS        20.673254       6.379287          30.400000   0.680041         NaN           0             0          0.0 2025-11-18\n",
      "   1628988      Aaron Holiday  HOU      ORL    PTS         4.363497       2.881682           7.200000   0.606041         NaN           0             0          0.0 2025-11-18\n",
      "   1630174      Aaron Nesmith  IND      PHX    PTS        13.153854       6.214634          31.800000   0.413643         NaN           0             0          0.0 2025-11-18\n",
      "   1630598      Aaron Wiggins  OKC      POR    PTS        14.682515       5.612288          27.400000   0.535858         NaN           0             0          0.0 2025-11-18\n",
      "   1642846         Ace Bailey  UTA      CHI    PTS         7.870999       3.992856          19.199421   0.409960         0.7           1             0          0.0 2025-11-18\n",
      "   1641745       Adam Flagler  OKC      NOP    PTS         2.527329       2.020175           8.400000   0.300873         NaN           0             0          0.0 2025-11-18\n",
      "   1641766       Adama Sanogo  CHI      CHA    PTS         3.474174       2.392811          10.250000   0.338944         NaN           0             0          0.0 2025-11-18\n",
      "   1641737          Adem Bona  PHI      DET    PTS         1.881119       2.792439          14.600000   0.128844         NaN           0             0          0.0 2025-11-18\n",
      "   1629678  Admiral Schofield  ORL      MIL    PTS         1.542254       1.687854           4.400000   0.350512         NaN           0             0          0.0 2025-11-18\n",
      "   1642876        Adou Thiero  LAL      MIL    PTS         6.219586       3.410668           8.732877   0.712204         0.7           0             0          0.0 2025-11-18\n",
      "   1642349      Ajay Mitchell  OKC      NOP    PTS        19.420708       6.277394          30.200000   0.643070         NaN           0             0          0.0 2025-11-18\n",
      "    201143         Al Horford  GSW      NOP    PTS         5.167161       3.615054          18.186255   0.284125         0.7           0             0          0.0 2025-11-18\n",
      "    202692         Alec Burks  MIA      NOP    PTS        12.371507       4.580705          20.200000   0.612451         NaN           0             0          0.0 2025-11-18\n",
      "   1630197 Aleksej Pokusevski  CHA      CLE    PTS         7.870700       3.992904          19.200000   0.409932         NaN           0             0          0.0 2025-11-18\n",
      "   1627936        Alex Caruso  OKC      CHA    PTS         6.027455       3.929062          19.800000   0.304417         NaN           0             0          0.0 2025-11-18\n",
      "   1642505         Alex Ducas  OKC      NOP    PTS         2.456736       1.972813           7.800000   0.314966         NaN           0             0          0.0 2025-11-18\n",
      "   1641788         Alex Fudge  DAL      OKC    PTS         1.926718       2.081660           4.200000   0.458742         NaN           0             0          0.0 2025-11-18\n",
      "    203458           Alex Len  LAL      POR    PTS         2.635805       2.678547          13.600000   0.193809         NaN           0             0          0.0 2025-11-18\n",
      "   1642024         Alex Reese  PHI      WAS    PTS         5.767966       3.577786          17.600000   0.327725         NaN           0             0          0.0 2025-11-18\n",
      "   1642259          Alex Sarr  WAS      BKN    PTS        19.532369       6.500658          31.800000   0.614225         NaN           0             0          0.0 2025-11-18\n",
      "   1631214   Alondes Williams  DET      ORL    PTS        22.091530       6.286235          28.750000   0.768401         NaN           0             0          0.0 2025-11-18\n",
      "   1630578     Alperen Sengun  HOU      ORL    PTS        32.127340       7.615291          35.000000   0.917924         NaN           0             0          0.0 2025-11-18\n",
      "   1641735       Amari Bailey  CHA      CLE    PTS         2.282404       2.085770           5.200000   0.438924         NaN           0             0          0.0 2025-11-18\n",
      "   1642873     Amari Williams  BOS      HOU    PTS         5.921100       4.094045          20.874751   0.283649         0.7           0             0          0.0 2025-11-18\n",
      "   1641708      Amen Thompson  HOU      ORL    PTS        18.219132       7.146195          36.400000   0.500526         NaN           0             0          0.0 2025-11-18\n",
      "   1629599        Amir Coffey  MIL      LAL    PTS         1.993167       2.230498          11.200000   0.177961         NaN           0             0          0.0 2025-11-18\n",
      "    203083     Andre Drummond  PHI      LAC    PTS        10.099052       5.735940          29.600000   0.341184         NaN           0             0          0.0 2025-11-18\n",
      "   1641748  Andre Jackson Jr.  MIL      LAL    PTS         0.518889       0.915047           3.800000   0.136550         NaN           0             0          0.0 2025-11-18\n",
      "   1641847        Andrew Funk  CHI      WAS    PTS         0.050410       0.289311           1.250000   0.040328         NaN           0             0          0.0 2025-11-18\n",
      "   1629614    Andrew Nembhard  IND      DET    PTS        16.417770       6.109350          30.200000   0.543635         NaN           0             0          0.0 2025-11-18\n",
      "    203952     Andrew Wiggins  MIA      NYK    PTS        16.211383       6.849373          35.000000   0.463182         NaN           0             0          0.0 2025-11-18\n",
      "   1629014    Anfernee Simons  BOS      LAC    PTS        11.254466       4.349061          19.021869   0.591659         0.7           0             0          0.0 2025-11-18\n",
      "   1641710      Anthony Black  ORL      HOU    PTS         8.271597       3.976973          18.755861   0.441014         0.7           0             0          0.0 2025-11-18\n",
      "    203076      Anthony Davis  DAL      IND    PTS        23.952407       7.274353          35.750000   0.669997         NaN           0             0          0.0 2025-11-18\n",
      "   1630162    Anthony Edwards  MIN      DAL    PTS        25.911110       7.087913          33.600000   0.771164         NaN           0             0          0.0 2025-11-18\n",
      "   1630264       Anthony Gill  WAS      CLE    PTS         2.418204       3.431965           3.000000   0.806068         NaN           0             0          0.0 2025-11-18\n"
     ]
    }
   ],
   "source": [
    "# -- Cell 17: per-minute rate models + today projections -----------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 0) Safety checks / inputs from previous cells\n",
    "# ---------------------------------------------------------------------------\n",
    "assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
    "    \"features_all missing. Run Cell 7 + Cell 0_data first.\"\n",
    "assert 'minutes_today' in globals() and isinstance(minutes_today, pd.DataFrame) and not minutes_today.empty, \\\n",
    "    \"minutes_today missing. Run Cells 5‚Äì7 first.\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1) Build leakage-safe rate targets for training\n",
    "#    We predict per-minute rates (not raw totals); later multiply by pred_minutes.\n",
    "# ---------------------------------------------------------------------------\n",
    "train = features_all.copy()\n",
    "\n",
    "# Ensure numeric MIN\n",
    "if \"MIN\" not in train.columns:\n",
    "    raise RuntimeError(\"MIN column not found in features_all.\")\n",
    "train[\"MIN\"] = pd.to_numeric(train[\"MIN\"], errors=\"coerce\")\n",
    "\n",
    "# Filter out super-low minute games (noisy rate)\n",
    "train = train[train[\"MIN\"].fillna(0) >= 6].copy()\n",
    "\n",
    "# Targets as same-day rates (no look-ahead)\n",
    "for stat in [\"PTS\",\"REB\",\"AST\"]:\n",
    "    if stat not in train.columns:\n",
    "        train[stat] = np.nan\n",
    "    train[f\"{stat}_per_min\"] = train[stat] / train[\"MIN\"].replace(0, np.nan)\n",
    "\n",
    "# Drop impossible rows\n",
    "for stat in [\"PTS_per_min\",\"REB_per_min\",\"AST_per_min\"]:\n",
    "    train = train[~np.isinf(train[stat])].copy()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2) Feature set for rate models\n",
    "#    Avoid using future minutes; keep context/skill/opponent/usage style features.\n",
    "# ---------------------------------------------------------------------------\n",
    "CANDIDATE_FEATURES = [\n",
    "    # form / efficiency (all must be shift(1) upstream in features_all)\n",
    "    \"TS_game_roll5\",\"TS_game_roll10\",\n",
    "    \"MIN_roll5\",\"MIN_roll10\",            # ok: proxy for role, but target is rate not minutes\n",
    "    \"PTS_roll5\",\"PTS_roll10\",\n",
    "    \"REB_roll5\",\"REB_roll10\",\n",
    "    \"AST_roll5\",\"AST_roll10\",\n",
    "    \"usage_share_roll5\",\n",
    "\n",
    "    # season labels\n",
    "    \"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\n",
    "\n",
    "    # team/matchup context (shifted rolling at team level)\n",
    "    \"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
    "\n",
    "    # optional opponent allowances by position (if present from Cell 7)\n",
    "    # Common column names look like: PTS_allowed_roll10_PG, AST_allowed_roll10_C, etc.\n",
    "    # We'll auto-include any *_allowed_roll10_* columns if present:\n",
    "] + [c for c in features_all.columns if \"_allowed_roll10_\" in c]\n",
    "\n",
    "# Situational flags (can influence rate a bit)\n",
    "SITUATIONAL = [\"HOME\",\"days_rest\",\"is_b2b\"]\n",
    "CANDIDATE_FEATURES += [c for c in SITUATIONAL if c in features_all.columns]\n",
    "\n",
    "# Robust final feature list (present in the dataframe)\n",
    "RATE_FEATURES = [c for c in CANDIDATE_FEATURES if c in train.columns]\n",
    "\n",
    "print(f\"Using {len(RATE_FEATURES)} features for rate models.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3) Train one model per stat rate with GroupKFold by player\n",
    "# ---------------------------------------------------------------------------\n",
    "models_rate = {}\n",
    "cv_scores_rate = {}\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "def train_rate_model(df: pd.DataFrame, target_col: str, feat_cols: list[str]):\n",
    "    df_ = df.dropna(subset=feat_cols + [target_col, \"PLAYER_ID\"]).copy()\n",
    "    X = df_[feat_cols]\n",
    "    y = df_[target_col]\n",
    "    groups = df_[\"PLAYER_ID\"]\n",
    "\n",
    "    fold_mae = []\n",
    "    for tr, te in gkf.split(X, y, groups):\n",
    "        Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
    "        ytr, yte = y.iloc[tr], y.iloc[te]\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=1.0,\n",
    "            reg_alpha=0.0,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(Xtr, ytr)\n",
    "        pred = model.predict(Xte)\n",
    "        fold_mae.append(mean_absolute_error(yte, pred))\n",
    "\n",
    "    model.fit(X, y)  # final fit\n",
    "    return model, float(np.mean(fold_mae)), float(np.std(fold_mae))\n",
    "\n",
    "for stat in [\"PTS\",\"REB\",\"AST\"]:\n",
    "    target = f\"{stat}_per_min\"\n",
    "    model, m, s = train_rate_model(train, target, RATE_FEATURES)\n",
    "    models_rate[stat] = model\n",
    "    cv_scores_rate[stat] = (m, s)\n",
    "    print(f\"üìè {stat}_per_min MAE: {m:.4f} ¬± {s:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4) Project TODAY's rates and totals = rate * predicted minutes\n",
    "# ---------------------------------------------------------------------------\n",
    "# Build today's feature frame: take latest per player and align with RATE_FEATURES.\n",
    "latest_today = (\n",
    "    features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "                .groupby(\"PLAYER_NAME\", as_index=False)\n",
    "                .tail(1)\n",
    "                .copy()\n",
    ")\n",
    "\n",
    "# Ensure all feature columns exist; if not, fill with neutral values\n",
    "for c in RATE_FEATURES:\n",
    "    if c not in latest_today.columns:\n",
    "        latest_today[c] = 0.0\n",
    "\n",
    "X_today = latest_today[RATE_FEATURES].copy()\n",
    "\n",
    "# Join minutes prediction\n",
    "mt = minutes_today.rename(columns={\"PLAYER_NAME\":\"PLAYER_NAME_mins\"})\n",
    "proj_base = latest_today.merge(\n",
    "    mt[[\"PLAYER_ID\",\"pred_minutes\",\"start_prob\",\"is_starter\",\"may_not_play\",\"injury_prob\"]],\n",
    "    on=\"PLAYER_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "# If a player lacks a minutes prediction, give a conservative fallback\n",
    "proj_base[\"pred_minutes\"] = proj_base[\"pred_minutes\"].fillna(proj_base.get(\"MIN_roll5\", 24)).clip(0, 48)\n",
    "\n",
    "# Predict rates\n",
    "out_frames = []\n",
    "for stat in [\"PTS\",\"REB\",\"AST\"]:\n",
    "    mu_rate = models_rate[stat].predict(X_today)\n",
    "\n",
    "    # Simple uncertainty model:\n",
    "    #   - empirical residual SD in rate space per stat (global)\n",
    "    #   - then combine with minutes variance (approx) for total SD\n",
    "    # Build residual SD once from training data\n",
    "    df_t = train.dropna(subset=RATE_FEATURES + [f\"{stat}_per_min\",\"PLAYER_ID\"]).copy()\n",
    "    pred_rate_t = models_rate[stat].predict(df_t[RATE_FEATURES])\n",
    "    resid = (df_t[f\"{stat}_per_min\"] - pred_rate_t).values\n",
    "    sd_rate = np.nanstd(resid, ddof=1) if len(resid) > 8 else 0.0\n",
    "\n",
    "    # Minutes uncertainty proxy from minutes model signals:\n",
    "    #   baseline 3.0 min SD, boosted if not confirmed starter or has injury_prob\n",
    "    min_sd = 3.0 \\\n",
    "             + 4.0*(1.0 - proj_base[\"start_prob\"].fillna(0.7).values) \\\n",
    "             + 4.0*(proj_base[\"injury_prob\"].fillna(0.0).values)\n",
    "\n",
    "    # Combine:\n",
    "    #   Var(total) ‚âà Var(rate*min) ‚âà E[min]^2 * Var(rate) + E[rate]^2 * Var(min)\n",
    "    pred_min = proj_base[\"pred_minutes\"].values\n",
    "    var_total = (pred_min**2) * (sd_rate**2) + (mu_rate**2) * (min_sd**2)\n",
    "    sd_total = np.sqrt(np.maximum(var_total, 1e-6))\n",
    "\n",
    "    totals = mu_rate * pred_min\n",
    "\n",
    "    df_out = pd.DataFrame({\n",
    "        \"PLAYER_ID\": proj_base[\"PLAYER_ID\"],\n",
    "        \"PLAYER_NAME\": proj_base[\"PLAYER_NAME\"],\n",
    "        \"TEAM_ABBREVIATION\": proj_base[\"TEAM_ABBREVIATION\"],\n",
    "        \"OPPONENT_ABBREVIATION\": proj_base[\"OPPONENT_ABBREVIATION\"],\n",
    "        \"market\": stat,\n",
    "        \"projection_mean\": totals,\n",
    "        \"projection_sd\": sd_total,\n",
    "        \"pred_minutes\": pred_min,\n",
    "        \"pred_rate\": mu_rate,\n",
    "        \"start_prob\": proj_base[\"start_prob\"].round(2),\n",
    "        \"is_starter\": proj_base[\"is_starter\"].fillna(0).astype(int),\n",
    "        \"may_not_play\": proj_base[\"may_not_play\"].fillna(0).astype(int),\n",
    "        \"injury_prob\": proj_base[\"injury_prob\"].fillna(0.0).round(2)\n",
    "    })\n",
    "    out_frames.append(df_out)\n",
    "\n",
    "proj_base[\"OPPONENT_ABBREVIATION\"] = proj_base[\"OPPONENT_ABBREVIATION\"].fillna(\"UNK\").astype(str)\n",
    "\n",
    "df_projections_all = pd.concat(out_frames, ignore_index=True)\n",
    "\n",
    "# Normalize export columns like your Cell 16 pipeline expects\n",
    "df_projections_all = df_projections_all.rename(columns={\n",
    "    \"PLAYER_NAME\": \"player\",\n",
    "    \"TEAM_ABBREVIATION\": \"team\",\n",
    "    \"OPPONENT_ABBREVIATION\": \"opponent\",\n",
    "    \"pred_minutes\": \"projected_minutes\"\n",
    "})\n",
    "df_projections_all[\"game_date\"] = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(\"‚úÖ Projections ready:\")\n",
    "print(df_projections_all.groupby(\"market\")[\"player\"].count().to_dict())\n",
    "print(df_projections_all.head(40).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce91ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -- Cell 18: Assign today's opponent to each player -----------------------\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_team_today\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create lookup: team -> opponent\u001b[39;00m\n\u001b[0;32m      6\u001b[0m opp_map \u001b[38;5;241m=\u001b[39m df_team_today\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopponent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -- Cell 18 (fixed): Assign today's opponent to each player -----------------------\n",
    "\n",
    "assert \"today_games_clean\" in globals()\n",
    "\n",
    "# Create lookup: team -> opponent\n",
    "opp_map = today_games_clean.set_index(\"team\")[\"opponent\"].to_dict()\n",
    "\n",
    "# Assign opponent to each player\n",
    "df_projections_all[\"opponent\"] = df_projections_all[\"team\"].map(opp_map)\n",
    "\n",
    "print(df_projections_all[[\"player\",\"team\",\"opponent\"]].head(20))\n",
    "\n",
    "# Filter only teams in today‚Äôs slate\n",
    "valid_teams = set(today_games_clean[\"team\"].unique())\n",
    "\n",
    "df_projections_all = df_projections_all[\n",
    "    df_projections_all[\"team\"].isin(valid_teams)\n",
    "].copy()\n",
    "\n",
    "print(\"Remaining teams:\", df_projections_all[\"team\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b22cd9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è± Projected total minutes per team:\n",
      "team  team_total_minutes\n",
      " ATL               240.0\n",
      " BKN               240.0\n",
      " BOS               240.0\n",
      " DET               240.0\n",
      " GSW               240.0\n",
      " LAL               240.0\n",
      " MEM               240.0\n",
      " ORL               240.0\n",
      " PHX               240.0\n",
      " POR               240.0\n",
      " SAS               240.0\n",
      " UTA               240.0\n"
     ]
    }
   ],
   "source": [
    "# -- Sanity check: projected minutes per team today -------------------------\n",
    "import pandas as pd\n",
    "\n",
    "assert \"minutes_today\" in globals(), \"minutes_today missing.\"\n",
    "assert \"today_games_clean\" in globals(), \"today_games_clean from Cell X missing.\"\n",
    "\n",
    "# Map players to today's teams only\n",
    "mt_today = minutes_today.copy()\n",
    "if \"team\" not in mt_today.columns and \"TEAM_ABBREVIATION\" in mt_today.columns:\n",
    "    mt_today[\"team\"] = mt_today[\"TEAM_ABBREVIATION\"]\n",
    "\n",
    "teams_today = today_games_clean[\"team\"].unique()\n",
    "mt_today = mt_today[mt_today[\"team\"].isin(teams_today)].copy()\n",
    "\n",
    "# Sum minutes per team\n",
    "mins_by_team = (\n",
    "    mt_today.groupby(\"team\")[\"pred_minutes\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"pred_minutes\":\"team_total_minutes\"})\n",
    ")\n",
    "\n",
    "print(\"‚è± Projected total minutes per team:\")\n",
    "print(mins_by_team.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361328fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for stat, model in models_rate.items():\n",
    "    importance = model.feature_importances_\n",
    "    sorted_idx = np.argsort(importance)[::-1]\n",
    "    sorted_feats = [RATE_FEATURES[i] for i in sorted_idx]\n",
    "    sorted_imp = importance[sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.title(f\"Feature Importance: {stat}_per_min\")\n",
    "    plt.barh(sorted_feats[:12][::-1], sorted_imp[:12][::-1])  # Top 12\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a823e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features used in rate models:\\n\", RATE_FEATURES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87786090",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05885691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -- cell 8_rate_model ---------------------------------------------------------\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 0) Safety checks\n",
    "# # ---------------------------------------------------------------------------\n",
    "# assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
    "#     \"features_all missing. Run Cell 7 + Cell 0_data first.\"\n",
    "# assert 'minutes_today' in globals() and isinstance(minutes_today, pd.DataFrame) and not minutes_today.empty, \\\n",
    "#     \"minutes_today missing. Build your base minutes first.\"\n",
    "\n",
    "# fa = features_all.copy()\n",
    "# if \"GAME_DATE\" in fa.columns:\n",
    "#     fa[\"GAME_DATE\"] = pd.to_datetime(fa[\"GAME_DATE\"])\n",
    "\n",
    "# # Minimal id keys (best-effort)\n",
    "# if \"PLAYER_ID\" not in fa.columns:\n",
    "#     # fabricate a stable id per name if you don't have PLAYER_ID\n",
    "#     fa[\"PLAYER_ID\"] = fa[\"PLAYER_NAME\"].factorize()[0] + 1\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 1) Build leakage-safe RATE targets using next game's totals/minutes\n",
    "# #    target_rate(stat) = stat_next / max(MIN_next, 1)\n",
    "# # ---------------------------------------------------------------------------\n",
    "# fa = fa.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).copy()\n",
    "# for col in [\"MIN\",\"PTS\",\"REB\",\"AST\"]:\n",
    "#     if col not in fa.columns:\n",
    "#         fa[col] = np.nan\n",
    "\n",
    "# fa[\"MIN_next\"] = fa.groupby(\"PLAYER_NAME\")[\"MIN\"].shift(-1)\n",
    "# fa[\"PTS_next\"] = fa.groupby(\"PLAYER_NAME\")[\"PTS\"].shift(-1)\n",
    "# fa[\"REB_next\"] = fa.groupby(\"PLAYER_NAME\")[\"REB\"].shift(-1)\n",
    "# fa[\"AST_next\"] = fa.groupby(\"PLAYER_NAME\")[\"AST\"].shift(-1)\n",
    "\n",
    "# def _rate_next(numer_next, min_next):\n",
    "#     m = np.maximum(min_next.astype(float), 1.0)\n",
    "#     return numer_next.astype(float) / m\n",
    "\n",
    "# fa[\"PTS_rate_next\"] = _rate_next(fa[\"PTS_next\"], fa[\"MIN_next\"])\n",
    "# fa[\"REB_rate_next\"] = _rate_next(fa[\"REB_next\"], fa[\"MIN_next\"])\n",
    "# fa[\"AST_rate_next\"] = _rate_next(fa[\"AST_next\"], fa[\"MIN_next\"])\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 2) Feature set (reuse what you already engineered if present)\n",
    "# #    Keep it robust to missing columns.\n",
    "# # ---------------------------------------------------------------------------\n",
    "# BASE_FEATURES = [\n",
    "#     \"MIN_roll5\",\"MIN_roll10\",\"TS_game_roll5\",\"TS_game_roll10\",\n",
    "#     \"usage_share_roll5\",\"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
    "#     \"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\n",
    "#     \"days_rest\",\"HOME\",\n",
    "#     # Extras if your pipeline created them:\n",
    "#     \"PTS_roll5\",\"PTS_roll10\",\"REB_roll5\",\"REB_roll10\",\"AST_roll5\",\"AST_roll10\",\n",
    "#     \"PTS_trend\",\"REB_trend\",\"AST_trend\",\n",
    "#     \"PTS_roll5_std\",\"REB_roll5_std\",\"AST_roll5_std\",\n",
    "#     \"usage_minutes_interact\",\"ts_usage_interact\",\n",
    "#     \"opp_ORtg_g_roll5\",\"opp_DRtg_g_roll5\",\"opp_Pace_g_roll5\",\"pace_diff5\"\n",
    "# ]\n",
    "# TARGETS = {\n",
    "#     \"PTS\": \"PTS_rate_next\",\n",
    "#     \"REB\": \"REB_rate_next\",\n",
    "#     \"AST\": \"AST_rate_next\",\n",
    "# }\n",
    "\n",
    "# def _present(cols): \n",
    "#     return [c for c in cols if c in fa.columns]\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 3) Train XGBRegressor per stat on RATE targets (time-ordered CV)\n",
    "# # ---------------------------------------------------------------------------\n",
    "# models_rate = {}\n",
    "# cv_scores = {}\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# for stat, tgt in TARGETS.items():\n",
    "#     feat_cols = _present(BASE_FEATURES)\n",
    "#     need = feat_cols + [\"PLAYER_ID\",\"GAME_DATE\",\"MIN_next\", tgt]\n",
    "#     data = fa.dropna(subset=[c for c in need if c in fa.columns]).copy()\n",
    "\n",
    "#     # Optional: restrict to games where next minutes >= 6 to reduce noisy targets\n",
    "#     data = data[data[\"MIN_next\"] >= 6].copy()\n",
    "\n",
    "#     if data.empty:\n",
    "#         print(f\"‚ö†Ô∏è No training data for {stat}. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     data = data.sort_values(\"GAME_DATE\")\n",
    "#     X = data[feat_cols].fillna(0.0)\n",
    "#     y = data[tgt].astype(float)\n",
    "\n",
    "#     fold_mae=[]\n",
    "#     for tr_idx, te_idx in tscv.split(X):\n",
    "#         Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "#         ytr, yte = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "#         model = XGBRegressor(\n",
    "#             n_estimators=500, learning_rate=0.05, max_depth=5,\n",
    "#             subsample=0.85, colsample_bytree=0.9,\n",
    "#             reg_lambda=1.0, reg_alpha=0.0,\n",
    "#             random_state=42, n_jobs=-1, verbosity=0\n",
    "#         )\n",
    "#         model.fit(Xtr, ytr)\n",
    "#         pred = model.predict(Xte)\n",
    "#         fold_mae.append(mean_absolute_error(yte, pred))\n",
    "#     cv_scores[stat] = (float(np.mean(fold_mae)), float(np.std(fold_mae)))\n",
    "#     print(f\"Rate {stat} MAE (TimeSeries CV): {np.mean(fold_mae):.3f} ¬± {np.std(fold_mae):.3f}\")\n",
    "\n",
    "#     final_model = XGBRegressor(\n",
    "#         n_estimators=600, learning_rate=0.045, max_depth=5,\n",
    "#         subsample=0.9, colsample_bytree=0.9,\n",
    "#         reg_lambda=1.0, reg_alpha=0.0,\n",
    "#         random_state=42, n_jobs=-1, verbosity=0\n",
    "#     )\n",
    "#     final_model.fit(X, y)\n",
    "#     models_rate[stat] = (final_model, feat_cols)\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 4) Build today's feature rows and merge with minutes_today\n",
    "# #    Use each player's latest historical row as \"today context\".\n",
    "# # ---------------------------------------------------------------------------\n",
    "# latest = (\n",
    "#     fa.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "#       .groupby(\"PLAYER_NAME\", as_index=False)\n",
    "#       .tail(1)\n",
    "#       .copy()\n",
    "# )\n",
    "\n",
    "# # Normalize team/opponent keys\n",
    "# for c in [\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]:\n",
    "#     if c not in latest.columns:\n",
    "#         latest[c] = np.nan\n",
    "\n",
    "# # align to players we have minutes for today\n",
    "# key_cols = [\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]\n",
    "# mt = minutes_today.copy()\n",
    "# if \"PLAYER_ID\" not in mt.columns:\n",
    "#     # map PLAYER_ID from latest by name when missing\n",
    "#     name_to_id = latest.set_index(\"PLAYER_NAME\")[\"PLAYER_ID\"].to_dict()\n",
    "#     mt[\"PLAYER_ID\"] = mt[\"PLAYER_NAME\"].map(name_to_id)\n",
    "\n",
    "# today = pd.merge(\n",
    "#     latest,\n",
    "#     mt[[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\",\n",
    "#         \"pred_minutes\",\"start_prob\"]].drop_duplicates(\"PLAYER_ID\"),\n",
    "#     on=[\"PLAYER_ID\",\"PLAYER_NAME\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"],\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\",\"\")\n",
    "# )\n",
    "\n",
    "# if today.empty:\n",
    "#     raise RuntimeError(\"No overlap between latest history and minutes_today. Check name/team keys.\")\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 5) Predict per-minute rates ‚Üí multiply by predicted minutes ‚Üí totals\n",
    "# #    Also compute a reasonable per-player SD per market.\n",
    "# # ---------------------------------------------------------------------------\n",
    "# proj_frames = []\n",
    "# for stat, (model, feat_cols) in models_rate.items():\n",
    "#     cols = [c for c in feat_cols if c in today.columns]\n",
    "#     if not cols:\n",
    "#         print(f\"‚ö†Ô∏è No features present for {stat}. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     Xp = today[cols].fillna(0.0)\n",
    "#     rate_hat = model.predict(Xp)                      # predicted stat per minute\n",
    "#     mins_hat = today[\"pred_minutes\"].astype(float).clip(lower=0, upper=48).values\n",
    "#     total_hat = np.clip(rate_hat * mins_hat, 0, None)\n",
    "\n",
    "#     # SD heuristic:\n",
    "#     # - player-specific per-minute volatility from last 10 games\n",
    "#     # - scaled by predicted minutes\n",
    "#     # - floor to avoid zero SD\n",
    "#     hist = (\n",
    "#         fa.assign(rate=lambda d: np.where(d[\"MIN\"]>0, d[stat] / d[\"MIN\"], np.nan))\n",
    "#           .sort_values([\"PLAYER_NAME\",\"GAME_DATE\"])\n",
    "#     )\n",
    "#     sd_map = (\n",
    "#         hist.groupby(\"PLAYER_NAME\")[\"rate\"]\n",
    "#             .apply(lambda s: s.tail(10).std(ddof=1))\n",
    "#             .replace([np.inf,-np.inf], np.nan)\n",
    "#     ).to_dict()\n",
    "#     sd_rate = today[\"PLAYER_NAME\"].map(sd_map).astype(float).fillna(0.10)   # fallback 0.10 per min\n",
    "#     sd_total = (sd_rate.values * np.sqrt(np.maximum(mins_hat, 1.0))).clip(0.75, None)\n",
    "\n",
    "#     dfp = pd.DataFrame({\n",
    "#         \"player\": today[\"PLAYER_NAME\"],\n",
    "#         \"team\": today[\"TEAM_ABBREVIATION\"],\n",
    "#         \"opponent\": today[\"OPPONENT_ABBREVIATION\"],\n",
    "#         \"game_date\": pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "#         \"market\": stat,\n",
    "#         \"projected_minutes\": mins_hat,\n",
    "#         \"start_prob\": today.get(\"start_prob\", pd.Series(0.75, index=today.index)).fillna(0.75).values,\n",
    "#         \"projection_mean\": total_hat,\n",
    "#         \"projection_sd\": sd_total\n",
    "#     })\n",
    "#     proj_frames.append(dfp)\n",
    "\n",
    "# df_projections_all = pd.concat(proj_frames, ignore_index=True) if proj_frames else pd.DataFrame()\n",
    "# df_projections_pts = df_projections_all[df_projections_all[\"market\"].eq(\"PTS\")].copy() if not df_projections_all.empty else pd.DataFrame()\n",
    "# df_projections_reb = df_projections_all[df_projections_all[\"market\"].eq(\"REB\")].copy() if not df_projections_all.empty else pd.DataFrame()\n",
    "# df_projections_ast = df_projections_all[df_projections_all[\"market\"].eq(\"AST\")].copy() if not df_projections_all.empty else pd.DataFrame()\n",
    "\n",
    "# print(\"\\n‚úÖ Rate models trained and projections built.\")\n",
    "# print(\"CV (MAE on rate targets):\", cv_scores)\n",
    "# print(\"Projection rows by market:\", df_projections_all[\"market\"].value_counts().to_dict() if not df_projections_all.empty else {})\n",
    "# print(df_projections_all.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--cell 8--#\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from xgboost import XGBRegressor\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # --- Load your logs and enriched season files ---\n",
    "# logs_2324 = pd.read_csv(\"nba_boxscores_2023-24.csv\")\n",
    "# logs_2425 = pd.read_csv(\"nba_boxscores_2024-25.csv\")\n",
    "# enriched_2324 = pd.read_csv(\"nba_player_stats_2023_24_enriched.csv\")\n",
    "# enriched_2425 = pd.read_csv(\"nba_player_stats_2024_25_enriched.csv\")\n",
    "\n",
    "# # --- Build feature tables per season and concatenate ---\n",
    "# feat_2324 = assemble_player_game_features(logs_2324, enriched_2324)\n",
    "# feat_2425 = assemble_player_game_features(logs_2425, enriched_2425)\n",
    "# features_all = pd.concat([feat_2324, feat_2425], ignore_index=True)\n",
    "\n",
    "# # --- Base feature pool ---\n",
    "# BASE_FEATURES = [\n",
    "#     \"MIN_roll5\", \"MIN_roll10\", \"TS_game_roll5\", \"TS_game_roll10\", \"usage_share_roll5\",\n",
    "#     \"ORtg_g_roll5\", \"DRtg_g_roll5\", \"Pace_g_roll5\",\n",
    "#     \"PER\", \"TS%\", \"USG%\", \"ORtg\", \"DRtg\", \"WS/48\", \"BPM\", \"VORP\",\n",
    "#     \"days_rest\", \"HOME\"\n",
    "# ]\n",
    "# STAT_ROLLING = {\n",
    "#     \"PTS\": [\"PTS_roll5\", \"PTS_roll10\"],\n",
    "#     \"REB\": [\"REB_roll5\", \"REB_roll10\"],\n",
    "#     \"AST\": [\"AST_roll5\", \"AST_roll10\"],\n",
    "# }\n",
    "# TARGETS = {\n",
    "#     \"PTS\": \"PTS_next\",\n",
    "#     \"REB\": \"REB_next\",\n",
    "#     \"AST\": \"AST_next\",\n",
    "# }\n",
    "\n",
    "# models = {}\n",
    "# feature_cols_by_stat = {}\n",
    "# cv_scores = {}\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# for stat, target_col in TARGETS.items():\n",
    "#     cand_feats = BASE_FEATURES + STAT_ROLLING[stat]\n",
    "#     feat_cols = [c for c in cand_feats if c in features_all.columns]\n",
    "#     feature_cols_by_stat[stat] = feat_cols\n",
    "\n",
    "#     data = features_all.dropna(subset=feat_cols + [target_col]).copy()\n",
    "#     if data.empty:\n",
    "#         print(f\"‚ö†Ô∏è No training data for {stat}. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     data_sorted = data.sort_values(\"GAME_DATE\")\n",
    "#     X = data_sorted[feat_cols]\n",
    "#     y = data_sorted[target_col]\n",
    "\n",
    "#     maes = []\n",
    "#     for train_idx, test_idx in tscv.split(X):\n",
    "#         Xtr, Xte = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         ytr, yte = y.iloc[train_idx], y.iloc[test_idx]\n",
    "#         model = XGBRegressor(\n",
    "#             n_estimators=300,\n",
    "#             learning_rate=0.1,\n",
    "#             max_depth=4,\n",
    "#             subsample=0.8,\n",
    "#             colsample_bytree=0.8,\n",
    "#             random_state=42,\n",
    "#             n_jobs=-1,\n",
    "#             verbosity=0\n",
    "#         )\n",
    "#         model.fit(Xtr, ytr)\n",
    "#         pred = model.predict(Xte)\n",
    "#         maes.append(mean_absolute_error(yte, pred))\n",
    "\n",
    "#     cv_scores[stat] = (float(np.mean(maes)), float(np.std(maes)))\n",
    "#     print(f\"XGBoost Player {stat} MAE (TimeSeries CV): {np.mean(maes):.2f} ¬± {np.std(maes):.2f}\")\n",
    "\n",
    "#     final_model = XGBRegressor(\n",
    "#         n_estimators=300,\n",
    "#         learning_rate=0.1,\n",
    "#         max_depth=4,\n",
    "#         subsample=0.8,\n",
    "#         colsample_bytree=0.8,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#         verbosity=0\n",
    "#     )\n",
    "#     final_model.fit(X, y)\n",
    "#     models[stat] = final_model\n",
    "\n",
    "# if \"PTS\" in models:\n",
    "#     model = models[\"PTS\"]\n",
    "#     feature_cols = feature_cols_by_stat[\"PTS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- cell 16 (feature importances ‚Äî robust for models_rate/models_mean/models) ---\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    def display(x): print(x)\n",
    "\n",
    "# 1) Detect trained models + their feature maps\n",
    "_models = None\n",
    "_feat_map = {}\n",
    "\n",
    "def _is_tuple_model(v):\n",
    "    # supports (model, feat_cols) or [model, feat_cols]\n",
    "    return isinstance(v, (tuple, list)) and len(v) >= 1\n",
    "\n",
    "if \"models_rate\" in globals() and isinstance(models_rate, dict) and models_rate:\n",
    "    # models_rate can be {\"PTS\": model} OR {\"PTS\": (model, feat_cols)}\n",
    "    _models = {}\n",
    "    _feat_map = {}\n",
    "    for k, v in models_rate.items():\n",
    "        if _is_tuple_model(v):\n",
    "            _models[k] = v[0]\n",
    "            _feat_map[k] = list(v[1]) if len(v) > 1 else []\n",
    "        else:\n",
    "            _models[k] = v\n",
    "            # fallback: use RATE_FEATURES if present, else empty\n",
    "            _feat_map[k] = list(globals().get(\"RATE_FEATURES\", []))\n",
    "elif \"models_mean\" in globals() and isinstance(models_mean, dict) and models_mean:\n",
    "    _models = models_mean\n",
    "    if \"feature_bags\" in globals() and isinstance(feature_bags, dict):\n",
    "        _feat_map = feature_bags\n",
    "    else:\n",
    "        # fallback: use RATE_FEATURES if present\n",
    "        rf = list(globals().get(\"RATE_FEATURES\", []))\n",
    "        _feat_map = {k: rf for k in _models.keys()}\n",
    "elif \"models\" in globals() and isinstance(models, dict) and models:\n",
    "    _models = models\n",
    "    if \"feature_cols_by_stat\" in globals() and isinstance(feature_cols_by_stat, dict):\n",
    "        _feat_map = feature_cols_by_stat\n",
    "    else:\n",
    "        rf = list(globals().get(\"RATE_FEATURES\", []))\n",
    "        _feat_map = {k: rf for k in _models.keys()}\n",
    "\n",
    "if not _models:\n",
    "    raise RuntimeError(\"No trained models found (expected models_rate / models_mean / models). Train first.\")\n",
    "\n",
    "# 2) Importance extractor for XGBoost (gain -> weight -> sklearn attr)\n",
    "def _xgb_importances(mdl, feat_cols):\n",
    "    # Try booster-based importances\n",
    "    booster = None\n",
    "    try:\n",
    "        booster = mdl.get_booster()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if booster is not None:\n",
    "        # prefer 'gain', else 'weight'\n",
    "        try:\n",
    "            raw = booster.get_score(importance_type=\"gain\")\n",
    "        except Exception:\n",
    "            raw = booster.get_score(importance_type=\"weight\")\n",
    "\n",
    "        s = pd.Series(raw, dtype=float)\n",
    "        if not s.empty:\n",
    "            # Map f0,f1,... to actual names if available\n",
    "            feat_names = None\n",
    "            try:\n",
    "                feat_names = booster.feature_names\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            if feat_names and all(isinstance(x, str) for x in feat_names):\n",
    "                if all(k.startswith(\"f\") and k[1:].isdigit() for k in s.index):\n",
    "                    idx_map = {f\"f{i}\": feat_names[i] for i in range(len(feat_names))}\n",
    "                    s.index = [idx_map.get(k, k) for k in s.index]\n",
    "            elif feat_cols:\n",
    "                # last-resort: align by index order if keys look like f0,f1,...\n",
    "                if all(k.startswith(\"f\") and k[1:].isdigit() for k in s.index) and len(feat_cols) >= len(s):\n",
    "                    idx_map = {f\"f{i}\": feat_cols[i] for i in range(len(feat_cols))}\n",
    "                    s.index = [idx_map.get(k, k) for k in s.index]\n",
    "            return s.sort_values(ascending=False)\n",
    "\n",
    "    # Fallback to sklearn-style attribute\n",
    "    if hasattr(mdl, \"feature_importances_\") and feat_cols:\n",
    "        s = pd.Series(mdl.feature_importances_, index=feat_cols, dtype=float)\n",
    "        return s.sort_values(ascending=False)\n",
    "\n",
    "    # Last fallback: return empty\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "# 3) Build & display per-stat importances\n",
    "rows = []\n",
    "print(\"=== Feature Importances (top 15 by stat) ===\")\n",
    "for stat, mdl in _models.items():\n",
    "    feat_cols = _feat_map.get(stat, [])\n",
    "    imp = _xgb_importances(mdl, feat_cols)\n",
    "\n",
    "    print(f\"\\nTop 15 ‚Äî {stat}:\")\n",
    "    if imp.empty:\n",
    "        print(\"(no importance info available)\")\n",
    "        continue\n",
    "\n",
    "    display(imp.head(15))\n",
    "    for feat, val in imp.items():\n",
    "        rows.append({\"stat\": stat, \"feature\": feat, \"importance\": float(val)})\n",
    "\n",
    "# 4) Save tidy CSV + normalized pivot\n",
    "imp_df = pd.DataFrame(rows)\n",
    "if not imp_df.empty:\n",
    "    out_dir = \"model_outputs_rate\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    imp_df[\"importance_norm\"] = (\n",
    "        imp_df.groupby(\"stat\")[\"importance\"].transform(lambda x: x / (x.sum() if x.sum() else 1.0))\n",
    "    )\n",
    "\n",
    "    ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = os.path.join(out_dir, f\"feature_importances_{ts}.csv\")\n",
    "    imp_df.sort_values([\"stat\", \"importance\"], ascending=[True, False]).to_csv(out_path, index=False)\n",
    "    print(f\"\\n‚úÖ Saved importances to: {out_path}\")\n",
    "\n",
    "    feature_importance_wide = imp_df.pivot_table(\n",
    "        index=\"feature\", columns=\"stat\", values=\"importance_norm\", aggfunc=\"max\", fill_value=0.0\n",
    "    ).sort_values(by=list(_models.keys())[0] if _models else None, ascending=False)\n",
    "    print(\"\\n(Preview) Normalized importance wide table:\")\n",
    "    display(feature_importance_wide.head(20))\n",
    "else:\n",
    "    print(\"\\n Nothing to export ‚Äî no importances produced.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40247d",
   "metadata": {},
   "source": [
    "## team-level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--cell 10--#\n",
    "# # Team game table\n",
    "# team_games = features_all.groupby([\"GAME_DATE\",\"TEAM_ABBREVIATION\"], as_index=False)\\\n",
    "#     .agg(\n",
    "#         team_pts=(\"PTS\",\"sum\"),\n",
    "#         team_pts_next=(\"PTS_next\",\"sum\"),\n",
    "#         or5=(\"ORtg_g_roll5\",\"mean\"),\n",
    "#         dr5=(\"DRtg_g_roll5\",\"mean\"),\n",
    "#         pace5=(\"Pace_g_roll5\",\"mean\"),\n",
    "#     )\n",
    "\n",
    "# # Join opponent features (same date)\n",
    "# opp = team_games.rename(columns={\n",
    "#     \"TEAM_ABBREVIATION\":\"OPPONENT_ABBREVIATION\",\n",
    "#     \"team_pts\":\"opp_pts\",\n",
    "#     \"team_pts_next\":\"opp_pts_next\",\n",
    "#     \"or5\":\"opp_or5\",\"dr5\":\"opp_dr5\",\"pace5\":\"opp_pace5\"\n",
    "# })\n",
    "# team_matchups = team_games.merge(opp, on=[\"GAME_DATE\"], how=\"inner\")\n",
    "\n",
    "# # Simple features for team total prediction\n",
    "# team_feature_cols = [\"or5\",\"dr5\",\"pace5\",\"opp_or5\",\"opp_dr5\",\"opp_pace5\"]\n",
    "# tm = team_matchups.dropna(subset=team_feature_cols + [\"team_pts_next\"]).copy()\n",
    "\n",
    "# from sklearn.linear_model import Ridge\n",
    "# X_tm = tm[team_feature_cols]\n",
    "# y_tm = tm[\"team_pts_next\"]\n",
    "# ridge = Ridge(alpha=5.0).fit(X_tm, y_tm)\n",
    "# print(\"Team PTS baseline R^2:\", ridge.score(X_tm, y_tm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Cell 17 (value bet finder) --\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def american_to_prob(odds):\n",
    "    if pd.isna(odds): return np.nan\n",
    "    o = float(odds)\n",
    "    return 100.0/(o+100.0) if o>0 else (-o)/(-o+100.0)\n",
    "\n",
    "def devig_pair(p_over, p_under):\n",
    "    if pd.isna(p_over) or pd.isna(p_under): return (np.nan, np.nan)\n",
    "    s = p_over + p_under\n",
    "    if s <= 0: return (np.nan, np.nan)\n",
    "    return (p_over/s, p_under/s)\n",
    "\n",
    "def kelly_fraction(p, american_odds, cap=0.25):\n",
    "    if pd.isna(p) or pd.isna(american_odds): return 0.0\n",
    "    o = float(american_odds)\n",
    "    b = o/100.0 if o>0 else 100.0/(-o)\n",
    "    f = (p*(b+1)-1)/b\n",
    "    return float(max(0.0, min(f, cap)))\n",
    "\n",
    "def ev_flat_over(p, american_odds):\n",
    "    if pd.isna(p) or pd.isna(american_odds): return np.nan\n",
    "    o = float(american_odds)\n",
    "    win = o/100.0 if o>0 else 100.0/(-o)\n",
    "    lose = 1.0\n",
    "    return p*win - (1-p)*lose\n",
    "\n",
    "# Normal CDF helper (if SciPy available) to turn mean/sd into p_over\n",
    "try:\n",
    "    from scipy.stats import norm\n",
    "    def p_over_from_normal(mu, sd, line):\n",
    "        if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: return np.nan\n",
    "        return 1.0 - norm.cdf((line - mu)/sd)\n",
    "except Exception:\n",
    "    def p_over_from_normal(mu, sd, line): return np.nan\n",
    "\n",
    "def build_value_bets_excel(\n",
    "    df_projections, df_odds, outfile_path=None,\n",
    "    join_keys=(\"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\"game_date\"),\n",
    "    cap_kelly=0.25\n",
    "):\n",
    "    def _norm(x): return None if pd.isna(x) else str(x).strip()\n",
    "    proj, odds = df_projections.copy(), df_odds.copy()\n",
    "    for k in join_keys:\n",
    "        if k in proj: proj[k] = proj[k].map(_norm)\n",
    "        if k in odds: odds[k] = odds[k].map(_norm)\n",
    "\n",
    "    merged = proj.merge(odds, on=list(join_keys), how=\"inner\", suffixes=(\"\", \"_odds\"))\n",
    "\n",
    "    if \"p_over_model\" not in merged.columns or merged[\"p_over_model\"].isna().all():\n",
    "        merged[\"p_over_model\"] = merged.apply(\n",
    "            lambda r: p_over_from_normal(r.get(\"projection_mean\"), r.get(\"projection_sd\"), r.get(\"line\")), axis=1\n",
    "        )\n",
    "\n",
    "    merged[\"p_over_imp\"]  = merged[\"over_odds\"].map(american_to_prob)\n",
    "    merged[\"p_under_imp\"] = merged[\"under_odds\"].map(american_to_prob)\n",
    "    merged[[\"p_over_fair\",\"p_under_fair\"]] = merged.apply(\n",
    "        lambda r: pd.Series(devig_pair(r[\"p_over_imp\"], r[\"p_under_imp\"])), axis=1\n",
    "    )\n",
    "\n",
    "    merged[\"edge_over\"]       = merged[\"p_over_model\"] - merged[\"p_over_fair\"]\n",
    "    merged[\"kelly_frac_over\"] = merged.apply(lambda r: kelly_fraction(r[\"p_over_model\"], r[\"over_odds\"], cap=cap_kelly), axis=1)\n",
    "    merged[\"EV_over_1u\"]      = merged.apply(lambda r: ev_flat_over(r[\"p_over_model\"], r[\"over_odds\"]), axis=1)\n",
    "    merged[\"asof_date\"]       = merged.get(\"asof_date\") if \"asof_date\" in merged else datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    preferred = [\n",
    "        \"asof_date\",\"game_date\",\"book\",\"player\",\"team\",\"opponent\",\"market\",\"line\",\"lineup_status\",\n",
    "        \"over_odds\",\"under_odds\",\"p_over_imp\",\"p_under_imp\",\"p_over_fair\",\"p_under_fair\",\"p_over_model\",\n",
    "        \"edge_over\",\"kelly_frac_over\",\"EV_over_1u\",\n",
    "        \"projected_minutes\",\"projection_mean\",\"projection_sd\",\"start_prob\",\n",
    "        \"opponent_allowance_idx\",\"team_orating\",\"opp_drating\",\n",
    "    ]\n",
    "    cols = [c for c in preferred if c in merged.columns] + [c for c in merged.columns if c not in preferred]\n",
    "    bets = merged[cols].sort_values([\"edge_over\",\"EV_over_1u\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"n_bets\":[len(bets)],\n",
    "        \"avg_edge_pp\":[bets[\"edge_over\"].mean()*100.0 if len(bets) else np.nan],\n",
    "        \"avg_kelly_pct\":[bets[\"kelly_frac_over\"].mean()*100.0 if len(bets) else np.nan],\n",
    "        \"avg_ev_1u\":[bets[\"EV_over_1u\"].mean() if len(bets) else np.nan],\n",
    "    })\n",
    "    by_market = bets.groupby(\"market\", dropna=False).agg(\n",
    "        n=(\"player\",\"count\"),\n",
    "        avg_edge_pp=(\"edge_over\", lambda x: 100.0*x.mean()),\n",
    "        avg_kelly_pct=(\"kelly_frac_over\", lambda x: 100.0*x.mean()),\n",
    "        avg_ev_1u=(\"EV_over_1u\",\"mean\")\n",
    "    ).reset_index()\n",
    "    by_book = bets.groupby(\"book\", dropna=False).agg(\n",
    "        n=(\"player\",\"count\"),\n",
    "        avg_edge_pp=(\"edge_over\", lambda x: 100.0*x.mean()),\n",
    "        avg_ev_1u=(\"EV_over_1u\",\"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "    if outfile_path is None:\n",
    "        outfile_path = f\"nba_value_bets_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "    with pd.ExcelWriter(outfile_path, engine=\"openpyxl\") as w:\n",
    "        bets.to_excel(w, sheet_name=\"Bets\", index=False)\n",
    "        summary.to_excel(w, sheet_name=\"Summary\", index=False, startrow=0)\n",
    "        by_market.to_excel(w, sheet_name=\"Summary\", index=False, startrow=5)\n",
    "        by_book.to_excel(w, sheet_name=\"Summary\", index=False, startrow=5+len(by_market)+3)\n",
    "\n",
    "        dd = pd.DataFrame([\n",
    "            (\"asof_date\",\"UTC run date\"), (\"game_date\",\"Game date\"),\n",
    "            (\"player\",\"Player\"), (\"team\",\"Team abbr\"), (\"opponent\",\"Opponent abbr\"),\n",
    "            (\"market\",\"PTS/REB/AST/3PM/PRA etc.\"), (\"line\",\"Book line\"), (\"book\",\"Sportsbook id\"),\n",
    "            (\"lineup_status\",\"EXPECTED/CONFIRMED/UNKNOWN\"),\n",
    "            (\"over_odds\",\"American odds Over\"), (\"under_odds\",\"American odds Under\"),\n",
    "            (\"p_over_imp\",\"Implied prob Over (pre-vig)\"), (\"p_under_imp\",\"Implied prob Under (pre-vig)\"),\n",
    "            (\"p_over_fair\",\"De-vigged prob Over\"), (\"p_under_fair\",\"De-vigged prob Under\"),\n",
    "            (\"p_over_model\",\"Model prob Over\"), (\"edge_over\",\"p_model ‚àí p_fair\"),\n",
    "            (\"kelly_frac_over\",\"Kelly fraction (cap)\"), (\"EV_over_1u\",\"EV if staking 1u\"),\n",
    "            (\"projected_minutes\",\"Projected minutes\"), (\"projection_mean\",\"Projected mean\"),\n",
    "            (\"projection_sd\",\"Projected stdev\"), (\"start_prob\",\"Start probability\"),\n",
    "            (\"opponent_allowance_idx\",\"Opponent allowance index\"),\n",
    "            (\"team_orating\",\"Team ORtg\"), (\"opp_drating\",\"Opponent DRtg\"),\n",
    "        ], columns=[\"column\",\"description\"])\n",
    "        dd.to_excel(w, sheet_name=\"Data_Dictionary\", index=False)\n",
    "\n",
    "    return bets, outfile_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# # Safety: need features_all built (from your Cell 7 + 0_data)\n",
    "# assert 'features_all' in globals() and isinstance(features_all, pd.DataFrame) and not features_all.empty, \\\n",
    "#     \"features_all missing. Run Cell 7 + 0_data first.\"\n",
    "\n",
    "# # Ensure GAME_DATE is datetime and sort\n",
    "# if \"GAME_DATE\" in features_all.columns:\n",
    "#     features_all[\"GAME_DATE\"] = pd.to_datetime(features_all[\"GAME_DATE\"])\n",
    "# features_all = features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).copy()\n",
    "\n",
    "# # ---------------- Features / Targets ----------------\n",
    "# BASE_FEATURES = [\n",
    "#     \"MIN_roll5\",\"MIN_roll10\",\n",
    "#     \"TS_game_roll5\",\"TS_game_roll10\",\n",
    "#     \"usage_share_roll5\",\n",
    "#     \"ORtg_g_roll5\",\"DRtg_g_roll5\",\"Pace_g_roll5\",\n",
    "#     \"PER\",\"TS%\",\"USG%\",\"ORtg\",\"DRtg\",\"WS/48\",\"BPM\",\"VORP\",\n",
    "#     \"days_rest\",\"HOME\"\n",
    "# ]\n",
    "# STAT_ROLLING = {\n",
    "#     \"PTS\": [\"PTS_roll5\",\"PTS_roll10\"],\n",
    "#     \"REB\": [\"REB_roll5\",\"REB_roll10\"],\n",
    "#     \"AST\": [\"AST_roll5\",\"AST_roll10\"],\n",
    "# }\n",
    "# TARGETS = {\n",
    "#     \"PTS\": \"PTS_next\",\n",
    "#     \"REB\": \"REB_next\",\n",
    "#     \"AST\": \"AST_next\",\n",
    "# }\n",
    "\n",
    "# models = {}\n",
    "# feature_cols_by_stat = {}\n",
    "# cv_scores = {}\n",
    "\n",
    "# # Time-aware CV across all players chronologically\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# for stat, target_col in TARGETS.items():\n",
    "#     # pick available cols only\n",
    "#     cand = BASE_FEATURES + STAT_ROLLING[stat]\n",
    "#     feat_cols = [c for c in cand if c in features_all.columns]\n",
    "#     feature_cols_by_stat[stat] = feat_cols\n",
    "\n",
    "#     # drop rows missing features/target\n",
    "#     data = features_all.dropna(subset=feat_cols + [target_col]).copy()\n",
    "#     if data.empty:\n",
    "#         print(f\"‚ö†Ô∏è No training data for {stat}. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     data = data.sort_values(\"GAME_DATE\")\n",
    "#     X = data[feat_cols]\n",
    "#     y = data[target_col]\n",
    "\n",
    "#     # CV MAE for sanity\n",
    "#     fold_mae = []\n",
    "#     for tr, te in tscv.split(X):\n",
    "#         Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
    "#         ytr, yte = y.iloc[tr], y.iloc[te]\n",
    "#         model = XGBRegressor(\n",
    "#             n_estimators=400,\n",
    "#             learning_rate=0.05,\n",
    "#             max_depth=5,\n",
    "#             subsample=0.85,\n",
    "#             colsample_bytree=0.9,\n",
    "#             reg_lambda=1.0,\n",
    "#             reg_alpha=0.0,\n",
    "#             random_state=42,\n",
    "#             n_jobs=-1,\n",
    "#             verbosity=0\n",
    "#         )\n",
    "#         model.fit(Xtr, ytr)\n",
    "#         pred = model.predict(Xte)\n",
    "#         fold_mae.append(mean_absolute_error(yte, pred))\n",
    "\n",
    "#     cv_scores[stat] = (float(np.mean(fold_mae)), float(np.std(fold_mae)))\n",
    "#     print(f\"‚úî {stat} MAE (TimeSeries CV): {np.mean(fold_mae):.2f} ¬± {np.std(fold_mae):.2f}\")\n",
    "\n",
    "#     # Fit final model on all data\n",
    "#     final_model = XGBRegressor(\n",
    "#         n_estimators=400,\n",
    "#         learning_rate=0.05,\n",
    "#         max_depth=5,\n",
    "#         subsample=0.85,\n",
    "#         colsample_bytree=0.9,\n",
    "#         reg_lambda=1.0,\n",
    "#         reg_alpha=0.0,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#         verbosity=0\n",
    "#     )\n",
    "#     final_model.fit(X, y)\n",
    "#     models[stat] = final_model\n",
    "\n",
    "# print(\"\\nDone. Trained models:\", list(models.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Cell 16: projections for PTS/REB/AST using your trained RF models ===\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Safety checks\n",
    "# if \"models\" not in globals() or not models:\n",
    "#     raise RuntimeError(\"No trained models found. Run Cell 7 first to populate `models` and `feature_cols_by_stat`.\")\n",
    "\n",
    "# # We'll project for these markets\n",
    "# MARKETS = [\"PTS\", \"REB\", \"AST\"]\n",
    "\n",
    "# # Latest row per player as basis for \"next game\"\n",
    "# latest = features_all.sort_values([\"PLAYER_NAME\",\"GAME_DATE\"]).groupby(\"PLAYER_NAME\").tail(1).copy()\n",
    "\n",
    "# # Helper: per-stat stdev from last N actual games\n",
    "# def _player_sd_map(stat: str, n=10):\n",
    "#     def _sd(g):\n",
    "#         s = g[stat].tail(n)\n",
    "#         if s.notna().sum() >= 4:\n",
    "#             return float(s.std(ddof=1))\n",
    "#         return float(features_all[stat].std(ddof=1))\n",
    "#     return features_all.groupby(\"PLAYER_NAME\").apply(_sd)\n",
    "\n",
    "# # Normalize export keys common to all markets\n",
    "# base_cols = {\n",
    "#     \"PLAYER_NAME\": \"player\",\n",
    "#     \"TEAM_ABBREVIATION\": \"team\",\n",
    "#     \"OPPONENT_ABBREVIATION\": \"opponent\",\n",
    "# }\n",
    "# base_out = latest.rename(columns=base_cols)[[\"player\",\"team\",\"opponent\"]].copy()\n",
    "# base_out[\"game_date\"] = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "# base_out[\"projected_minutes\"] = latest.get(\"MIN_roll5\", pd.Series(index=latest.index)).fillna(30).clip(lower=10, upper=40).values\n",
    "# base_out[\"start_prob\"] = 0.90\n",
    "# base_out[\"lineup_status\"] = \"EXPECTED\"\n",
    "\n",
    "# # Build one projection frame per market\n",
    "# proj_frames = {}\n",
    "# for stat in MARKETS:\n",
    "#     if stat not in models:\n",
    "#         print(f\"‚ö†Ô∏è Skipping {stat}: model not found in `models`.\")\n",
    "#         continue\n",
    "#     feat_cols = feature_cols_by_stat.get(stat, [])\n",
    "#     if not feat_cols:\n",
    "#         print(f\"‚ö†Ô∏è Skipping {stat}: no feature columns recorded in `feature_cols_by_stat`.\")\n",
    "#         continue\n",
    "\n",
    "#     X_pred = latest[feat_cols].fillna(method=\"ffill\").fillna(0)\n",
    "#     pred_mean = models[stat].predict(X_pred)\n",
    "\n",
    "#     # per-player SD\n",
    "#     sd_map = _player_sd_map(stat)\n",
    "#     pred_sd = latest[\"PLAYER_NAME\"].map(sd_map)\n",
    "#     # conservative fallback SD = 15% of mean (min 1.0)\n",
    "#     sd_fallback = np.maximum(np.abs(pred_mean) * 0.15, 1.0)\n",
    "#     pred_sd = np.where(np.isnan(pred_sd), sd_fallback, pred_sd)\n",
    "\n",
    "#     dfp = base_out.copy()\n",
    "#     dfp[\"projection_mean\"] = pred_mean\n",
    "#     dfp[\"projection_sd\"] = pred_sd\n",
    "#     dfp[\"market\"] = stat\n",
    "\n",
    "#     # Expose per-market frames\n",
    "#     proj_frames[stat] = dfp[[\"player\",\"team\",\"opponent\",\"game_date\",\"market\",\n",
    "#                              \"projection_mean\",\"projection_sd\",\"projected_minutes\",\"start_prob\",\"lineup_status\"]].copy()\n",
    "\n",
    "# # Individual frames (kept for backward compatibility)\n",
    "# df_projections_pts = proj_frames.get(\"PTS\", pd.DataFrame())\n",
    "# df_projections_reb = proj_frames.get(\"REB\", pd.DataFrame())\n",
    "# df_projections_ast = proj_frames.get(\"AST\", pd.DataFrame())\n",
    "\n",
    "# # Combined projections across markets\n",
    "# df_projections_all = pd.concat(list(proj_frames.values()), ignore_index=True) if proj_frames else pd.DataFrame()\n",
    "\n",
    "# print(\"Projection rows by market:\",\n",
    "#       {k: len(v) for k, v in proj_frames.items()})\n",
    "\n",
    "\n",
    "# display(df_projections_all.head(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a69d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Cell 18: Helper: turn wide props (per-book columns) into a long, tidy table ---\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def odds_wide_to_long_from_columns(\n",
    "#     wide_df: pd.DataFrame,\n",
    "#     *,\n",
    "#     books: tuple[str, ...] = (\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\",\"espnbet\",\"hardrock\"),\n",
    "#     markets: tuple[str, ...] = (\"PTS\",\"REB\",\"AST\"),\n",
    "#     player_cols=(\"name\",\"player\",\"PLAYER_NAME\"),\n",
    "#     team_cols=(\"team\",\"TEAM\",\"team_name\",\"TEAM_ABBREVIATION\"),\n",
    "#     opp_cols=(\"opponent\",\"opp\",\"OPPONENT\",\"OPPONENT_ABBREVIATION\"),\n",
    "#     date_cols=(\"game_date\",\"GAME_DATE\",\"date\")\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Convert a 'wide' props frame into a tidy long format:\n",
    "#     one row per (player, market, book), with numeric line and American odds.\n",
    "\n",
    "#     Expected column patterns (flexible by regex):\n",
    "#       <book>_<suffix>                 -> the line (e.g., mgm_pts, fanduel_ast)\n",
    "#       <book>_<suffix>_over_odds       -> over odds (American)\n",
    "#       <book>_<suffix>_under_odds      -> under odds (American)\n",
    "\n",
    "#     Suffixes recognized per market:\n",
    "#       PTS:  'pts','points'\n",
    "#       REB:  'reb','rebounds'\n",
    "#       AST:  'ast','assists'\n",
    "#     \"\"\"\n",
    "#     df = wide_df.copy()\n",
    "\n",
    "#     # Identify reference columns\n",
    "#     def _first_col(cands):\n",
    "#         for c in cands:\n",
    "#             if c in df.columns: return c\n",
    "#         return None\n",
    "\n",
    "#     player_col = _first_col(player_cols)\n",
    "#     team_col   = _first_col(team_cols)\n",
    "#     opp_col    = _first_col(opp_cols)\n",
    "#     date_col   = _first_col(date_cols)\n",
    "\n",
    "#     # Fallbacks if totally missing\n",
    "#     if player_col is None:\n",
    "#         raise ValueError(\"Could not find a player name column in wide_df. \"\n",
    "#                          f\"Tried {player_cols}. Got columns: {list(df.columns)[:20]}...\")\n",
    "\n",
    "#     # Normalize helpers\n",
    "#     def _num_float(x):\n",
    "#         if pd.isna(x): return np.nan\n",
    "#         m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
    "#         return float(m.group()) if m else np.nan\n",
    "\n",
    "#     def _num_int(x):\n",
    "#         if pd.isna(x): return np.nan\n",
    "#         m = re.search(r\"[-+]?\\d+\", str(x))\n",
    "#         return int(m.group()) if m else np.nan\n",
    "\n",
    "#     # Market suffix map (flex)\n",
    "#     market_suffixes = {\n",
    "#         \"PTS\": (\"pts\",\"points\"),\n",
    "#         \"REB\": (\"reb\",\"rebounds\"),\n",
    "#         \"AST\": (\"ast\",\"assists\"),\n",
    "#     }\n",
    "\n",
    "#     # Build long rows\n",
    "#     long_rows = []\n",
    "#     # Iterate rows once; pull columns per book/market dynamically\n",
    "#     for _, row in df.iterrows():\n",
    "#         base = {\n",
    "#             \"player\": row[player_col],\n",
    "#             \"team\": row[team_col] if team_col else np.nan,\n",
    "#             \"opponent\": row[opp_col] if opp_col else np.nan,\n",
    "#             \"game_date\": row[date_col] if date_col else np.nan,\n",
    "#         }\n",
    "#         for mkt in markets:\n",
    "#             suffixes = market_suffixes.get(mkt, ())\n",
    "#             for b in books:\n",
    "#                 # Find the *line* column by trying allowed suffixes\n",
    "#                 line_val = np.nan\n",
    "#                 over_val = np.nan\n",
    "#                 under_val = np.nan\n",
    "#                 line_col_used = None\n",
    "\n",
    "#                 for suf in suffixes:\n",
    "#                     # exact line column (most common)\n",
    "#                     c_line = f\"{b}_{suf}\"\n",
    "#                     if c_line in df.columns and pd.notna(row[c_line]):\n",
    "#                         line_val = row[c_line]\n",
    "#                         line_col_used = c_line\n",
    "#                         # odds columns (several sites use these names)\n",
    "#                         for over_name in (f\"{b}_{suf}_over_odds\", f\"{b}_{suf}_o_odds\", f\"{b}_{suf}_over\"):\n",
    "#                             if over_name in df.columns:\n",
    "#                                 over_val = row[over_name]\n",
    "#                                 break\n",
    "#                         for under_name in (f\"{b}_{suf}_under_odds\", f\"{b}_{suf}_u_odds\", f\"{b}_{suf}_under\"):\n",
    "#                             if under_name in df.columns:\n",
    "#                                 under_val = row[under_name]\n",
    "#                                 break\n",
    "#                         break  # found a suffix match\n",
    "\n",
    "#                 # If not found, try a looser search (e.g., 'mgm_pts_line')\n",
    "#                 if (isinstance(line_val, float) and np.isnan(line_val)) or line_col_used is None:\n",
    "#                     pat = re.compile(rf\"^{re.escape(b)}_({ '|'.join(map(re.escape, suffixes)) })(_line)?$\", re.I)\n",
    "#                     for c in df.columns:\n",
    "#                         if pat.match(str(c)) and pd.notna(row[c]):\n",
    "#                             line_val = row[c]\n",
    "#                             line_col_used = c\n",
    "#                             # odds columns with same base\n",
    "#                             base_prefix = re.sub(r\"(_line)?$\", \"\", c)\n",
    "#                             for over_name in (f\"{base_prefix}_over_odds\", f\"{base_prefix}_o_odds\", f\"{base_prefix}_over\"):\n",
    "#                                 if over_name in df.columns:\n",
    "#                                     over_val = row[over_name]\n",
    "#                                     break\n",
    "#                             for under_name in (f\"{base_prefix}_under_odds\", f\"{base_prefix}_u_odds\", f\"{base_prefix}_under\"):\n",
    "#                                 if under_name in df.columns:\n",
    "#                                     under_val = row[under_name]\n",
    "#                                     break\n",
    "#                             break\n",
    "\n",
    "#                 # Only emit a row if we actually found a line\n",
    "#                 if pd.notna(line_val):\n",
    "#                     long_rows.append({\n",
    "#                         **base,\n",
    "#                         \"market\": mkt,\n",
    "#                         \"book\": b,\n",
    "#                         \"line\": _num_float(line_val),\n",
    "#                         \"over_odds\": _num_int(over_val),\n",
    "#                         \"under_odds\": _num_int(under_val),\n",
    "#                     })\n",
    "\n",
    "#     out = pd.DataFrame(long_rows)\n",
    "\n",
    "#     # Clean up: drop obviously invalid lines\n",
    "#     if not out.empty:\n",
    "#         out = out[pd.notna(out[\"line\"])]\n",
    "#         # remove zero/negative lines that can't be real for these markets (optional)\n",
    "#         out = out[out[\"line\"] > 0]\n",
    "\n",
    "#         # De-duplicate best-effort (sometimes the page contains duplicates per book)\n",
    "#         out = (out.sort_values([\"player\",\"market\",\"book\",\"line\"])\n",
    "#                   .drop_duplicates(subset=[\"player\",\"market\",\"book\"], keep=\"last\")\n",
    "#                   .reset_index(drop=True))\n",
    "\n",
    "#     return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Cell 19: robust wide->long adapter for Rotowire props ---\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def odds_wide_to_long_rotowire(\n",
    "#     wide_df: pd.DataFrame,\n",
    "#     *,\n",
    "#     books=(\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\",\"espnbet\",\"hardrock\"),\n",
    "#     markets=(\"PTS\",\"REB\",\"AST\"),\n",
    "#     player_cols=(\"name\",\"player\",\"PLAYER_NAME\"),\n",
    "#     team_cols=(\"team\",\"TEAM_ABBREVIATION\"),\n",
    "#     opp_cols=(\"opponent\",\"opp\",\"OPPONENT_ABBREVIATION\"),\n",
    "#     date_cols=(\"game_date\",\"GAME_DATE\")\n",
    "# ) -> pd.DataFrame:\n",
    "#     df = wide_df.copy()\n",
    "\n",
    "#     def _first_col(cols):\n",
    "#         for c in cols:\n",
    "#             if c in df.columns: return c\n",
    "#         return None\n",
    "\n",
    "#     ply = _first_col(player_cols)\n",
    "#     tm  = _first_col(team_cols)\n",
    "#     opp = _first_col(opp_cols)\n",
    "#     dt  = _first_col(date_cols)\n",
    "#     if ply is None:\n",
    "#         raise ValueError(f\"No player column found. Tried {player_cols}. Got sample: {list(df.columns)[:25]}\")\n",
    "\n",
    "#     # market suffixes we‚Äôll search (order matters)\n",
    "#     suffixes = {\"PTS\": (\"pts\",\"p\",\"points\"),\n",
    "#                 \"REB\": (\"reb\",\"rebounds\"),\n",
    "#                 \"AST\": (\"ast\",\"assists\")}\n",
    "\n",
    "#     # helpers\n",
    "#     def _num_float(x):\n",
    "#         if pd.isna(x): return np.nan\n",
    "#         m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
    "#         return float(m.group()) if m else np.nan\n",
    "\n",
    "#     def _num_int(x):\n",
    "#         if pd.isna(x): return np.nan\n",
    "#         m = re.search(r\"[-+]?\\d+\", str(x))\n",
    "#         return int(m.group()) if m else np.nan\n",
    "\n",
    "#     cols_lc = {c.lower(): c for c in df.columns}  # lower->actual\n",
    "\n",
    "#     def _find(name_like: str):\n",
    "#         return cols_lc.get(name_like.lower())\n",
    "\n",
    "#     rows = []\n",
    "#     for _, r in df.iterrows():\n",
    "#         base = {\n",
    "#             \"player\": r[ply],\n",
    "#             \"team\": r[tm] if tm else np.nan,\n",
    "#             \"opponent\": r[opp] if opp else np.nan,\n",
    "#             \"game_date\": r[dt] if dt else np.nan,\n",
    "#         }\n",
    "#         for mkt in markets:\n",
    "#             for book in books:\n",
    "#                 ln = np.nan; ov = np.nan; un = np.nan; used = None\n",
    "#                 # find the line column (e.g. mgm_pts / fanduel_p / caesars_ast)\n",
    "#                 for suf in suffixes[mkt]:\n",
    "#                     for cand in (f\"{book}_{suf}\", f\"{book}_{suf}_line\"):\n",
    "#                         real = _find(cand)\n",
    "#                         if real and pd.notna(r.get(real)):\n",
    "#                             ln = r[real]; used = real\n",
    "#                             break\n",
    "#                     if used: break\n",
    "\n",
    "#                 if used:\n",
    "#                     # odds columns around that base; support camel & underscore\n",
    "#                     base_prefix = re.sub(r\"_line$\", \"\", used, flags=re.I)\n",
    "#                     over_cands  = [f\"{base_prefix}Over\", f\"{base_prefix}_over\",\n",
    "#                                    f\"{base_prefix}_o\", f\"{base_prefix}_over_odds\"]\n",
    "#                     under_cands = [f\"{base_prefix}Under\", f\"{base_prefix}_under\",\n",
    "#                                    f\"{base_prefix}_u\", f\"{base_prefix}_under_odds\"]\n",
    "#                     for oc in over_cands:\n",
    "#                         c = _find(oc)\n",
    "#                         if c and pd.notna(r.get(c)): ov = r[c]; break\n",
    "#                     for uc in under_cands:\n",
    "#                         c = _find(uc)\n",
    "#                         if c and pd.notna(r.get(c)): un = r[c]; break\n",
    "\n",
    "#                     rows.append({\n",
    "#                         **base,\n",
    "#                         \"market\": mkt,\n",
    "#                         \"book\": book,\n",
    "#                         \"line\": _num_float(ln),\n",
    "#                         \"over_odds\": _num_int(ov),\n",
    "#                         \"under_odds\": _num_int(un),\n",
    "#                     })\n",
    "\n",
    "#     out = pd.DataFrame(rows)\n",
    "#     if not out.empty:\n",
    "#         out = out[pd.notna(out[\"line\"]) & (out[\"line\"] > 0)]\n",
    "#         out = (out.sort_values([\"player\",\"market\",\"book\",\"line\"])\n",
    "#                  .drop_duplicates(subset=[\"player\",\"market\",\"book\"], keep=\"last\")\n",
    "#                  .reset_index(drop=True))\n",
    "#         if \"game_date\" in out and out[\"game_date\"].isna().all():\n",
    "#             out[\"game_date\"] = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
    "#     return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b92fd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 20 (fixed): wide‚Üílong with robust Over/Under detection ===\n",
    "import re, numpy as np, pandas as pd\n",
    "\n",
    "def odds_wide_to_long_rotowire_final_v2(\n",
    "    wide_df: pd.DataFrame,\n",
    "    *,\n",
    "    books=(\"mgm\",\"draftkings\",\"fanduel\",\"betrivers\"),  # focus on these\n",
    "    markets=(\"PTS\",\"REB\",\"AST\"),\n",
    "    player_cols=(\"name\",\"player\",\"PLAYER_NAME\"),\n",
    "    team_cols=(\"team\",\"TEAM_ABBREVIATION\",\"TEAM\"),\n",
    "    opp_cols=(\"opponent\",\"opp\",\"OPPONENT_ABBREVIATION\",\"OPPONENT\"),\n",
    "    date_cols=(\"game_date\",\"GAME_DATE\",\"asof_date\"),\n",
    ") -> pd.DataFrame:\n",
    "    df = wide_df.copy()\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî helpers to pick identity columns ‚Äî‚Äî‚Äî\n",
    "    def _first_col(cands):\n",
    "        for c in cands:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    ply = _first_col(player_cols)\n",
    "    tm  = _first_col(team_cols)\n",
    "    opp = _first_col(opp_cols)\n",
    "    dt  = _first_col(date_cols)\n",
    "    if ply is None:\n",
    "        raise ValueError(\"No player column found in wide odds frame.\")\n",
    "\n",
    "    # market suffixes we‚Äôll search (ALL of them, not just the first)\n",
    "    suf_map = {\n",
    "        \"PTS\": (\"pts\", \"points\", \"p\"),\n",
    "        \"REB\": (\"reb\", \"rebounds\"),\n",
    "        \"AST\": (\"ast\", \"assists\"),\n",
    "    }\n",
    "\n",
    "    # numeric cleaners\n",
    "    def _num_float(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
    "        return float(m.group()) if m else np.nan\n",
    "\n",
    "    def _num_int(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        m = re.search(r\"[-+]?\\d+\", str(x))\n",
    "        return int(m.group()) if m else np.nan\n",
    "\n",
    "    # prebuild a case-insensitive lookup for columns\n",
    "    lc_to_real = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    def _get_series_any(names):\n",
    "        \"\"\"return the first non-missing column among name list (case-insensitive)\"\"\"\n",
    "        for n in names:\n",
    "            key = n.lower()\n",
    "            if key in lc_to_real:\n",
    "                return df[lc_to_real[key]]\n",
    "        return pd.Series([np.nan] * len(df))\n",
    "\n",
    "    rows = []\n",
    "    # iterate rows once; for each book+market pick the most plausible columns\n",
    "    for idx, r in df.iterrows():\n",
    "        base = {\n",
    "            \"player\":   r[ply],\n",
    "            \"team\":     (r[tm]  if tm  else np.nan),\n",
    "            \"opponent\": (r[opp] if opp else np.nan),\n",
    "            \"game_date\":(r[dt]  if dt  else np.nan),\n",
    "        }\n",
    "\n",
    "        for mkt in markets:\n",
    "            suffixes = suf_map[mkt]\n",
    "            # --- line column candidates, e.g. mgm_pts / draftkings_points ---\n",
    "            for book in books:\n",
    "                line = np.nan\n",
    "                over = np.nan\n",
    "                under = np.nan\n",
    "\n",
    "                # 1) try explicit line columns\n",
    "                line_names = []\n",
    "                for suf in suffixes:\n",
    "                    line_names += [f\"{book}_{suf}\", f\"{book}_{suf}_line\"]\n",
    "                # pick the first present\n",
    "                for nm in line_names:\n",
    "                    key = nm.lower()\n",
    "                    if key in lc_to_real and pd.notna(r[lc_to_real[key]]):\n",
    "                        line = r[lc_to_real[key]]\n",
    "                        break\n",
    "\n",
    "                # 2) over/under with lots of spellings (camel + underscore + *_odds)\n",
    "                # build patterns that include ANY of the suffixes\n",
    "                # e.g. ^mgm_.*(pts|points)\\w*(over(_odds)?|overodds)?$\n",
    "                suf_pat = \"(\" + \"|\".join(map(re.escape, suffixes)) + \")\"\n",
    "                # scan all columns once; pick the first non-na for over/under\n",
    "                for c in df.columns:\n",
    "                    cl = c.lower()\n",
    "                    if cl.startswith(book + \"_\"):\n",
    "                        if re.search(suf_pat, cl):\n",
    "                            if re.search(r\"(over)(_odds|odds)?$\", cl):\n",
    "                                if pd.notna(r[c]) and pd.isna(over):\n",
    "                                    over = r[c]\n",
    "                            elif re.search(r\"(under)(_odds|odds)?$\", cl):\n",
    "                                if pd.notna(r[c]) and pd.isna(under):\n",
    "                                    under = r[c]\n",
    "\n",
    "                # skip if absolutely nothing present for this book+market on this row\n",
    "                if pd.isna(line) and pd.isna(over) and pd.isna(under):\n",
    "                    continue\n",
    "\n",
    "                rows.append({\n",
    "                    **base,\n",
    "                    \"market\": mkt,\n",
    "                    \"book\": book,\n",
    "                    \"line\": _num_float(line),\n",
    "                    \"over_odds\": _num_int(over),\n",
    "                    \"under_odds\": _num_int(under),\n",
    "                })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "\n",
    "    if out.empty:\n",
    "        return out\n",
    "\n",
    "    # keep ONLY rows with a real line and at least one price\n",
    "    has_line = out[\"line\"].notna()\n",
    "    has_price = out[\"over_odds\"].notna() | out[\"under_odds\"].notna()\n",
    "    out = out[has_line & has_price].copy()\n",
    "\n",
    "    # positive / plausible lines\n",
    "    out = out[out[\"line\"] > 0]\n",
    "\n",
    "    # dedupe within (player, market, book) keeping the most recent non-na price/line\n",
    "    out = (out.sort_values([\"player\", \"market\", \"book\", \"line\"])\n",
    "              .drop_duplicates(subset=[\"player\", \"market\", \"book\"], keep=\"last\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "    # fill missing dates with today if needed\n",
    "    if \"game_date\" in out and out[\"game_date\"].isna().all():\n",
    "        out[\"game_date\"] = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32d3b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fetched 1125 odds rows | 264 columns | book=mgm\n",
      "‚úÖ Fetched 1125 odds rows | 264 columns | book=draftkings\n",
      "‚úÖ Fetched 1125 odds rows | 264 columns | book=fanduel\n",
      "‚úÖ Fetched 1125 odds rows | 264 columns | book=caesars\n",
      "‚úÖ Fetched 1125 odds rows | 264 columns | book=betrivers\n",
      "‚úÖ Combined long odds rows: 2970\n",
      "üõü Filled 0 missing lines via group fallback.\n",
      "‚úÖ Usable odds rows after filters: 990\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "df_projections_all missing ‚Äì run the projection cell first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 3) Join with projections\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_projections_all\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m df_projections_all\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_projections_all missing ‚Äì run the projection cell first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_norm_player\u001b[39m(s):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mstr\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: df_projections_all missing ‚Äì run the projection cell first."
     ]
    }
   ],
   "source": [
    "# === Cell 21 (fixed): fetch odds for multiple books ‚Üí long ‚Üí join with projections ===\n",
    "from datetime import datetime\n",
    "import re, unicodedata, numpy as np, pandas as pd\n",
    "from statistics import NormalDist\n",
    "\n",
    "BOOKS = (\"mgm\",\"draftkings\",\"fanduel\",\"caesars\",\"betrivers\")\n",
    "\n",
    "scraper = NBAOddsScraper()\n",
    "\n",
    "# 1) Scrape EACH book and convert to long immediately (avoids NaN rows for non-present books)\n",
    "long_parts = []\n",
    "for b in BOOKS:\n",
    "    wide_b = scraper.get_player_props_odds_wide_raw(book=b)\n",
    "    if wide_b.empty:\n",
    "        print(f\"‚ö†Ô∏è {b}: no rows scraped.\")\n",
    "        continue\n",
    "    # Use the converter that already works for you in Cell 2\n",
    "    long_b = odds_wide_to_long_from_columns(wide_b, books=(b,), markets=(\"PTS\",\"REB\",\"AST\"))\n",
    "    if long_b.empty:\n",
    "        print(f\"‚ö†Ô∏è {b}: long table empty after conversion.\")\n",
    "    else:\n",
    "        long_parts.append(long_b)\n",
    "\n",
    "odds_long = pd.concat(long_parts, ignore_index=True) if long_parts else pd.DataFrame()\n",
    "print(f\"‚úÖ Combined long odds rows: {len(odds_long)}\")\n",
    "\n",
    "# 2) Row-level fallback line within each (player, market, game_date) group\n",
    "if not odds_long.empty:\n",
    "    grp = [\"player\",\"market\",\"game_date\"]\n",
    "    # take the first non-null line within the group\n",
    "    line_fallback = odds_long.groupby(grp)[\"line\"].transform(lambda s: s.dropna().iloc[0] if s.dropna().size else np.nan)\n",
    "    missing_before = odds_long[\"line\"].isna().sum()\n",
    "    odds_long[\"line\"] = odds_long[\"line\"].fillna(line_fallback)\n",
    "    missing_after  = odds_long[\"line\"].isna().sum()\n",
    "    print(f\"üõü Filled {missing_before - missing_after} missing lines via group fallback.\")\n",
    "\n",
    "    # Keep only rows with a usable line and at least one price\n",
    "    odds_long = odds_long[(odds_long[\"line\"].notna()) & ( (odds_long[\"over_odds\"].notna()) | (odds_long[\"under_odds\"].notna()) )].copy()\n",
    "    print(f\"‚úÖ Usable odds rows after filters: {len(odds_long)}\")\n",
    "\n",
    "# 3) Join with projections\n",
    "if \"df_projections_all\" not in globals() or df_projections_all.empty:\n",
    "    raise RuntimeError(\"df_projections_all missing ‚Äì run the projection cell first.\")\n",
    "\n",
    "def _norm_player(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = re.sub(r\"[.\\-`'‚Äô]\", \"\", s).strip().lower()\n",
    "    s = re.sub(r\"\\s+\",\" \", s)\n",
    "    return s\n",
    "\n",
    "odds_long[\"player_key\"] = odds_long[\"player\"].map(_norm_player)\n",
    "df_projections_all[\"player_key\"] = df_projections_all[\"player\"].map(_norm_player)\n",
    "\n",
    "def p_over_from_normal(mu, sd, line):\n",
    "    if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: return np.nan\n",
    "    z = (line - mu) / sd\n",
    "    return 1.0 - NormalDist().cdf(z)\n",
    "\n",
    "def implied_prob(a):\n",
    "    if pd.isna(a): return np.nan\n",
    "    a = float(a)\n",
    "    return (-a)/(-a+100.0) if a < 0 else 100.0/(a+100.0)\n",
    "\n",
    "joined = []\n",
    "for mkt in (\"PTS\",\"REB\",\"AST\"):\n",
    "    proj = df_projections_all.query(\"market == @mkt\")\n",
    "    odds = odds_long.query(\"market == @mkt\")\n",
    "    if proj.empty or odds.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping {mkt} (proj empty? {proj.empty}, odds empty? {odds.empty})\")\n",
    "        continue\n",
    "\n",
    "    dfj = proj.merge(\n",
    "        odds,\n",
    "        on=[\"player_key\",\"market\"],\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_proj\",\"_odds\")\n",
    "    )\n",
    "    if dfj.empty:\n",
    "        print(f\"‚ö†Ô∏è No matches for {mkt} after merge.\")\n",
    "        continue\n",
    "\n",
    "    # model P(over)\n",
    "    dfj[\"p_over_model\"] = dfj.apply(\n",
    "        lambda r: p_over_from_normal(r[\"projection_mean\"], r[\"projection_sd\"], r[\"line\"]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # market implied\n",
    "    dfj[\"p_over_imp\"]  = dfj[\"over_odds\"].map(implied_prob)\n",
    "    dfj[\"p_under_imp\"] = dfj[\"under_odds\"].map(implied_prob)\n",
    "\n",
    "    # edge vs implied (de-vig will happen in Cell 22)\n",
    "    dfj[\"edge_over\"] = dfj[\"p_over_model\"] - dfj[\"p_over_imp\"]\n",
    "\n",
    "    joined.append(dfj)\n",
    "\n",
    "df_proj_join_all = pd.concat(joined, ignore_index=True) if joined else pd.DataFrame()\n",
    "\n",
    "print(f\"üîó Joined frame size: {len(df_proj_join_all)}\")\n",
    "print(odds_long.head(10))\n",
    "print(df_proj_join_all.head(10))\n",
    "\n",
    "# Optional: export a trace file to inspect later\n",
    "df_proj_join_all.to_csv(f\"nba_player_props_joined_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def peek_cols(df, book, key=\"pts\"):\n",
    "#     cols = [c for c in df.columns if re.match(fr\"^{book}_.{{0,12}}{key}\", c, re.I) or c.lower().startswith(f\"{book}_{key}\")]\n",
    "#     print(book, key, \"->\", cols[:20])\n",
    "\n",
    "# peek_cols(wide_raw, \"mgm\", \"pts\")\n",
    "# peek_cols(wide_raw, \"fanduel\", \"p\")     # note the short 'p'\n",
    "# peek_cols(wide_raw, \"caesars\", \"ast\")\n",
    "\n",
    "# print(df_proj_join_all['under_odds'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6db0195",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Run Cell 21 first to build df_proj_join_all.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NormalDist\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 0Ô∏è‚É£ Safety check\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_proj_join_all\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_proj_join_all\u001b[38;5;241m.\u001b[39mempty, \\\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun Cell 21 first to build df_proj_join_all.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m df_proj_join_all\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìà Starting pricing with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m merged projection/odds rows...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Run Cell 21 first to build df_proj_join_all."
     ]
    }
   ],
   "source": [
    "# === Cell 22 (Final) ‚Äî Price, Edge, EV & Kelly Calculations ==================\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from statistics import NormalDist\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 0Ô∏è‚É£ Safety check\n",
    "# ---------------------------------------------------------------------\n",
    "assert \"df_proj_join_all\" in globals() and not df_proj_join_all.empty, \\\n",
    "    \"Run Cell 21 first to build df_proj_join_all.\"\n",
    "\n",
    "df = df_proj_join_all.copy()\n",
    "print(f\"üìà Starting pricing with {len(df):,} merged projection/odds rows...\")\n",
    "print(df.head(20))\n",
    "# ---------------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Normalize & coalesce entity columns\n",
    "# ---------------------------------------------------------------------\n",
    "def _coalesce(df_, target, candidates):\n",
    "    s = pd.Series(index=df_.index, dtype=object)\n",
    "    for c in candidates:\n",
    "        if c in df_:\n",
    "            s = s.fillna(df_[c])\n",
    "    df_[target] = s\n",
    "\n",
    "_coalesce(df, \"player\",   [\"player_odds\",\"player_proj\",\"player\"])\n",
    "_coalesce(df, \"team\",     [\"team_odds\",\"team_proj\",\"team\"])\n",
    "_coalesce(df, \"opponent\", [\"opponent_odds\",\"opponent_proj\",\"opponent\"])\n",
    "_coalesce(df, \"game_date\",[\"game_date_odds\",\"game_date_proj\",\"game_date\"])\n",
    "\n",
    "# drop duplicate versions of these columns\n",
    "to_drop = [c for c in [\n",
    "    \"player_odds\",\"player_proj\",\"team_odds\",\"team_proj\",\n",
    "    \"opponent_odds\",\"opponent_proj\",\"game_date_odds\",\"game_date_proj\"\n",
    "] if c in df.columns]\n",
    "df.drop(columns=to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# deduplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()].copy()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Filter to rows with valid odds\n",
    "# ---------------------------------------------------------------------\n",
    "if not {\"over_odds\",\"under_odds\"}.issubset(df.columns):\n",
    "    raise RuntimeError(\"Missing odds columns. Re-run Cell 21 to rebuild df_proj_join_all.\")\n",
    "\n",
    "priced = df.dropna(subset=[\"over_odds\",\"under_odds\"], how=\"all\").copy()\n",
    "print(f\"‚úÖ {len(priced):,} rows with valid odds available for pricing.\")\n",
    "print(priced.head(5))\n",
    "# ---------------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Numeric coercion helpers\n",
    "# ---------------------------------------------------------------------\n",
    "def _num_int(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    m = re.search(r\"[-+]?\\d+\", str(x))\n",
    "    return int(m.group()) if m else np.nan\n",
    "\n",
    "def _num_float(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
    "    return float(m.group()) if m else np.nan\n",
    "\n",
    "for c in [\"line\",\"projection_mean\",\"projection_sd\"]:\n",
    "    if c in priced.columns:\n",
    "        priced[c] = priced[c].apply(_num_float)\n",
    "for c in [\"over_odds\",\"under_odds\"]:\n",
    "    if c in priced.columns:\n",
    "        priced[c] = priced[c].apply(_num_int)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Handle missing SD (fallback 15% of mean, min = 1.0)\n",
    "# ---------------------------------------------------------------------\n",
    "if (\"projection_sd\" not in priced.columns) or priced[\"projection_sd\"].fillna(0).eq(0).all():\n",
    "    priced[\"projection_sd\"] = (priced[\"projection_mean\"].abs() * 0.15).clip(lower=1.0)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Model probability: P(over) from Normal(Œº, œÉ)\n",
    "# ---------------------------------------------------------------------\n",
    "def p_over_from_normal(mu, sd, line):\n",
    "    if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: \n",
    "        return np.nan\n",
    "    z = (line - mu) / sd\n",
    "    return 1.0 - NormalDist().cdf(z)\n",
    "\n",
    "priced[\"p_over_model\"] = priced.apply(\n",
    "    lambda r: p_over_from_normal(r[\"projection_mean\"], r[\"projection_sd\"], r[\"line\"]), axis=1\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ Market-implied probabilities + de-vig + edge\n",
    "# ---------------------------------------------------------------------\n",
    "def implied_prob(a):\n",
    "    if pd.isna(a): return np.nan\n",
    "    a = float(a)\n",
    "    return (-a)/(-a+100.0) if a < 0 else 100.0/(a+100.0)\n",
    "\n",
    "priced[\"p_over_imp\"]  = priced[\"over_odds\"].map(implied_prob)\n",
    "priced[\"p_under_imp\"] = priced[\"under_odds\"].map(implied_prob)\n",
    "\n",
    "def devig_pair(p_o, p_u):\n",
    "    if pd.isna(p_o) or pd.isna(p_u): return (np.nan, np.nan)\n",
    "    s = p_o + p_u\n",
    "    if s <= 0: return (np.nan, np.nan)\n",
    "    return (p_o/s, p_u/s)\n",
    "\n",
    "fair = priced.apply(\n",
    "    lambda r: pd.Series(devig_pair(r[\"p_over_imp\"], r[\"p_under_imp\"]),\n",
    "                        index=[\"p_over_fair\",\"p_under_fair\"]),\n",
    "    axis=1\n",
    ")\n",
    "priced = pd.concat([priced, fair], axis=1)\n",
    "\n",
    "priced[\"edge_over\"] = np.where(\n",
    "    priced[\"p_over_fair\"].notna(),\n",
    "    priced[\"p_over_model\"] - priced[\"p_over_fair\"],\n",
    "    priced[\"p_over_model\"] - priced[\"p_over_imp\"]\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 7Ô∏è‚É£ EV and Kelly (capped ‚â§ 25%)\n",
    "# ---------------------------------------------------------------------\n",
    "def kelly_fraction(p, american, cap=0.25):\n",
    "    if pd.isna(p) or pd.isna(american): return 0.0\n",
    "    a = float(american)\n",
    "    b = (a/100.0) if a > 0 else (100.0/abs(a))\n",
    "    f = (p*(b+1)-1)/b\n",
    "    return float(max(0.0, min(f, cap)))\n",
    "\n",
    "def ev_flat_over(p, american):\n",
    "    if pd.isna(p) or pd.isna(american): return np.nan\n",
    "    a = float(american)\n",
    "    win = (a/100.0) if a > 0 else (100.0/abs(a))\n",
    "    lose = 1.0\n",
    "    return p*win - (1-p)*lose\n",
    "\n",
    "priced[\"kelly_frac_over\"] = priced.apply(lambda r: kelly_fraction(r[\"p_over_model\"], r[\"over_odds\"]), axis=1)\n",
    "priced[\"EV_over_1u\"]      = priced.apply(lambda r: ev_flat_over(r[\"p_over_model\"], r[\"over_odds\"]), axis=1)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 8Ô∏è‚É£ Clean duplicates and column conflicts\n",
    "# ---------------------------------------------------------------------\n",
    "if priced.columns.duplicated().any():\n",
    "    print(\"‚ö†Ô∏è Duplicate columns detected ‚Äî removing duplicates.\")\n",
    "    priced = priced.loc[:, ~priced.columns.duplicated()].copy()\n",
    "\n",
    "if priced.columns.duplicated().any():\n",
    "    raise RuntimeError(\"Column duplication persists ‚Äî please inspect DataFrame.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 9Ô∏è‚É£ Build sorted slates\n",
    "# ---------------------------------------------------------------------\n",
    "cols_keep = [\n",
    "    \"game_date\",\"book\",\"player\",\"team\",\"opponent\",\"market\",\"line\",\"lineup_status\",\n",
    "    \"over_odds\",\"under_odds\",\"p_over_imp\",\"p_under_imp\",\"p_over_fair\",\"p_under_fair\",\n",
    "    \"p_over_model\",\"edge_over\",\"EV_over_1u\",\"kelly_frac_over\",\n",
    "    \"projected_minutes\",\"projection_mean\",\"projection_sd\",\"start_prob\"\n",
    "]\n",
    "cols_keep = [c for c in cols_keep if c in priced.columns]\n",
    "\n",
    "priced_sorted = priced.sort_values([\"player\",\"market\",\"edge_over\"], ascending=[True,True,False])\n",
    "best_per_player = priced_sorted.drop_duplicates(subset=[\"player\",\"market\"], keep=\"first\")[cols_keep].reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üîü Filtering thresholds for ‚Äúvalue slate‚Äù\n",
    "# ---------------------------------------------------------------------\n",
    "EDGE_MIN   = 0.02   # ‚â• 2% model edge\n",
    "EV_MIN     = 0.00   # non-negative EV\n",
    "KELLY_MIN  = 0.01   # ‚â• 1% Kelly fraction\n",
    "MIN_MINUTES= 14\n",
    "START_PROB = 0.50\n",
    "\n",
    "slate = best_per_player[\n",
    "    (best_per_player[\"edge_over\"] >= EDGE_MIN) &\n",
    "    (best_per_player[\"EV_over_1u\"] >= EV_MIN) &\n",
    "    (best_per_player[\"kelly_frac_over\"] >= KELLY_MIN) &\n",
    "    (best_per_player[\"projected_minutes\"].fillna(0) >= MIN_MINUTES) &\n",
    "    (best_per_player[\"start_prob\"].fillna(1.0) >= START_PROB)\n",
    "].sort_values([\"edge_over\",\"EV_over_1u\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Final value slate built ‚Äî {len(slate)} bets meet thresholds.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£  Save outputs\n",
    "# ---------------------------------------------------------------------\n",
    "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.makedirs(\"data/bets\", exist_ok=True)\n",
    "csv_all   = f\"data/bets/nba_priced_candidates_{stamp}.csv\"\n",
    "csv_slate = f\"data/bets/nba_priced_slate_{stamp}.csv\"\n",
    "xlsx_path = f\"data/bets/nba_priced_{stamp}.xlsx\"\n",
    "\n",
    "best_per_player.to_csv(csv_all, index=False)\n",
    "slate.to_csv(csv_slate, index=False)\n",
    "with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as w:\n",
    "    best_per_player.to_excel(w, sheet_name=\"Candidates\", index=False)\n",
    "    slate.to_excel(w, sheet_name=\"Slate\", index=False)\n",
    "\n",
    "print(\"\\nüìÅ Files saved:\")\n",
    "print(f\"  ‚Ä¢ {csv_all}\")\n",
    "print(f\"  ‚Ä¢ {csv_slate}\")\n",
    "print(f\"  ‚Ä¢ {xlsx_path}\")\n",
    "\n",
    "# expose to later cells\n",
    "df_best = best_per_player.copy()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# ‚úÖ  Quick summary preview\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\nEdge quantiles:\")\n",
    "print(best_per_player[\"edge_over\"].quantile([0.1,0.25,0.5,0.75,0.9]))\n",
    "\n",
    "print(\"\\nTop 10 by edge:\")\n",
    "display(best_per_player.sort_values(\"edge_over\", ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a468138",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Run the priced-slate cell first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NormalDist\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_best\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df_best, pd\u001b[38;5;241m.\u001b[39mDataFrame), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun the priced-slate cell first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m ND \u001b[38;5;241m=\u001b[39m NormalDist()\n\u001b[0;32m      9\u001b[0m dfD \u001b[38;5;241m=\u001b[39m df_best\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mAssertionError\u001b[0m: Run the priced-slate cell first."
     ]
    }
   ],
   "source": [
    "# === Cell 23: Diagnostics + more-forgiving slate builder (FIXED) ===\n",
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "from statistics import NormalDist\n",
    "\n",
    "assert 'df_best' in globals() and isinstance(df_best, pd.DataFrame), \"Run the priced-slate cell first.\"\n",
    "\n",
    "ND = NormalDist()\n",
    "dfD = df_best.copy()\n",
    "\n",
    "# --- Helpers -----------------------------------------------------------------\n",
    "def american_to_decimal(a):\n",
    "    \"\"\"Convert American odds to Decimal odds; return NaN if not valid.\"\"\"\n",
    "    if pd.isna(a): return np.nan\n",
    "    a = float(a)\n",
    "    if a == 0: return np.nan\n",
    "    return 1.0 + (a/100.0 if a > 0 else 100.0/abs(a))\n",
    "\n",
    "def implied_from_decimal(d):\n",
    "    \"\"\"Break-even probability from decimal odds.\"\"\"\n",
    "    return np.nan if (pd.isna(d) or d <= 1) else 1.0 / d\n",
    "\n",
    "def kelly_fraction_decimal(p, dec_odds, cap=0.25):\n",
    "    if pd.isna(p) or pd.isna(dec_odds) or dec_odds <= 1: return 0.0\n",
    "    b = dec_odds - 1.0\n",
    "    f = (p*(b+1) - 1) / b\n",
    "    return float(max(0.0, min(f, cap)))\n",
    "\n",
    "def ev_flat_decimal(p, dec_odds):\n",
    "    if pd.isna(p) or pd.isna(dec_odds) or dec_odds <= 1: return np.nan\n",
    "    return p*(dec_odds-1) - (1-p)*1.0\n",
    "\n",
    "def p_over_from_normal(mu, sd, line):\n",
    "    if pd.isna(mu) or pd.isna(sd) or pd.isna(line) or sd <= 0: return np.nan\n",
    "    z = (line - mu) / sd\n",
    "    return 1.0 - ND.cdf(z)\n",
    "\n",
    "# --- Ensure we have decimal odds columns -------------------------------------\n",
    "# Build from American odds if missing\n",
    "if \"over_dec\" not in dfD.columns:\n",
    "    dfD[\"over_dec\"] = dfD.get(\"over_odds\").map(american_to_decimal)\n",
    "if \"under_dec\" not in dfD.columns:\n",
    "    dfD[\"under_dec\"] = dfD.get(\"under_odds\").map(american_to_decimal)\n",
    "\n",
    "# --- Quick coverage checks ----------------------------------------------------\n",
    "have_over  = dfD['over_dec'].notna()  & (dfD['over_dec']  > 1.0)\n",
    "have_under = dfD['under_dec'].notna() & (dfD['under_dec'] > 1.0)\n",
    "print(\"Coverage:\")\n",
    "print(f\"  with over_dec:  {have_over.sum()} / {len(dfD)}\")\n",
    "print(f\"  with under_dec: {have_under.sum()} / {len(dfD)}\")\n",
    "print(f\"  both prices:    {(have_over & have_under).sum()} / {len(dfD)}\")\n",
    "\n",
    "# --- Edge distribution snapshot ----------------------------------------------\n",
    "q = dfD['edge_over'].dropna().quantile([0.1,0.25,0.5,0.75,0.9]) if 'edge_over' in dfD else pd.Series(dtype=float)\n",
    "print(\"\\nEdge quantiles (model - fair/imp):\")\n",
    "print(q.to_string())\n",
    "\n",
    "# --- Top 20 by edge (even if below your threshold) ---------------------------\n",
    "cols_preview = [c for c in [\n",
    "    \"player\",\"team\",\"opponent\",\"market\",\"line\",\"book\",\n",
    "    \"over_dec\",\"under_dec\",\"p_over_model\",\"p_over_fair\",\"p_over_imp\",\"edge_over\",\"EV_over_1u\",\"kelly_frac_over\"\n",
    "] if c in dfD.columns]\n",
    "print(\"\\nTop by edge (first 20):\")\n",
    "print(dfD.sort_values('edge_over', ascending=False).head(20)[cols_preview].to_string(index=False))\n",
    "\n",
    "# =========================\n",
    "# Alternative slates\n",
    "# =========================\n",
    "\n",
    "# 1) EV-positive slate (uses model p_over and OVER decimal price)\n",
    "MIN_EV  = 0.01   # > 0.01u per 1u stake\n",
    "MIN_DEC = 1.01   # must have a real price\n",
    "slate_ev = dfD[\n",
    "    (dfD[\"EV_over_1u\"] > MIN_EV) &\n",
    "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
    "].copy()\n",
    "\n",
    "# 2) Lower-edge slate (relax edge threshold)\n",
    "MIN_EDGE_RELAXED = 0.005   # 0.5%\n",
    "slate_edge_relaxed = dfD[\n",
    "    (dfD[\"edge_over\"] >= MIN_EDGE_RELAXED) &\n",
    "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
    "].copy()\n",
    "\n",
    "# 3) Price-only slate (ignore de-vig; compare model vs break-even p from OVER decimal)\n",
    "dfD[\"p_over_price\"] = dfD[\"over_dec\"].map(implied_from_decimal)\n",
    "dfD[\"edge_vs_price\"] = dfD[\"p_over_model\"] - dfD[\"p_over_price\"]\n",
    "MIN_EDGE_PRICE = 0.01  # 1% vs break-even\n",
    "slate_price_only = dfD[\n",
    "    (dfD[\"edge_vs_price\"] >= MIN_EDGE_PRICE) &\n",
    "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
    "].copy()\n",
    "\n",
    "# 4) Sensitivity slate: try a slightly tighter SD (10% of mean) if SD looked fallback-ish\n",
    "need_sd_tighten = dfD[\"projection_sd\"].isna() | (dfD[\"projection_sd\"] <= 0)\n",
    "sd_tight = (dfD[\"projection_mean\"].abs() * 0.10).clip(lower=0.75)\n",
    "p_model_tight = []\n",
    "for mu, sd, line, tight_sd in zip(dfD[\"projection_mean\"], dfD[\"projection_sd\"], dfD[\"line\"], sd_tight):\n",
    "    use_sd = sd if pd.notna(sd) and sd > 0 else tight_sd\n",
    "    p_model_tight.append(p_over_from_normal(mu, use_sd, line))\n",
    "dfD[\"p_over_model_tight\"] = p_model_tight\n",
    "dfD[\"EV_over_1u_tight\"] = dfD.apply(lambda r: ev_flat_decimal(r[\"p_over_model_tight\"], r[\"over_dec\"]), axis=1)\n",
    "dfD[\"edge_over_tight\"] = np.where(dfD[\"p_over_fair\"].notna(),\n",
    "                                  dfD[\"p_over_model_tight\"] - dfD[\"p_over_fair\"],\n",
    "                                  dfD[\"p_over_model_tight\"] - dfD[\"p_over_imp\"])\n",
    "slate_tight = dfD[\n",
    "    (dfD[\"EV_over_1u_tight\"] > MIN_EV) &\n",
    "    (dfD[\"over_dec\"].fillna(0) > MIN_DEC)\n",
    "].copy()\n",
    "\n",
    "def _keep_cols(d):\n",
    "    keep = [c for c in [\n",
    "        \"asof_date\",\"game_date\",\"book\",\"player\",\"team\",\"opponent\",\"market\",\"line\",\"lineup_status\",\n",
    "        \"over_dec\",\"under_dec\",\n",
    "        \"p_over_imp\",\"p_under_imp\",\"p_over_fair\",\"p_under_fair\",\n",
    "        \"p_over_model\",\"edge_over\",\"EV_over_1u\",\"kelly_frac_over\",\n",
    "        \"p_over_price\",\"edge_vs_price\",\n",
    "        \"p_over_model_tight\",\"edge_over_tight\",\"EV_over_1u_tight\",\n",
    "        \"projected_minutes\",\"projection_mean\",\"projection_sd\",\"start_prob\"\n",
    "    ] if c in d.columns]\n",
    "    return d[keep].sort_values([\"market\",\"edge_over\"], ascending=[True, False])\n",
    "\n",
    "print(\"\\nSlate sizes:\")\n",
    "print(f\"  EV-positive (>{MIN_EV:.2f}u):           {len(slate_ev)}\")\n",
    "print(f\"  Relaxed edge (‚â•{MIN_EDGE_RELAXED*100:.1f}%): {len(slate_edge_relaxed)}\")\n",
    "print(f\"  Price-only edge (‚â•{MIN_EDGE_PRICE*100:.1f}%): {len(slate_price_only)}\")\n",
    "print(f\"  Tight-SD EV-positive:                  {len(slate_tight)}\")\n",
    "\n",
    "# Preview a few from each\n",
    "for name, slate_df in [\n",
    "    (\"EV-positive\", slate_ev),\n",
    "    (\"Relaxed-edge\", slate_edge_relaxed),\n",
    "    (\"Price-only\", slate_price_only),\n",
    "    (\"Tight-SD EV+\", slate_tight),\n",
    "]:\n",
    "    if not slate_df.empty:\n",
    "        print(f\"\\n{name} ‚Äî top 10\")\n",
    "        print(_keep_cols(slate_df).head(10).to_string(index=False))\n",
    "\n",
    "# Save all variants\n",
    "ts = pd.Timestamp.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.makedirs(\"data/bets\", exist_ok=True)\n",
    "_keep_cols(slate_ev).to_csv(f\"data/bets/nba_slate_evpos_{ts}.csv\", index=False)\n",
    "_keep_cols(slate_edge_relaxed).to_csv(f\"data/bets/nba_slate_edge_relaxed_{ts}.csv\", index=False)\n",
    "_keep_cols(slate_price_only).to_csv(f\"data/bets/nba_slate_price_only_{ts}.csv\", index=False)\n",
    "_keep_cols(slate_tight).to_csv(f\"data/bets/nba_slate_tightsd_{ts}.csv\", index=False)\n",
    "print(f\"\\nSaved CSVs with the four slate variants (timestamp {ts}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 19: Export clean value-bets CSV (adds PUnderModel) --\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Merge (already built earlier): best_per_player + dfD on [\"player\",\"market\"]\n",
    "merged_df = best_per_player.merge(\n",
    "    dfD, on=[\"player\", \"market\"], how=\"inner\", suffixes=(\"_best\", \"_dfD\")\n",
    ")\n",
    "\n",
    "# Optional quick peek that this column exists\n",
    "if \"p_over_model_dfD\" in merged_df.columns:\n",
    "    display(merged_df[\"p_over_model_dfD\"].head())\n",
    "\n",
    "# Columns we want to keep from the merge\n",
    "# NOTE: use line_dfD (from dfD) as the line source since that's what you previewed\n",
    "selected_columns = [\n",
    "    \"player\",\n",
    "    \"team_best\",\n",
    "    \"opponent_best\",\n",
    "    \"market\",\n",
    "    \"line_dfD\",                 # keep dfD line\n",
    "    \"over_odds_best\",\n",
    "    \"under_odds_best\",\n",
    "    \"p_over_imp_best\",\n",
    "    \"p_under_imp_best\",\n",
    "    \"p_over_fair_best\",\n",
    "    \"p_under_fair_best\",\n",
    "    \"projected_minutes_best\",\n",
    "    \"projection_mean_best\",\n",
    "    \"projection_sd_best\",\n",
    "    \"p_over_model_dfD\",\n",
    "]\n",
    "\n",
    "# Clean column names for output\n",
    "column_rename = {\n",
    "    \"player\": \"Player\",\n",
    "    \"team_best\": \"Team\",\n",
    "    \"opponent_best\": \"Opponent\",\n",
    "    \"market\": \"Market\",\n",
    "    \"line_dfD\": \"Line\",                 # map dfD line -> Line\n",
    "    \"over_odds_best\": \"OverOdds\",\n",
    "    \"under_odds_best\": \"UnderOdds\",\n",
    "    \"p_over_imp_best\": \"POverImp\",\n",
    "    \"p_under_imp_best\": \"PUnderImp\",\n",
    "    \"p_over_fair_best\": \"POverFair\",\n",
    "    \"p_under_fair_best\": \"PUnderFair\",\n",
    "    \"projected_minutes_best\": \"ProjMins\",\n",
    "    \"projection_mean_best\": \"ProjMean\",\n",
    "    \"projection_sd_best\": \"ProjSD\",\n",
    "    \"p_over_model_dfD\": \"POverModel\",\n",
    "}\n",
    "\n",
    "# Build clean frame\n",
    "missing = [c for c in selected_columns if c not in merged_df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing expected columns in merged_df: {missing}\")\n",
    "\n",
    "merged_df_clean = merged_df[selected_columns].rename(columns=column_rename)\n",
    "\n",
    "# Add PUnderModel = 1 - POverModel (clip to [0,1] for safety)\n",
    "merged_df_clean[\"PUnderModel\"] = (1.0 - merged_df_clean[\"POverModel\"]).clip(lower=0.0, upper=1.0)\n",
    "\n",
    "# Export\n",
    "os.makedirs(\"data/bets\", exist_ok=True)\n",
    "csv_path = os.path.join(\"data/bets\", f\"value_bets_top100_{datetime.now().strftime('%Y%m%d')}.csv\")\n",
    "merged_df_clean.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Saved clean value bets to: {csv_path}\")\n",
    "print(f\"Columns: {list(merged_df_clean.columns)}\")\n",
    "print(f\"Rows: {len(merged_df_clean)}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(merged_df_clean.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Convert American odds ‚Üí Decimal odds and save ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Load latest value bets CSV (use today‚Äôs date automatically) ---\n",
    "today_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "input_path = f\"data/bets/value_bets_top100_{today_str}.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# --- Convert American ‚Üí Decimal ---\n",
    "def american_to_decimal(american):\n",
    "    \"\"\"Convert American odds to decimal odds.\"\"\"\n",
    "    if pd.isna(american):\n",
    "        return None\n",
    "    try:\n",
    "        american = float(american)\n",
    "        if american > 0:\n",
    "            return 1 + (american / 100)\n",
    "        elif american < 0:\n",
    "            return 1 + (100 / abs(american))\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply conversion\n",
    "df[\"OverDecimal\"] = df[\"OverOdds\"].apply(american_to_decimal)\n",
    "df[\"UnderDecimal\"] = df[\"UnderOdds\"].apply(american_to_decimal)\n",
    "\n",
    "# --- Option A: keep both versions (recommended) ---\n",
    "# rename old odds for clarity\n",
    "df.rename(columns={\"OverOdds\": \"OverOdds_American\", \"UnderOdds\": \"UnderOdds_American\"}, inplace=True)\n",
    "\n",
    "# --- Option B: if you really want to remove them, uncomment this ---\n",
    "# df.drop(columns=[\"OverOdds\", \"UnderOdds\"], inplace=True)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "output_path = f\"data/bets/value_bets_top100_{today_str}_decimal.csv\"\n",
    "os.makedirs(\"data/bets\", exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Converted odds and saved to: {output_path}\")\n",
    "print(\"Preview:\")\n",
    "print(df[[\"Player\", \"Market\", \"OverDecimal\", \"UnderDecimal\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visual diagnostics for model vs decimal odds (with market labels) ===\n",
    "import os, glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Load latest decimal CSV ----------\n",
    "cand = sorted(glob.glob(\"data/bets/value_bets_top100_*_decimal.csv\"))\n",
    "if not cand:\n",
    "    cand = sorted(glob.glob(\"data/bets/value_bets_top100_*.csv\"))\n",
    "    if not cand:\n",
    "        raise FileNotFoundError(\"No value bets file found in data/bets.\")\n",
    "path = cand[-1]\n",
    "print(f\"Using file: {path}\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# ---------- Inspect columns ----------\n",
    "print(\"All columns in CSV:\", list(df.columns))\n",
    "\n",
    "# ---------- Map column names (robustly) ----------\n",
    "def find_col(df, candidates):\n",
    "    cols_lc = {c.lower(): c for c in df.columns}\n",
    "    for name in candidates:\n",
    "        c = cols_lc.get(name.lower())\n",
    "        if c: return c\n",
    "    return None\n",
    "\n",
    "col_player   = find_col(df, [\"Player\"])\n",
    "col_team     = find_col(df, [\"Team\"])\n",
    "col_opp      = find_col(df, [\"Opponent\"])\n",
    "col_market   = find_col(df, [\"Market\"])\n",
    "col_line     = find_col(df, [\"Line\", \"line_dfD\", \"posted_line\"])\n",
    "col_p_model  = find_col(df, [\"POverModel\",\"p_over_model\",\"P_over_model\",\"pModel\",\"p_model\"])\n",
    "col_over_dec = find_col(df, [\"OverDecimal\",\"over_dec\",\"OverDec\",\"OverDecimalOdds\"])\n",
    "\n",
    "required = [col_player, col_market, col_p_model, col_over_dec]\n",
    "if any(x is None for x in required):\n",
    "    missing = [n for n, x in zip(\n",
    "        [\"Player\",\"Market\",\"POverModel\",\"OverDecimal\"], required) if x is None]\n",
    "    raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# ---------- Build working frame ----------\n",
    "opt_cols = [col_team, col_opp, col_line, find_col(df, [\"ProjMean\"]), find_col(df, [\"ProjSD\"]), \"ProjMins\", \"POverImp\", \"POverFair\"]\n",
    "keep = [c for c in [col_player, col_market, col_over_dec, col_p_model] + opt_cols if c and c in df.columns]\n",
    "d = df[keep].copy()\n",
    "\n",
    "# Coerce numerics (robust)\n",
    "def _to_float(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(s))\n",
    "        return float(m.group()) if m else np.nan\n",
    "\n",
    "for c in [col_over_dec, col_p_model, col_line] if col_line else [col_over_dec, col_p_model]:\n",
    "    d[c] = d[c].apply(_to_float)\n",
    "\n",
    "# ---------- Derived metrics ----------\n",
    "d[\"p_over_price\"] = 1.0 / d[col_over_dec]\n",
    "d[\"edge_over\"]    = d[col_p_model] - d[\"p_over_price\"]\n",
    "d[\"EV_over_1u\"]   = d[col_p_model] * (d[col_over_dec] - 1.0) - (1.0 - d[col_p_model])\n",
    "\n",
    "# Label like \"Player o7.5\"\n",
    "def fmt_line(x):\n",
    "    return \"\" if pd.isna(x) else f\"{x:g}\"\n",
    "d[\"label\"] = d.apply(\n",
    "    lambda r: f\"{r[col_player]} o{fmt_line(r[col_line])}\" if col_line else f\"{r[col_player]}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter usable rows\n",
    "viz = d[\n",
    "    d[col_over_dec].notna() &\n",
    "    d[col_p_model].notna() &\n",
    "    (d[col_over_dec] > 1.0) &\n",
    "    (d[col_p_model].between(0.01, 0.99))\n",
    "].copy()\n",
    "\n",
    "print(\"Usable rows for visuals:\", len(viz))\n",
    "if viz.empty:\n",
    "    print(\"No usable rows to visualize. Sample:\")\n",
    "    print(d.head(10))\n",
    "else:\n",
    "    # ---------- Output paths ----------\n",
    "    outdir = \"data/bets/visuals\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # ---------- Color by market ----------\n",
    "    color_map = {\"PTS\": \"C0\", \"REB\": \"C1\", \"AST\": \"C2\"}\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for mkt, grp in viz.groupby(col_market):\n",
    "        ax.scatter(\n",
    "            grp[col_over_dec], grp[col_p_model],\n",
    "            alpha=0.65, s=40, label=mkt, c=color_map.get(str(mkt), \"C3\")\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Over decimal odds\")\n",
    "    ax.set_ylabel(\"Model P(Over)\")\n",
    "    ax.set_title(f\"Model Probability vs Over Decimal Odds\\n({len(viz)} bets)\")\n",
    "\n",
    "    # Break-even curve & shaded \"value zone\"\n",
    "    x_min = max(1.01, float(viz[col_over_dec].min()))\n",
    "    x_max = float(viz[col_over_dec].max())\n",
    "    x = np.linspace(x_min, x_max, 300)\n",
    "    y = 1.0 / x\n",
    "    ax.plot(x, y, color=\"red\", linewidth=2, label=\"Break-even line\")\n",
    "    ax.fill_between(x, y, 1.0, color=\"green\", alpha=0.08, label=\"Value zone\")\n",
    "\n",
    "    # Label top N by edge\n",
    "    TOP_N_LABELS = 20\n",
    "    to_label = viz.sort_values(\"edge_over\", ascending=False).head(TOP_N_LABELS)\n",
    "    for _, r in to_label.iterrows():\n",
    "        ax.annotate(\n",
    "            r[\"label\"],\n",
    "            (r[col_over_dec], r[col_p_model]),\n",
    "            textcoords=\"offset points\", xytext=(5, 4),\n",
    "            fontsize=8, color=\"black\"\n",
    "        )\n",
    "\n",
    "    ax.legend(loc=\"best\", title=\"Market\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    scatter_path = os.path.join(outdir, f\"prob_vs_decimal_{stamp}.png\")\n",
    "    fig.savefig(scatter_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Saved:\", scatter_path)\n",
    "\n",
    "    # ---------- Calibration plot ----------\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    viz_cal = viz.copy()\n",
    "    viz_cal[\"p_market_over\"] = 1.0 / viz_cal[col_over_dec]\n",
    "    for mkt, grp in viz_cal.groupby(col_market):\n",
    "        ax.scatter(\n",
    "            grp[\"p_market_over\"], grp[col_p_model],\n",
    "            alpha=0.65, s=40, label=mkt, c=color_map.get(str(mkt), \"C3\")\n",
    "        )\n",
    "    ax.plot([0, 1], [0, 1], color=\"red\", linewidth=2, label=\"Perfect calibration\")\n",
    "    ax.set_xlabel(\"Market implied P(Over) = 1 / OverDecimal\")\n",
    "    ax.set_ylabel(\"Model P(Over)\")\n",
    "    ax.set_title(f\"Calibration: Model vs Market\\n({len(viz_cal)} bets)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"best\", title=\"Market\")\n",
    "    fig.tight_layout()\n",
    "    calib_path = os.path.join(outdir, f\"calibration_{stamp}.png\")\n",
    "    fig.savefig(calib_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Saved:\", calib_path)\n",
    "\n",
    "    # ---------- Edge distribution ----------\n",
    "    edges = viz[\"edge_over\"].dropna()\n",
    "    if not edges.empty:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.hist(edges, bins=30, alpha=0.75, edgecolor=\"black\")\n",
    "        ax.set_xlabel(\"Edge = Model P(Over) - Market implied P\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"Edge Distribution (mean={edges.mean():.3f}, sd={edges.std():.3f})\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        hist_path = os.path.join(outdir, f\"edge_distribution_{stamp}.png\")\n",
    "        fig.savefig(hist_path, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        print(\"Saved:\", hist_path)\n",
    "\n",
    "    # ---------- Top 20 preview + export ----------\n",
    "    top = viz.sort_values(\"edge_over\", ascending=False).head(50).copy()\n",
    "    show_cols = [c for c in [\n",
    "        col_player, col_team, col_opp, col_market, col_line,\n",
    "        col_over_dec, col_p_model, \"p_over_price\", \"edge_over\", \"EV_over_1u\"\n",
    "    ] if c in top.columns]\n",
    "    print(\"\\nTop 20 value bets (by edge):\")\n",
    "    if not top.empty:\n",
    "        print(top.head(20)[show_cols].to_string(index=False,\n",
    "              float_format=lambda x: f\"{x:.3f}\" if isinstance(x, float) else str(x)))\n",
    "    outdir_csv = os.path.join(\"data/bets/visuals\")\n",
    "    os.makedirs(outdir_csv, exist_ok=True)\n",
    "    top_path = os.path.join(outdir_csv, f\"top_value_{stamp}.csv\")\n",
    "    top.to_csv(top_path, index=False)\n",
    "    print(\"Saved ranked value table ‚Üí\", top_path)\n",
    "\n",
    "print(\"\\nVisualization complete. Check the 'data/bets/visuals' folder for results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visual: Model P(Under) vs Under Decimal Odds ‚Äî color by market with legend (top 20 labels) ===\n",
    "import os, glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# -------- 1) Load latest decimal bets file --------\n",
    "cands = sorted(glob.glob(\"data/bets/value_bets_top100_*_decimal.csv\"))\n",
    "if not cands:\n",
    "    cands = sorted(glob.glob(\"data/bets/value_bets_top100_*.csv\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No value bets files found in data/bets/\")\n",
    "path = cands[-1]\n",
    "print(\"Using:\", path)\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# -------- 2) Column resolution (tolerant to naming) --------\n",
    "def find_col(dframe, names):\n",
    "    cols = {re.sub(r\"[\\W_]+\",\"\", c).lower(): c for c in dframe.columns.astype(str)}\n",
    "    for n in names:\n",
    "        k = re.sub(r\"[\\W_]+\",\"\", n).lower()\n",
    "        if k in cols: return cols[k]\n",
    "    return None\n",
    "\n",
    "col_player = find_col(df, [\"Player\"])\n",
    "col_market = find_col(df, [\"Market\"])\n",
    "col_line   = find_col(df, [\"Line\",\"line_dfD\",\"posted_line\",\"line\"])\n",
    "col_punder = find_col(df, [\"PUnderModel\",\"p_under_model\"])\n",
    "col_pover  = find_col(df, [\"POverModel\",\"p_over_model\"])  # fallback to compute p_under\n",
    "col_underD = find_col(df, [\"UnderDecimal\",\"under_dec\",\"UnderDec\",\"UnderDecimalOdds\"])\n",
    "col_underUS= find_col(df, [\"UnderOdds_American\",\"UnderOdds\",\"under_odds\"])  # for conversion if needed\n",
    "\n",
    "# American ‚Üí decimal (fallback)\n",
    "def american_to_decimal(a):\n",
    "    if pd.isna(a): return np.nan\n",
    "    try:\n",
    "        a = float(a)\n",
    "    except Exception:\n",
    "        m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(a))\n",
    "        a = float(m.group()) if m else np.nan\n",
    "    if pd.isna(a): return np.nan\n",
    "    return 1.0 + (a/100.0) if a > 0 else 1.0 + (100.0/abs(a))\n",
    "\n",
    "# Build UnderDecimal if missing\n",
    "if col_underD is None and col_underUS is not None:\n",
    "    df[\"UnderDecimal_fallback\"] = df[col_underUS].map(american_to_decimal)\n",
    "    col_underD = \"UnderDecimal_fallback\"\n",
    "\n",
    "need = [col_player, col_market, col_line, col_underD]\n",
    "miss = [n for n,v in zip([\"Player\",\"Market\",\"Line\",\"UnderDecimal\"], need) if v is None]\n",
    "if miss:\n",
    "    raise KeyError(f\"Missing required columns in file: {miss}\")\n",
    "\n",
    "# Canonicalize core columns\n",
    "df = df.rename(columns={\n",
    "    col_player:\"player\",\n",
    "    col_market:\"market\",\n",
    "    col_line:\"line\",\n",
    "    col_underD:\"under_dec\",\n",
    "})\n",
    "\n",
    "# p_under_model: use direct column if present, else 1 - p_over_model\n",
    "if col_punder:\n",
    "    df = df.rename(columns={col_punder:\"p_under_model\"})\n",
    "    df[\"p_under_model\"] = pd.to_numeric(df[\"p_under_model\"], errors=\"coerce\")\n",
    "elif col_pover:\n",
    "    df[\"p_under_model\"] = 1.0 - pd.to_numeric(df[col_pover], errors=\"coerce\")\n",
    "else:\n",
    "    raise KeyError(\"Need either PUnderModel/p_under_model or POverModel/p_over_model to derive P(Under).\")\n",
    "\n",
    "# Ensure numeric types\n",
    "for c in [\"line\",\"under_dec\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# -------- 3) Metrics & filter for plotting --------\n",
    "df[\"p_under_price\"] = 1.0 / df[\"under_dec\"]\n",
    "df[\"edge_under\"]    = df[\"p_under_model\"] - df[\"p_under_price\"]\n",
    "\n",
    "viz = df[\n",
    "    df[\"under_dec\"].notna() & (df[\"under_dec\"] > 1.0) &\n",
    "    df[\"p_under_model\"].between(0.01, 0.99)\n",
    "].copy()\n",
    "\n",
    "if viz.empty:\n",
    "    raise SystemExit(\"No usable rows to plot (need UnderDecimal>1 and valid PUnderModel).\")\n",
    "\n",
    "# Short label \"Player u7.5\"\n",
    "def fmt_line(x):\n",
    "    return \"\" if pd.isna(x) else f\"{x:g}\"\n",
    "viz[\"label\"] = viz.apply(lambda r: f\"{r['player']} u{fmt_line(r['line'])}\", axis=1)\n",
    "\n",
    "# -------- 4) Scatter colored by market with legend (mirrors Over plot style) --------\n",
    "MARKETS = [\"PTS\",\"REB\",\"AST\"]\n",
    "color_map = {\"PTS\": \"C0\", \"REB\": \"C1\", \"AST\": \"C2\"}  # consistent with OVER plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for mkt, grp in viz.groupby(viz[\"market\"].astype(str).str.upper()):\n",
    "    ax.scatter(\n",
    "        grp[\"under_dec\"], grp[\"p_under_model\"],\n",
    "        s=40, alpha=0.65, label=mkt, c=color_map.get(mkt, \"C3\")\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Under decimal odds\")\n",
    "ax.set_ylabel(\"Model P(Under)\")\n",
    "ax.set_title(f\"Model Probability vs Under Decimal Odds\\n({len(viz)} bets)\")\n",
    "\n",
    "# Break-even line and shaded \"value zone\" for UNDERS (y > 1/x)\n",
    "x_min = max(1.01, float(viz[\"under_dec\"].min()))\n",
    "x_max = float(viz[\"under_dec\"].max())\n",
    "x = np.linspace(x_min, x_max, 300)\n",
    "y = 1.0 / x\n",
    "ax.plot(x, y, color=\"red\", linewidth=2, label=\"Break-even line\")\n",
    "ax.fill_between(x, y, 1.0, color=\"green\", alpha=0.08, label=\"Value zone\")\n",
    "\n",
    "# Label only the top 20 by edge_under\n",
    "TOP_N_LABELS = 20\n",
    "to_label = viz.sort_values(\"edge_under\", ascending=False).head(TOP_N_LABELS)\n",
    "for _, r in to_label.iterrows():\n",
    "    ax.annotate(\n",
    "        r[\"label\"],\n",
    "        (r[\"under_dec\"], r[\"p_under_model\"]),\n",
    "        textcoords=\"offset points\", xytext=(5, 4),\n",
    "        fontsize=8, color=\"black\"\n",
    "    )\n",
    "\n",
    "ax.legend(loc=\"best\", title=\"Market\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save\n",
    "outdir = \"data/bets/visuals\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "stamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(outdir, f\"prob_vs_under_decimal_{stamp}.png\")\n",
    "fig.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3662135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EVALUATE YESTERDAY'S BETS (Europe/Athens) ‚Äî model-driven suggestions (OVER/UNDER) ===\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# ------------------ settings: yesterday in Europe/Athens ------------------\n",
    "TZ = ZoneInfo(\"Europe/Athens\")\n",
    "today_local = datetime.now(TZ).date()\n",
    "ydate = today_local - timedelta(days=1)\n",
    "ystr = ydate.strftime(\"%Y%m%d\")\n",
    "print(f\"Evaluating bets for YESTERDAY (Europe/Athens): {ydate} ({ystr})\")\n",
    "print(f\"Today is: {today_local}\")\n",
    "\n",
    "# where to save evaluation CSVs\n",
    "os.makedirs(\"data/eval\", exist_ok=True)\n",
    "\n",
    "# ------------------ helpers ------------------\n",
    "def _norm_player(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    return re.sub(r\"[.`'‚Äô\\-]\", \"\", s.strip()).lower()\n",
    "\n",
    "def pick_col(df, candidates, default=np.nan):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return df[c]\n",
    "    return pd.Series([default]*len(df))\n",
    "\n",
    "def _first_float(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", str(x))\n",
    "    return float(m.group()) if m else np.nan\n",
    "\n",
    "def infer_opponent(df):\n",
    "    if \"OPPONENT_ABBREVIATION\" in df.columns:\n",
    "        return df[\"OPPONENT_ABBREVIATION\"]\n",
    "    matchup = pick_col(df, [\"MATCHUP\",\"Matchup\"])\n",
    "    team = pick_col(df, [\"TEAM_ABBREVIATION\",\"TEAM\"])\n",
    "    out = []\n",
    "    for t, m in zip(team.fillna(\"\"), matchup.fillna(\"\")):\n",
    "        opp = np.nan\n",
    "        if isinstance(m, str) and m:\n",
    "            parts = re.split(r\"[@vVsS]+\\.*\", m)\n",
    "            if len(parts) >= 2:\n",
    "                cand = parts[-1].strip().upper()\n",
    "                if cand == str(t).upper() and len(parts) >= 2:\n",
    "                    cand = parts[0].strip().upper()\n",
    "                opp = cand\n",
    "        out.append(opp)\n",
    "    return pd.Series(out, index=df.index)\n",
    "\n",
    "def parse_date8_from_name(path):\n",
    "    m = re.search(r\"(20\\d{6})\", os.path.basename(path))\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "# ------------------ 1) Find the bets file in data/bets with the requested structure ------------------\n",
    "required_cols = {\n",
    "    \"Player\",\"Team\",\"Opponent\",\"Market\",\"Line\",\n",
    "    \"OverOdds_American\",\"UnderOdds_American\",\"POverImp\",\"PUnderImp\",\n",
    "    \"POverFair\",\"PUnderFair\",\"ProjMins\",\"ProjMean\",\"ProjSD\",\n",
    "    \"POverModel\",\"PUnderModel\",\"OverDecimal\",\"UnderDecimal\"\n",
    "}\n",
    "\n",
    "# Accept case-insensitive match and allow underscores vs camel\n",
    "def has_required_columns(path):\n",
    "    try:\n",
    "        if path.lower().endswith(\".csv\"):\n",
    "            head = pd.read_csv(path, nrows=0)\n",
    "        else:\n",
    "            with pd.ExcelFile(path) as xf:\n",
    "                head = pd.read_excel(path, sheet_name=xf.sheet_names[0], nrows=0)\n",
    "        cols_norm = {re.sub(r\"[\\W_]+\", \"\", c).lower() for c in head.columns.astype(str)}\n",
    "        need_norm = {re.sub(r\"[\\W_]+\", \"\", c).lower() for c in required_cols}\n",
    "        return need_norm.issubset(cols_norm)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "candidates = sorted(\n",
    "    glob.glob(\"data/bets/*.csv\") + glob.glob(\"data/bets/*.xlsx\")\n",
    ")\n",
    "\n",
    "# Filter to files that have the required columns\n",
    "candidates = [p for p in candidates if has_required_columns(p)]\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\n",
    "        \"No bets files in data/bets matching the required columns: \"\n",
    "        \"Player, Team, Opponent, Market, Line, OverOdds_American, UnderOdds_American, \"\n",
    "        \"POverImp, PUnderImp, POverFair, PUnderFair, ProjMins, ProjMean, ProjSD, \"\n",
    "        \"POverModel, PUnderModel, OverDecimal, UnderDecimal\"\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(candidates)} candidate files with required columns:\")\n",
    "for c in candidates:\n",
    "    print(f\"  - {os.path.basename(c)}\")\n",
    "\n",
    "# Look for bets file with the SAME date as yesterday\n",
    "bets_path = None\n",
    "for p in candidates:\n",
    "    ds = parse_date8_from_name(p)\n",
    "    if ds == ystr:  # Exact match for yesterday's date\n",
    "        bets_path = p\n",
    "        print(f\"Found exact match for yesterday: {os.path.basename(bets_path)}\")\n",
    "        break\n",
    "\n",
    "# If no exact match, use the most recent file BEFORE yesterday\n",
    "if bets_path is None:\n",
    "    dated_files = []\n",
    "    for p in candidates:\n",
    "        ds = parse_date8_from_name(p)\n",
    "        if ds and ds <= ystr:  # Only consider files dated on or before yesterday\n",
    "            dated_files.append((ds, p))\n",
    "    \n",
    "    if dated_files:\n",
    "        dated_files.sort(key=lambda x: x[0])\n",
    "        bets_path = dated_files[-1][1]  # Use the most recent one\n",
    "        print(f\"Warning: No bets file found for {ystr}. Using most recent available: {os.path.basename(bets_path)}\")\n",
    "    else:\n",
    "        # Fallback to latest file (even if future dated)\n",
    "        bets_path = candidates[-1]\n",
    "        print(f\"Warning: No dated bets files found. Using: {os.path.basename(bets_path)}\")\n",
    "\n",
    "print(\"Using bets file:\", os.path.basename(bets_path))\n",
    "\n",
    "# ------------------ 2) Load bets ------------------\n",
    "if bets_path.lower().endswith(\".csv\"):\n",
    "    bets = pd.read_csv(bets_path)\n",
    "else:\n",
    "    with pd.ExcelFile(bets_path) as xf:\n",
    "        bets = pd.read_excel(bets_path, sheet_name=xf.sheet_names[0])\n",
    "\n",
    "print(f\"Loaded bets rows: {len(bets)}\")\n",
    "\n",
    "# Map to canonical names using EXACT column names from your file\n",
    "cols = {c.lower(): c for c in bets.columns}\n",
    "def col(name_variants):\n",
    "    for v in name_variants:\n",
    "        key = v.lower()\n",
    "        if key in cols: return cols[key]\n",
    "    return None\n",
    "\n",
    "# Use the exact column names from your file\n",
    "cn_player = col([\"Player\"])\n",
    "cn_team   = col([\"Team\"])\n",
    "cn_opp    = col([\"Opponent\"])\n",
    "cn_mkt    = col([\"Market\"])\n",
    "cn_line   = col([\"Line\"])\n",
    "cn_pom    = col([\"POverModel\"])\n",
    "cn_pum    = col([\"PUnderModel\"])\n",
    "cn_od     = col([\"OverDecimal\"])\n",
    "cn_ud     = col([\"UnderDecimal\"])\n",
    "\n",
    "# Check for required columns\n",
    "need = [cn_player, cn_team, cn_opp, cn_mkt, cn_line, cn_pom, cn_od, cn_ud]\n",
    "if any(x is None for x in need):\n",
    "    missing = [n for n, x in zip(\n",
    "        [\"Player\",\"Team\",\"Opponent\",\"Market\",\"Line\",\"POverModel\",\"OverDecimal\",\"UnderDecimal\"], need) if x is None]\n",
    "    raise KeyError(f\"Missing expected columns in bets file: {missing}\")\n",
    "\n",
    "# Rename columns to standard names for processing\n",
    "bets = bets.rename(columns={\n",
    "    cn_player: \"player\",\n",
    "    cn_team: \"team\", \n",
    "    cn_opp: \"opponent\",\n",
    "    cn_mkt: \"market\", \n",
    "    cn_line: \"line\",\n",
    "    cn_pom: \"p_over_model\", \n",
    "    cn_pum: \"p_under_model\",\n",
    "    cn_od: \"over_dec\", \n",
    "    cn_ud: \"under_dec\"\n",
    "})\n",
    "\n",
    "# Convert numeric columns\n",
    "bets[\"line\"] = pd.to_numeric(bets[\"line\"], errors=\"coerce\")\n",
    "bets[\"p_over_model\"] = pd.to_numeric(bets[\"p_over_model\"], errors=\"coerce\")\n",
    "bets[\"p_under_model\"] = pd.to_numeric(bets[\"p_under_model\"], errors=\"coerce\")\n",
    "bets[\"over_dec\"] = pd.to_numeric(bets[\"over_dec\"], errors=\"coerce\")\n",
    "bets[\"under_dec\"] = pd.to_numeric(bets[\"under_dec\"], errors=\"coerce\")\n",
    "\n",
    "# Add key for joining to box scores\n",
    "bets[\"player_key\"] = bets[\"player\"].map(_norm_player)\n",
    "\n",
    "# ------------------ 3) Load boxscores for yesterday (from data_raw/) ------------------\n",
    "BOXSCORE_DIR = \"data_raw\"\n",
    "\n",
    "def load_boxscores_for_date(target_date):\n",
    "    \"\"\"Load boxscores for a specific date, handling various file naming patterns\"\"\"\n",
    "    target_date_str = target_date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    # Try multiple file patterns\n",
    "    patterns = [\n",
    "        f\"nba_boxscores_{target_date_str}.csv\",\n",
    "        f\"nba_boxscores_*{target_date_str}*.csv\",\n",
    "        \"nba_boxscores_*.csv\"  # season file\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = glob.glob(os.path.join(BOXSCORE_DIR, pattern))\n",
    "        if matches:\n",
    "            # Use the most recent file if multiple matches\n",
    "            box_file = sorted(matches)[-1]\n",
    "            box = pd.read_csv(box_file)\n",
    "            print(f\"Loaded boxscores from: {os.path.basename(box_file)}\")\n",
    "            \n",
    "            # Filter to target date\n",
    "            date_cols = [\"GAME_DATE\", \"GAME_DATE_EST\", \"GAME_DATE_LCL\", \"Date\", \"date\"]\n",
    "            for date_col in date_cols:\n",
    "                if date_col in box.columns:\n",
    "                    box_dates = pd.to_datetime(box[date_col], errors='coerce').dt.date\n",
    "                    filtered = box[box_dates == target_date].copy()\n",
    "                    if len(filtered) > 0:\n",
    "                        print(f\"Filtered to {target_date} using column '{date_col}': {len(filtered)} rows\")\n",
    "                        return filtered\n",
    "            \n",
    "            # If no date filtering worked but we have data, return all\n",
    "            if len(box) > 0:\n",
    "                print(f\"Warning: Could not filter by date. Using all {len(box)} rows.\")\n",
    "                return box\n",
    "    \n",
    "    raise FileNotFoundError(f\"No boxscore data found for {target_date}\")\n",
    "\n",
    "try:\n",
    "    box = load_boxscores_for_date(ydate)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    # Create empty evaluation file\n",
    "    eval_out = os.path.join(\"data/eval\", f\"value_bets_eval_{ystr}.csv\")\n",
    "    bets.assign(\n",
    "        actual=np.nan, suggestion=\"NO BET\", suggested_prob=np.nan, result_model=\"NA\"\n",
    "    ).to_csv(eval_out, index=False)\n",
    "    print(f\"Saved empty evaluation to: {eval_out}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# ------------------ 4) Normalize box & join ------------------\n",
    "box = box.copy()\n",
    "box[\"player\"] = pick_col(box, [\"PLAYER_NAME\",\"Player\"])\n",
    "box[\"player_key\"] = box[\"player\"].map(_norm_player)\n",
    "box[\"PTS\"] = pd.to_numeric(pick_col(box, [\"PTS\",\"Points\"]), errors=\"coerce\")\n",
    "box[\"REB\"] = pd.to_numeric(pick_col(box, [\"REB\",\"Rebounds\"]), errors=\"coerce\")\n",
    "box[\"AST\"] = pd.to_numeric(pick_col(box, [\"AST\",\"Assists\"]), errors=\"coerce\")\n",
    "box[\"TEAM_ABBREVIATION\"] = pick_col(box, [\"TEAM_ABBREVIATION\",\"TEAM\"])\n",
    "box[\"OPPONENT_ABBREVIATION\"] = infer_opponent(box)\n",
    "\n",
    "joined = bets.merge(\n",
    "    box[[\"player_key\",\"PTS\",\"REB\",\"AST\",\"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"]],\n",
    "    on=\"player_key\", how=\"left\", suffixes=(\"\",\"_box\")\n",
    ")\n",
    "\n",
    "def pick_actual(row):\n",
    "    m = str(row.get(\"market\",\"\")).upper()\n",
    "    return row.get(m, np.nan) if m in [\"PTS\",\"REB\",\"AST\"] else np.nan\n",
    "\n",
    "joined[\"actual\"] = joined.apply(pick_actual, axis=1)\n",
    "\n",
    "# ------------------ 5) Model suggestion & grading ------------------\n",
    "THRESH = 0.59  # model-confidence threshold\n",
    "\n",
    "def suggest_side(row):\n",
    "    po = row.get(\"p_over_model\", np.nan)\n",
    "    pu = row.get(\"p_under_model\", np.nan)\n",
    "    # If both are NaN ‚Üí NO BET\n",
    "    if pd.isna(po) and pd.isna(pu):\n",
    "        return \"NO BET\", np.nan\n",
    "    # Determine which side meets threshold and pick the higher prob if both do\n",
    "    cand = []\n",
    "    if pd.notna(po) and po >= THRESH:\n",
    "        cand.append((\"OVER\", float(po)))\n",
    "    if pd.notna(pu) and pu >= THRESH:\n",
    "        cand.append((\"UNDER\", float(pu)))\n",
    "    if not cand:\n",
    "        return \"NO BET\", max([v for v in [po, pu] if pd.notna(v)] + [np.nan])\n",
    "    # pick the larger probability among the qualifying sides\n",
    "    cand.sort(key=lambda x: x[1], reverse=True)\n",
    "    return cand[0]\n",
    "\n",
    "joined[[\"suggestion\",\"suggested_prob\"]] = joined.apply(\n",
    "    lambda r: pd.Series(suggest_side(r)), axis=1\n",
    ")\n",
    "\n",
    "def grade_row(row):\n",
    "    side = row.get(\"suggestion\", \"NO BET\")\n",
    "    act  = row.get(\"actual\", np.nan)\n",
    "    line = row.get(\"line\", np.nan)\n",
    "    if side == \"NO BET\" or pd.isna(act) or pd.isna(line):\n",
    "        return \"NA\"\n",
    "    if side == \"OVER\":\n",
    "        if act > line:  return \"WIN\"\n",
    "        if act == line: return \"PUSH\"\n",
    "        return \"LOSS\"\n",
    "    if side == \"UNDER\":\n",
    "        if act < line:  return \"WIN\"\n",
    "        if act == line: return \"PUSH\"\n",
    "        return \"LOSS\"\n",
    "    return \"NA\"\n",
    "\n",
    "joined[\"result_model\"] = joined.apply(grade_row, axis=1)\n",
    "\n",
    "# ------------------ 6) Summary & save ------------------\n",
    "is_bet = joined[\"suggestion\"].isin([\"OVER\",\"UNDER\"])\n",
    "graded = joined.loc[is_bet & joined[\"result_model\"].isin([\"WIN\",\"LOSS\",\"PUSH\"])]\n",
    "\n",
    "wins   = (graded[\"result_model\"]==\"WIN\").sum()\n",
    "losses = (graded[\"result_model\"]==\"LOSS\").sum()\n",
    "pushes = (graded[\"result_model\"]==\"PUSH\").sum()\n",
    "hitrate = wins / max(wins+losses, 1)\n",
    "\n",
    "print(f\"Suggested bets (THRESH={THRESH:.2f}): {is_bet.sum()} of {len(joined)} rows\")\n",
    "print(f\"Graded bets: {len(graded)}  (WIN={wins}, LOSS={losses}, PUSH={pushes})\")\n",
    "print(f\"Hit rate (excl. pushes): {hitrate:.1%}\")\n",
    "\n",
    "# Side-specific breakdown\n",
    "graded_over  = graded.loc[joined[\"suggestion\"]==\"OVER\"]\n",
    "graded_under = graded.loc[joined[\"suggestion\"]==\"UNDER\"]\n",
    "def _rate(g):\n",
    "    w = (g[\"result_model\"]==\"WIN\").sum()\n",
    "    l = (g[\"result_model\"]==\"LOSS\").sum()\n",
    "    return w / max(w+l,1)\n",
    "\n",
    "print(f\"OVER bets graded:  {len(graded_over)}  | Hit: {_rate(graded_over):.1%}\")\n",
    "print(f\"UNDER bets graded: {len(graded_under)} | Hit: {_rate(graded_under):.1%}\")\n",
    "\n",
    "eval_out = os.path.join(\"data/eval\", f\"value_bets_eval_{ystr}.csv\")\n",
    "joined.to_csv(eval_out, index=False)\n",
    "print(f\"Saved evaluation to: {eval_out}\")\n",
    "\n",
    "# Preview a few rows with the actual column names from your file\n",
    "cols_preview = [\n",
    "    \"player\",\"team\",\"opponent\",\"market\",\"line\",\"actual\",\n",
    "    \"p_over_model\",\"p_under_model\",\"over_dec\",\"under_dec\",\n",
    "    \"suggestion\",\"suggested_prob\",\"result_model\",\n",
    "    \"TEAM_ABBREVIATION\",\"OPPONENT_ABBREVIATION\"\n",
    "]\n",
    "print(\"\\nPreview:\")\n",
    "print(joined[ [c for c in cols_preview if c in joined.columns] ].head(25).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load feature importance file\n",
    "fi = pd.read_csv(\"model_outputs_rate/feature_importances_20251106_140212.csv\")\n",
    "\n",
    "# Preview to see what columns exist\n",
    "print(fi.head())\n",
    "\n",
    "# Normalize and compute mean importance\n",
    "cols = [c for c in fi.columns if \"importance\" in c.lower()]\n",
    "fi[\"mean_importance\"] = fi[cols].mean(axis=1)\n",
    "fi = fi.sort_values(\"mean_importance\", ascending=False)\n",
    "\n",
    "# Show top & bottom\n",
    "print(\"üèÜ Top 20 most important features:\")\n",
    "print(fi.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\nü™∂ Bottom 20 least important features:\")\n",
    "print(fi.tail(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1666e30",
   "metadata": {},
   "source": [
    "## TEAM LEVEL PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec101ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 20: Build team-game dataset for team models (fixed) ----------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We assume logs_2324, logs_2425, logs_2526 already loaded in your data cells.\n",
    "for name in [\"logs_2324\", \"logs_2425\", \"logs_2526\"]:\n",
    "    assert name in globals(), f\"{name} missing. Make sure your log DataFrames are loaded.\"\n",
    "\n",
    "def _build_team_games_from_logs(logs: pd.DataFrame, season_label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate player boxscores into team-level game rows.\n",
    "    Each row = one team in one game (so 2 rows per game_id).\n",
    "    Does NOT require an 'opponent' column in the logs; we reconstruct opponent later.\n",
    "    \"\"\"\n",
    "    df = logs.copy()\n",
    "\n",
    "    # Standardize some expected columns if needed\n",
    "    col_map = {\n",
    "        \"TEAM_ABBREVIATION\": \"team\",\n",
    "        \"GAME_ID\": \"game_id\",\n",
    "        \"GAME_DATE\": \"game_date\",\n",
    "        \"HOME\": \"home\",          # 1 if home, 0 if away (if exists)\n",
    "        \"PLUS_MINUS\": \"plus_minus\",\n",
    "    }\n",
    "    for old, new in col_map.items():\n",
    "        if old in df.columns and new not in df.columns:\n",
    "            df = df.rename(columns={old: new})\n",
    "\n",
    "    # Minimal sanity\n",
    "    if \"team\" not in df.columns or \"game_id\" not in df.columns:\n",
    "        raise RuntimeError(\"logs must have TEAM_ABBREVIATION and GAME_ID (or mapped).\")\n",
    "\n",
    "    # We aggregate common stats\n",
    "    agg_spec = {}\n",
    "    for c in [\"PTS\",\"REB\",\"AST\",\"TOV\",\n",
    "              \"FGM\",\"FGA\",\"FG3M\",\"FG3A\",\"FTM\",\"FTA\",\n",
    "              \"OREB\",\"DREB\"]:\n",
    "        if c in df.columns:\n",
    "            agg_spec[c] = \"sum\"\n",
    "\n",
    "    # Some team-level flags\n",
    "    if \"home\" in df.columns:\n",
    "        agg_spec[\"home\"] = \"max\"   # if any player flagged home, team is home\n",
    "    if \"game_date\" in df.columns:\n",
    "        agg_spec[\"game_date\"] = \"max\"\n",
    "    if \"plus_minus\" in df.columns:\n",
    "        agg_spec[\"plus_minus\"] = \"sum\"\n",
    "\n",
    "    # Aggregate by game and team (no opponent column needed yet)\n",
    "    team_games = (\n",
    "        df.groupby([\"game_id\",\"team\"], as_index=False)\n",
    "          .agg(agg_spec)\n",
    "    )\n",
    "\n",
    "    # Reconstruct opponent for each (game_id, team) pair\n",
    "    # For each game_id, there should be exactly 2 teams.\n",
    "    opp_map = team_games[[\"game_id\",\"team\"]].rename(columns={\"team\": \"opponent\"})\n",
    "\n",
    "    team_games = team_games.merge(opp_map, on=\"game_id\", how=\"left\")\n",
    "\n",
    "    # Remove self matches so each row has the *other* team as opponent\n",
    "    team_games = team_games[team_games[\"team\"] != team_games[\"opponent\"]].copy()\n",
    "\n",
    "    # If there were more than two teams per game_id for some reason,\n",
    "    # this may duplicate rows. We keep the first opponent per (game_id, team).\n",
    "    team_games = (\n",
    "        team_games.sort_values([\"game_id\",\"team\",\"opponent\"])\n",
    "                  .drop_duplicates(subset=[\"game_id\",\"team\"])\n",
    "                  .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Derived team-level fields\n",
    "    if \"FG3M\" in team_games.columns and \"FGM\" in team_games.columns:\n",
    "        team_games[\"FG2M\"] = team_games[\"FGM\"] - team_games[\"FG3M\"]\n",
    "    if \"FG3A\" in team_games.columns and \"FGA\" in team_games.columns:\n",
    "        team_games[\"FG2A\"] = team_games[\"FGA\"] - team_games[\"FG3A\"]\n",
    "\n",
    "    # Possessions (simple estimate)\n",
    "    if all(c in team_games.columns for c in [\"FGA\",\"FTA\",\"TOV\",\"OREB\"]):\n",
    "        team_games[\"POSS\"] = (\n",
    "            team_games[\"FGA\"]\n",
    "            + 0.44 * team_games[\"FTA\"]\n",
    "            + team_games[\"TOV\"]\n",
    "            - team_games[\"OREB\"]\n",
    "        )\n",
    "    else:\n",
    "        team_games[\"POSS\"] = np.nan\n",
    "\n",
    "    # Offensive Rating (points per 100 possessions)\n",
    "    if \"PTS\" in team_games.columns:\n",
    "        team_games[\"OFF_RTG\"] = 100 * team_games[\"PTS\"] / team_games[\"POSS\"].replace(0, np.nan)\n",
    "    else:\n",
    "        team_games[\"OFF_RTG\"] = np.nan\n",
    "\n",
    "    # Mark season for weighting later if desired\n",
    "    team_games[\"season\"] = season_label\n",
    "\n",
    "    return team_games\n",
    "\n",
    "team_games_2324 = _build_team_games_from_logs(logs_2324, \"2023-24\")\n",
    "team_games_2425 = _build_team_games_from_logs(logs_2425, \"2024-25\")\n",
    "team_games_2526 = _build_team_games_from_logs(logs_2526, \"2025-26\")\n",
    "\n",
    "team_games_all = pd.concat([team_games_2324, team_games_2425, team_games_2526], ignore_index=True)\n",
    "\n",
    "# Parse dates\n",
    "if \"game_date\" in team_games_all.columns:\n",
    "    team_games_all[\"game_date\"] = pd.to_datetime(team_games_all[\"game_date\"])\n",
    "\n",
    "print(\"team_games_all shape:\", team_games_all.shape)\n",
    "display(team_games_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 21: Add rolling team features ---------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "assert \"team_games_all\" in globals(), \"team_games_all missing. Run Cell 20_team first.\"\n",
    "\n",
    "def add_team_rolling_features(df_team: pd.DataFrame, windows=(5, 10)) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each team, compute rolling averages and sums over last N games.\n",
    "    \"\"\"\n",
    "    df = df_team.sort_values([\"team\",\"game_date\"]).copy()\n",
    "\n",
    "    stat_cols = [c for c in [\n",
    "        \"PTS\",\"REB\",\"AST\",\"TOV\",\"FGM\",\"FGA\",\"FG3M\",\"FG3A\",\n",
    "        \"FTM\",\"FTA\",\"FG2M\",\"FG2A\",\"POSS\",\"OFF_RTG\"\n",
    "    ] if c in df.columns]\n",
    "\n",
    "    for w in windows:\n",
    "        rolled = (\n",
    "            df.groupby(\"team\", group_keys=False)[stat_cols]\n",
    "              .rolling(w, min_periods=1)\n",
    "              .mean()\n",
    "              .add_suffix(f\"_roll{w}\")\n",
    "        )\n",
    "        for col in rolled.columns:\n",
    "            df[col] = rolled[col].values\n",
    "\n",
    "    # Simple rest features: days since last game, B2B, 3-in-4, etc.\n",
    "    if \"game_date\" in df.columns:\n",
    "        df[\"prev_game_date\"] = (\n",
    "            df.groupby(\"team\")[\"game_date\"]\n",
    "              .shift(1)\n",
    "        )\n",
    "        df[\"days_rest\"] = (df[\"game_date\"] - df[\"prev_game_date\"]).dt.days.fillna(3)\n",
    "        df[\"is_b2b\"] = (df[\"days_rest\"] == 1).astype(int)\n",
    "        df[\"is_3in4\"] = (\n",
    "            df.groupby(\"team\")[\"is_b2b\"]\n",
    "              .rolling(3, min_periods=1)\n",
    "              .sum()\n",
    "              .reset_index(level=0, drop=True) >= 2\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        df[\"days_rest\"] = 3\n",
    "        df[\"is_b2b\"] = 0\n",
    "        df[\"is_3in4\"] = 0\n",
    "\n",
    "    # Win / loss target and spread\n",
    "    if \"PTS\" in df.columns:\n",
    "        # Merge opponent points to compute WIN & margin\n",
    "        opp_pts = df[[\"game_id\",\"team\",\"PTS\"]].rename(columns={\"team\":\"team_tmp\",\"PTS\":\"PTS_opp\"})\n",
    "        df = df.merge(\n",
    "            opp_pts,\n",
    "            left_on=[\"game_id\",\"opponent\"],\n",
    "            right_on=[\"game_id\",\"team_tmp\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        df.drop(columns=[\"team_tmp\"], inplace=True)\n",
    "        df[\"POINT_MARGIN\"] = df[\"PTS\"] - df[\"PTS_opp\"]\n",
    "        df[\"WIN\"] = (df[\"POINT_MARGIN\"] > 0).astype(int)\n",
    "    else:\n",
    "        df[\"POINT_MARGIN\"] = np.nan\n",
    "        df[\"WIN\"] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "team_features_all = add_team_rolling_features(team_games_all)\n",
    "\n",
    "print(\"team_features_all shape:\", team_features_all.shape)\n",
    "display(team_features_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3aab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 22: Train team-level prop models ------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error, log_loss\n",
    "\n",
    "assert \"team_features_all\" in globals(), \"team_features_all missing. Run Cell 21_team first.\"\n",
    "\n",
    "df = team_features_all.copy()\n",
    "\n",
    "# Basic sanity: drop rows with missing target essentials\n",
    "df = df.dropna(subset=[\"PTS\",\"REB\",\"AST\",\"TOV\"]).reset_index(drop=True)\n",
    "\n",
    "# Feature columns for team models\n",
    "TEAM_FEATURES = []\n",
    "\n",
    "# Rolling stats\n",
    "for base in [\"PTS\",\"REB\",\"AST\",\"TOV\",\"FG3M\",\"FG3A\",\"FGA\",\"FTM\",\"FTA\",\"OFF_RTG\",\"POSS\"]:\n",
    "    for w in [5, 10]:\n",
    "        col = f\"{base}_roll{w}\"\n",
    "        if col in df.columns:\n",
    "            TEAM_FEATURES.append(col)\n",
    "\n",
    "# Scheduling and context\n",
    "for col in [\"home\",\"days_rest\",\"is_b2b\",\"is_3in4\"]:\n",
    "    if col in df.columns:\n",
    "        TEAM_FEATURES.append(col)\n",
    "\n",
    "TEAM_FEATURES = sorted(set(TEAM_FEATURES))\n",
    "print(f\"Using {len(TEAM_FEATURES)} features for team models.\")\n",
    "\n",
    "gkf = GroupKFold(n_splits=8)\n",
    "models_team_reg = {}\n",
    "cv_scores_team_reg = {}\n",
    "\n",
    "def train_team_regressor(df_in: pd.DataFrame, target_col: str):\n",
    "    df_ = df_in.dropna(subset=TEAM_FEATURES + [target_col, \"team\"]).copy()\n",
    "    X = df_[TEAM_FEATURES]\n",
    "    y = df_[target_col]\n",
    "    groups = df_[\"team\"]\n",
    "\n",
    "    fold_mae = []\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    for tr_idx, te_idx in gkf.split(X, y, groups):\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred = model.predict(X_te)\n",
    "        fold_mae.append(mean_absolute_error(y_te, pred))\n",
    "\n",
    "    model.fit(X, y)\n",
    "    return model, float(np.mean(fold_mae)), float(np.std(fold_mae))\n",
    "\n",
    "# Train regressors for common team prop stats\n",
    "TEAM_TARGETS = [\"PTS\",\"REB\",\"AST\",\"TOV\",\"FG3M\",\"FG2M\",\"FTM\"]\n",
    "for tgt in TEAM_TARGETS:\n",
    "    if tgt not in df.columns:\n",
    "        print(f\"Skipping {tgt}: not in data.\")\n",
    "        continue\n",
    "    model, m, s = train_team_regressor(df, tgt)\n",
    "    models_team_reg[tgt] = model\n",
    "    cv_scores_team_reg[tgt] = (m, s)\n",
    "    print(f\"üìä Team {tgt} MAE: {m:.3f} ¬± {s:.3f}\")\n",
    "\n",
    "# Train classification model for WIN\n",
    "df_cls = df.dropna(subset=TEAM_FEATURES + [\"WIN\"]).copy()\n",
    "X = df_cls[TEAM_FEATURES]\n",
    "y = df_cls[\"WIN\"].astype(int)\n",
    "groups = df_cls[\"team\"]\n",
    "\n",
    "win_model = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"logloss\",\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "fold_ll = []\n",
    "for tr_idx, te_idx in gkf.split(X, y, groups):\n",
    "    X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "    win_model.fit(X_tr, y_tr)\n",
    "    p_te = win_model.predict_proba(X_te)[:,1]\n",
    "    # Clip probs for logloss stability\n",
    "    p_te = np.clip(p_te, 1e-4, 1-1e-4)\n",
    "    fold_ll.append(log_loss(y_te, p_te))\n",
    "\n",
    "win_model.fit(X, y)\n",
    "cv_win_logloss = (float(np.mean(fold_ll)), float(np.std(fold_ll)))\n",
    "\n",
    "print(f\"\\nüèÜ WIN model logloss: {cv_win_logloss[0]:.4f} ¬± {cv_win_logloss[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 23: Build today's games from odds_long ------------------------\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "assert \"odds_long\" in globals(), \"odds_long not found. Run the odds scraper cell first.\"\n",
    "\n",
    "# Step 1: filter to today's date\n",
    "today_str = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "odds_today = odds_long[odds_long[\"game_date\"] == today_str].copy()\n",
    "\n",
    "if odds_today.empty:\n",
    "    print(f\"‚ö†Ô∏è No odds found for today ({today_str}).\")\n",
    "else:\n",
    "    # Clean opponent & away flag\n",
    "    odds_today[\"opp_clean\"] = odds_today[\"opponent\"].astype(str).str.replace(\"@\",\"\", regex=False).str.strip()\n",
    "    odds_today[\"is_away\"] = odds_today[\"opponent\"].astype(str).str.startswith(\"@\")\n",
    "\n",
    "    # Determine home/away teams\n",
    "    odds_today[\"home_team\"] = odds_today.apply(\n",
    "        lambda r: r[\"opp_clean\"] if r[\"is_away\"] else r[\"team\"], axis=1\n",
    "    )\n",
    "    odds_today[\"away_team\"] = odds_today.apply(\n",
    "        lambda r: r[\"team\"] if r[\"is_away\"] else r[\"opp_clean\"], axis=1\n",
    "    )\n",
    "\n",
    "    # Build unique game key\n",
    "    odds_today[\"game_key\"] = (\n",
    "        odds_today[\"game_date\"].astype(str) + \"_\" +\n",
    "        odds_today[\"home_team\"] + \"_\" +\n",
    "        odds_today[\"away_team\"]\n",
    "    )\n",
    "\n",
    "    games_unique = (\n",
    "        odds_today[[\"game_date\",\"game_key\",\"home_team\",\"away_team\"]]\n",
    "        .drop_duplicates(\"game_key\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"üìå Games detected from odds:\")\n",
    "    print(games_unique.to_string(index=False))\n",
    "\n",
    "    # Build final today_games (home and away rows)\n",
    "    today_games = pd.concat([\n",
    "        # Home side\n",
    "        games_unique.assign(\n",
    "            game_id = games_unique[\"game_key\"],\n",
    "            team = games_unique[\"home_team\"],\n",
    "            opponent = games_unique[\"away_team\"],\n",
    "            home = 1\n",
    "        )[[\"game_id\",\"team\",\"opponent\",\"home\",\"game_date\"]],\n",
    "\n",
    "        # Away side\n",
    "        games_unique.assign(\n",
    "            game_id = games_unique[\"game_key\"],\n",
    "            team = games_unique[\"away_team\"],\n",
    "            opponent = games_unique[\"home_team\"],\n",
    "            home = 0\n",
    "        )[[\"game_id\",\"team\",\"opponent\",\"home\",\"game_date\"]],\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    print(\"\\n‚úÖ today_games:\")\n",
    "    print(today_games.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 24: Enrich team_features_all with opponent, pace, rest, Elo, matchup ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "assert \"team_features_all\" in globals(), \"team_features_all missing.\"\n",
    "assert \"team_games_all\" in globals(), \"team_games_all missing.\"\n",
    "\n",
    "# Base frame: one row per team-game with existing rolling stats\n",
    "df = team_features_all.sort_values([\"team\", \"game_date\"]).copy()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Merge in opponent RAW stats for each game (what this team allows)\n",
    "# -------------------------------------------------------------------\n",
    "opp_raw = (\n",
    "    team_games_all[\n",
    "        [\n",
    "            \"game_id\",\n",
    "            \"team\",\n",
    "            \"PTS\",\n",
    "            \"REB\",\n",
    "            \"AST\",\n",
    "            \"TOV\",\n",
    "            \"FG3M\",\n",
    "            \"FG2M\",\n",
    "            \"FTM\",\n",
    "            \"POSS\",\n",
    "        ]\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"team\": \"opponent\",\n",
    "            \"PTS\": \"opp_PTS_raw\",\n",
    "            \"REB\": \"opp_REB_raw\",\n",
    "            \"AST\": \"opp_AST_raw\",\n",
    "            \"TOV\": \"opp_TOV_raw\",\n",
    "            \"FG3M\": \"opp_FG3M_raw\",\n",
    "            \"FG2M\": \"opp_FG2M_raw\",\n",
    "            \"FTM\": \"opp_FTM_raw\",\n",
    "            \"POSS\": \"opp_POSS_raw\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df.merge(opp_raw, on=[\"game_id\", \"opponent\"], how=\"left\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Rolling ALLOWED stats per team ‚Üí defensive profile\n",
    "#     (shifted by 1 to avoid look-ahead leakage)\n",
    "# -------------------------------------------------------------------\n",
    "for stat in [\"PTS\", \"REB\", \"AST\", \"TOV\", \"FG3M\", \"FG2M\", \"FTM\", \"POSS\"]:\n",
    "    col = f\"opp_{stat}_raw\"\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "    for w in (5, 10):\n",
    "        roll_col = f\"{stat}_allowed_roll{w}\"\n",
    "        df[roll_col] = (\n",
    "            df.groupby(\"team\")[col]\n",
    "              .transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Rest days and simple flags\n",
    "# -------------------------------------------------------------------\n",
    "df = df.sort_values([\"team\", \"game_date\"])\n",
    "df[\"prev_game_date\"] = df.groupby(\"team\")[\"game_date\"].shift(1)\n",
    "df[\"days_rest\"] = (df[\"game_date\"] - df[\"prev_game_date\"]).dt.days.clip(lower=0)\n",
    "df[\"is_b2b\"] = (df[\"days_rest\"] == 1).astype(int)\n",
    "\n",
    "# Rest advantage vs opponent in the same game\n",
    "if \"game_id\" in df.columns:\n",
    "    mean_rest_by_game = df.groupby(\"game_id\")[\"days_rest\"].transform(\"mean\")\n",
    "    df[\"is_rest_advantage\"] = (df[\"days_rest\"] > mean_rest_by_game).astype(int)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Projected pace as the average of available rolling possessions\n",
    "# -------------------------------------------------------------------\n",
    "pace_cols = [c for c in df.columns if \"POSS_roll\" in c]\n",
    "if pace_cols:\n",
    "    df[\"proj_pace\"] = df[pace_cols].mean(axis=1)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Build Elo ratings (FiveThirtyEight-style)\n",
    "# -------------------------------------------------------------------\n",
    "def compute_elo_table(games: pd.DataFrame,\n",
    "                      base_elo: float = 1500.0,\n",
    "                      k_factor: float = 20.0,\n",
    "                      hca_points: float = 100.0,\n",
    "                      carry_over: float = 0.75,\n",
    "                      mean_elo: float = 1500.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute per-team pre-game Elo ratings for each game_id/team.\n",
    "    Expect columns: game_id, game_date, season, team, opponent, PTS, home.\n",
    "    \"\"\"\n",
    "    required_cols = {\"game_id\", \"game_date\", \"season\", \"team\", \"opponent\", \"PTS\"}\n",
    "    missing = required_cols - set(games.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"compute_elo_table: games missing columns: {missing}\")\n",
    "\n",
    "    games_local = games.copy()\n",
    "    games_local = games_local.sort_values([\"season\", \"game_date\", \"game_id\"])\n",
    "\n",
    "    # Ensure 'home' exists; if not, approximate (first row home)\n",
    "    if \"home\" not in games_local.columns:\n",
    "        # Assume that for each game, exactly one row is home (we'll assign later if absent)\n",
    "        games_local[\"home\"] = 0\n",
    "\n",
    "    # Per-team current Elo and last season tracking\n",
    "    elo = defaultdict(lambda: base_elo)\n",
    "    last_season = {}\n",
    "\n",
    "    records = []\n",
    "\n",
    "    # Group by game_id in chronological order\n",
    "    # Use sort=False to preserve order from the sorted frame\n",
    "    for gid, g in games_local.groupby(\"game_id\", sort=False):\n",
    "        if len(g) != 2:\n",
    "            # Skip games without exactly 2 team-rows\n",
    "            continue\n",
    "\n",
    "        g = g.copy()\n",
    "\n",
    "        # Identify home/away\n",
    "        if \"home\" in g.columns and g[\"home\"].isin([0, 1]).all():\n",
    "            g_home = g[g[\"home\"] == 1]\n",
    "            if len(g_home) == 1:\n",
    "                home_row = g_home.iloc[0]\n",
    "                away_row = g[g[\"team\"] != home_row[\"team\"]].iloc[0]\n",
    "            else:\n",
    "                # Fallback: first row home\n",
    "                home_row = g.iloc[0]\n",
    "                away_row = g.iloc[1]\n",
    "        else:\n",
    "            home_row = g.iloc[0]\n",
    "            away_row = g.iloc[1]\n",
    "\n",
    "        # Make sure season is defined for both rows (assume same)\n",
    "        season = home_row[\"season\"]\n",
    "\n",
    "        for row in (home_row, away_row):\n",
    "            t = row[\"team\"]\n",
    "            s = row[\"season\"]\n",
    "            if t not in last_season:\n",
    "                last_season[t] = s\n",
    "            elif last_season[t] != s:\n",
    "                # New season for this team: regress Elo to mean\n",
    "                elo[t] = carry_over * elo[t] + (1 - carry_over) * mean_elo\n",
    "                last_season[t] = s\n",
    "\n",
    "        team_home = home_row[\"team\"]\n",
    "        team_away = away_row[\"team\"]\n",
    "\n",
    "        pts_home = home_row[\"PTS\"]\n",
    "        pts_away = away_row[\"PTS\"]\n",
    "\n",
    "        # Pre-game Elo\n",
    "        Ra = elo[team_home]\n",
    "        Rb = elo[team_away]\n",
    "\n",
    "        # Home-court advantage: +HCA for home\n",
    "        elo_diff = (Ra + hca_points) - Rb\n",
    "        exp_home = 1.0 / (1.0 + 10.0 ** (-elo_diff / 400.0))\n",
    "        exp_away = 1.0 - exp_home\n",
    "\n",
    "        # Margin of victory multiplier (approx 538's formula)\n",
    "        margin = abs(pts_home - pts_away)\n",
    "        mov_mult = ((margin + 3) ** 0.8) / (7.5 + 0.006 * abs(elo_diff))\n",
    "\n",
    "        # Outcome\n",
    "        if pts_home > pts_away:\n",
    "            # Home win\n",
    "            Ra_new = Ra + k_factor * mov_mult * (1 - exp_home)\n",
    "            Rb_new = Rb - k_factor * mov_mult * (1 - exp_home)\n",
    "        else:\n",
    "            # Away win\n",
    "            Ra_new = Ra - k_factor * mov_mult * (1 - exp_away)\n",
    "            Rb_new = Rb + k_factor * mov_mult * (1 - exp_away)\n",
    "\n",
    "        # Store pre-game Elo for each team\n",
    "        records.append(\n",
    "            {\n",
    "                \"game_id\": home_row[\"game_id\"],\n",
    "                \"team\": team_home,\n",
    "                \"elo_pre\": Ra,\n",
    "                \"opp_team\": team_away,\n",
    "                \"opp_elo_pre\": Rb,\n",
    "                \"elo_diff_pre\": Ra - Rb,\n",
    "            }\n",
    "        )\n",
    "        records.append(\n",
    "            {\n",
    "                \"game_id\": away_row[\"game_id\"],\n",
    "                \"team\": team_away,\n",
    "                \"elo_pre\": Rb,\n",
    "                \"opp_team\": team_home,\n",
    "                \"opp_elo_pre\": Ra,\n",
    "                \"elo_diff_pre\": Rb - Ra,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Update Elo\n",
    "        elo[team_home] = Ra_new\n",
    "        elo[team_away] = Rb_new\n",
    "\n",
    "    elo_df = pd.DataFrame(records)\n",
    "    return elo_df\n",
    "\n",
    "\n",
    "# Compute Elo from team_games_all and merge into df\n",
    "elo_input_cols = [\"game_id\", \"game_date\", \"season\", \"team\", \"opponent\", \"PTS\"]\n",
    "missing_elo_cols = set(elo_input_cols) - set(team_games_all.columns)\n",
    "if missing_elo_cols:\n",
    "    raise ValueError(f\"team_games_all missing required Elo cols: {missing_elo_cols}\")\n",
    "\n",
    "elo_table = compute_elo_table(team_games_all[elo_input_cols + ([\"home\"] if \"home\" in team_games_all.columns else [])])\n",
    "\n",
    "df = df.merge(\n",
    "    elo_table[[\"game_id\", \"team\", \"elo_pre\", \"opp_elo_pre\", \"elo_diff_pre\"]],\n",
    "    on=[\"game_id\", \"team\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6) Opponent rolling features (offense + defense)\n",
    "#     ‚Üí we self-merge df to bring opponent rolling stats into each row.\n",
    "# -------------------------------------------------------------------\n",
    "rolling_cols = [\n",
    "    c\n",
    "    for c in df.columns\n",
    "    if ((\"_roll5\" in c or \"_roll10\" in c) and not c.startswith(\"opp_\"))\n",
    "]\n",
    "\n",
    "if rolling_cols:\n",
    "    opp_feats = df[[\"game_id\", \"team\"] + rolling_cols].copy()\n",
    "    rename_map = {\"team\": \"opponent\"}\n",
    "    rename_map.update({c: f\"opp_{c}\" for c in rolling_cols})\n",
    "    opp_feats = opp_feats.rename(columns=rename_map)\n",
    "\n",
    "    df = df.merge(opp_feats, on=[\"game_id\", \"opponent\"], how=\"left\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7) Matchup features ‚Üí team strengths vs opponent weaknesses\n",
    "# -------------------------------------------------------------------\n",
    "# Example: PTS_roll10 - opp_PTS_allowed_roll10, etc.\n",
    "stats_for_matchup = [\"PTS\", \"FG3M\", \"FG2M\", \"REB\", \"AST\", \"TOV\", \"POSS\"]\n",
    "\n",
    "for stat in stats_for_matchup:\n",
    "    for w in (5, 10):\n",
    "        off_col = f\"{stat}_roll{w}\"\n",
    "        def_col = f\"opp_{stat}_allowed_roll{w}\"\n",
    "        if off_col in df.columns and def_col in df.columns:\n",
    "            df[f\"matchup_{stat}_roll{w}\"] = df[off_col] - df[def_col]\n",
    "\n",
    "# Pace matchup (optionally: own pace + opp allowed pace)\n",
    "for w in (5, 10):\n",
    "    off_col = f\"POSS_roll{w}\"\n",
    "    def_col = f\"opp_POSS_allowed_roll{w}\"\n",
    "    if off_col in df.columns and def_col in df.columns:\n",
    "        df[f\"matchup_POSS_roll{w}\"] = df[off_col] + df[def_col]\n",
    "\n",
    "team_features_all_enriched = df\n",
    "\n",
    "print(\"‚úÖ Built team_features_all_enriched:\", team_features_all_enriched.shape)\n",
    "print(team_features_all_enriched.tail().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 25: Train team models with enriched features --------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error, log_loss\n",
    "\n",
    "assert \"team_features_all_enriched\" in globals(), \"team_features_all_enriched missing; run Cell 36_team_fixed.\"\n",
    "\n",
    "df = team_features_all_enriched.copy()\n",
    "\n",
    "# Basic sanity: drop rows with missing target essentials\n",
    "df = df.dropna(subset=[\"PTS\", \"REB\", \"AST\", \"TOV\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Build candidate feature list:\n",
    "#   - rolling offense/defense\n",
    "#   - opponent rolling\n",
    "#   - matchup features\n",
    "#   - Elo\n",
    "#   - pace & rest\n",
    "#   - home & injuries\n",
    "# -------------------------------------------------------------------\n",
    "candidate_feats = []\n",
    "for c in df.columns:\n",
    "    if any(\n",
    "        tok in c\n",
    "        for tok in [\n",
    "            \"_roll5\",\n",
    "            \"_roll10\",\n",
    "            \"_allowed_roll5\",\n",
    "            \"_allowed_roll10\",\n",
    "            \"proj_pace\",\n",
    "            \"days_rest\",\n",
    "            \"is_b2b\",\n",
    "            \"is_rest_advantage\",\n",
    "            \"home\",\n",
    "            \"missing_usage_team\",\n",
    "            \"elo_pre\",\n",
    "            \"elo_diff_pre\",\n",
    "            \"opp_\",\n",
    "            \"matchup_\",\n",
    "        ]\n",
    "    ):\n",
    "        candidate_feats.append(c)\n",
    "\n",
    "# Remove true leakage: raw stats (non-rolled) and explicit labels\n",
    "leak_exact = {\"PTS\", \"REB\", \"AST\", \"TOV\", \"FGM\", \"FGA\"}\n",
    "leak_contains = [\"_raw\", \"WIN\", \"LOSS\", \"TARGET\", \"label\"]\n",
    "\n",
    "TEAM_FEATURES = [\n",
    "    c\n",
    "    for c in candidate_feats\n",
    "    if c not in leak_exact and not any(tok in c for tok in leak_contains)\n",
    "]\n",
    "\n",
    "TEAM_FEATURES = sorted(set(TEAM_FEATURES))\n",
    "\n",
    "print(f\"Using {len(TEAM_FEATURES)} team features\")\n",
    "print(TEAM_FEATURES[:50])\n",
    "\n",
    "X = df[TEAM_FEATURES].fillna(0.0)\n",
    "\n",
    "# Use season if present, fall back to game_id as grouping key for CV\n",
    "groups = df[\"season\"] if \"season\" in df.columns else df[\"game_id\"]\n",
    "\n",
    "n_groups = groups.nunique()\n",
    "n_splits = min(5, n_groups)\n",
    "\n",
    "if n_splits < 2:\n",
    "    print(f\"‚ö†Ô∏è Not enough groups for CV (only {n_groups}). Training models without cross-validation.\")\n",
    "    gkf = None\n",
    "else:\n",
    "    print(f\"Using GroupKFold with n_splits={n_splits} (groups={n_groups})\")\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Regression models for team stats\n",
    "# -------------------------------------------------------------------\n",
    "targets_reg = [\"PTS\", \"REB\", \"AST\", \"TOV\", \"FG2M\", \"FG3M\", \"FTM\"]\n",
    "models_team_reg = {}\n",
    "\n",
    "for tgt in targets_reg:\n",
    "    if tgt not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Skipping {tgt}: not found in dataframe.\")\n",
    "        continue\n",
    "\n",
    "    y = df[tgt]\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=700,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.02,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "\n",
    "    fold_mae = []\n",
    "    if gkf is not None:\n",
    "        for tr, te in gkf.split(X, y, groups):\n",
    "            model.fit(X.iloc[tr], y.iloc[tr])\n",
    "            pred = model.predict(X.iloc[te])\n",
    "            fold_mae.append(mean_absolute_error(y.iloc[te], pred))\n",
    "\n",
    "        print(f\"üìà {tgt} MAE: {np.mean(fold_mae):.3f} ¬± {np.std(fold_mae):.3f}\")\n",
    "    else:\n",
    "        print(f\"üìà {tgt}: no CV (not enough groups), training on full data.\")\n",
    "\n",
    "    model.fit(X, y)\n",
    "    models_team_reg[tgt] = model\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Win / loss model\n",
    "# -------------------------------------------------------------------\n",
    "if \"WIN\" in df.columns:\n",
    "    y_win = df[\"WIN\"].astype(int)\n",
    "elif \"opp_PTS_raw\" in df.columns:\n",
    "    y_win = (df[\"PTS\"] > df[\"opp_PTS_raw\"]).astype(int)\n",
    "else:\n",
    "    raise ValueError(\"Cannot build WIN label; add WIN or opp_PTS_raw to team_features_all_enriched.\")\n",
    "\n",
    "win_model = XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "\n",
    "fold_ll = []\n",
    "if gkf is not None:\n",
    "    for tr, te in gkf.split(X, y_win, groups):\n",
    "        win_model.fit(X.iloc[tr], y_win.iloc[tr])\n",
    "        p = win_model.predict_proba(X.iloc[te])[:, 1]\n",
    "        p = np.clip(p, 1e-4, 1 - 1e-4)\n",
    "        fold_ll.append(log_loss(y_win.iloc[te], p))\n",
    "\n",
    "    print(f\"üèÜ WIN model logloss: {np.mean(fold_ll):.4f} ¬± {np.std(fold_ll):.4f}\")\n",
    "else:\n",
    "    print(\"üèÜ WIN model: no CV (not enough groups), training on full data.\")\n",
    "\n",
    "win_model.fit(X, y_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 26: Build enriched today_team (schedule + features) ------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "assert \"today_games\" in globals(), \"today_games missing; build it from schedule.\"\n",
    "assert \"team_features_all_enriched\" in globals(), \"team_features_all_enriched missing; run Cell 36_team_fixed.\"\n",
    "\n",
    "# Use the latest available game before today for each team\n",
    "today_date = today_games[\"game_date\"].max()\n",
    "\n",
    "hist = team_features_all_enriched[team_features_all_enriched[\"game_date\"] < today_date].copy()\n",
    "hist = hist.sort_values([\"team\", \"game_date\"])\n",
    "\n",
    "team_latest = (\n",
    "    hist.groupby(\"team\")\n",
    "        .tail(1)\n",
    "        .drop_duplicates(\"team\", keep=\"last\")\n",
    ")\n",
    "\n",
    "print(\"team_latest shape:\", team_latest.shape)\n",
    "\n",
    "today_team = (\n",
    "    today_games.merge(team_latest, on=\"team\", how=\"left\", suffixes=(\"\", \"_feat\"))\n",
    ")\n",
    "\n",
    "# Standardize potential _x / _y columns from merges\n",
    "rename = {}\n",
    "for col in [\"game_id_x\", \"game_date_x\", \"opponent_x\"]:\n",
    "    if col in today_team.columns:\n",
    "        rename[col] = col.replace(\"_x\", \"\")\n",
    "today_team = today_team.rename(columns=rename)\n",
    "\n",
    "if today_team.isna().sum().sum() > 0:\n",
    "    print(\"‚ö†Ô∏è Some missing values in today_team ‚Äî filling with zeros.\")\n",
    "    today_team = today_team.fillna(0)\n",
    "\n",
    "print(\"‚úÖ today_team (enriched) built. Shape:\", today_team.shape)\n",
    "print(today_team.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac4ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 27: Predict today team props + improved Monte Carlo ------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "assert \"today_team\" in globals(), \"today_team missing; run Cell 38_team_fixed.\"\n",
    "assert \"models_team_reg\" in globals(), \"models_team_reg missing; run Cell 37_team_fixed.\"\n",
    "assert \"win_model\" in globals(), \"win_model missing; run Cell 37_team_fixed.\"\n",
    "assert \"TEAM_FEATURES\" in globals(), \"TEAM_FEATURES missing; run Cell 37_team_fixed.\"\n",
    "\n",
    "# Standardize column names in case of _x / _y from merges\n",
    "tt = today_team.rename(\n",
    "    columns={\n",
    "        \"game_id_x\": \"game_id\",\n",
    "        \"opponent_x\": \"opponent\",\n",
    "        \"game_date_x\": \"game_date\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Build feature matrix for today\n",
    "X_today = tt[TEAM_FEATURES].fillna(0.0)\n",
    "\n",
    "# Minimal frame with identifiers\n",
    "id_cols = [c for c in [\"game_id\", \"team\", \"opponent\", \"home\"] if c in tt.columns]\n",
    "df_team_today = tt[id_cols].copy()\n",
    "\n",
    "# Predict core team stats\n",
    "for tgt, model in models_team_reg.items():\n",
    "    df_team_today[f\"pred_{tgt}\"] = model.predict(X_today)\n",
    "\n",
    "# Simple injury-based adjustment: reduce scoring / assists if a lot of usage missing\n",
    "if \"missing_usage_team\" in tt.columns:\n",
    "    mu = tt[\"missing_usage_team\"].clip(0.0, 0.5)  # in [0, 0.5] after clipping\n",
    "    scale_pts = 1.0 - 0.3 * mu                     # up to -15% PTS if half usage missing\n",
    "    scale_ast = 1.0 - 0.2 * mu                     # up to -10% AST\n",
    "\n",
    "    if \"pred_PTS\" in df_team_today.columns:\n",
    "        df_team_today[\"pred_PTS\"] = df_team_today[\"pred_PTS\"] * scale_pts.values\n",
    "    if \"pred_AST\" in df_team_today.columns:\n",
    "        df_team_today[\"pred_AST\"] = df_team_today[\"pred_AST\"] * scale_ast.values\n",
    "\n",
    "# --- Win probabilities from classifier (use the model's own feature list) ---\n",
    "booster = win_model.get_booster()\n",
    "clf_features = booster.feature_names\n",
    "\n",
    "missing = [f for f in clf_features if f not in tt.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Today's data is missing classifier features: {missing}\")\n",
    "\n",
    "X_today_clf = tt[clf_features].fillna(0.0)\n",
    "\n",
    "win_probs = win_model.predict_proba(X_today_clf)[:, 1]\n",
    "df_team_today[\"win_prob\"] = win_probs\n",
    "\n",
    "print(\"‚úÖ Today team predictions (enriched):\")\n",
    "print(df_team_today.to_string(index=False))\n",
    "\n",
    "# --- Monte Carlo simulation of game scores / totals / margins -------------\n",
    "def simulate_games(df_today: pd.DataFrame, n_sims: int = 5000, stat: str = \"PTS\") -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for gid, g in df_today.groupby(\"game_id\"):\n",
    "        g = g.sort_values(\"home\", ascending=False).reset_index(drop=True)\n",
    "        if len(g) != 2:\n",
    "            print(f\"Skipping {gid}: expected 2 teams, found {len(g)}\")\n",
    "            continue\n",
    "\n",
    "        home = g.iloc[0]\n",
    "        away = g.iloc[1]\n",
    "\n",
    "        mean_H = home.get(f\"pred_{stat}\", np.nan)\n",
    "        mean_A = away.get(f\"pred_{stat}\", np.nan)\n",
    "\n",
    "        if np.isnan(mean_H) or np.isnan(mean_A):\n",
    "            print(f\"Skipping {gid}: missing pred_{stat} for one of the teams.\")\n",
    "            continue\n",
    "\n",
    "        # Simple residual model; can be calibrated from training residuals\n",
    "        resid_std = 12.0\n",
    "        sims_H = np.random.normal(mean_H, resid_std, size=n_sims)\n",
    "        sims_A = np.random.normal(mean_A, resid_std, size=n_sims)\n",
    "\n",
    "        total = sims_H + sims_A\n",
    "        margin = sims_H - sims_A\n",
    "        win_H = (margin > 0).mean()\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"game_id\": gid,\n",
    "                \"team_home\": home[\"team\"],\n",
    "                \"team_away\": away[\"team\"],\n",
    "                \"sim_home_win_prob\": win_H,\n",
    "                \"sim_avg_home_pts\": float(sims_H.mean()),\n",
    "                \"sim_avg_away_pts\": float(sims_A.mean()),\n",
    "                \"sim_avg_total\": float(total.mean()),\n",
    "                \"sim_avg_margin\": float(margin.mean()),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_sim_games = simulate_games(df_team_today, n_sims=5000, stat=\"PTS\")\n",
    "\n",
    "print(\"\\nüé≤ Simulation summary (enriched):\")\n",
    "print(df_sim_games.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af236da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 28: Aggregate player projections to team level (robust) ----------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "assert \"df_projections_all\" in globals(), \"Run Cell 15 first.\"\n",
    "assert \"minutes_today_clean\" in globals(), \"Run Cell 14c first.\"\n",
    "assert \"today_games_clean\" in globals(), \"today_games_clean missing.\"\n",
    "\n",
    "# 1) Keep only players on teams in today's slate\n",
    "slate_teams = set(minutes_today_clean[\"team\"].unique())\n",
    "proj = df_projections_all[df_projections_all[\"team\"].isin(slate_teams)].copy()\n",
    "\n",
    "# 2) Force correct opponent from today_games_clean\n",
    "proj = proj.drop(columns=[\"opponent\"], errors=\"ignore\")\n",
    "\n",
    "opp_map = (\n",
    "    today_games_clean\n",
    "    .assign(team=lambda d: d[\"team\"].astype(str).str.upper().str.strip())\n",
    "    .set_index(\"team\")[\"opponent\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "proj[\"opponent\"] = proj[\"team\"].map(opp_map)\n",
    "\n",
    "# 3) Build team-level player sums\n",
    "team_player_agg = (\n",
    "    proj.pivot_table(\n",
    "        index=[\"team\", \"opponent\"],\n",
    "        columns=\"market\",\n",
    "        values=\"projection_mean\",\n",
    "        aggfunc=\"sum\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "team_player_agg.columns.name = None\n",
    "\n",
    "print(\"‚úÖ team_player_agg built from player projections:\")\n",
    "print(team_player_agg.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29005e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cell 29: Blend team model and player-aggregate projections (robust) ----\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "assert \"df_team_today\" in globals(), \"Run 39_team_fixed first (team model).\"\n",
    "assert \"team_player_agg\" in globals(), \"Run Cell X2 first.\"\n",
    "assert \"df_projections_all\" in globals(), \"Run Cell 15 first.\"\n",
    "\n",
    "keys = [\"team\", \"opponent\"]\n",
    "\n",
    "# 1) Join team model predictions with player sums\n",
    "blend = df_team_today.merge(\n",
    "    team_player_agg,\n",
    "    on=keys,\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_playersum\")\n",
    ")\n",
    "\n",
    "# Fill missing player sums with 0 (shouldn't happen if everything is aligned)\n",
    "for stat in [\"PTS\", \"REB\", \"AST\"]:\n",
    "    col_sum = f\"{stat}_playersum\"\n",
    "    if col_sum in blend.columns:\n",
    "        blend[col_sum] = blend[col_sum].fillna(0.0)\n",
    "\n",
    "# 2) Compute scale factors: team_model / player_sum (clamped)\n",
    "scales = {}\n",
    "for stat in [\"PTS\", \"REB\", \"AST\"]:\n",
    "    if stat not in blend.columns:\n",
    "        continue\n",
    "    col_sum = f\"{stat}_playersum\"\n",
    "    if col_sum not in blend.columns:\n",
    "        continue\n",
    "\n",
    "    team_pred = blend[stat].values\n",
    "    player_sum = blend[col_sum].values\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        raw_scale = np.where(player_sum > 1e-6, team_pred / player_sum, 1.0)\n",
    "\n",
    "    scale = np.clip(raw_scale, 0.8, 1.2)\n",
    "    scales[stat] = scale\n",
    "    blend[f\"{stat}_scale\"] = scale\n",
    "\n",
    "print(\"\\nüîç Blend preview:\")\n",
    "cols = [c for c in [\n",
    "    \"team\",\"opponent\",\n",
    "    \"PTS\",\"PTS_playersum\",\"PTS_scale\",\n",
    "    \"REB\",\"REB_playersum\",\"REB_scale\",\n",
    "    \"AST\",\"AST_playersum\",\"AST_scale\"\n",
    "] if c in blend.columns]\n",
    "print(blend[cols].head().to_string(index=False))\n",
    "\n",
    "# 3) Apply scales back to player projections\n",
    "df_blended = df_projections_all.copy()\n",
    "\n",
    "for stat in [\"PTS\", \"REB\", \"AST\"]:\n",
    "    if stat not in scales:\n",
    "        continue\n",
    "\n",
    "    scale_map = (\n",
    "        blend[keys + [f\"{stat}_scale\"]]\n",
    "        .drop_duplicates(keys)\n",
    "        .set_index(keys)[f\"{stat}_scale\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    mask = df_blended[\"market\"] == stat\n",
    "    df_blended.loc[mask, \"projection_mean\"] = df_blended[mask].apply(\n",
    "        lambda r: r[\"projection_mean\"] * scale_map.get((r[\"team\"], r[\"opponent\"]), 1.0),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "df_projections_final = df_blended.copy()\n",
    "\n",
    "print(\"\\nüéØ Final blended player projections (first 30 rows):\")\n",
    "print(df_projections_final.head(30).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46bead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
